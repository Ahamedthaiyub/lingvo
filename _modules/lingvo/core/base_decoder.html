<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>lingvo.core.base_decoder &mdash; Lingvo  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> Lingvo
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../lingvo.html">lingvo package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Lingvo</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>lingvo.core.base_decoder</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for lingvo.core.base_decoder</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;Common decoder interface.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">collections</span>

<span class="kn">import</span> <span class="nn">lingvo.compat</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">base_layer</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">beam_search_helper</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">py_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">target_sequence_sampler</span>

<span class="c1"># metrics: Dict[Text, Tuple[float, float]] A dict of named metrics, which must</span>
<span class="c1">#   include &#39;loss&#39;. The value of the dict is (metric_val, count), where</span>
<span class="c1">#   metric_val is the sum of the metric over all examples, and count is the</span>
<span class="c1">#   number of examples seen. The mean value of the metric is metric_val/count.</span>
<span class="c1">#   This is the first output of ComputeLoss.</span>
<span class="c1"># predictions: Union[Tensor, Dict[Text, Tensor], NestedMap] This is the output</span>
<span class="c1">#   of ComputePredictions.</span>
<span class="c1"># per_sequence: Dict[Text, Tensor] This is the second output of ComputeLoss.</span>
<span class="n">DecoderOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s1">&#39;DecoderOutput&#39;</span><span class="p">,</span>
    <span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">,</span> <span class="s1">&#39;predictions&#39;</span><span class="p">,</span> <span class="s1">&#39;per_sequence&#39;</span><span class="p">],</span>
<span class="p">)</span>


<div class="viewcode-block" id="BaseDecoder"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseDecoder">[docs]</a><span class="k">class</span> <span class="nc">BaseDecoder</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Base class for all decoders.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseDecoder.Params"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseDecoder.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;packed_input&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;If True, decoder and all layers support &#39;</span>
        <span class="s1">&#39;multiple examples in a single sequence.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="BaseDecoder.UpdateTargetVocabSize"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseDecoder.UpdateTargetVocabSize">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">UpdateTargetVocabSize</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">wpm_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the vocab size and wpm model in the params.</span>

<span class="sd">    Args:</span>
<span class="sd">      p: model params.</span>
<span class="sd">      vocab_size: size of the vocabulary.</span>
<span class="sd">      wpm_model: file name prefix pointing to a wordpiece model.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Model target vocabulary params updated with the vocab size and wpm model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseDecoder.FProp"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseDecoder.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decodes `targets` given encoded source.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      targets: A NestedMap containing additional inputs to the decoder,</span>
<span class="sd">        such as the targets being predicted.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A DecoderOutput namedtuple.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ComputePredictions</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
    <span class="n">metrics</span><span class="p">,</span> <span class="n">per_sequence</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ComputeLoss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">DecoderOutput</span><span class="p">(</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">per_sequence</span><span class="o">=</span><span class="n">per_sequence</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseDecoder.ComputePredictions"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseDecoder.ComputePredictions">[docs]</a>  <span class="k">def</span> <span class="nf">ComputePredictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span></div>

<div class="viewcode-block" id="BaseDecoder.ComputeLoss"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseDecoder.ComputeLoss">[docs]</a>  <span class="k">def</span> <span class="nf">ComputeLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span></div></div>


<span class="c1"># A finite value used to represent a negative infinity log-probability.</span>
<span class="n">LARGE_NEGATIVE_NUMBER</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1e9</span>


<div class="viewcode-block" id="_KeepTopP"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder._KeepTopP">[docs]</a><span class="k">def</span> <span class="nf">_KeepTopP</span><span class="p">(</span><span class="n">sorted_log_probs</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Keeps the top-p probability mass of `sorted_log_probs`.</span>

<span class="sd">  For each row, elements that are not included in the first `p` probability mass</span>
<span class="sd">  are set to `LARGE_NEGATIVE_NUMBER`. The first element is always kept as-is.</span>

<span class="sd">  Args:</span>
<span class="sd">    sorted_log_probs: A float tensor of shape [batch, k] that represents</span>
<span class="sd">      log-probabilities sorted in descending order. The probabilities do not</span>
<span class="sd">      need to sum to 1.</span>
<span class="sd">    p: A float tensor of shape [batch] that represents a probability threshold</span>
<span class="sd">      for each batch item.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tensor like `sorted_log_probs` where elements outside the top-p</span>
<span class="sd">    probability mass are set to `LARGE_NEGATIVE_NUMBER`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">sorted_cum_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">sorted_log_probs</span><span class="p">),</span> <span class="n">exclusive</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">sorted_cum_probs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
  <span class="c1"># Set mask[:, 0] = True to always keep the first element.</span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">true</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">true</span><span class="p">,</span> <span class="n">mask</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">filtered_sorted_log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
      <span class="n">mask</span><span class="p">,</span> <span class="n">sorted_log_probs</span><span class="p">,</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">sorted_log_probs</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">LARGE_NEGATIVE_NUMBER</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">sorted_log_probs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)))</span>
  <span class="k">return</span> <span class="n">filtered_sorted_log_probs</span></div>


<div class="viewcode-block" id="_BatchScatter"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder._BatchScatter">[docs]</a><span class="k">def</span> <span class="nf">_BatchScatter</span><span class="p">(</span><span class="n">default_tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Performs tf.tensor_scatter_nd_update for each batch item.</span>

<span class="sd">  Args:</span>
<span class="sd">    default_tensor: A float tensor of shape [batch, vocab] that contains the</span>
<span class="sd">      default values.</span>
<span class="sd">    indices: An int tensor of shape [batch, k] that represents the k indices of</span>
<span class="sd">      `default_tensor` to update.</span>
<span class="sd">    values: A float tensor of shape [batch, k] that represents the value to</span>
<span class="sd">      replace with for each corresponding element of `indices`.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tensor like `default_tensor` where the (i, indices[i][j]) element has been</span>
<span class="sd">    replaced with values[i][j].</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">default_tensor</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="c1"># Prepend batch indices to `indices`.</span>
  <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">indices</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">batch_indices</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">batch_indices</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span>
  <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">batch_indices</span><span class="p">,</span> <span class="n">indices</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">tensor_scatter_nd_update</span><span class="p">(</span><span class="n">default_tensor</span><span class="p">,</span> <span class="n">batch_indices</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span></div>


<div class="viewcode-block" id="_BatchLookup"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder._BatchLookup">[docs]</a><span class="k">def</span> <span class="nf">_BatchLookup</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">table_keys</span><span class="p">,</span> <span class="n">table_values</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Looks up `keys` in a given key-value table.</span>

<span class="sd">  Args:</span>
<span class="sd">    keys: An int tensor of shape [batch, 1] that represents keys to look up.</span>
<span class="sd">    table_keys: An int tensor of shape [batch, k] that represents table keys.</span>
<span class="sd">    table_values: A float tensor of shape [batch, k] that represents table</span>
<span class="sd">      values.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A float tensor of shape [batch, 1] that holds values from `table_values`</span>
<span class="sd">    whose corresponding elements of `table_keys` match `keys`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">match_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="n">table_keys</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span>
          <span class="n">table_values</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">match_indices</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">batch_dims</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
      <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="_BatchSampleGumbel"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder._BatchSampleGumbel">[docs]</a><span class="k">def</span> <span class="nf">_BatchSampleGumbel</span><span class="p">(</span><span class="n">batch_seed</span><span class="p">,</span> <span class="n">time_step</span><span class="p">,</span> <span class="n">src_ids</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span>
                       <span class="n">dtype</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Samples (standard) Gumbel noises of a given shape for each batch item.</span>

<span class="sd">  The random seed for the i-th batch item is determined by batch_seed[i],</span>
<span class="sd">  time_step, and the sum of non-padding elements of src_ids[i].</span>

<span class="sd">  Args:</span>
<span class="sd">    batch_seed: An int tensor of shape [batch] that holds a seed for each batch</span>
<span class="sd">      item.</span>
<span class="sd">    time_step: An int tensor used as a secondary seed.</span>
<span class="sd">    src_ids: An int tensor of shape [batch, src_seq] that represents source IDs.</span>
<span class="sd">      Used for turning the random seed into a function of source IDs.</span>
<span class="sd">    src_paddings: A 0/1 float tensor of shape [batch, src_seq] where 1 means</span>
<span class="sd">      that the corresponding element of src_ids is a padding.</span>
<span class="sd">    shape: A shape of the Gumbel noises to sample.</span>
<span class="sd">    dtype: A type of the Gumbel noises.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `dtype` tensor of shape [batch, ...] that holds Gumbel noises.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Turn batch_seed into a function of the source IDs by adding the sum of the</span>
  <span class="c1"># source IDs. Without doing this, the same pattern of random noises would be</span>
  <span class="c1"># used no matter what the source sequence is, resulting in a systematic bias</span>
  <span class="c1"># among the output for a given seed value.</span>
  <span class="c1"># Mask padding IDs by 0.</span>
  <span class="n">src_ids</span> <span class="o">=</span> <span class="n">src_ids</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">src_ids</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="c1"># Compute the sum of source IDs.</span>
  <span class="n">src_ids_sum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">src_ids</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># shape: [src_batch]</span>
  <span class="n">batch_seed_plus_src_ids_sum</span> <span class="o">=</span> <span class="n">batch_seed</span> <span class="o">+</span> <span class="n">src_ids_sum</span>

  <span class="k">def</span> <span class="nf">SampleForBeam</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">stateless_uniform</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">seed</span><span class="p">,</span> <span class="n">time_step</span><span class="p">]))))</span>

  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">map_fn</span><span class="p">(</span><span class="n">SampleForBeam</span><span class="p">,</span> <span class="n">batch_seed_plus_src_ids_sum</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span></div>


<div class="viewcode-block" id="_SampleGumbelWithMax"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder._SampleGumbelWithMax">[docs]</a><span class="k">def</span> <span class="nf">_SampleGumbelWithMax</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">target_max</span><span class="p">,</span> <span class="n">batch_seed</span><span class="p">,</span> <span class="n">time_step</span><span class="p">,</span> <span class="n">src_ids</span><span class="p">,</span>
                         <span class="n">src_paddings</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Samples a set of Gumbel noises with a specified maximum value.</span>

<span class="sd">  A set of values are sampled from Gumbel distributions with location parameters</span>
<span class="sd">  `phi` under the condition that their maximum is equal to `target_max`.</span>

<span class="sd">  The numerical stable implementation from Appendix B.3 of</span>
<span class="sd">  https://arxiv.org/pdf/1903.06059.pdf is used.</span>

<span class="sd">  Args:</span>
<span class="sd">    phi: A float tensor of shape [tgt_batch, k] thtat represents location</span>
<span class="sd">      parameters of Gumbel distributions.</span>
<span class="sd">    target_max: A float tensor of shape [tgt_batch, 1] that represents the</span>
<span class="sd">      target max values.</span>
<span class="sd">    batch_seed: An int tensor of shape [src_batch] that holds a seed value for</span>
<span class="sd">      each batch item. src_batch must be equal to tgt_batch / num_hyps_per_beam.</span>
<span class="sd">      The same seed is used within each consecutive num_hyps_per_beam items</span>
<span class="sd">      along the tgt_batch axis.</span>
<span class="sd">    time_step: A float tensor used as a secondary seed.</span>
<span class="sd">    src_ids: An int tensor of shape [src_batch, src_seq] that represents source</span>
<span class="sd">      IDs. Used for turning the random seed into a function of source IDs.</span>
<span class="sd">    src_paddings: A 0/1 float tensor of shape [src_batch, src_seq] where 1 means</span>
<span class="sd">      that the corresponding element of src_ids is a padding.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A float tensor like `phi` where their maximum values along the second axis</span>
<span class="sd">    is (almost) equal to `target_max`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">dtype</span>
  <span class="n">tgt_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">phi</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">phi</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">src_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">batch_seed</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">num_hyps_per_beam</span> <span class="o">=</span> <span class="n">tgt_batch</span> <span class="o">//</span> <span class="n">src_batch</span>

  <span class="c1"># Sample noises from Gumbel distributions with location parameters `phi`.</span>
  <span class="c1"># shape: [src_batch, num_hyps_per_beam, k]</span>
  <span class="n">gumbel_noises</span> <span class="o">=</span> <span class="n">_BatchSampleGumbel</span><span class="p">(</span><span class="n">batch_seed</span><span class="p">,</span> <span class="n">time_step</span><span class="p">,</span> <span class="n">src_ids</span><span class="p">,</span>
                                     <span class="n">src_paddings</span><span class="p">,</span> <span class="p">[</span><span class="n">num_hyps_per_beam</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span>
                                     <span class="n">dtype</span><span class="p">)</span>
  <span class="c1"># shape: [num_hyps_per_beam, src_batch, k]</span>
  <span class="n">gumbel_noises</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">gumbel_noises</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
  <span class="c1"># shape: [tgt_batch, k]</span>
  <span class="n">gumbel_noises</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">gumbel_noises</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">phi</span><span class="p">))</span>
  <span class="c1"># shape: [tgt_batch, k]</span>
  <span class="n">g_phi</span> <span class="o">=</span> <span class="n">phi</span> <span class="o">+</span> <span class="n">gumbel_noises</span>

  <span class="c1"># shape: [tgt_batch, 1]</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">g_phi</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="c1"># Equation (23).</span>
  <span class="c1"># shape: [tgt_batch, k]</span>
  <span class="n">v</span> <span class="o">=</span> <span class="n">target_max</span> <span class="o">-</span> <span class="n">g_phi</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span>
      <span class="c1"># Without taking max, sometimes the result of log1p would become NaN on</span>
      <span class="c1"># TPU.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">g_phi</span> <span class="o">-</span> <span class="n">z</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)))</span>

  <span class="c1"># Equation (24).</span>
  <span class="k">return</span> <span class="n">target_max</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">v</span><span class="p">)))</span></div>


<div class="viewcode-block" id="BaseBeamSearchDecoder"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder">[docs]</a><span class="k">class</span> <span class="nc">BaseBeamSearchDecoder</span><span class="p">(</span><span class="n">BaseDecoder</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Decoder that does beam search.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseBeamSearchDecoder.Params"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;target_sos_id&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Id of the target sequence sos symbol.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;target_eos_id&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;Id of the target sequence eos symbol.&#39;</span><span class="p">)</span>
    <span class="c1"># TODO(rpang): remove target_seq_len and use beam_search.target_seq_len</span>
    <span class="c1"># instead.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;target_seq_len&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Target seq length.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;beam_search&#39;</span><span class="p">,</span> <span class="n">beam_search_helper</span><span class="o">.</span><span class="n">BeamSearchHelper</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;BeamSearchHelper params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;greedy_search&#39;</span><span class="p">,</span> <span class="n">beam_search_helper</span><span class="o">.</span><span class="n">GreedySearchHelper</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;GreedySearchHelper params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;target_sequence_sampler&#39;</span><span class="p">,</span>
             <span class="n">target_sequence_sampler</span><span class="o">.</span><span class="n">TargetSequenceSampler</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;TargetSequenceSampler params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;bias_only_if_consistent&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;BeamSearchBiased bias is only&#39;</span>
        <span class="s1">&#39;applied if the hypothesis has been consistent with targets so far.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;stochastic_beam_search_top_k&#39;</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span>
        <span class="s1">&#39;As a performance optimization, the stochastic beam search &#39;</span>
        <span class="s1">&#39;implementation first performs top-k filtering of the &#39;</span>
        <span class="s1">&#39;log-probabilities so that only k values need to be maintained for &#39;</span>
        <span class="s1">&#39;each hypothesis.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder.UpdateTargetVocabSize"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder.UpdateTargetVocabSize">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">UpdateTargetVocabSize</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">wpm_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the vocab size and wpm model in the params.</span>

<span class="sd">    Args:</span>
<span class="sd">      p: model params.</span>
<span class="sd">      vocab_size: size of the vocabulary.</span>
<span class="sd">      wpm_model: file name prefix pointing to a wordpiece model.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Model target vocabulary params updated with the vocab size and wpm model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="p">,</span> <span class="s1">&#39;target_seq_len&#39;</span><span class="p">):</span>
      <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">target_seq_len</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="p">,</span> <span class="s1">&#39;target_sos_id&#39;</span><span class="p">):</span>
      <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">target_sos_id</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_sos_id</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="p">,</span> <span class="s1">&#39;target_eos_id&#39;</span><span class="p">):</span>
      <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">target_eos_id</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_eos_id</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;beam_search&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">greedy_search</span><span class="o">.</span><span class="n">target_seq_len</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span>
    <span class="n">p</span><span class="o">.</span><span class="n">greedy_search</span><span class="o">.</span><span class="n">target_sos_id</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_sos_id</span>
    <span class="n">p</span><span class="o">.</span><span class="n">greedy_search</span><span class="o">.</span><span class="n">target_eos_id</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_eos_id</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;greedy_search&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">greedy_search</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">target_sequence_sampler</span><span class="o">.</span><span class="n">target_seq_len</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span>
    <span class="n">p</span><span class="o">.</span><span class="n">target_sequence_sampler</span><span class="o">.</span><span class="n">target_sos_id</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_sos_id</span>
    <span class="n">p</span><span class="o">.</span><span class="n">target_sequence_sampler</span><span class="o">.</span><span class="n">target_eos_id</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_eos_id</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;target_sequence_sampler&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">target_sequence_sampler</span><span class="p">)</span>

<div class="viewcode-block" id="BaseBeamSearchDecoder.AddExtraDecodingInfo"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder.AddExtraDecodingInfo">[docs]</a>  <span class="k">def</span> <span class="nf">AddExtraDecodingInfo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds extra decoding information to encoded_outputs.</span>

<span class="sd">    Args:</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      targets: a NestedMap containing target input fields.</span>

<span class="sd">    Returns:</span>
<span class="sd">      encoder_ouputs with extra information used for decoding.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">encoder_outputs</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder.BeamSearchDecode"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder.BeamSearchDecode">[docs]</a>  <span class="k">def</span> <span class="nf">BeamSearchDecode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">num_hyps_per_beam_override</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Performs beam search based decoding.</span>

<span class="sd">    Args:</span>
<span class="sd">      encoder_outputs: the outputs of the encoder.</span>
<span class="sd">      num_hyps_per_beam_override: If set to a value &lt;= 0, this parameter is</span>
<span class="sd">        ignored. If set to a value &gt; 0, then this value will be used to override</span>
<span class="sd">        p.num_hyps_per_beam.</span>

<span class="sd">    Returns:</span>
<span class="sd">      `.BeamSearchDecodeOutput`, A namedtuple whose elements are tensors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">BeamSearchDecodeWithTheta</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
                                          <span class="n">num_hyps_per_beam_override</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder.BeamSearchDecodeWithTheta"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder.BeamSearchDecodeWithTheta">[docs]</a>  <span class="k">def</span> <span class="nf">BeamSearchDecodeWithTheta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                <span class="n">theta</span><span class="p">,</span>
                                <span class="n">encoder_outputs</span><span class="p">,</span>
                                <span class="n">num_hyps_per_beam_override</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">BeamSearchDecode</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
                                             <span class="n">num_hyps_per_beam_override</span><span class="p">,</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">_InitBeamSearchStateCallback</span><span class="p">,</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">_PreBeamSearchStepCallback</span><span class="p">,</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">_PostBeamSearchStepCallback</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder.GreedySearchDecode"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder.GreedySearchDecode">[docs]</a>  <span class="k">def</span> <span class="nf">GreedySearchDecode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Performs beam search based decoding.</span>

<span class="sd">    Args:</span>
<span class="sd">      encoder_outputs: the outputs of the encoder.</span>

<span class="sd">    Returns:</span>
<span class="sd">      greedy search decode output.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">GreedySearchDecodeWithTheta</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder.GreedySearchDecodeWithTheta"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder.GreedySearchDecodeWithTheta">[docs]</a>  <span class="k">def</span> <span class="nf">GreedySearchDecodeWithTheta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy_search</span><span class="o">.</span><span class="n">GreedySearchDecode</span><span class="p">(</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_InitBeamSearchStateCallback</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_PreBeamSearchStepCallback</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_PostBeamSearchStepCallback</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder._PostprocessSample"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder._PostprocessSample">[docs]</a>  <span class="k">def</span> <span class="nf">_PostprocessSample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">,</span> <span class="n">is_tpu</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Add topk_hyps, topk_ids, topk_lens, topk_scores tensors to `sample`.</span>

<span class="sd">    These features are required by `.BeamSearchDecodeOutput`.</span>

<span class="sd">    Args:</span>
<span class="sd">      sample: a NestedMap with `id`, `paddings`, and `logits` fields.</span>
<span class="sd">      is_tpu: whether inference is being run on TPU.</span>

<span class="sd">    Returns:</span>
<span class="sd">      sample with additional feature that matches `.BeamSearchDecodeOutput`</span>
<span class="sd">      requirements. `topk_hyps` is empty.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">bs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">num_hyps_per_beam</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_sequence_sampler</span><span class="o">.</span><span class="n">num_hyps_per_beam</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">logits</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span>

    <span class="c1"># tf.string is not supported on tpu.</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_hyps</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">bs</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span> <span class="k">if</span> <span class="n">is_tpu</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">)</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_hyps</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">topk_hyps</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="p">])</span>

    <span class="n">sample</span><span class="o">.</span><span class="n">topk_ids</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">ids</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">sample</span><span class="o">.</span><span class="n">paddings</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_lens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="c1"># Computing the hypothesis scores based on the returned ids</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
        <span class="n">sample</span><span class="o">.</span><span class="n">topk_ids</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">sample</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">token_log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ijk,ijk-&gt;ij&#39;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">logits</span><span class="p">),</span>
                                <span class="n">mask</span><span class="p">)</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_scores</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">token_log_probs</span> <span class="o">*</span> <span class="n">weights</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># At this point batch dimension is (batch_size*num_hyps_per_beam),</span>
    <span class="c1"># interleaved as [num_hyps_per_beam, batch_size].</span>
    <span class="c1"># This does not match the order expected by beam search post-processing.</span>
    <span class="c1"># Must transpose to [batch_size, num_hyps_per_beam] and flatten back.</span>
    <span class="n">max_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">topk_ids</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">topk_ids</span><span class="p">,</span>
                                 <span class="p">[</span><span class="n">num_hyps_per_beam</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="p">])</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">topk_ids</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">topk_ids</span><span class="p">,</span> <span class="p">[</span><span class="n">bs</span><span class="p">,</span> <span class="n">max_len</span><span class="p">])</span>

    <span class="c1"># The same for topk_lens and topk_scores</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_lens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">topk_lens</span><span class="p">,</span> <span class="p">[</span><span class="n">num_hyps_per_beam</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_lens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">topk_lens</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_lens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">topk_lens</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">sample</span><span class="o">.</span><span class="n">topk_scores</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">topk_scores</span><span class="p">,</span> <span class="p">[</span><span class="n">num_hyps_per_beam</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_scores</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">topk_scores</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_scores</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">topk_scores</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">sample</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder.SampleTargetSequences"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder.SampleTargetSequences">[docs]</a>  <span class="k">def</span> <span class="nf">SampleTargetSequences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">random_seed</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Performs target sequence sampling.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A NestedMap object containing weights&#39; values of this layer and its</span>
<span class="sd">        children layers.</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      random_seed: a scalar int32 tensor representing the random seed.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A NestedMap containing the following tensors</span>

<span class="sd">      - &#39;ids&#39;: [batch, max_target_length] of int32, representing the target</span>
<span class="sd">        sequence ids, not including target_sos_id, but maybe ending with</span>
<span class="sd">        target_eos_id if target_eos_id is sampled.</span>
<span class="sd">      - &#39;paddings&#39;: [batch, max_target_length] of 0/1, where 1 represents</span>
<span class="sd">        a padded timestep.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_sequence_sampler</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">random_seed</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_InitBeamSearchStateCallback</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_PreBeamSearchStepCallback</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PostBeamSearchStepCallback</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder.BeamSearchDecodeBiased"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder.BeamSearchDecodeBiased">[docs]</a>  <span class="k">def</span> <span class="nf">BeamSearchDecodeBiased</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                             <span class="n">encoder_outputs</span><span class="p">,</span>
                             <span class="n">num_hyps_per_beam_override</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Performs beam-search decoding while biasing towards provided targets.</span>

<span class="sd">    Args:</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder. Must include `targets`,</span>
<span class="sd">        which is used to bias beam search.</span>
<span class="sd">      num_hyps_per_beam_override: If set to a value &lt;= 0, this parameter is</span>
<span class="sd">        ignored. If set to a value &gt; 0, then this value will be used to override</span>
<span class="sd">        `p.num_hyps_per_beam`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      BeamSearchDecodeOutput, a namedtuple containing the decode results.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">StochasticBeamSearchDecodeBiased</span><span class="p">(</span>
        <span class="n">encoder_outputs</span><span class="p">,</span>
        <span class="n">biased</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">stochastic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">num_hyps_per_beam_override</span><span class="o">=</span><span class="n">num_hyps_per_beam_override</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder.StochasticBeamSearchDecodeBiased"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder.StochasticBeamSearchDecodeBiased">[docs]</a>  <span class="k">def</span> <span class="nf">StochasticBeamSearchDecodeBiased</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                       <span class="n">encoder_outputs</span><span class="p">,</span>
                                       <span class="n">biased</span><span class="p">,</span>
                                       <span class="n">stochastic</span><span class="p">,</span>
                                       <span class="n">num_hyps_per_beam_override</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Performs beam search based decoding with optional advanced features.</span>

<span class="sd">    If `biased` is true, the target biasing feature is added. `encoder_outputs`</span>
<span class="sd">    must include the following auxiliary inputs:</span>

<span class="sd">    - targets.labels: An int tensor of shape [batch, seq] that represents target</span>
<span class="sd">      labels to bias beam search towards.</span>
<span class="sd">    - targets.paddings: A 0/1 float tensor of shape [batch, seq] where 1 means</span>
<span class="sd">      that the corresponding element of targets.labels is a padding.</span>
<span class="sd">    - targets.weights: A float tensor of shape [batch, seq] that represents</span>
<span class="sd">      biasing weights. 1.0 means forced-decoding.</span>

<span class="sd">    If `stochastic` is true, the stochastic beam search feature</span>
<span class="sd">    (https://arxiv.org/pdf/1903.06059.pdf) is added. Also, top-p filtering (i.e.</span>
<span class="sd">    sampling only from the top-p probability mass of the token distribution) is</span>
<span class="sd">    performed to ensure the quality of samples. Note that there are slight</span>
<span class="sd">    differences from the implementation in the original paper, e.g., length</span>
<span class="sd">    normalization and coverage penalty are applied to the perturbed</span>
<span class="sd">    probabilities. `encoder_outputs` must include the following auxiliary</span>
<span class="sd">    inputs:</span>

<span class="sd">    - stochastic_beam_search.top_p_threshold: A float tensor of shape [batch]</span>
<span class="sd">      that represents the thresholds of top-p filtering. Must satisfy</span>
<span class="sd">      0 &lt; top_p_threshold &lt;= 1. If the value is low, the quality of samples will</span>
<span class="sd">      be high but the diversity will be low. If the value is high, the quality</span>
<span class="sd">      of samples will be low but the diversity will be high. Stochastic beam</span>
<span class="sd">      search is performed only if top_p_threshold &gt; 0 for some batch items.</span>
<span class="sd">    - stochastic_beam_search.seed: An int tensor of shape [batch] the represents</span>
<span class="sd">      the random seeds. If the seeds are the same, the same samples are drawn.</span>
<span class="sd">    - stochastic_beam_search.src_ids: An int tensor of shape [batch, src_seq]</span>
<span class="sd">      that represents source IDs. Used for turning the random seed into a</span>
<span class="sd">      function of source IDs.</span>
<span class="sd">    - stochastic_beam_search.src_paddings: A 0/1 float tensor of shape [batch,</span>
<span class="sd">      src_seq] where 1 means that the corresponding element of</span>
<span class="sd">      stochastic_beam_search.src_ids is a padding.</span>

<span class="sd">    Args:</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      biased: If true, add the target decoding feature.</span>
<span class="sd">      stochastic: If true, add the stochastic beam search feature.</span>
<span class="sd">      num_hyps_per_beam_override: If set to a value &lt;= 0, this parameter is</span>
<span class="sd">        ignored. If set to a value &gt; 0, then this value will be used to override</span>
<span class="sd">        `p.num_hyps_per_beam`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      BeamSearchDecodeOutput, a namedtuple containing the decode results.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">if</span> <span class="n">biased</span><span class="p">:</span>
      <span class="n">targets</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">targets</span>
      <span class="n">targets</span><span class="o">.</span><span class="n">weights</span> <span class="o">*=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">PadToTargetSeqLen</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">constant</span><span class="p">):</span>
        <span class="n">length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tensor</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">pad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">target_seq_len</span> <span class="o">-</span> <span class="n">length</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad</span><span class="p">]],</span> <span class="n">constant_values</span><span class="o">=</span><span class="n">constant</span><span class="p">)</span>

      <span class="n">targets</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">PadToTargetSeqLen</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">targets</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">PadToTargetSeqLen</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">stochastic</span><span class="p">:</span>
      <span class="c1"># Determine whether to perform stochastic beam search.</span>
      <span class="n">stochastic_beam_search</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">stochastic_beam_search</span>
      <span class="n">stochastic_beam_search</span><span class="o">.</span><span class="n">enable</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">stochastic_beam_search</span><span class="o">.</span><span class="n">top_p_threshold</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">))</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">BeamSearchDecode</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">num_hyps_per_beam_override</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_WrapInitBeamSearchStateCallback</span><span class="p">(</span><span class="n">biased</span><span class="p">,</span> <span class="n">stochastic</span><span class="p">),</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_WrapPreBeamSearchStepCallback</span><span class="p">(</span><span class="n">biased</span><span class="p">,</span> <span class="n">stochastic</span><span class="p">),</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_WrapPostBeamSearchStepCallback</span><span class="p">(</span><span class="n">stochastic</span><span class="p">))</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder._WrapInitBeamSearchStateCallback"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder._WrapInitBeamSearchStateCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_WrapInitBeamSearchStateCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">biased</span><span class="p">,</span> <span class="n">stochastic</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a new callback that wraps self._InitBeamSearchStateCallback.</span>

<span class="sd">    Used by the implementation of StochasticBeamSearchDecodeBiased().</span>

<span class="sd">    If `biased` is True, attaches the following field to the states:</span>

<span class="sd">    - consistent: A boolean tensor of shape [tgt_batch, 1] which tracks whether</span>
<span class="sd">      each hypothesis has exactly matched encoder_outputs.targets so far.</span>

<span class="sd">    If `stochastic_beam_search` is True, attaches the following fields to the</span>
<span class="sd">    states:</span>

<span class="sd">    - cumulative_log_probs: A float tensor of shape [tgt_batch, k] that</span>
<span class="sd">      represents the cumulative (unperturbed) log-probabilities.</span>
<span class="sd">    - perturbed_cumulative_log_probs: A float tensor of shape [tgt_batch, k]</span>
<span class="sd">      that represents the perturbed counterpart of `cumulative_log_probs`.</span>
<span class="sd">      Initialized with 0 (see the footnote 2 of the original paper), which</span>
<span class="sd">      ensures that perturbed_cumulative_log_probs is always non-positive, which</span>
<span class="sd">      is desirable since it gets divided by the length normalization at the end</span>
<span class="sd">      of the beam search.</span>
<span class="sd">    - tmp_states: A NestedMap that holds internal info passed from</span>
<span class="sd">      PreBeamSearchStepCallback to PostBeamSearchStepCallback.</span>

<span class="sd">    It is assumed that the wrapped callback provides states.time_step which is</span>
<span class="sd">    scalar indicating current step (=0 for initial state) of decoder.</span>

<span class="sd">    Args:</span>
<span class="sd">      biased: If true, add the target decoding feature.</span>
<span class="sd">      stochastic: If true, add the stochastic beam search feature.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A new function that has the same interface as</span>
<span class="sd">      self._InitBeamSearchStateCallback.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">stochastic_beam_search_top_k</span>

    <span class="k">def</span> <span class="nf">Callback</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="p">):</span>
      <span class="n">initial_results</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_InitBeamSearchStateCallback</span><span class="p">(</span>
          <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="p">)</span>
      <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="s1">&#39;time_step&#39;</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>  <span class="c1"># Required for multisource models.</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">1</span><span class="p">]</span>
      <span class="n">num_hyps</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_hyps_per_beam</span>

      <span class="k">if</span> <span class="n">biased</span><span class="p">:</span>
        <span class="c1"># states.consistent is initially all True</span>
        <span class="n">states</span><span class="o">.</span><span class="n">consistent</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span>
            <span class="n">num_hyps</span><span class="p">,</span>
        <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">stochastic</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
        <span class="n">states</span><span class="o">.</span><span class="n">cumulative_log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">states</span><span class="o">.</span><span class="n">perturbed_cumulative_log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                                                         <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="c1"># Temporary tensors that store information passed from</span>
        <span class="c1"># PreBeamSearchStepCallback to PostBeamSearchStepCallback. These are</span>
        <span class="c1"># used for updating states.cumulative_log_probs and</span>
        <span class="c1"># states.perturbed_cumulative_log_probs for the next step, which</span>
        <span class="c1"># requires the knowledge of the chosen IDs, which only becomes available</span>
        <span class="c1"># after PreBeamSearchStepCallback.</span>
        <span class="n">states</span><span class="o">.</span><span class="n">tmp_states</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
            <span class="c1"># Top-k (non-perturbed) log-probs. Used for updating</span>
            <span class="c1"># `cumulative_log_probs` in PostBeamSearchStepCallback.</span>
            <span class="n">top_k_log_probs</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
            <span class="c1"># Vocab ID of each item of `top_k_log_probs`.</span>
            <span class="n">top_k_ids</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
            <span class="c1"># Perturbed cumulative log-probs of the top-k IDs. Used for updating</span>
            <span class="c1"># `perturbed_cumulative_log_probs` in PostBeamSearchStepCallback.</span>
            <span class="n">new_perturbed_cumulative_log_probs</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span>
                                                        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">),</span>
        <span class="p">)</span>

      <span class="k">return</span> <span class="n">initial_results</span><span class="p">,</span> <span class="n">states</span>

    <span class="k">return</span> <span class="n">Callback</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder._WrapPreBeamSearchStepCallback"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder._WrapPreBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_WrapPreBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">biased</span><span class="p">,</span> <span class="n">stochastic</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a new callback that wraps self._PreBeamSearchStepCallback.</span>

<span class="sd">    Used by the implementation of StochasticBeamSearchDecodeBiased().</span>

<span class="sd">    Modifies results.log_probs as follows:</span>

<span class="sd">    1. If `biased` is True, biases results.log_probs towards provided</span>
<span class="sd">       encoder_outputs.targets.</span>
<span class="sd">    2. If `stochastic_beam_search` is True, perturbs results.log_probs by Gumbel</span>
<span class="sd">       noises.</span>

<span class="sd">    It is assumed that the wrapped callback maintains states.time_step which is</span>
<span class="sd">    scalar indicating current step (=0 for initial state) of decoder.</span>

<span class="sd">    Args:</span>
<span class="sd">      biased: If true, add the target decoding feature.</span>
<span class="sd">      stochastic: If true, add the stochastic beam search feature.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A new function that has the same interface as</span>
<span class="sd">      self._PreBeamSearchStepCallback.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">stochastic_beam_search_top_k</span>

    <span class="k">def</span> <span class="nf">Callback</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">step_ids</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="p">,</span>
                 <span class="n">cur_step</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
      <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
      <span class="n">time_step</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">time_step</span>
      <span class="n">bs_results</span><span class="p">,</span> <span class="n">out_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PreBeamSearchStepCallback</span><span class="p">(</span>
          <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">step_ids</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="p">,</span> <span class="n">cur_step</span><span class="p">,</span>
          <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">TileForBeamAndFlatten</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># [1, src_batch]</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="p">[</span><span class="n">num_hyps_per_beam</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># [num_hyps_per_beam, src_batch]</span>
        <span class="n">tgt_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">step_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># num_hyps_per_beam*src_batch</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="p">[</span><span class="n">tgt_batch</span><span class="p">])</span>

      <span class="k">if</span> <span class="n">biased</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">labels</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">weights</span>

        <span class="k">def</span> <span class="nf">ApplyBias</span><span class="p">():</span>
          <span class="sd">&quot;&quot;&quot;Bias and update log_probs and consistent.&quot;&quot;&quot;</span>

          <span class="c1"># Consistent if step_ids == labels from previous step</span>
          <span class="c1"># TODO(navari): Consider updating consistent only if weights &gt; 0. Then</span>
          <span class="c1"># re-evaluate the need for bias_only_if_consistent=True.</span>
          <span class="c1"># Note that prev_label is incorrrect for step 0 but is overridden</span>
          <span class="c1"># later</span>
          <span class="n">prev_label</span> <span class="o">=</span> <span class="n">TileForBeamAndFlatten</span><span class="p">(</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">time_step</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
          <span class="n">is_step0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">time_step</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
          <span class="n">local_consistence</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span>
              <span class="n">is_step0</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">prev_label</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">step_ids</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
          <span class="n">consistent</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">consistent</span><span class="p">,</span> <span class="n">local_consistence</span><span class="p">)</span>

          <span class="c1"># get label, weight slices corresponding to current time_step</span>
          <span class="n">label</span> <span class="o">=</span> <span class="n">TileForBeamAndFlatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">time_step</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
          <span class="n">weight</span> <span class="o">=</span> <span class="n">TileForBeamAndFlatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">time_step</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
          <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">bias_only_if_consistent</span><span class="p">:</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">consistent</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>

          <span class="c1"># convert from dense label to sparse label probs</span>
          <span class="n">vocab_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">bs_results</span><span class="o">.</span><span class="n">log_probs</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
          <span class="n">label_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
              <span class="n">label</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span>
              <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>  <span class="c1"># [tgt_batch, vocab_size]</span>
          <span class="n">pred_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">bs_results</span><span class="o">.</span><span class="n">log_probs</span><span class="p">)</span>

          <span class="c1"># interpolate predicted probs and label probs</span>
          <span class="n">weight</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
          <span class="n">probs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">([</span>
              <span class="n">py_utils</span><span class="o">.</span><span class="n">assert_less_equal</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span>
              <span class="n">py_utils</span><span class="o">.</span><span class="n">assert_greater_equal</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
          <span class="p">],</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">pred_probs</span> <span class="o">+</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">label_probs</span><span class="p">)</span>
          <span class="c1"># Ensure that tf.math.log is applied to positive values.</span>
          <span class="n">probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">probs</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
          <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">),</span> <span class="n">consistent</span>

        <span class="k">def</span> <span class="nf">NoApplyBias</span><span class="p">():</span>
          <span class="sd">&quot;&quot;&quot;No-op. Return original log_probs and consistent.&quot;&quot;&quot;</span>
          <span class="k">return</span> <span class="n">bs_results</span><span class="o">.</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">states</span><span class="o">.</span><span class="n">consistent</span>

        <span class="n">log_probs</span><span class="p">,</span> <span class="n">consistent</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)),</span> <span class="n">NoApplyBias</span><span class="p">,</span> <span class="n">ApplyBias</span><span class="p">)</span>
        <span class="n">bs_results</span><span class="o">.</span><span class="n">log_probs</span> <span class="o">=</span> <span class="n">log_probs</span>
        <span class="n">out_states</span><span class="o">.</span><span class="n">consistent</span> <span class="o">=</span> <span class="n">consistent</span>

      <span class="k">if</span> <span class="n">stochastic</span><span class="p">:</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">bs_results</span><span class="o">.</span><span class="n">log_probs</span>

        <span class="k">def</span> <span class="nf">PerturbedLogProbs</span><span class="p">():</span>
          <span class="c1"># STEP 1: Perform top-k filtering. This is done as a performance</span>
          <span class="c1"># optimization of avoiding sorting the entire `log_probs`, which is</span>
          <span class="c1"># prohibitively slow.</span>
          <span class="n">top_k</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="nb">sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
          <span class="c1"># shape: [tgt_batch, k]</span>
          <span class="n">top_k_log_probs</span> <span class="o">=</span> <span class="n">top_k</span><span class="o">.</span><span class="n">values</span>
          <span class="c1"># shape: [tgt_batch, k]</span>
          <span class="n">top_k_ids</span> <span class="o">=</span> <span class="n">top_k</span><span class="o">.</span><span class="n">indices</span>

          <span class="c1"># STEP 2: Perform top-p filtering.</span>
          <span class="c1"># shape: [tgt_batch]</span>
          <span class="n">top_p_threshold</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">stochastic_beam_search</span><span class="o">.</span><span class="n">top_p_threshold</span>
          <span class="n">top_p_threshold</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">top_p_threshold</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
          <span class="n">top_p_threshold</span> <span class="o">=</span> <span class="n">TileForBeamAndFlatten</span><span class="p">(</span><span class="n">top_p_threshold</span><span class="p">)</span>
          <span class="c1"># shape: [tgt_batch, k]</span>
          <span class="n">filtered_top_k_log_probs</span> <span class="o">=</span> <span class="n">_KeepTopP</span><span class="p">(</span><span class="n">top_k_log_probs</span><span class="p">,</span> <span class="n">top_p_threshold</span><span class="p">)</span>

          <span class="c1"># STEP 3: Perturb cumulative log-probs.</span>
          <span class="c1"># shape: [tgt_batch, 1]</span>
          <span class="n">last_cumulative_log_probs</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">cumulative_log_probs</span>
          <span class="c1"># shape: [tgt_batch, 1]</span>
          <span class="n">last_perturbed_cumulative_log_probs</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">perturbed_cumulative_log_probs</span>
          <span class="c1"># Compute cumulative log-probs of the current step.</span>
          <span class="c1"># shape: [tgt_batch, k]</span>
          <span class="n">cumulative_log_probs</span> <span class="o">=</span> <span class="p">(</span>
              <span class="n">last_cumulative_log_probs</span> <span class="o">+</span> <span class="n">filtered_top_k_log_probs</span><span class="p">)</span>
          <span class="c1"># Perturb cumulative log-probs by Gumbel noises under the condition</span>
          <span class="c1"># that the max of the new perturbed log-probs is equal to</span>
          <span class="c1"># perturbed_cumulative_log_probs of the previous step.</span>
          <span class="c1"># shape: [tgt_batch, k]</span>
          <span class="n">new_perturbed_cumulative_log_probs</span> <span class="o">=</span> <span class="n">_SampleGumbelWithMax</span><span class="p">(</span>
              <span class="n">cumulative_log_probs</span><span class="p">,</span> <span class="n">last_perturbed_cumulative_log_probs</span><span class="p">,</span>
              <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">stochastic_beam_search</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span> <span class="n">time_step</span><span class="p">,</span>
              <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">stochastic_beam_search</span><span class="o">.</span><span class="n">src_ids</span><span class="p">,</span>
              <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">stochastic_beam_search</span><span class="o">.</span><span class="n">src_paddings</span><span class="p">)</span>

          <span class="c1"># STEP 4: Compute updated log_probs. This step is necessary because</span>
          <span class="c1"># the output of PreBeamSearchStepCallback must be &quot;per-step&quot;</span>
          <span class="c1"># log-probs, whereas so far &quot;cumulative&quot; log-probs have been computed.</span>
          <span class="c1"># shape: [tgt_batch, k]</span>
          <span class="n">updated_top_k_log_probs</span> <span class="o">=</span> <span class="p">(</span>
              <span class="n">new_perturbed_cumulative_log_probs</span> <span class="o">-</span>
              <span class="n">last_perturbed_cumulative_log_probs</span><span class="p">)</span>
          <span class="c1"># Convert to the shape [tgt_batch, vocab_size].</span>
          <span class="n">updated_log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">log_probs</span><span class="p">),</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">LARGE_NEGATIVE_NUMBER</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">log_probs</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
          <span class="n">updated_log_probs</span> <span class="o">=</span> <span class="n">_BatchScatter</span><span class="p">(</span><span class="n">updated_log_probs</span><span class="p">,</span> <span class="n">top_k_ids</span><span class="p">,</span>
                                            <span class="n">updated_top_k_log_probs</span><span class="p">)</span>

          <span class="k">return</span> <span class="p">(</span>
              <span class="n">updated_log_probs</span><span class="p">,</span>
              <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
                  <span class="n">new_perturbed_cumulative_log_probs</span><span class="o">=</span><span class="n">new_perturbed_cumulative_log_probs</span><span class="p">,</span>
                  <span class="n">top_k_log_probs</span><span class="o">=</span><span class="n">top_k_log_probs</span><span class="p">,</span>
                  <span class="n">top_k_ids</span><span class="o">=</span><span class="n">top_k_ids</span><span class="p">,</span>
              <span class="p">))</span>

        <span class="p">(</span><span class="n">bs_results</span><span class="o">.</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">out_states</span><span class="o">.</span><span class="n">tmp_states</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
            <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">stochastic_beam_search</span><span class="o">.</span><span class="n">enable</span><span class="p">,</span>
            <span class="n">PerturbedLogProbs</span><span class="p">,</span>
            <span class="c1"># No-op.</span>
            <span class="k">lambda</span><span class="p">:</span> <span class="p">(</span><span class="n">bs_results</span><span class="o">.</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">states</span><span class="o">.</span><span class="n">tmp_states</span><span class="p">))</span>
        <span class="c1"># These states are not updated here but will be updated in</span>
        <span class="c1"># PostBeamSearchStepCallback since doing so requires the knowledge of</span>
        <span class="c1"># the next step IDs.</span>
        <span class="n">out_states</span><span class="o">.</span><span class="n">cumulative_log_probs</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">cumulative_log_probs</span>
        <span class="n">out_states</span><span class="o">.</span><span class="n">perturbed_cumulative_log_probs</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">perturbed_cumulative_log_probs</span>

      <span class="k">return</span> <span class="n">bs_results</span><span class="p">,</span> <span class="n">out_states</span>

    <span class="k">return</span> <span class="n">Callback</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder._WrapPostBeamSearchStepCallback"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder._WrapPostBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_WrapPostBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stochastic</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a new callback that wraps self._PostBeamSearchStateCallback.</span>

<span class="sd">    Used by the implementation of StochasticBeamSearchDecodeBiased().</span>

<span class="sd">    Args:</span>
<span class="sd">      stochastic: If true, add the stochastic beam search feature.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A new function that has the same interface as</span>
<span class="sd">      self._PostBeamSearchStepCallback.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">Callback</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">new_step_ids</span><span class="p">,</span> <span class="n">other_states</span><span class="p">):</span>
      <span class="n">final_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PostBeamSearchStepCallback</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
                                                      <span class="n">new_step_ids</span><span class="p">,</span>
                                                      <span class="n">other_states</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">stochastic</span><span class="p">:</span>
        <span class="c1"># Update perturbed_cumulative_log_probs and cumulative_log_probs if</span>
        <span class="c1"># stochastic beam search is requested.</span>

        <span class="n">perturbed_cumulative_log_probs</span> <span class="o">=</span> <span class="n">other_states</span><span class="o">.</span><span class="n">perturbed_cumulative_log_probs</span>
        <span class="n">cumulative_log_probs</span> <span class="o">=</span> <span class="n">other_states</span><span class="o">.</span><span class="n">cumulative_log_probs</span>
        <span class="n">tmp_states</span> <span class="o">=</span> <span class="n">other_states</span><span class="o">.</span><span class="n">tmp_states</span>

        <span class="k">def</span> <span class="nf">UpdateCumulativeScores</span><span class="p">():</span>
          <span class="n">new_perturbed_cumulative_log_probs</span> <span class="o">=</span> <span class="n">_BatchLookup</span><span class="p">(</span>
              <span class="n">new_step_ids</span><span class="p">,</span> <span class="n">tmp_states</span><span class="o">.</span><span class="n">top_k_ids</span><span class="p">,</span>
              <span class="n">tmp_states</span><span class="o">.</span><span class="n">new_perturbed_cumulative_log_probs</span><span class="p">)</span>
          <span class="n">new_log_probs</span> <span class="o">=</span> <span class="n">_BatchLookup</span><span class="p">(</span><span class="n">new_step_ids</span><span class="p">,</span> <span class="n">tmp_states</span><span class="o">.</span><span class="n">top_k_ids</span><span class="p">,</span>
                                       <span class="n">tmp_states</span><span class="o">.</span><span class="n">top_k_log_probs</span><span class="p">)</span>
          <span class="n">new_cumulative_log_probs</span> <span class="o">=</span> <span class="n">cumulative_log_probs</span> <span class="o">+</span> <span class="n">new_log_probs</span>
          <span class="k">return</span> <span class="n">new_perturbed_cumulative_log_probs</span><span class="p">,</span> <span class="n">new_cumulative_log_probs</span>

        <span class="p">(</span><span class="n">final_states</span><span class="o">.</span><span class="n">perturbed_cumulative_log_probs</span><span class="p">,</span>
         <span class="n">final_states</span><span class="o">.</span><span class="n">cumulative_log_probs</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
             <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">stochastic_beam_search</span><span class="o">.</span><span class="n">enable</span><span class="p">,</span>
             <span class="n">UpdateCumulativeScores</span><span class="p">,</span>
             <span class="c1"># No-op.</span>
             <span class="k">lambda</span><span class="p">:</span> <span class="p">(</span><span class="n">perturbed_cumulative_log_probs</span><span class="p">,</span> <span class="n">cumulative_log_probs</span><span class="p">))</span>

      <span class="k">return</span> <span class="n">final_states</span>

    <span class="k">return</span> <span class="n">Callback</span></div>

<div class="viewcode-block" id="BaseBeamSearchDecoder.InferenceAdditionalEncoder"><a class="viewcode-back" href="../../../lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder.InferenceAdditionalEncoder">[docs]</a>  <span class="k">def</span> <span class="nf">InferenceAdditionalEncoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feeds</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate an inference graph for the additional encoder.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(),</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>