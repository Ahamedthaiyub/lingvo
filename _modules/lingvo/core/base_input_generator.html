

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>lingvo.core.base_input_generator &mdash; Lingvo  documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> Lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../lingvo.html">lingvo package</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>lingvo.core.base_input_generator</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for lingvo.core.base_input_generator</h1><div class="highlight"><pre>
<span></span><span class="c1"># Lint as: python3</span>
<span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;Input generators.</span>

<span class="sd">There are three types of batch sizes:</span>

<span class="sd">* Device split batch size: Defined by Params() and is the batch size</span>
<span class="sd">  on each device/TPU core. BaseInputGenerator.params.batch_size and</span>
<span class="sd">  BaseSequenceInputGenerator.params.bucket_batch_limit specify per-split batch</span>
<span class="sd">  size.</span>

<span class="sd">* GlobalBatchSize: number of examples in a global batch.</span>

<span class="sd">* InfeedBatchSize: global_batch_size // num_infeed_hosts, where</span>
<span class="sd">  num_infeed_hosts is cluster.num_tpu_hosts if using per-host infeed with TPU,</span>
<span class="sd">  otherwise num_infeed_hosts is 1.</span>

<span class="sd">TODO(rpang): Deal with on packed_inputs.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">inspect</span>

<span class="kn">import</span> <span class="nn">lingvo.compat</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">base_layer</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">batch_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">cluster</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">cluster_factory</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">datasource</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">hyperparams</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">input_generator_helper</span> <span class="k">as</span> <span class="n">ig_helper</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">inspect_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">py_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">tokenizers</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">tpu_embedding_layers</span>

<span class="c1"># pylint: disable=g-direct-tensorflow-import</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="kn">import</span> <span class="n">io_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.tpu</span> <span class="kn">import</span> <span class="n">tpu_embedding</span> <span class="k">as</span> <span class="n">tpu_embedding_lib</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.tpu</span> <span class="kn">import</span> <span class="n">tpu_feed</span>
<span class="c1"># pylint: enable=g-direct-tensorflow-import</span>

<span class="n">DEFAULT_TOKENIZER_KEY</span> <span class="o">=</span> <span class="s1">&#39;default&#39;</span>
<span class="n">INPUT_DATA_STATS_SUMMARIES_COLLECTION</span> <span class="o">=</span> <span class="s1">&#39;INPUT_DATA_STATS_SUMMARIES&#39;</span>


<div class="viewcode-block" id="BaseInputGenerator"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator">[docs]</a><span class="k">class</span> <span class="nc">BaseInputGenerator</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;The abstract base input generator.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseInputGenerator.DefineInfeedParams"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.DefineInfeedParams">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">DefineInfeedParams</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="c1"># TPU related infeed tuning.</span>
    <span class="c1"># Supported use cases:</span>
    <span class="c1">#</span>
    <span class="c1"># Data parallelism (num_partitions=None)</span>
    <span class="c1">#  - single host (use_per_host_infeed=False, tpu_infeed_parallelism=1))</span>
    <span class="c1">#  - multi host (use_per_host_infeed=False, tpu_infeed_parallelism&gt;1)</span>
    <span class="c1">#  - per host (use_per_host_infeed=True)</span>
    <span class="c1">#    - unsharded inputs (_InputBatch returns a single NestedMap)</span>
    <span class="c1">#    - sharded inputs (_InputBatch returns a list containing</span>
    <span class="c1">#      tpu_number_of_shards NestedMaps)</span>
    <span class="c1"># Model parallelism (num_partitions&gt;1 where)</span>
    <span class="c1">#  - non-partitioned infeed (use_partitioned_infeed_queue=False):</span>
    <span class="c1">#    - Only first partition gets infeed (e.g. manual partition)</span>
    <span class="c1">#      - single host (use_per_host_infeed=False)</span>
    <span class="c1">#      - per host (use_per_host_infeed=True)</span>
    <span class="c1">#    - All partitions gets data parallel infeed (e.g. MoE)</span>
    <span class="c1">#      - single host not supported</span>
    <span class="c1">#      - per host (use_per_host_infeed=True, use_per_core_infeed=True)</span>
    <span class="c1">#        num_partitions should be set to number of partitions per replica</span>
    <span class="c1">#  - partitioned infeed (use_partitioned_infeed_queue=True)</span>
    <span class="c1">#    - single host (use_per_host_infeed=False)</span>
    <span class="c1">#    - per host (use_per_host_infeed=True)</span>
    <span class="c1">#        num_partitions should be set to number of partitions per replica</span>
    <span class="c1">#        and all partitions should exist on a single host</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;use_per_host_infeed&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;Whether run infeed op on each host.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;use_per_core_infeed&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;Whether to shard the infeed per TPU core instead of per replica&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;tpu_infeed_parallelism&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">&#39;Uses these many python threads to drive infeed concurrently.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;use_partitioned_infeed_queue&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Use partitioned infeed&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;num_partitions&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;Number of partitions to split the model graph into. Used with &#39;</span>
        <span class="s1">&#39;model parallelism. When &gt;1, it specifies the number of devices &#39;</span>
        <span class="s1">&#39;used to place one replica of the model graph nodes.&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseInputGenerator.Params"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Defaults params for input generators.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;input&#39;</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;file_datasource&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;The DataSource that produces input batches for this input generator.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Batch size for a device split. This will be &#39;</span>
        <span class="s1">&#39;scaled to match the accelarator hardware topology.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;num_samples&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s1">&#39;If non-zero, the dataset contains these many samples. &#39;</span>
        <span class="s1">&#39;For test/eval dataset, if we want the test/evel job evaluate &#39;</span>
        <span class="s1">&#39;the whole dataset, this param must be set precisely. Otherwise, &#39;</span>
        <span class="s1">&#39;this param is optional.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;resettable&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;If True, the input generator must implement Reset().&#39;</span><span class="p">)</span>
    <span class="c1"># For an input generator to support samples_per_summary == 0 to indicate</span>
    <span class="c1"># using the entire dataset, it must (1) be resettable, and (2) throws</span>
    <span class="c1"># tf.errors.OutOfRangeError when reading a batch beyond an epoch.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;eval_samples_per_summary&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;If not None, overrides &#39;</span>
        <span class="s1">&#39;task_p.eval.samples_per_summary directly. Allowed to be 0, which &#39;</span>
        <span class="s1">&#39;means to use the entire dataset.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;decoder_samples_per_summary&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;If not None, overrides &#39;</span>
        <span class="s1">&#39;task_p.eval.decoder_samples_per_summary directly. Allowed to be 0, &#39;</span>
        <span class="s1">&#39;which means to use the entire dataset.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;filter_sparse_tensors&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;If true, filter out SparseTensors in input_batch before enqueuing &#39;</span>
        <span class="s1">&#39;onto TPU.&#39;</span><span class="p">)</span>
    <span class="bp">cls</span><span class="o">.</span><span class="n">DefineInfeedParams</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;remote&#39;</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Params to configure remote input policy.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">remote</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;max_inflights_per_target&#39;</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="s1">&#39;The maximum number of &#39;</span>
        <span class="s1">&#39;concurrent inflight remote input fetches per remote target.&#39;</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;input_stats_summary_interval_steps&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s1">&#39;Number of steps in between logging of TF scalar summaries for &#39;</span>
        <span class="s1">&#39;training related input data stats.&#39;</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;skip_tpu_embedding_enqueue_ops&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;Whether to skip CreateTpuEmbeddingEnqueueOps. This is useful for &#39;</span>
        <span class="s1">&#39;multi-program training with one tasking having tpu embedding and &#39;</span>
        <span class="s1">&#39;the other not.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="c1"># parameter to tell the bprop one hot for all the files.</span>
    <span class="c1"># TODO(ankurbpn): Initialize when using sources from mixed record yielders.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_bprop_onehot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># Each entry is a regular expression specifying the set of variables</span>
    <span class="c1"># to bprop per data source.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_bprop_variable_filters</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">]</span>
    <span class="c1"># For TPU enqueue ops, we do not use graph collections, instead, we rely</span>
    <span class="c1"># on this member variable. This is especially useful for</span>
    <span class="c1"># executor-driven multiple programs, as we need more fine-grained</span>
    <span class="c1"># access to drive the infeed for a specific program, rather than</span>
    <span class="c1"># a single global collection across the graph.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_infeed_op</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># A list of InfeedQueues.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_queues</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Set to true in GetPreprocessedInputBatch() (and thus _InputBatch())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_processed_input_batch</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Merged TF scalar summaries for training related input data stats.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_merged_input_data_summary_op</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Tensorboard layout for charts displaying input data stats.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_input_data_summary_layout</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">CreateDatasource</span><span class="p">()</span>

<div class="viewcode-block" id="BaseInputGenerator.CreateDatasource"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.CreateDatasource">[docs]</a>  <span class="k">def</span> <span class="nf">CreateDatasource</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">file_datasource</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;datasource&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">file_datasource</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">datasource</span><span class="o">.</span><span class="n">SetInputGenerator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseInputGenerator.CommonInputOpArgs"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.CommonInputOpArgs">[docs]</a>  <span class="k">def</span> <span class="nf">CommonInputOpArgs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Common input params.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{}</span></div>

<div class="viewcode-block" id="BaseInputGenerator.GetBpropVariableFilters"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.GetBpropVariableFilters">[docs]</a>  <span class="k">def</span> <span class="nf">GetBpropVariableFilters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bprop_variable_filters</span></div>

<div class="viewcode-block" id="BaseInputGenerator.GetInputSourceOneHot"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.GetInputSourceOneHot">[docs]</a>  <span class="k">def</span> <span class="nf">GetInputSourceOneHot</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get the current bprop type of the input generator batch.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bprop_onehot</span></div>

<div class="viewcode-block" id="BaseInputGenerator.GlobalBatchSize"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.GlobalBatchSize">[docs]</a>  <span class="k">def</span> <span class="nf">GlobalBatchSize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the total batch size (for stats), int or dynamic int tensor.&quot;&quot;&quot;</span>
    <span class="c1"># Uses `InfeedBatchSize()` instead of calculating it from `p.batch_size`</span>
    <span class="c1"># because the behavior would be overridden by subclasses.</span>
    <span class="n">global_batch_size</span> <span class="o">=</span> <span class="n">batch_utils</span><span class="o">.</span><span class="n">scale_infeed_to_global</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">InfeedBatchSize</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">use_per_host_infeed</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;GlobalBatchSize </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">global_batch_size</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">global_batch_size</span></div>

<div class="viewcode-block" id="BaseInputGenerator.InfeedBatchSize"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.InfeedBatchSize">[docs]</a>  <span class="k">def</span> <span class="nf">InfeedBatchSize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the batch size of the input batch: int or dynamic int tensor.&quot;&quot;&quot;</span>
    <span class="n">batch_per_input</span> <span class="o">=</span> <span class="n">batch_utils</span><span class="o">.</span><span class="n">scale_split_to_infeed</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">use_per_host_infeed</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;batch_per_input: </span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">batch_per_input</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch_per_input</span></div>

<div class="viewcode-block" id="BaseInputGenerator.Initialize"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.Initialize">[docs]</a>  <span class="k">def</span> <span class="nf">Initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initialize using a session.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;datasource&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">datasource</span><span class="o">.</span><span class="n">Initialize</span><span class="p">(</span><span class="n">sess</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseInputGenerator._InputBatch"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator._InputBatch">[docs]</a>  <span class="k">def</span> <span class="nf">_InputBatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The current input batch, not preprocessed.</span>

<span class="sd">    This is meant to be overridden by subclasses, but not called directly.</span>
<span class="sd">    Callers should use `GetPreprocessedInputBatch()`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A NestedMap (or list of NestedMaps when using TPU sharded infeed) of</span>
<span class="sd">      input tensors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseInputGenerator._PreprocessInputBatch"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator._PreprocessInputBatch">[docs]</a>  <span class="k">def</span> <span class="nf">_PreprocessInputBatch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Preprocesses input batch from _InputBatch.</span>

<span class="sd">    Args:</span>
<span class="sd">      batch: A NestedMap (or list of NestedMaps when using TPU sharded infeed)</span>
<span class="sd">        containing input tensors in the format returned by _InputBatch.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A NestedMap containing preprocessed inputs to feed to the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">batch</span></div>

<div class="viewcode-block" id="BaseInputGenerator.GetPreprocessedInputBatch"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.GetPreprocessedInputBatch">[docs]</a>  <span class="k">def</span> <span class="nf">GetPreprocessedInputBatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns preprocessed batch of inputs.</span>

<span class="sd">    These are the actual inputs fed to the model.</span>

<span class="sd">    Subclasses generally should not override this function directly. Instead,</span>
<span class="sd">    override _InputBatch and maybe _PreprocessInputBatch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_processed_input_batch</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="c1"># TODO(b/139345706): Use self.datasource.GetNext() for all datasource.</span>
    <span class="k">if</span> <span class="p">(</span><span class="s1">&#39;datasource&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span> <span class="ow">and</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">datasource</span><span class="p">,</span> <span class="n">datasource</span><span class="o">.</span><span class="n">TFDatasetSource</span><span class="p">)):</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">input_targets</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;TFDatasetSource subclassed DataSources do not support using &#39;</span>
            <span class="s1">&#39;train_input_replica. Try tf_data_service_replicas instead.&#39;</span><span class="p">)</span>
      <span class="c1"># pylint: disable=protected-access</span>
      <span class="k">if</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_InputBatch</span><span class="o">.</span><span class="vm">__func__</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">BaseInputGenerator</span><span class="o">.</span><span class="n">_InputBatch</span> <span class="ow">and</span>
           <span class="bp">self</span><span class="o">.</span><span class="n">_InputBatch</span><span class="o">.</span><span class="vm">__func__</span>
           <span class="ow">is</span> <span class="ow">not</span> <span class="n">BaseInputGeneratorFromFiles</span><span class="o">.</span><span class="n">_InputBatch</span><span class="p">)</span> <span class="ow">or</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_PreprocessInputBatch</span><span class="o">.</span><span class="vm">__func__</span>
          <span class="ow">is</span> <span class="ow">not</span> <span class="n">BaseInputGenerator</span><span class="o">.</span><span class="n">_PreprocessInputBatch</span><span class="p">):</span>
        <span class="c1"># pylint: enable=protected-access</span>
        <span class="c1"># If you hit this error trying to run with --tf_data_service_replicas,</span>
        <span class="c1"># try to refactor your input generator by moving all the code inside</span>
        <span class="c1"># _InputBatch and _PreprocessInputBatch to _DataSourceFromFilePattern.</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;Batches obtained through p.file_datasource do not go through &#39;</span>
            <span class="s1">&#39;self._InputBatch() or self._PreprocessInputBatch(). To reduce the &#39;</span>
            <span class="s1">&#39;potential of mistakes, this error is raised when either of those &#39;</span>
            <span class="s1">&#39;functions have been overridden.&#39;</span><span class="p">)</span>
      <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasource</span><span class="o">.</span><span class="n">GetNext</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PreprocessInputBatch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_InputBatch</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_processed_input_batch</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetUnitTestSession</span><span class="p">():</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">Initialize</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetUnitTestSession</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">batch</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">tpu_number_of_shards</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Number of shards to split the input batch into.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">num_tpu_hosts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_tpu_hosts</span>
    <span class="n">num_infeed_hosts</span> <span class="o">=</span> <span class="n">num_tpu_hosts</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="n">shards</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">total_worker_devices</span> <span class="o">//</span> <span class="n">num_infeed_hosts</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_partitioned_infeed_queue</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_core_infeed</span><span class="p">:</span>
      <span class="n">shards</span> <span class="o">=</span> <span class="n">shards</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_devices_per_split</span>
    <span class="k">return</span> <span class="n">shards</span>

<div class="viewcode-block" id="BaseInputGenerator.CreateTpuEnqueueOps"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.CreateTpuEnqueueOps">[docs]</a>  <span class="k">def</span> <span class="nf">CreateTpuEnqueueOps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">job_name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create the host-side enqueue ops.</span>

<span class="sd">    This should be called in an outer non-TPU context.</span>
<span class="sd">    Args:</span>
<span class="sd">      job_name: the name of the job on which the enqueue operations run.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_queues</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;CreateTpuEnqueueOps should only be called &#39;</span>
                                  <span class="s1">&#39;once.&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_queues</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_per_host_batches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_per_host_emb_batches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># A list of lists, where the [i][j] element is the j-th passthrought batch</span>
    <span class="c1"># of the i-th task. Each task will have more than one passthrought batch iff</span>
    <span class="c1"># sharded infeed is used.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_per_host_passthrough_batches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">num_tpu_hosts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_tpu_hosts</span>
    <span class="n">num_cores_per_host</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">total_worker_devices</span> <span class="o">//</span> <span class="n">num_tpu_hosts</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="s1">&#39;CreateTpuEnqueueOps num_splits_per_client=</span><span class="si">{}</span><span class="s1"> &#39;</span>
        <span class="s1">&#39;num_devices_per_split=</span><span class="si">{}</span><span class="s1"> num_tpu_hosts=</span><span class="si">{}</span><span class="s1"> use_per_host_infeed=</span><span class="si">{}</span><span class="s1">&#39;</span>
        <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_splits_per_client</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_devices_per_split</span><span class="p">,</span> <span class="n">num_tpu_hosts</span><span class="p">,</span>
                <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span><span class="p">))</span>

    <span class="k">assert</span> <span class="n">num_tpu_hosts</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;num_tpu_hosts: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">num_tpu_hosts</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_core_infeed</span><span class="p">:</span>
      <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span><span class="p">)</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">use_partitioned_infeed_queue</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;use_per_core_infeed need to have use_per_host_infeed &#39;</span>
                         <span class="s1">&#39;but not use_partitioned_infeed_queue.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_devices_per_split</span> <span class="o">&gt;</span> <span class="n">num_cores_per_host</span> <span class="ow">and</span>
        <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_core_infeed</span><span class="p">)):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">fatal</span><span class="p">(</span><span class="s1">&#39;Doesn</span><span class="se">\&#39;</span><span class="s1">t support per host infeed mode when &#39;</span>
                       <span class="s1">&#39;num_devices_per_split(</span><span class="si">{}</span><span class="s1">) &gt; num_cores_per_host(</span><span class="si">{}</span><span class="s1">).&#39;</span>
                       <span class="s1">&#39;Each host must be able to accommodate &gt;= 1 split when &#39;</span>
                       <span class="s1">&#39;using per_host_infeed.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                           <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_devices_per_split</span><span class="p">,</span>
                           <span class="n">num_cores_per_host</span><span class="p">))</span>

    <span class="n">shards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tpu_number_of_shards</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;shards </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">shards</span><span class="p">))</span>

    <span class="n">input_ops_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">cpu_passthrough_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GetCpuPassthroughKeys</span><span class="p">()</span>

    <span class="n">num_infeed_hosts</span> <span class="o">=</span> <span class="n">num_tpu_hosts</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;num_infeed_hosts: </span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">num_infeed_hosts</span><span class="p">)</span>
    <span class="n">host_devices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">ListDevices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">job_spec</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span> <span class="ow">and</span> <span class="n">num_infeed_hosts</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">host_devices</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="sa">f</span><span class="s1">&#39;Configuration mismatch, number of infeed hosts </span><span class="si">{</span><span class="n">num_infeed_hosts</span><span class="si">}</span><span class="s1"> &#39;</span>
          <span class="sa">f</span><span class="s1">&#39;does not match available devices </span><span class="si">{</span><span class="n">host_devices</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">task_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_infeed_hosts</span><span class="p">):</span>
      <span class="n">host_device</span> <span class="o">=</span> <span class="n">host_devices</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">cpu_passthrough_keys</span> <span class="ow">and</span> <span class="p">(</span>
          <span class="s1">&#39;/task:</span><span class="si">{}</span><span class="s1">/device:CPU:0&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">task_id</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">host_device</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s1">&#39;CPU passthrough configuration mismatch, device </span><span class="si">{</span><span class="n">host_device</span><span class="si">}</span><span class="s1"> &#39;</span>
            <span class="sa">f</span><span class="s1">&#39;does not match task id </span><span class="si">{</span><span class="n">task_id</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">host_device</span><span class="p">),</span> <span class="n">cluster</span><span class="o">.</span><span class="n">InfeedContextScope</span><span class="p">(</span>
          <span class="n">infeed_host_index</span><span class="o">=</span><span class="n">task_id</span><span class="p">,</span> <span class="n">num_infeed_hosts</span><span class="o">=</span><span class="n">num_infeed_hosts</span><span class="p">):</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GetPreprocessedInputBatch</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
          <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch</span><span class="p">]</span>

        <span class="n">cur_passthrough_batches</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)):</span>
          <span class="n">b</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
          <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">)</span>
          <span class="c1"># Hack: bucket_keys and xxx.bucket_keys are not needed on TPU.</span>
          <span class="c1"># Note that when MultiTaskData is used, bucket_keys will be at the</span>
          <span class="c1"># second level of the dictionary.</span>
          <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">FilterKeyVal</span><span class="p">(</span><span class="k">lambda</span> <span class="n">k</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="ow">not</span> <span class="n">k</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;bucket_keys&#39;</span><span class="p">))</span>

          <span class="c1"># Split out any keys that are meant for CPU passthrough only.</span>
          <span class="n">cur_passthrough_batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
              <span class="n">b</span><span class="o">.</span><span class="n">FilterKeyVal</span><span class="p">(</span><span class="k">lambda</span> <span class="n">k</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">cpu_passthrough_keys</span><span class="p">))</span>
          <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">FilterKeyVal</span><span class="p">(</span><span class="k">lambda</span> <span class="n">k</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cpu_passthrough_keys</span><span class="p">)</span>
          <span class="n">batch</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span>
          <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># If the input batch is already sharded, check that the shards are</span>
            <span class="c1"># compatible with each other.</span>
            <span class="k">assert</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">IsCompatible</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_per_host_passthrough_batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_passthrough_batches</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;CPU passthrough keys: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">cpu_passthrough_keys</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_sparse_tensors</span><span class="p">:</span>
          <span class="c1"># Make a copy of this host&#39;s input batch, then filter out any</span>
          <span class="c1"># SparseTensor features. This way, SparseTensor features are not fed</span>
          <span class="c1"># into the TPU InfeedQueue (and only to TPUEmbedding).</span>
          <span class="c1"># TODO(jeffreyzhao): Hack, come up with better solution.</span>
          <span class="c1"># Ideally we would like users to override</span>
          <span class="c1"># _CreateTpuEmbeddingEnqueueOpsForHost() to modify the input batch</span>
          <span class="c1"># and remove fields they don&#39;t want to enqueue onto TPU.</span>
          <span class="c1"># However, the TPUEmbedding singleton and TPU embedding enqueue ops</span>
          <span class="c1"># are currently constructed after CreateTpuEnqueueOps() is called.</span>
          <span class="n">emb_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))]</span>
          <span class="n">new_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))]</span>
          <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">b</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
              <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
                <span class="n">emb_batch</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
              <span class="k">else</span><span class="p">:</span>
                <span class="n">new_batch</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_per_host_emb_batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">emb_batch</span><span class="p">)</span>
          <span class="n">batch</span> <span class="o">=</span> <span class="n">new_batch</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_nm_types</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;host_device: </span><span class="si">%s</span><span class="s1">, batch: </span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">host_device</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_per_host_batches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
          <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">b</span><span class="o">.</span><span class="n">FlattenItems</span><span class="p">():</span>
            <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">is_fully_defined</span><span class="p">(),</span> <span class="p">(</span>
                <span class="s1">&#39;Shape must be fully defined: </span><span class="si">%s</span><span class="s1">: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
          <span class="c1"># TODO(cwhipkey): if it&#39;s a string (or other type not supported on</span>
          <span class="c1"># TPU), drop it from feeding and on the other end add in an op that</span>
          <span class="c1"># fails if used.</span>
        <span class="n">shapes</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="n">dtypes</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;host_device: </span><span class="si">%s</span><span class="s1"> infeed shapes: </span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">host_device</span><span class="p">,</span>
                        <span class="n">shapes</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;host_device: </span><span class="si">%s</span><span class="s1"> infeed dtypes: </span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">host_device</span><span class="p">,</span>
                        <span class="n">dtypes</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_partitioned_infeed_queue</span><span class="p">:</span>
          <span class="n">device_assignment</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetTpuDeviceAssignment</span><span class="p">(</span><span class="n">job_name</span><span class="p">)</span>

          <span class="n">host_device</span> <span class="o">=</span> <span class="n">device_assignment</span><span class="o">.</span><span class="n">host_device</span><span class="p">(</span>
              <span class="n">replica</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">job</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">FLAGS</span><span class="o">.</span><span class="n">tf_master</span><span class="p">)</span>
          <span class="n">host_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">host_device</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/task:&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/device:&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;host_id: </span><span class="si">{}</span><span class="s1"> host_device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
              <span class="n">host_id</span><span class="p">,</span> <span class="n">host_device</span><span class="p">))</span>
          <span class="n">q</span> <span class="o">=</span> <span class="n">tpu_feed</span><span class="o">.</span><span class="n">_PartitionedInfeedQueue</span><span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>
              <span class="n">number_of_tuple_elements</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">dtypes</span><span class="p">),</span>
              <span class="n">device_assignment</span><span class="o">=</span><span class="n">device_assignment</span><span class="p">,</span>
              <span class="n">host_id</span><span class="o">=</span><span class="n">host_id</span><span class="p">,</span>
              <span class="n">input_partition_dims</span><span class="o">=</span><span class="p">[</span>
                  <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_partitions</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">shapes</span>
              <span class="p">],</span>
              <span class="n">tuple_types</span><span class="o">=</span><span class="n">dtypes</span><span class="p">,</span>
              <span class="n">tuple_shapes</span><span class="o">=</span><span class="n">shapes</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_core_infeed</span><span class="p">:</span>
            <span class="n">q</span> <span class="o">=</span> <span class="n">tpu_feed</span><span class="o">.</span><span class="n">InfeedQueue</span><span class="p">(</span>
                <span class="n">tuple_types</span><span class="o">=</span><span class="n">dtypes</span><span class="p">,</span>
                <span class="n">tuple_shapes</span><span class="o">=</span><span class="n">shapes</span><span class="p">,</span>
                <span class="n">number_of_partitions</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">num_partitions</span><span class="p">)</span>
          <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># When the input batch is sharded, the unsharded dtypes and shapes</span>
            <span class="c1"># will be determined later by the generate_enqueue_ops() call.</span>
            <span class="n">q</span> <span class="o">=</span> <span class="n">tpu_feed</span><span class="o">.</span><span class="n">InfeedQueue</span><span class="p">(</span>
                <span class="n">number_of_tuple_elements</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()))</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">q</span> <span class="o">=</span> <span class="n">tpu_feed</span><span class="o">.</span><span class="n">InfeedQueue</span><span class="p">(</span><span class="n">tuple_types</span><span class="o">=</span><span class="n">dtypes</span><span class="p">,</span> <span class="n">tuple_shapes</span><span class="o">=</span><span class="n">shapes</span><span class="p">)</span>
          <span class="k">assert</span> <span class="n">shards</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
          <span class="n">q</span><span class="o">.</span><span class="n">set_number_of_shards</span><span class="p">(</span><span class="n">shards</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_queues</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_partitioned_infeed_queue</span><span class="p">:</span>
          <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
          <span class="n">input_ops</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">generate_enqueue_ops</span><span class="p">([</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()])</span>
        <span class="k">elif</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span><span class="p">:</span>
          <span class="c1"># TODO(ylc/zhifengc): Add this to a policy module and test it.</span>
          <span class="k">def</span> <span class="nf">TPUOrdinalFunction</span><span class="p">(</span><span class="n">shard_index_in_host</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_core_infeed</span><span class="p">:</span>
              <span class="k">return</span> <span class="n">shard_index_in_host</span>
            <span class="n">device_assignment</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetTpuDeviceAssignment</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">device_assignment</span><span class="p">:</span>
              <span class="c1"># We put both enqueue/dequeue ops at core 0 in each replica.</span>
              <span class="n">replica</span> <span class="o">=</span> <span class="n">device_assignment</span><span class="o">.</span><span class="n">lookup_replicas</span><span class="p">(</span>
                  <span class="n">task_id</span><span class="p">,</span> <span class="mi">0</span><span class="p">)[</span><span class="n">shard_index_in_host</span><span class="p">]</span>  <span class="c1"># pylint: disable=cell-var-from-loop</span>
              <span class="k">return</span> <span class="n">device_assignment</span><span class="o">.</span><span class="n">tpu_ordinal</span><span class="p">(</span><span class="n">replica</span><span class="o">=</span><span class="n">replica</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
              <span class="k">return</span> <span class="n">shard_index_in_host</span>

          <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># In this case, the `shard_index_in_host` argument of</span>
            <span class="c1"># `TPUOrdinalFunction` is the index of a sharded batch in the</span>
            <span class="c1"># `batch` list.</span>
            <span class="n">input_ops</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">generate_enqueue_ops</span><span class="p">(</span>
                <span class="p">[</span><span class="n">b</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span>
                <span class="n">placement_function</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">host_device</span><span class="p">,</span>  <span class="c1"># pylint: disable=cell-var-from-loop</span>
                <span class="n">tpu_ordinal_function</span><span class="o">=</span><span class="n">TPUOrdinalFunction</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">input_ops</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">split_inputs_and_generate_enqueue_ops</span><span class="p">(</span>
                <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
                <span class="n">placement_function</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">host_device</span><span class="p">,</span>  <span class="c1"># pylint: disable=cell-var-from-loop</span>
                <span class="n">tpu_ordinal_function</span><span class="o">=</span><span class="n">TPUOrdinalFunction</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
          <span class="n">input_ops</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">split_inputs_and_generate_enqueue_ops</span><span class="p">(</span>
              <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
              <span class="n">device_assignment</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetTpuDeviceAssignment</span><span class="p">(</span><span class="n">job_name</span><span class="p">))</span>
        <span class="n">input_ops_list</span> <span class="o">+=</span> <span class="n">input_ops</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;input_ops_list </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">input_ops_list</span><span class="p">)</span>
    <span class="n">grouped_infeed_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="o">*</span><span class="n">input_ops_list</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_infeed_op</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">tpu_infeed_parallelism</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_infeed_op</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grouped_infeed_op</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseInputGenerator.TpuDequeueBatch"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.TpuDequeueBatch">[docs]</a>  <span class="k">def</span> <span class="nf">TpuDequeueBatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create TPU dequeue ops.</span>

<span class="sd">    This should only be called within a TPU context.</span>

<span class="sd">    Returns:</span>
<span class="sd">    - A NestedMap of the input batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_queues</span><span class="p">,</span> <span class="s1">&#39;CreateTpuEnqueueOps must be called first.&#39;</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">tpu</span><span class="o">.</span><span class="n">core</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
      <span class="c1"># Note that the dequeue_tuple op on the TPU core</span>
      <span class="c1"># only cares about the shape/types being dequeued</span>
      <span class="c1"># which is why this is hard-coded to the first Queue.</span>
      <span class="n">tensors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_queues</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">generate_dequeue_op</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_nm_types</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseInputGenerator.CreateTpuEmbeddingEnqueueOps"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.CreateTpuEmbeddingEnqueueOps">[docs]</a>  <span class="k">def</span> <span class="nf">CreateTpuEmbeddingEnqueueOps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode_override</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates the TpuEmbedding enqueue ops on all hosts.</span>

<span class="sd">    Note that this must be called after the instantiation of the</span>
<span class="sd">    monolithic TPUEmbeddingLayer.</span>

<span class="sd">    Args:</span>
<span class="sd">      mode_override: String to override TPU embedding mode. See</span>
<span class="sd">        TPUEmbedding.generate_enqueue_ops()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">skip_tpu_embedding_enqueue_ops</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="n">tpu_embedding_collection</span> <span class="o">=</span> <span class="n">tpu_embedding_layers</span><span class="o">.</span><span class="n">TpuEmbeddingCollection</span><span class="o">.</span><span class="n">Get</span><span class="p">()</span>
    <span class="n">tpu_embedding</span> <span class="o">=</span> <span class="n">tpu_embedding_collection</span><span class="o">.</span><span class="n">tpu_embedding</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">tpu_embedding</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="n">num_tpu_hosts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_tpu_hosts</span>
    <span class="n">num_infeed_hosts</span> <span class="o">=</span> <span class="n">num_tpu_hosts</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_sparse_tensors</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_per_host_emb_batches</span><span class="p">)</span> <span class="o">==</span> <span class="n">num_infeed_hosts</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_per_host_batches</span><span class="p">)</span> <span class="o">==</span> <span class="n">num_infeed_hosts</span>

    <span class="k">if</span> <span class="n">num_tpu_hosts</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">tpu_embedding</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span><span class="p">:</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">fatal</span><span class="p">(</span>
            <span class="s1">&#39;TPU Embedding must be used with per_host_infeed with multiple &#39;</span>
            <span class="s1">&#39;TPU host topologies.&#39;</span><span class="p">)</span>

    <span class="n">enqueue_ops</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">task_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_infeed_hosts</span><span class="p">):</span>
      <span class="n">host_device</span> <span class="o">=</span> <span class="s1">&#39;/task:</span><span class="si">{}</span><span class="s1">/device:CPU:0&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">task_id</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_sparse_tensors</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_host_emb_batches</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_host_batches</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Tpu Embedding doesn&#39;t support sharded inputs.&quot;</span>
      <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">host_device</span><span class="p">):</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;host_device: </span><span class="si">%s</span><span class="s1">, batch: </span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">host_device</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
        <span class="n">enqueue_ops</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_CreateTpuEmbeddingEnqueueOpsForHost</span><span class="p">(</span>
            <span class="n">tpu_embedding</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">mode_override</span><span class="o">=</span><span class="n">mode_override</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_infeed_op</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="o">*</span><span class="n">enqueue_ops</span><span class="p">))</span></div>

<div class="viewcode-block" id="BaseInputGenerator._CreateTpuEmbeddingEnqueueOpsForHost"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator._CreateTpuEmbeddingEnqueueOpsForHost">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateTpuEmbeddingEnqueueOpsForHost</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                           <span class="n">tpu_embedding</span><span class="p">,</span>
                                           <span class="n">input_batch</span><span class="p">,</span>
                                           <span class="n">mode_override</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Hook for creating TPU embedding enqueue ops for a single host.</span>

<span class="sd">    Used by CreateTpuEmbeddingEnqueueOps(). Override this method in input</span>
<span class="sd">    generators to control how embedding inputs are enqueued onto TPU.</span>

<span class="sd">    Args:</span>
<span class="sd">      tpu_embedding: The monolithic TpuEmbedding object.</span>
<span class="sd">      input_batch: The input batch for this host.</span>
<span class="sd">      mode_override: String to override TPU embedding mode. See</span>
<span class="sd">        TPUEmbedding.generate_enqueue_ops()</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of TPU Embedding enqueue ops.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tpu_emb_input_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tpu_embedding</span><span class="o">.</span><span class="n">feature_to_config_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;tpu_emb_input_keys: </span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">tpu_emb_input_keys</span><span class="p">)</span>

    <span class="n">num_cores_per_host</span> <span class="o">=</span> <span class="n">tpu_embedding</span><span class="o">.</span><span class="n">num_cores_per_host</span>
    <span class="n">enqueue_dict_per_core</span> <span class="o">=</span> <span class="p">[{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_cores_per_host</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">tpu_emb_input_keys</span><span class="p">:</span>
      <span class="n">feat</span> <span class="o">=</span> <span class="n">input_batch</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">):</span>
        <span class="n">tpu_emb_feat_splitted</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
            <span class="n">feat</span><span class="p">,</span> <span class="n">num_cores_per_host</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">core</span><span class="p">,</span> <span class="n">split</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tpu_emb_feat_splitted</span><span class="p">):</span>
          <span class="n">enqueue_data</span> <span class="o">=</span> <span class="n">tpu_embedding_lib</span><span class="o">.</span><span class="n">EnqueueData</span><span class="o">.</span><span class="n">from_sparse_tensor</span><span class="p">(</span><span class="n">split</span><span class="p">)</span>
          <span class="n">enqueue_dict_per_core</span><span class="p">[</span><span class="n">core</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">enqueue_data</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">tpu_emb_feat_splitted</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="n">num_cores_per_host</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">core</span><span class="p">,</span> <span class="n">split</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tpu_emb_feat_splitted</span><span class="p">):</span>
          <span class="c1"># Dense to sparse. Note the assumption of a padding id.</span>
          <span class="n">sample_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">not_equal</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
          <span class="n">embedding_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="n">sample_indices</span><span class="p">)</span>
          <span class="n">enqueue_data</span> <span class="o">=</span> <span class="n">tpu_embedding_lib</span><span class="o">.</span><span class="n">EnqueueData</span><span class="p">(</span><span class="n">embedding_indices</span><span class="p">,</span>
                                                       <span class="n">sample_indices</span><span class="p">)</span>
          <span class="n">enqueue_dict_per_core</span><span class="p">[</span><span class="n">core</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">enqueue_data</span>
    <span class="k">return</span> <span class="n">tpu_embedding</span><span class="o">.</span><span class="n">generate_enqueue_ops</span><span class="p">(</span>
        <span class="n">enqueue_dict_per_core</span><span class="p">,</span> <span class="n">mode_override</span><span class="o">=</span><span class="n">mode_override</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseInputGenerator.GetCpuPassthroughKeys"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.GetCpuPassthroughKeys">[docs]</a>  <span class="k">def</span> <span class="nf">GetCpuPassthroughKeys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a list of keys from the input to skip sending to the device.</span>

<span class="sd">    When running on TPU, a user may want to avoid sending some inputs to the</span>
<span class="sd">    device; either the type is not supported (e.g., string), or the input will</span>
<span class="sd">    not be processed on the device at all.  However, these items may be still</span>
<span class="sd">    useful to passthrough to the &quot;output&quot;, e.g., for decoding purposes.</span>

<span class="sd">    This function should return a list of keys from InputBatch() that should not</span>
<span class="sd">    be sent to the TPU, but can be combined with the outputs of Decode() before</span>
<span class="sd">    passing to PostProcessDecodeOut().</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of keys from the input to filter from being sent to the device,</span>
<span class="sd">        which may be combined with the output of Decode() prior to</span>
<span class="sd">        PostProcessDecodeOut().</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[]</span></div>

<div class="viewcode-block" id="BaseInputGenerator.CreateCpuPassthroughEnqueueOps"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.CreateCpuPassthroughEnqueueOps">[docs]</a>  <span class="k">def</span> <span class="nf">CreateCpuPassthroughEnqueueOps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates enqueue ops to pass through CPU inputs to the output.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">num_tpu_hosts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_tpu_hosts</span>
    <span class="n">num_infeed_hosts</span> <span class="o">=</span> <span class="n">num_tpu_hosts</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span> <span class="k">else</span> <span class="mi">1</span>

    <span class="n">cpu_passthrough_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GetCpuPassthroughKeys</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">cpu_passthrough_keys</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="c1"># There is one enqueue op per host.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_host_queues</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">enqueue_ops</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_per_host_batches</span><span class="p">)</span> <span class="o">==</span> <span class="n">num_infeed_hosts</span>
    <span class="k">for</span> <span class="n">task_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_infeed_hosts</span><span class="p">):</span>
      <span class="n">host_device</span> <span class="o">=</span> <span class="s1">&#39;/task:</span><span class="si">{}</span><span class="s1">/device:CPU:0&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">task_id</span><span class="p">)</span>
      <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_host_passthrough_batches</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span>
      <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">host_device</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cpu_nm_types</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">batch</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;host_device CPU passthrough types: </span><span class="si">%s</span><span class="s1">, batch: </span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span>
                        <span class="n">host_device</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
        <span class="n">cpu_dtypes</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">batch</span><span class="p">))</span>
        <span class="c1"># NOTE: we use a large capacity queue under the assumption that the size</span>
        <span class="c1"># of these tensors will be generally smaller than that sent to the TPU,</span>
        <span class="c1"># and that the TPU queue will likely fill up before the host queue,</span>
        <span class="c1"># blocking further enqueues.</span>
        <span class="n">host_queue</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">FIFOQueue</span><span class="p">(</span><span class="n">capacity</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">=</span><span class="n">cpu_dtypes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_host_queues</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">host_queue</span>
        <span class="n">enqueue_ops</span> <span class="o">+=</span> <span class="p">[</span><span class="n">host_queue</span><span class="o">.</span><span class="n">enqueue</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">batch</span><span class="p">))]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_infeed_op</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="o">*</span><span class="n">enqueue_ops</span><span class="p">))</span></div>

<div class="viewcode-block" id="BaseInputGenerator.DequeueCpuPassthrough"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.DequeueCpuPassthrough">[docs]</a>  <span class="k">def</span> <span class="nf">DequeueCpuPassthrough</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">concat</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create CPU dequeue ops.</span>

<span class="sd">    Args:</span>
<span class="sd">      concat: Whether to concat the passthrough batches for each host into one</span>
<span class="sd">        batch.</span>

<span class="sd">    Returns:</span>
<span class="sd">      None if there are no CPU passthrough values. Otherwise, a NestedMap of the</span>
<span class="sd">      CPU passthrough input batch if `concat`, or a list of NestedMaps (one for</span>
<span class="sd">      each host) if not `concat`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cpu_passthrough_keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GetCpuPassthroughKeys</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">cpu_passthrough_keys</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">None</span>

    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">num_tpu_hosts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_tpu_hosts</span>
    <span class="n">num_infeed_hosts</span> <span class="o">=</span> <span class="n">num_tpu_hosts</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span> <span class="k">else</span> <span class="mi">1</span>
    <span class="n">tensor_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">task_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_infeed_hosts</span><span class="p">):</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;/task:</span><span class="si">{}</span><span class="s1">/device:CPU:0&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">task_id</span><span class="p">)):</span>
        <span class="n">tensors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_host_queues</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span><span class="o">.</span><span class="n">dequeue</span><span class="p">()</span>
        <span class="c1"># Make list if only one tensor.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
          <span class="n">tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensors</span><span class="p">]</span>
        <span class="n">tensor_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>

    <span class="c1"># TODO(laigd): consider moving the concat logic out to make the API simpler.</span>
    <span class="k">if</span> <span class="n">concat</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;/task:0/device:CPU:0&#39;</span><span class="p">):</span>
        <span class="c1"># Transpose to get per-dequeue-element tuples, then concat.</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">xs</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">tensor_list</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cpu_nm_types</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>

    <span class="c1"># Return a list of batches, one per host.</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">py_utils</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cpu_nm_types</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span> <span class="k">for</span> <span class="n">xs</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">]</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">tpu_infeed_op</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_infeed_op</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tpu_infeed_op</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;TPU infeed op not set. Call CreateTpuEnqueueOps first.&#39;</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">merged_input_data_summary_op</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_merged_input_data_summary_op</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">input_data_summary_layout</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_data_summary_layout</span>

<div class="viewcode-block" id="BaseInputGenerator.SplitInputBatch"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.SplitInputBatch">[docs]</a>  <span class="k">def</span> <span class="nf">SplitInputBatch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_splits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Splits the current InputBatch into num_splits ways.</span>

<span class="sd">    Args:</span>
<span class="sd">      num_splits: The number of splits.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of `.NestedMap`. Each `.NestedMap` represents the input</span>
<span class="sd">      tensors in one split.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">num_splits</span> <span class="o">&gt;=</span> <span class="mi">1</span>

    <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GetPreprocessedInputBatch</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">num_splits</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># Special case. No split is needed.</span>
      <span class="k">return</span> <span class="p">[</span><span class="n">batch</span><span class="p">]</span>

    <span class="k">assert</span> <span class="ow">not</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">()</span>
    <span class="n">field_split</span> <span class="o">=</span> <span class="n">ig_helper</span><span class="o">.</span><span class="n">SplitTensors</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> <span class="n">num_splits</span><span class="p">)</span>
    <span class="n">num_fields</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">field_split</span><span class="p">)</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_splits</span><span class="p">):</span>
      <span class="n">split_flatten</span> <span class="o">=</span> <span class="p">[</span><span class="n">field_split</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_fields</span><span class="p">)]</span>
      <span class="n">split</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="n">split_flatten</span><span class="p">)</span>
      <span class="n">ret</span> <span class="o">+=</span> <span class="p">[</span><span class="n">split</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">ret</span></div>

<div class="viewcode-block" id="BaseInputGenerator.Reset"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGenerator.Reset">[docs]</a>  <span class="k">def</span> <span class="nf">Reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reset the input-generator.</span>

<span class="sd">    Override so that the input_generator reproduces examples as if from a fresh</span>
<span class="sd">    instantiation.</span>

<span class="sd">    Args:</span>
<span class="sd">      sess: A tensorflow session.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_map_args</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Default args for tf.data.DataSet.map().&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;num_parallel_calls&#39;</span><span class="p">:</span>
            <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">in_unit_test</span> <span class="k">else</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">,</span>
        <span class="s1">&#39;deterministic&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">require_sequential_input_order</span>
    <span class="p">}</span></div>


<div class="viewcode-block" id="FilePatternToDataSource"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.FilePatternToDataSource">[docs]</a><span class="k">def</span> <span class="nf">FilePatternToDataSource</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper to turn p.file_pattern (deprecated) into p.file_datasource.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">SimpleDataSource</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">file_pattern</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">if</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">]):</span>
      <span class="c1"># While this violates the documentation and intended use, there are</span>
      <span class="c1"># subclasses that have used a tuple of strings, rather than a list of</span>
      <span class="c1"># string, weight tuples.  Rather than treating lists and tuples</span>
      <span class="c1"># differently, support both here until p.file_pattern is removed.</span>
      <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">SimpleDataSource</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">file_pattern</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">p</span><span class="o">.</span><span class="n">use_within_batch_mixing</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">)))</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="c1"># Within batch mixing doesn&#39;t work with backprop filters, i.e. when</span>
        <span class="c1"># file_pattern param contains a list of</span>
        <span class="c1"># &lt;file_pattern, weight, [bprop_variable_filter]&gt; tuples.</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Expected a list of pairs, got </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">)</span>

      <span class="n">file_patterns</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">))</span>

      <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">SimpleDataSource</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">file_pattern</span><span class="o">=</span><span class="n">file_patterns</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># Otherwise fall back to MixByWeight-based approach.</span>
      <span class="n">datasources</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">bprop_variable_filters</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">input_entry</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_entry</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Should explicitly specify weights, got string: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
                           <span class="n">input_entry</span><span class="p">)</span>
        <span class="n">file_pattern</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="n">input_entry</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">datasources</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">datasource</span><span class="o">.</span><span class="n">SimpleDataSource</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">file_pattern</span><span class="o">=</span><span class="n">file_pattern</span><span class="p">))</span>
        <span class="n">weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">bprop_variable_filter</span> <span class="o">=</span> <span class="n">input_entry</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_entry</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
        <span class="n">bprop_variable_filters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bprop_variable_filter</span><span class="p">)</span>
      <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">CrossBatchMixingDataSource</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">sub</span><span class="o">=</span><span class="n">datasources</span><span class="p">,</span>
          <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
          <span class="n">bprop_variable_filters</span><span class="o">=</span><span class="n">bprop_variable_filters</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot parse p.file_pattern into a datasource.&#39;</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">cluster_factory</span><span class="o">.</span><span class="n">Current</span><span class="p">()</span><span class="o">.</span><span class="n">tf_data_service_address</span><span class="p">:</span>
    <span class="n">bucket_upper_bound</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="s1">&#39;bucket_upper_bound&#39;</span> <span class="ow">in</span> <span class="n">p</span><span class="p">:</span>
      <span class="n">bucket_upper_bound</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">bucket_upper_bound</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">TFDataServiceSource</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
        <span class="n">sub</span><span class="o">=</span><span class="n">ds</span><span class="p">,</span> <span class="n">bucket_upper_bound</span><span class="o">=</span><span class="n">bucket_upper_bound</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">TFDatasetPrefetch</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">sub</span><span class="o">=</span><span class="n">ds</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">ds</span></div>


<div class="viewcode-block" id="BaseInputGeneratorFromFiles"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGeneratorFromFiles">[docs]</a><span class="k">class</span> <span class="nc">BaseInputGeneratorFromFiles</span><span class="p">(</span><span class="n">BaseInputGenerator</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Base class for input generators that reads from files.</span>

<span class="sd">  Subclasses should implement _DataSourceFromFilePattern.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseInputGeneratorFromFiles.Params"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGeneratorFromFiles.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Defaults params for input generators.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="c1"># NOTE: file_pattern is deprecated.  New params should use</span>
        <span class="c1"># file_datasource instead.</span>
        <span class="c1"># TODO(b/139345706) remove file_pattern parameter</span>
        <span class="s1">&#39;file_pattern&#39;</span><span class="p">,</span>
        <span class="s1">&#39;&#39;</span><span class="p">,</span>
        <span class="s1">&#39;A single file pattern string, a list of file pattern strings or a list&#39;</span>
        <span class="s1">&#39; of &lt;file_pattern, weight&gt; pairs or a list of  &lt;file_pattern, weight, &#39;</span>
        <span class="s1">&#39;bprop_variable_filter&gt; tuples. Some of the cases may not be supported &#39;</span>
        <span class="s1">&#39;with use_within_batch_mixing, where probablistic samples are from the &#39;</span>
        <span class="s1">&#39;inputs proportional to their weights. Typically, values are binary &#39;</span>
        <span class="s1">&#39;protocol buffers containing train/eval samples. Keys are not used.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;file_random_seed&#39;</span><span class="p">,</span> <span class="mi">301</span><span class="p">,</span>
             <span class="s1">&#39;Random seed for shuffling the input data.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;file_buffer_size&#39;</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span>
        <span class="s1">&#39;How many records are buffered for random shuffling. This param &#39;</span>
        <span class="s1">&#39;affects how much RAM a train/test job needs. E.g., if an average &#39;</span>
        <span class="s1">&#39;record is about 500KB, the buffer needs 5GB ram.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;file_buffer_size_in_seconds&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s1">&#39;If non-zero, keep enough records in the buffer to handle N seconds &#39;</span>
        <span class="s1">&#39;worth of demand. E.g., if the training job is reading 1000 records &#39;</span>
        <span class="s1">&#39;per second and this parameter is set to 10, the buffer is resized &#39;</span>
        <span class="s1">&#39;to contain 10000 records. This parameter is useful when reading from &#39;</span>
        <span class="s1">&#39;many data sources at different speeds, as it automatically tunes the &#39;</span>
        <span class="s1">&#39;size of buffers to fit demand. The file_buffer_size parameter is an &#39;</span>
        <span class="s1">&#39;upper bound to the buffer size.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;file_parallelism&#39;</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="s1">&#39;How many files to read concurrently.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;flush_every_n&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;If non-zero, flushes all batches buffered &#39;</span>
        <span class="s1">&#39;so far every these many records are yielded.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_batcher_threads&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Number of threads to use for input &#39;</span>
             <span class="s1">&#39;record batcher.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;repeat_count&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="s1">&#39;Number of repetitions of a dataset before throwing OutOfRange error &#39;</span>
        <span class="s1">&#39;when using require_sequential_input_order. Must only be set if &#39;</span>
        <span class="s1">&#39;cluster.require_sequential_input_order is True.&#39;</span><span class="p">)</span>
    <span class="c1"># TODO(b/139345706) when file_pattern is deleted use_within_batch_mixing</span>
    <span class="c1"># will be specified by setting weights in SimpleDataSource in</span>
    <span class="c1"># p.file_datasource and this param should be deleted as well.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;use_within_batch_mixing&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Whether to mix records from &#39;</span>
        <span class="s1">&#39;different input sources within batch or across batches (the &#39;</span>
        <span class="s1">&#39;default option). This option only takes effect when file_pattern&#39;</span>
        <span class="s1">&#39; is a list of file patterns with weights.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">use_per_host_infeed</span> <span class="ow">and</span> <span class="n">params</span><span class="o">.</span><span class="n">file_random_seed</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;file_random_seed needs to be 0 when &#39;</span>
                       <span class="s1">&#39;use_per_host_infeed == True.&#39;</span><span class="p">)</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

<div class="viewcode-block" id="BaseInputGeneratorFromFiles.CreateDatasource"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGeneratorFromFiles.CreateDatasource">[docs]</a>  <span class="k">def</span> <span class="nf">CreateDatasource</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="p">(</span>
        <span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">file_datasource</span>
    <span class="p">),</span> <span class="s1">&#39;Only one of file_pattern and file_datasource can be specified&#39;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">file_datasource</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">file_datasource</span> <span class="o">=</span> <span class="n">FilePatternToDataSource</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="c1"># TODO(b/139345706) remove support for file_pattern</span>
      <span class="c1"># p.file_pattern = &#39;&#39;</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">CreateDatasource</span><span class="p">()</span></div>

<div class="viewcode-block" id="BaseInputGeneratorFromFiles.CommonInputOpArgs"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGeneratorFromFiles.CommonInputOpArgs">[docs]</a>  <span class="k">def</span> <span class="nf">CommonInputOpArgs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Common input params.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="n">args</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">CommonInputOpArgs</span><span class="p">()</span>
    <span class="n">num_input_replicas</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">input_replica_id</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">infeed_context</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">GetInfeedContext</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">infeed_context</span><span class="p">:</span>
      <span class="n">num_input_replicas</span> <span class="o">=</span> <span class="n">infeed_context</span><span class="o">.</span><span class="n">num_infeed_hosts</span>
      <span class="n">input_replica_id</span> <span class="o">=</span> <span class="n">infeed_context</span><span class="o">.</span><span class="n">infeed_host_index</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;input_replica_id=</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">input_replica_id</span><span class="p">,</span>
                      <span class="n">num_input_replicas</span><span class="p">)</span>
    <span class="c1"># Legacy behavior for Lingvo input ops: require_sequential_order defaults to</span>
    <span class="c1"># False for eval jobs. Note that this value is different from</span>
    <span class="c1"># self.cluster.require_sequential_input_order.</span>
    <span class="n">require_sequential_order</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">require_sequential_input_order</span><span class="p">)</span>
    <span class="n">args</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
        <span class="s1">&#39;file_random_seed&#39;</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">file_random_seed</span><span class="p">,</span>
        <span class="s1">&#39;file_buffer_size&#39;</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">file_buffer_size</span><span class="p">,</span>
        <span class="s1">&#39;file_parallelism&#39;</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">file_parallelism</span><span class="p">,</span>
        <span class="s1">&#39;file_buffer_size_in_seconds&#39;</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">file_buffer_size_in_seconds</span><span class="p">,</span>
        <span class="s1">&#39;flush_every_n&#39;</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">flush_every_n</span><span class="p">,</span>
        <span class="s1">&#39;num_threads&#39;</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">num_batcher_threads</span><span class="p">,</span>
        <span class="s1">&#39;require_sequential_order&#39;</span><span class="p">:</span> <span class="n">require_sequential_order</span><span class="p">,</span>
        <span class="s1">&#39;repeat_count&#39;</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">repeat_count</span><span class="p">,</span>
        <span class="s1">&#39;num_input_replicas&#39;</span><span class="p">:</span> <span class="n">num_input_replicas</span><span class="p">,</span>
        <span class="s1">&#39;input_replica_id&#39;</span><span class="p">:</span> <span class="n">input_replica_id</span><span class="p">,</span>
    <span class="p">})</span>
    <span class="n">args</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_InputOpBucketingArgs</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">args</span></div>

<div class="viewcode-block" id="BaseInputGeneratorFromFiles._InputOpBucketingArgs"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGeneratorFromFiles._InputOpBucketingArgs">[docs]</a>  <span class="k">def</span> <span class="nf">_InputOpBucketingArgs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;bucket_upper_bound&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000000</span><span class="p">],</span>
        <span class="s1">&#39;bucket_batch_limit&#39;</span><span class="p">:</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">InfeedBatchSize</span><span class="p">()],</span>
        <span class="s1">&#39;bucket_adjust_every_n&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">}</span></div>

<div class="viewcode-block" id="BaseInputGeneratorFromFiles._InputBatch"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGeneratorFromFiles._InputBatch">[docs]</a>  <span class="k">def</span> <span class="nf">_InputBatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_BuildDataSource</span><span class="p">()</span></div>

  <span class="c1"># TODO(b/139345706): After p.file_pattern is deleted, the following functions</span>
  <span class="c1"># _DataSourceFromFilePattern, _BuildDataSourceWithMetadata, _BuildDataSource</span>
  <span class="c1"># can be deleted and functionality moved to using the DataSource directly.</span>
<div class="viewcode-block" id="BaseInputGeneratorFromFiles._DataSourceFromFilePattern"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGeneratorFromFiles._DataSourceFromFilePattern">[docs]</a>  <span class="k">def</span> <span class="nf">_DataSourceFromFilePattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_pattern</span><span class="p">,</span> <span class="n">input_source_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a NestedMap containing an input batch from a string file_pattern.</span>

<span class="sd">    Subclasses should implement this function.</span>

<span class="sd">    Args:</span>
<span class="sd">      file_pattern: A string file pattern.</span>
<span class="sd">      input_source_weights: A list of float input source weights to control</span>
<span class="sd">        input example mix in the batch. The records will be sampled from inputs</span>
<span class="sd">        proportionally to these weights. Defaults to None which should be</span>
<span class="sd">        treated as an empty list.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `.NestedMap` of tf.Tensors containing a batch of input data with shapes</span>
<span class="sd">      [batch, ...].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span></div>

<div class="viewcode-block" id="BaseInputGeneratorFromFiles._BuildDataSourceWithMetadata"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGeneratorFromFiles._BuildDataSourceWithMetadata">[docs]</a>  <span class="k">def</span> <span class="nf">_BuildDataSourceWithMetadata</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Read and return input batch from `p.file_pattern`.</span>

<span class="sd">    `p.file_pattern` may be a string file_pattern or a</span>
<span class="sd">    list of (file_pattern, weight, [bprop_variable_filter]) tuples.</span>
<span class="sd">    bprop_variable_filter is optional. When bprop_variable_filter is used,</span>
<span class="sd">    batches will always contain the examples from the same source. Otherwise,</span>
<span class="sd">    examples from different sources may be mixed together.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `.NestedMap` containing</span>

<span class="sd">      - data: `.NestedMap` of tf.Tensor as in `_DataSourceFromFilePattern()`.</span>
<span class="sd">      - source_selected: optional tensor of size [batch_size, #datasources].</span>
<span class="sd">      - selected_bprop: optional tensor of size [#datasources].</span>
<span class="sd">      - bprop_variable_filters: optional list of filters for each source.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If file_datasource is not set</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_in_get_processed_input_batch</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s1">&#39;This input generator does not support p.use_per_host_infeed. &#39;</span>
          <span class="s1">&#39;Please set it to False, or move the call to self._BuildDataSource() &#39;</span>
          <span class="s1">&#39;from self.__init__() to self._InputBatch() for batches to be &#39;</span>
          <span class="s1">&#39;correctly replicated per host.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">file_datasource</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">:</span>
      <span class="c1"># This is a workaround for subclasses which have defined</span>
      <span class="c1"># their own data source-like functionality.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
          <span class="s1">&#39;Creating data source-like output from class </span><span class="si">%s</span><span class="s1"> using &#39;</span>
          <span class="s1">&#39;file_pattern </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">)</span>
      <span class="n">ret</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>
      <span class="n">ret</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_DataSourceFromFilePattern</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
          <span class="s1">&#39;Building data source </span><span class="si">%s</span><span class="s1"> with params </span><span class="si">%s</span><span class="s1"> and &#39;</span>
          <span class="s1">&#39;file_pattern </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasource</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasource</span><span class="o">.</span><span class="n">params</span><span class="p">,</span>
          <span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">)</span>
      <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasource</span><span class="o">.</span><span class="n">GetNext</span><span class="p">()</span>
      <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasource</span><span class="o">.</span><span class="n">GetMeta</span><span class="p">()</span>
      <span class="n">ret</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="k">if</span> <span class="s1">&#39;selected_bprop&#39;</span> <span class="ow">in</span> <span class="n">ret</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_bprop_onehot</span> <span class="o">=</span> <span class="n">ret</span><span class="o">.</span><span class="n">selected_bprop</span>
    <span class="k">if</span> <span class="s1">&#39;bprop_variable_filters&#39;</span> <span class="ow">in</span> <span class="n">ret</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_bprop_variable_filters</span> <span class="o">=</span> <span class="n">ret</span><span class="o">.</span><span class="n">bprop_variable_filters</span>
    <span class="k">if</span> <span class="s1">&#39;source_selected&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ret</span><span class="p">:</span>
      <span class="n">ret</span><span class="o">.</span><span class="n">source_selected</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">ret</span></div>

<div class="viewcode-block" id="BaseInputGeneratorFromFiles._BuildDataSource"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseInputGeneratorFromFiles._BuildDataSource">[docs]</a>  <span class="k">def</span> <span class="nf">_BuildDataSource</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Read and return input batch from `p.file_pattern`.</span>

<span class="sd">    Same as _BuildDataSourceWithMetadata but does not return any metadata.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `.NestedMap` of tf.Tensor as in `self._DataSourceFromFilePattern()`.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If unknown token type.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_BuildDataSourceWithMetadata</span><span class="p">()[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span></div></div>


<div class="viewcode-block" id="BaseSequenceInputGenerator"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseSequenceInputGenerator">[docs]</a><span class="k">class</span> <span class="nc">BaseSequenceInputGenerator</span><span class="p">(</span><span class="n">BaseInputGeneratorFromFiles</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;The basic sequence input generator.</span>

<span class="sd">  Subclasses should implement _DataSourceFromFilePattern defined in</span>
<span class="sd">  BaseInputGeneratorFromFiles.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseSequenceInputGenerator.Params"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseSequenceInputGenerator.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Defaults params for sequence input generators.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Delete</span><span class="p">(</span><span class="s1">&#39;batch_size&#39;</span><span class="p">)</span>

    <span class="c1"># How input should be bucketized.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;bucket_upper_bound&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2560</span><span class="p">],</span> <span class="s1">&#39;Bucketing scheme. Required to be&#39;</span>
        <span class="s1">&#39;a sorted list of integers. Examples that are longer than all bucket&#39;</span>
        <span class="s1">&#39;upper bounds are skipped.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;bucket_batch_limit&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">8</span><span class="p">],</span>
        <span class="s1">&#39;Desired per-split batch size per bucket. Scaled in &#39;</span>
        <span class="s1">&#39;infeed_bucket_batch_limit to the infeed size.&#39;</span>
        <span class="s1">&#39;Must be the same length as bucket_upper_bound.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;bucket_adjust_every_n&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;If non-zero, optimize the values of &#39;</span>
        <span class="s1">&#39;bucket_upper_bound except the last one after every N records &#39;</span>
        <span class="s1">&#39;based on the current input length distribution.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;source_max_length&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
             <span class="s1">&#39;The maximum length of the source sequence.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;target_max_length&#39;</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span>
             <span class="s1">&#39;The maximum length of the target sequence.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;pad_to_max_seq_length&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;If True, input tensors will be padded to max_length.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;tokenizer&#39;</span><span class="p">,</span> <span class="n">tokenizers</span><span class="o">.</span><span class="n">AsciiTokenizer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Tokenizer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;tokenizer_dict&#39;</span><span class="p">,</span> <span class="p">{},</span>
        <span class="s1">&#39;If multiple tokenizers are required, they can be accessed through &#39;</span>
        <span class="s1">&#39;this dict via a key.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">:</span>
      <span class="k">assert</span> <span class="n">DEFAULT_TOKENIZER_KEY</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">tokenizer_dict</span>
      <span class="n">p</span><span class="o">.</span><span class="n">tokenizer_dict</span><span class="p">[</span><span class="n">DEFAULT_TOKENIZER_KEY</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">tokenizer</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">tokenizer_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">p</span><span class="p">:</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;_tokenizer_&#39;</span> <span class="o">+</span> <span class="n">k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">DEFAULT_TOKENIZER_KEY</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_dict</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_dict</span><span class="p">[</span><span class="n">DEFAULT_TOKENIZER_KEY</span><span class="p">]</span>

  <span class="nd">@property</span>  <span class="c1"># Adjust batch size according to the cluster spec.</span>
  <span class="k">def</span> <span class="nf">infeed_bucket_batch_limit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the bucket batch limit for one infeed host.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">infeed_bucket_batch_limit</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">batch_utils</span><span class="o">.</span><span class="n">scale_split_to_infeed</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">bucket_batch_limit</span>
    <span class="p">]</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="s1">&#39;infeed_bucket_batch_limit=</span><span class="si">{}</span><span class="s1"> num_splits_per_client=</span><span class="si">{}</span><span class="s1"> bucket_batch_limit=</span><span class="si">{}</span><span class="s1">&#39;</span>
        <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">infeed_bucket_batch_limit</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_splits_per_client</span><span class="p">,</span>
                <span class="n">p</span><span class="o">.</span><span class="n">bucket_batch_limit</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">infeed_bucket_batch_limit</span>

<div class="viewcode-block" id="BaseSequenceInputGenerator.InfeedBatchSize"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseSequenceInputGenerator.InfeedBatchSize">[docs]</a>  <span class="k">def</span> <span class="nf">InfeedBatchSize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the batch size of one infeed pipeline.</span>

<span class="sd">    Override in subclass to provide dynamically shaped infeed batch size.</span>

<span class="sd">    If use_per_host_infeed is False then there is only one infeed pipeline and</span>
<span class="sd">    then the GlobalBatchSize() and the InfeedBatchSize() is the same.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">buckets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">infeed_bucket_batch_limit</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">x</span> <span class="o">!=</span> <span class="n">buckets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">buckets</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Using max bucket batch limit but not all limits are &#39;</span>
                         <span class="s1">&#39;the same </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">buckets</span><span class="p">))</span>
    <span class="n">infeed_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">buckets</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;InfeedBatchSize: </span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">infeed_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">infeed_size</span></div>

<div class="viewcode-block" id="BaseSequenceInputGenerator._InputOpBucketingArgs"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseSequenceInputGenerator._InputOpBucketingArgs">[docs]</a>  <span class="k">def</span> <span class="nf">_InputOpBucketingArgs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">bucket_batch_limit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">infeed_bucket_batch_limit</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;infeed_bucket_batch_limit </span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">bucket_batch_limit</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;bucket_upper_bound&#39;</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">bucket_upper_bound</span><span class="p">,</span>
        <span class="s1">&#39;bucket_batch_limit&#39;</span><span class="p">:</span> <span class="n">bucket_batch_limit</span><span class="p">,</span>
        <span class="s1">&#39;bucket_adjust_every_n&#39;</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">bucket_adjust_every_n</span><span class="p">,</span>
    <span class="p">}</span></div>

<div class="viewcode-block" id="BaseSequenceInputGenerator.StringsToIds"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseSequenceInputGenerator.StringsToIds">[docs]</a>  <span class="k">def</span> <span class="nf">StringsToIds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                   <span class="n">strs</span><span class="p">,</span>
                   <span class="n">is_source</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                   <span class="n">external_max_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">external_append_eos</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">languages</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tokenize strs into vocab ids.</span>

<span class="sd">    Args:</span>
<span class="sd">      strs: A vector of strings.</span>
<span class="sd">      is_source: A bool to indicate whether to use `source_max_length` to pad</span>
<span class="sd">        &#39;strs&#39;.</span>
<span class="sd">      external_max_length: An int providing the max_length for strs.</span>
<span class="sd">      external_append_eos: Bool or None. If None, will be ignored and</span>
<span class="sd">        `params.append_eos` will be used. If bool, will determine if an eos</span>
<span class="sd">        symbol will be added to tokens.</span>
<span class="sd">      key: A string key in case the model has multiple tokenizers.</span>
<span class="sd">      languages: A vector of str with the same length as `strs`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (ids, labels, paddings) with the same shape [batch, maxlen].</span>

<span class="sd">      - ids[i, j] is the input token id of i-th sample for j-th step.</span>
<span class="sd">      - labels[i, j] is the target token id of i-th sample for j-th step.</span>
<span class="sd">      - paddings[i, j] is 1 iff i-th sample&#39;s j-th step is padded.</span>

<span class="sd">      Usually ids[i, 0] == SOS, ids[i, j+1] == labels[i, j], and labels[i, :]</span>
<span class="sd">      ends with EOS. That is, `ids` and `labels` are inputs and ground-truth</span>
<span class="sd">      labels for step-by-step teacher-forcing training, respectively.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If unknown token type.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">if</span> <span class="n">external_max_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">maxlen</span> <span class="o">=</span> <span class="n">external_max_length</span>
    <span class="k">elif</span> <span class="n">is_source</span><span class="p">:</span>
      <span class="n">maxlen</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">source_max_length</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">maxlen</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_max_length</span>

    <span class="n">key</span> <span class="o">=</span> <span class="n">key</span> <span class="ow">or</span> <span class="n">DEFAULT_TOKENIZER_KEY</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">StringsToIds</span><span class="p">(</span>
        <span class="n">strs</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">external_append_eos</span><span class="p">,</span> <span class="n">languages</span><span class="o">=</span><span class="n">languages</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseSequenceInputGenerator.StringsToIdsWithOffsets"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseSequenceInputGenerator.StringsToIdsWithOffsets">[docs]</a>  <span class="k">def</span> <span class="nf">StringsToIdsWithOffsets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                              <span class="n">strs</span><span class="p">,</span>
                              <span class="n">is_source</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                              <span class="n">external_max_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                              <span class="n">external_append_eos</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                              <span class="n">key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                              <span class="n">languages</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tokenize strs into vocab ids, and also return byte-level offsets.</span>

<span class="sd">    Args:</span>
<span class="sd">      strs: A vector of strings.</span>
<span class="sd">      is_source: A bool to indicate whether to use `source_max_length` to pad</span>
<span class="sd">        &#39;strs&#39;.</span>
<span class="sd">      external_max_length: An int providing the max_length for strs.</span>
<span class="sd">      external_append_eos: Bool or None. If None, will be ignored and</span>
<span class="sd">        `params.append_eos` will be used. If bool, will determine if an eos</span>
<span class="sd">        symbol will be added to tokens.</span>
<span class="sd">      key: A string key in case the model has multiple tokenizers.</span>
<span class="sd">      languages: A vector of str with the same length as `strs`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (ids, labels, paddings) with the same shape [batch, maxlen].</span>

<span class="sd">      - ids[i, j] is the input token id of i-th sample for j-th step.</span>
<span class="sd">      - labels[i, j] is the target token id of i-th sample for j-th step.</span>
<span class="sd">      - paddings[i, j] is 1 iff i-th sample&#39;s j-th step is padded.</span>
<span class="sd">      - start_offset[i, j] is the byte-level offset of the start of the j-th id</span>
<span class="sd">          in the i-th original string</span>
<span class="sd">      - end_offset[i, j] is the byte-level offset of the end of the j-th id</span>
<span class="sd">          in the i-th original string</span>

<span class="sd">      Usually ids[i, 0] == SOS, ids[i, j+1] == labels[i, j], and labels[i, :]</span>
<span class="sd">      ends with EOS. That is, `ids` and `labels` are inputs and ground-truth</span>
<span class="sd">      labels for step-by-step teacher-forcing training, respectively.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If unknown token type.</span>
<span class="sd">      Exception: If the specified tokenizer does not support offsets.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">if</span> <span class="n">external_max_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">maxlen</span> <span class="o">=</span> <span class="n">external_max_length</span>
    <span class="k">elif</span> <span class="n">is_source</span><span class="p">:</span>
      <span class="n">maxlen</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">source_max_length</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">maxlen</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_max_length</span>

    <span class="n">key</span> <span class="o">=</span> <span class="n">key</span> <span class="ow">or</span> <span class="n">DEFAULT_TOKENIZER_KEY</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">StringsToIdsWithOffsets</span><span class="p">(</span>
        <span class="n">strs</span><span class="p">,</span> <span class="n">maxlen</span><span class="p">,</span> <span class="n">external_append_eos</span><span class="p">,</span> <span class="n">languages</span><span class="o">=</span><span class="n">languages</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseSequenceInputGenerator.IdsToStrings"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseSequenceInputGenerator.IdsToStrings">[docs]</a>  <span class="k">def</span> <span class="nf">IdsToStrings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">,</span> <span class="n">lens</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts ids back to strings.</span>

<span class="sd">    Args:</span>
<span class="sd">      ids: A matrix of shape [batch, seqlen]. ids[i, :] is the i-th sample&#39;s</span>
<span class="sd">        ids.</span>
<span class="sd">      lens: A vector of shape [batch]. lens[i] is the sequence length of the</span>
<span class="sd">        i-th sample. Only the first lens[i] tokens in ids[i, :] are valid tokens</span>
<span class="sd">        for the i-th sequence.</span>
<span class="sd">      key: A string key in case the model has multiple tokenizers.</span>

<span class="sd">    Returns:</span>
<span class="sd">      sequences - A vector of shape [batch]. The converted string sequence.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If unknown token type.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">key</span> <span class="o">=</span> <span class="n">key</span> <span class="ow">or</span> <span class="n">DEFAULT_TOKENIZER_KEY</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">IdsToStrings</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">lens</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseSequenceInputGenerator.Cast"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseSequenceInputGenerator.Cast">[docs]</a>  <span class="k">def</span> <span class="nf">Cast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Cast tensor dtype to fprop_dtype.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">v</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="BaseTinyDatasetInput"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseTinyDatasetInput">[docs]</a><span class="k">class</span> <span class="nc">BaseTinyDatasetInput</span><span class="p">(</span><span class="n">BaseInputGenerator</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Input generator for tiny dataset which are stored in tf checkpoint.</span>

<span class="sd">      | Input batch (b: batch size, h: height, w: width, d: depth):</span>
<span class="sd">      |   raw: Samples. [b, h, w, d].</span>
<span class="sd">      |   data: Preprocessed samples. [b, h, w, d].</span>
<span class="sd">      |   label: Labels. [b].</span>
<span class="sd">      |   weight: [b]. weight[i] is 1.0 if i-th sample is considered to</span>
<span class="sd">      |     be a real example. Otherwise, weight[i] is 0.0.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseTinyDatasetInput.Params"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseTinyDatasetInput.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Defaults params.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;ckpt&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;A TensorFlow checkpoint.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;x_train&#39;</span><span class="p">,</span> <span class="s1">&#39;The tensor name in the ckpt.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;data_dtype&#39;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="s1">&#39;The tensor dtype in the ckpt.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;data_shape&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s1">&#39;A tuple of ints. E.g., a tiny image &#39;</span>
        <span class="s1">&#39;has the shape (height, weight, depth).&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;y_train&#39;</span><span class="p">,</span> <span class="s1">&#39;The tensor name in the ckpt.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;label_dtype&#39;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="s1">&#39;The tensor dtype in the ckpt.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;repeat&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;If true, goes through the dataset repeatedly.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">use_per_host_infeed</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="BaseTinyDatasetInput._InputBatch"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseTinyDatasetInput._InputBatch">[docs]</a>  <span class="k">def</span> <span class="nf">_InputBatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">ReadData</span><span class="p">():</span>
      <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">io_ops</span><span class="o">.</span><span class="n">restore_v2</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">ckpt</span><span class="p">,</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">label</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
                               <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">data_dtype</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">label_dtype</span><span class="p">])</span>
      <span class="c1"># Always convert to float32.</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Loads data and label into memory and keep it around.</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cached_call</span><span class="p">(</span>
        <span class="n">f</span><span class="o">=</span><span class="n">ReadData</span><span class="o">.</span><span class="n">get_concrete_function</span><span class="p">(),</span> <span class="n">T</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">])</span>
    <span class="n">b</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">InfeedBatchSize</span><span class="p">(),</span> <span class="nb">list</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data_shape</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">shape</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]])</span>
    <span class="n">sample_ids</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">random_permutation_sequence</span><span class="p">(</span>
        <span class="n">num</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">batch</span><span class="o">=</span><span class="n">b</span><span class="p">,</span>
        <span class="n">repeat</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">repeat</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">random_seed</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">random_seed</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">sample_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">raw</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">PadOrTrimTo</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sample_ids</span><span class="p">),</span> <span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">+</span> <span class="n">shape</span><span class="p">)</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
        <span class="n">raw</span><span class="o">=</span><span class="n">raw</span><span class="p">,</span>
        <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_Preprocess</span><span class="p">(</span><span class="n">raw</span><span class="p">),</span>
        <span class="n">label</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">PadOrTrimTo</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">sample_ids</span><span class="p">),</span> <span class="p">[</span><span class="n">b</span><span class="p">]),</span>
        <span class="n">weight</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">PadOrTrimTo</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">n</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="p">[</span><span class="n">b</span><span class="p">]))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">():</span>
      <span class="n">ret</span><span class="p">[</span><span class="s1">&#39;sample_ids&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_ids</span>
    <span class="k">return</span> <span class="n">ret</span></div>

<div class="viewcode-block" id="BaseTinyDatasetInput._Preprocess"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseTinyDatasetInput._Preprocess">[docs]</a>  <span class="k">def</span> <span class="nf">_Preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">raw</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">raw</span></div></div>


<div class="viewcode-block" id="TFDataSequenceInputGenerator"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.TFDataSequenceInputGenerator">[docs]</a><span class="k">class</span> <span class="nc">TFDataSequenceInputGenerator</span><span class="p">(</span><span class="n">BaseSequenceInputGenerator</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;tf.data input pipeline for sequences.</span>

<span class="sd">  Inherits params from BaseSequenceInputGenerator so this can be a drop-in</span>
<span class="sd">  replacement for existing input generators inheriting from</span>
<span class="sd">  BaseSequenceInputGenerator. However, many params may be ignored / unused.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="TFDataSequenceInputGenerator.Params"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.TFDataSequenceInputGenerator.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;prefetch_buffer_size&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Local prefetch buffer size.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">resettable</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="TFDataSequenceInputGenerator.CreateDatasource"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.TFDataSequenceInputGenerator.CreateDatasource">[docs]</a>  <span class="k">def</span> <span class="nf">CreateDatasource</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">file_datasource</span><span class="p">:</span>
      <span class="c1"># Convert p.file_pattern into p.file_datasource.</span>
      <span class="n">ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ConvertFilePatternToDataSource</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span><span class="p">)</span>
      <span class="n">p</span><span class="o">.</span><span class="n">file_pattern</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">ds</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">file_datasource</span>

    <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">CustomTFDatasetTransform</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
        <span class="n">sub</span><span class="o">=</span><span class="n">ds</span><span class="p">,</span> <span class="n">fn</span><span class="o">=</span><span class="s1">&#39;TakeEvalSamples&#39;</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">TFDatasetBatchBySequenceLength</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
        <span class="n">sub</span><span class="o">=</span><span class="n">ds</span><span class="p">,</span>
        <span class="n">seqlen_fn</span><span class="o">=</span><span class="s1">&#39;GetSequenceLength&#39;</span><span class="p">,</span>
        <span class="n">input_shape_fn</span><span class="o">=</span><span class="s1">&#39;_InputShape&#39;</span><span class="p">,</span>
        <span class="n">input_padding_fn</span><span class="o">=</span><span class="s1">&#39;_InputPaddingValue&#39;</span><span class="p">,</span>
        <span class="n">bucket_upper_bound</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">bucket_upper_bound</span><span class="p">,</span>
        <span class="n">bucket_batch_limit</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">bucket_batch_limit</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">tf_data_service_address</span><span class="p">:</span>
      <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">TFDataServiceSource</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">sub</span><span class="o">=</span><span class="n">ds</span><span class="p">,</span> <span class="n">bucket_upper_bound</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">bucket_upper_bound</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">TFDatasetPrefetch</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
        <span class="n">sub</span><span class="o">=</span><span class="n">ds</span><span class="p">,</span> <span class="n">buffer_size</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">prefetch_buffer_size</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">file_datasource</span> <span class="o">=</span> <span class="n">ds</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">CreateDatasource</span><span class="p">()</span></div>

<div class="viewcode-block" id="TFDataSequenceInputGenerator.ConvertFilePatternToDataSource"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.TFDataSequenceInputGenerator.ConvertFilePatternToDataSource">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">ConvertFilePatternToDataSource</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">file_pattern</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">file_pattern</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
      <span class="n">file_patterns</span> <span class="o">=</span> <span class="n">file_pattern</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
      <span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">file_pattern</span><span class="p">]):</span>
        <span class="n">file_patterns</span> <span class="o">=</span> <span class="n">file_pattern</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">elif</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">file_pattern</span><span class="p">]):</span>
        <span class="n">file_patterns</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">file_pattern</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s1">&#39;file_pattern must be all strings or all tuples, but got: &#39;</span>
            <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">file_pattern</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">fp</span> <span class="ow">in</span> <span class="n">file_patterns</span><span class="p">:</span>
      <span class="k">if</span> <span class="s1">&#39;,&#39;</span> <span class="ow">in</span> <span class="n">fp</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;file_pattern should not contain comma: </span><span class="si">{</span><span class="n">fp</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">ds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">fp</span> <span class="ow">in</span> <span class="n">file_patterns</span><span class="p">:</span>
      <span class="n">ds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">datasource</span><span class="o">.</span><span class="n">TFDatasetFnInput</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">load_fn</span><span class="o">=</span><span class="s1">&#39;LoadDataset&#39;</span><span class="p">,</span>
          <span class="n">kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">file_pattern</span><span class="o">=</span><span class="n">fp</span><span class="p">),</span>
          <span class="n">shuffle_buffer_size</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">file_buffer_size</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">use_within_batch_mixing</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;Only p.use_within_batch_mixing is supported with multiple &#39;</span>
            <span class="s1">&#39;file_patterns.&#39;</span><span class="p">)</span>
      <span class="n">ds</span> <span class="o">=</span> <span class="p">[</span><span class="n">datasource</span><span class="o">.</span><span class="n">TFDatasetMixer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">sub</span><span class="o">=</span><span class="n">ds</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)]</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">CustomTFDatasetTransform</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
        <span class="n">sub</span><span class="o">=</span><span class="n">ds</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">fn</span><span class="o">=</span><span class="s1">&#39;ProcessDataset&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ds</span></div>

<div class="viewcode-block" id="TFDataSequenceInputGenerator.Reset"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.TFDataSequenceInputGenerator.Reset">[docs]</a>  <span class="k">def</span> <span class="nf">Reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">datasource</span><span class="o">.</span><span class="n">Reset</span><span class="p">(</span><span class="n">sess</span><span class="p">)</span></div>

<div class="viewcode-block" id="TFDataSequenceInputGenerator.GetPreprocessedInputBatch"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.TFDataSequenceInputGenerator.GetPreprocessedInputBatch">[docs]</a>  <span class="k">def</span> <span class="nf">GetPreprocessedInputBatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasource</span><span class="o">.</span><span class="n">GetNext</span><span class="p">()</span></div>

<div class="viewcode-block" id="TFDataSequenceInputGenerator.LoadDataset"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.TFDataSequenceInputGenerator.LoadDataset">[docs]</a>  <span class="k">def</span> <span class="nf">LoadDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_pattern</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Load a dataset from file.</span>

<span class="sd">    Args:</span>
<span class="sd">      file_pattern: the path to the file to load.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tf.data.Dataset() whose elements represent a single training sample</span>
<span class="sd">      without a leading batch dim.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="TFDataSequenceInputGenerator.TakeEvalSamples"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.TFDataSequenceInputGenerator.TakeEvalSamples">[docs]</a>  <span class="k">def</span> <span class="nf">TakeEvalSamples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_samples</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataset</span></div>

<div class="viewcode-block" id="TFDataSequenceInputGenerator.ProcessDataset"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.TFDataSequenceInputGenerator.ProcessDataset">[docs]</a>  <span class="k">def</span> <span class="nf">ProcessDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Processes a dataset returned by LoadDataset.</span>

<span class="sd">    Args:</span>
<span class="sd">      dataset: A dataset returned by LoadDataset.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A processed dataset containing NestedMaps of Tensors without a leading</span>
<span class="sd">      batch dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="TFDataSequenceInputGenerator.GetSequenceLength"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.TFDataSequenceInputGenerator.GetSequenceLength">[docs]</a>  <span class="k">def</span> <span class="nf">GetSequenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">example</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns sequence length for the example NestedMap from the dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">      example: A NestedMap containing an input example. Tensors in the example</span>
<span class="sd">        do not have a leading batch dimension.</span>

<span class="sd">    Returns:</span>
<span class="sd">      An integer sequence length for the example.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="TFDataSequenceInputGenerator._InputShape"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.TFDataSequenceInputGenerator._InputShape">[docs]</a>  <span class="k">def</span> <span class="nf">_InputShape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the final shape of the tensor corresponding to key as a tuple.</span>

<span class="sd">    The shape should not include a leading batch dimension.</span>

<span class="sd">    Args:</span>
<span class="sd">      key: The NestedMap key to return shape for.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;source_id&#39;</span><span class="p">,</span> <span class="s1">&#39;bucket_keys&#39;</span><span class="p">):</span>
      <span class="k">return</span> <span class="p">()</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unexpected key </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">key</span><span class="p">)</span></div>

<div class="viewcode-block" id="TFDataSequenceInputGenerator._InputPaddingValue"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.TFDataSequenceInputGenerator._InputPaddingValue">[docs]</a>  <span class="k">def</span> <span class="nf">_InputPaddingValue</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">tensorspec</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the value to pad the tensor corresponding to key with.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_paddings&#39;</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensorspec</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensorspec</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="BaseDataExampleInputGenerator"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseDataExampleInputGenerator">[docs]</a><span class="k">class</span> <span class="nc">BaseDataExampleInputGenerator</span><span class="p">(</span><span class="n">BaseInputGenerator</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Base class for input generators that read Feature protos via tf.data.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseDataExampleInputGenerator.Params"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseDataExampleInputGenerator.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;input_files&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Delimited glob of input files.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;dataset_type&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;A dataset class constructor such as tf.data.TFRecordDataset. &#39;</span>
        <span class="s1">&#39;The class constructor must take a list of filenames and produce an &#39;</span>
        <span class="s1">&#39;object that extends tf.data.Dataset.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;randomize_order&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;Whether to randomize the order.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;parallel_readers&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Number of parallel reader threads.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_examples&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Number of examples (-1 for unlimited).&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;num_epochs&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="s1">&#39;Number of passes through the data to make (-1 for unlimited).&#39;</span>
        <span class="s1">&#39;`tf.errors.OutOfRangeError` is thrown after the limit is reached.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;randomize_shuffle_size&#39;</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span>
             <span class="s1">&#39;Size of the random shuffle buffer.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">input_files</span><span class="p">,</span> <span class="p">(</span>
        <span class="s1">&#39;input_files is required for a tf.data example input generator&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">dataset_type</span><span class="p">,</span> <span class="p">(</span>
        <span class="s1">&#39;dataset_type is required for a tf.data example input generator&#39;</span><span class="p">)</span>

<div class="viewcode-block" id="BaseDataExampleInputGenerator.GetFeatureSpec"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseDataExampleInputGenerator.GetFeatureSpec">[docs]</a>  <span class="k">def</span> <span class="nf">GetFeatureSpec</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Subclasses must implement and return a feature spec.</span>

<span class="sd">    Returns:</span>
<span class="sd">      NestedMap of features compatible with tf.io.parse_example. Default</span>
<span class="sd">      implementation returns an empty dict.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{}</span></div>

<div class="viewcode-block" id="BaseDataExampleInputGenerator.GetPreprocessedInputBatch"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.BaseDataExampleInputGenerator.GetPreprocessedInputBatch">[docs]</a>  <span class="k">def</span> <span class="nf">GetPreprocessedInputBatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">def</span> <span class="nf">ParseAndProcess</span><span class="p">(</span><span class="o">*</span><span class="n">cols</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Parses a Tensorflow example into features.&quot;&quot;&quot;</span>
      <span class="c1"># Assume either one or two column input. If one, then the record is</span>
      <span class="c1"># assumed to be that column. If 2, then it is assumed to be a KV store</span>
      <span class="c1"># and the record is the second column.</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span>
          <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
      <span class="p">],</span> <span class="p">(</span><span class="s1">&#39;BaseExampleInputGenerator supports one or two column input&#39;</span><span class="p">)</span>
      <span class="n">record</span> <span class="o">=</span> <span class="n">cols</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
      <span class="n">feature_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GetFeatureSpec</span><span class="p">()</span>
      <span class="n">features</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">parse_example</span><span class="p">(</span><span class="n">record</span><span class="p">,</span> <span class="n">feature_spec</span><span class="p">))</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PreprocessInputBatch</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

    <span class="n">dataset_factory</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dataset_type</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">list_files</span><span class="p">(</span>
            <span class="n">p</span><span class="o">.</span><span class="n">input_files</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">randomize_order</span><span class="p">))</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">parallel_interleave</span><span class="p">(</span>
                    <span class="n">dataset_factory</span><span class="p">,</span>
                    <span class="n">cycle_length</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">parallel_readers</span><span class="p">,</span>
                    <span class="n">sloppy</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">randomize_order</span><span class="p">)))</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">randomize_order</span><span class="p">:</span>
      <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">randomize_shuffle_size</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_examples</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">InfeedBatchSize</span><span class="p">(),</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="n">ParseAndProcess</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">parallel_readers</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="n">iterator</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">make_one_shot_iterator</span><span class="p">()</span>
    <span class="n">input_batch</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">input_batch</span></div></div>


<div class="viewcode-block" id="DefineTFDataInput"><a class="viewcode-back" href="../../../lingvo.core.base_input_generator.html#lingvo.core.base_input_generator.DefineTFDataInput">[docs]</a><span class="k">def</span> <span class="nf">DefineTFDataInput</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">ignore_args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">map_args</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Defines a new InputGenerator class from given tf.data pipeline.</span>

<span class="sd">  This function allows users to utilize existing tf.data pipelines which are</span>
<span class="sd">  defined externally, without making binding boilerplates.</span>
<span class="sd">  The generated InputGenerator behaves like a one-shot iterator of the given</span>
<span class="sd">  pipeline. If the iterator is designed to be repeated, the returned</span>
<span class="sd">  InputGenerator will work similarly.</span>
<span class="sd">  This function generates `Params` automatically by analysing the given</span>
<span class="sd">  pipeline&#39;s signature so that the behavior of the pipeline can be saved into</span>
<span class="sd">  `Params`.</span>
<span class="sd">  This function defines the InputGenerator class on the caller&#39;s module. To</span>
<span class="sd">  avoid any confusion, the returned class have to be stored in the module-level</span>
<span class="sd">  symbol with the same identifier with given `name`.</span>

<span class="sd">  Example:</span>
<span class="sd">    &gt;&gt;&gt; # A tf.data pipeline which returns a dict of Tensors.</span>
<span class="sd">    &gt;&gt;&gt; def my_dataset(begin=0, end=10):</span>
<span class="sd">    ...   ds = tf.data.Dataset.from_tensor_slices(tf.range(begin, end))</span>
<span class="sd">    ...   return ds.map(lambda x: {&#39;value&#39;: x})</span>

<span class="sd">    &gt;&gt;&gt; # Defines the InputGenerator class for my_dataset.</span>
<span class="sd">    &gt;&gt;&gt; MyInput = DefineTFDataInput(&#39;MyInput&#39;, my_dataset)</span>

<span class="sd">    &gt;&gt;&gt; # Obtains Params of MyInput.</span>
<span class="sd">    &gt;&gt;&gt; p = MyInput.Params()</span>
<span class="sd">    &gt;&gt;&gt; assert p.args.begin == 0</span>
<span class="sd">    &gt;&gt;&gt; assert p.args.end == 10</span>

<span class="sd">    &gt;&gt;&gt; # Instantiates the InputGenerator from Params.</span>
<span class="sd">    &gt;&gt;&gt; ig = p.Instantiate()</span>
<span class="sd">    &gt;&gt;&gt; assert isinstance(ig, MyInput)</span>

<span class="sd">    &gt;&gt;&gt; # Obtains the data tensors.</span>

<span class="sd">    &gt;&gt;&gt; # In TFv1:</span>
<span class="sd">    &gt;&gt;&gt; data = ig.GetPreprocessedInputBatch()</span>
<span class="sd">    &gt;&gt;&gt; with tf.Session() as sess:</span>
<span class="sd">    ...   values = sess.run(data)  # {&#39;value&#39;: 0}</span>
<span class="sd">    ...   values = sess.run(data)  # {&#39;value&#39;: 1}</span>
<span class="sd">    ...   values = sess.run(data)  # {&#39;value&#39;: 2}</span>

<span class="sd">    &gt;&gt;&gt; # In TFv2:</span>
<span class="sd">    &gt;&gt;&gt; values = ig.GetPreprocessedInputBatch()  # {&#39;value&#39;: 0}</span>
<span class="sd">    &gt;&gt;&gt; values = ig.GetPreprocessedInputBatch()  # {&#39;value&#39;: 1}</span>
<span class="sd">    &gt;&gt;&gt; values = ig.GetPreprocessedInputBatch()  # {&#39;value&#39;: 2}</span>

<span class="sd">  Args:</span>
<span class="sd">    name: A string, representing the name of the new InputGenerator class.</span>
<span class="sd">    func: A callable to be analysed to generate the new InputGenerator. The</span>
<span class="sd">      return value of `func` must be a single `tf.data.Dataset` which yields a</span>
<span class="sd">      dict or its subclasses. The signature (parameter list) of `func` must have</span>
<span class="sd">      all explicit parameters needed to configure the pipeline. `*args` and</span>
<span class="sd">      `**kwargs` parameters would be ignored from defining `Params`.</span>
<span class="sd">    ignore_args: A collection of strings, representing the set of parameter</span>
<span class="sd">      names to be ignored from defining `Params`.</span>
<span class="sd">    map_args: A {str: str} dict, representing mappings from existing fields in</span>
<span class="sd">      `Params()` to `func`&#39;s parameter. These mappings can be used to propagate</span>
<span class="sd">      some particular Lingvo-specific options defined by others (typically by</span>
<span class="sd">      super classes: `BaseInputGenerator` or `BaseLayer`) to the given function.</span>
<span class="sd">      Each entry in the dict represents a `{func_param: layer_param}` pair such</span>
<span class="sd">      that the `Params().layer_param` field will be mapped to the parameter</span>
<span class="sd">      `func_param` of `func`. `func_param` won&#39;t be added into `Params().args`</span>
<span class="sd">      to avoid duplicated definitions about the same parameters.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A new InputGenerator class that invokes `func` internally. The `Params()`</span>
<span class="sd">    method of the returned class makes a new Params containing the `args` field</span>
<span class="sd">    representing the parameters of `func`. The `GetPreprocessedInputBatch()`</span>
<span class="sd">    method returns a `py_utils.NestedMap` representing the same dict of the</span>
<span class="sd">    obtained data from the dataset.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">ignore_args</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">ignore_args</span> <span class="k">if</span> <span class="n">ignore_args</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">())</span>
  <span class="n">map_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">map_args</span> <span class="k">if</span> <span class="n">map_args</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{})</span>

  <span class="c1"># Defines the class first as it will be required to call `super()`.</span>
  <span class="n">generated_cls</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">(</span><span class="n">BaseInputGenerator</span><span class="p">,),</span> <span class="p">{})</span>

  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">_Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generates Params to configure the InputGenerator.</span>

<span class="sd">    This function analyses the signature of the given callable `func` and</span>
<span class="sd">    defines corresponding fields into `Params` to the obtained function</span>
<span class="sd">    parameters.</span>

<span class="sd">    Returns:</span>
<span class="sd">      An `InstantiableParams` object representing the InputGenerator. It has the</span>
<span class="sd">      `args` field which contains the set of parameters of `func`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Keys in `map_args` will also be ignored.</span>
    <span class="n">actual_ignore_args</span> <span class="o">=</span> <span class="n">ignore_args</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span><span class="n">map_args</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">generated_cls</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>

    <span class="c1"># Introduces a new group `args` to avoid confusion between `func`&#39;s</span>
    <span class="c1"># parameters and existing params defined by super classes.</span>
    <span class="c1"># TODO(oday): For better UX, consider removing this nested field and add</span>
    <span class="c1"># `func`s parameters to `p` directly. We need to make sure that there are no</span>
    <span class="c1"># side effects by integrating `func`&#39;s parameters and follows:</span>
    <span class="c1"># - BaseInputGenerator.Params()</span>
    <span class="c1"># - BaseLayer.Params()</span>
    <span class="c1"># - InstantiableParams.cls</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;args&#39;</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span> <span class="s1">&#39;Parameter list of the pipeline.&#39;</span><span class="p">)</span>
    <span class="n">inspect_utils</span><span class="o">.</span><span class="n">DefineParams</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">args</span><span class="p">,</span> <span class="n">actual_ignore_args</span><span class="p">)</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">TFDatasetFnInput</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
        <span class="n">load_fn</span><span class="o">=</span><span class="s1">&#39;GetDataset&#39;</span><span class="p">,</span> <span class="n">shuffle_buffer_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cluster_factory</span><span class="o">.</span><span class="n">Current</span><span class="p">()</span><span class="o">.</span><span class="n">tf_data_service_address</span><span class="p">:</span>
      <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">TFDataServiceSource</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">sub</span><span class="o">=</span><span class="n">ds</span><span class="p">)</span>
      <span class="n">ds</span> <span class="o">=</span> <span class="n">datasource</span><span class="o">.</span><span class="n">TFDatasetPrefetch</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">sub</span><span class="o">=</span><span class="n">ds</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">file_datasource</span> <span class="o">=</span> <span class="n">ds</span>
    <span class="k">return</span> <span class="n">p</span>

  <span class="k">def</span> <span class="nf">_GetDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">overrides</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">Get</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">map_args</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">inspect_utils</span><span class="o">.</span><span class="n">CallWithParams</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">overrides</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">tf1</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">tf2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">)),</span> <span class="p">(</span>
        <span class="s1">&#39;DefineTFDataInput must take a callable which returns a &#39;</span>
        <span class="s1">&#39;`tf.data.Dataset`. The given callable `</span><span class="si">%s</span><span class="s1">` returned `</span><span class="si">%s</span><span class="s1">`&#39;</span> <span class="o">%</span>
        <span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">dataset</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">dataset</span>

  <span class="k">def</span> <span class="nf">_GetPreprocessedInputBatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generates data tensors by invoking the pipeline.&quot;&quot;&quot;</span>
    <span class="c1"># TFv1: Returns Tensors which will be determined by Session.run().</span>
    <span class="c1"># TFv2: Returns Tensors with actual values.</span>
    <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">datasource</span><span class="o">.</span><span class="n">GetNext</span><span class="p">()</span>

    <span class="c1"># Converts dict to NestedMap to maintain consistency with existing</span>
    <span class="c1"># functionalities in base_input_generator.</span>
    <span class="c1"># TODO(oday): Consider mitigating this restriction.</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">),</span> <span class="p">(</span>
        <span class="s1">&#39;DefineTFDataInput accepts only datasets that returns a dict or its &#39;</span>
        <span class="s1">&#39;subclasses.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">):</span>
      <span class="n">data</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="o">.</span><span class="n">FromNestedDict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">data</span>

  <span class="c1"># Overrides member methods.</span>
  <span class="n">generated_cls</span><span class="o">.</span><span class="n">Params</span> <span class="o">=</span> <span class="n">_Params</span>
  <span class="n">generated_cls</span><span class="o">.</span><span class="n">GetDataset</span> <span class="o">=</span> <span class="n">_GetDataset</span>
  <span class="n">generated_cls</span><span class="o">.</span><span class="n">GetPreprocessedInputBatch</span> <span class="o">=</span> <span class="n">_GetPreprocessedInputBatch</span>

  <span class="c1"># Sets __module__ to the caller&#39;s module name for pickling and restoring from</span>
  <span class="c1"># Params to work.</span>
  <span class="c1"># See also the namedtuple&#39;s implementation for details.</span>
  <span class="n">module</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">stack</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">frame</span><span class="o">.</span><span class="n">f_globals</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;__name__&#39;</span><span class="p">,</span> <span class="s1">&#39;__main__&#39;</span><span class="p">)</span>
  <span class="n">generated_cls</span><span class="o">.</span><span class="vm">__module__</span> <span class="o">=</span> <span class="n">module</span>

  <span class="k">return</span> <span class="n">generated_cls</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2018.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>