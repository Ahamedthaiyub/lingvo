

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>lingvo.core.base_model &mdash; Lingvo  documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> Lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../lingvo.html">lingvo package</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>lingvo.core.base_model</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for lingvo.core.base_model</h1><div class="highlight"><pre>
<span></span><span class="c1"># Lint as: python3</span>
<span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;Base model.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="kn">import</span> <span class="nn">lingvo.compat</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">base_input_generator</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">base_layer</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">build_data</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">cluster_factory</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">early_stop</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">hyperparams</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">learner</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">optimizer</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">pruning_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">py_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">schedule</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">summary_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">task_scheduler</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">tpu_embedding_layers</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">decoder_lib</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">input_policy</span>
<span class="kn">from</span> <span class="nn">model_pruning.python</span> <span class="kn">import</span> <span class="n">pruning</span>


<div class="viewcode-block" id="DecodeFinalizeArgs"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.DecodeFinalizeArgs">[docs]</a><span class="k">class</span> <span class="nc">DecodeFinalizeArgs</span><span class="p">(</span>
    <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;DecodeFinalizeArgs&#39;</span><span class="p">,</span>
                           <span class="p">[</span><span class="s1">&#39;decode_out_path&#39;</span><span class="p">,</span> <span class="s1">&#39;decode_out&#39;</span><span class="p">])):</span>
  <span class="sd">&quot;&quot;&quot;Arguments to BaseTask.DecodeFinalize().</span>

<span class="sd">  Attributes:</span>
<span class="sd">   decode_out_path: Path to where decoder outputs can be written.</span>
<span class="sd">   decode_out: A list of key value pairs aggregated from return values of.</span>
<span class="sd">     PostProcessDecodeOut().</span>
<span class="sd">  &quot;&quot;&quot;</span></div>


<div class="viewcode-block" id="_VariablesForEMA"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model._VariablesForEMA">[docs]</a><span class="k">def</span> <span class="nf">_VariablesForEMA</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">model_var_list</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Gets a list of variables that need to apply exponential moving average.&quot;&quot;&quot;</span>
  <span class="c1"># Use variable reference since variable is not hashable in eager mode.</span>
  <span class="n">ref_set</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">variables</span><span class="p">:</span> <span class="nb">set</span><span class="p">([</span><span class="n">v</span><span class="o">.</span><span class="n">ref</span><span class="p">()</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">])</span>

  <span class="n">trainable_variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">model_var_list</span> <span class="k">if</span> <span class="n">var</span><span class="o">.</span><span class="n">trainable</span><span class="p">]</span>

  <span class="c1"># We need to apply EMA to trainable and moving average variable of the task,</span>
  <span class="c1"># not just bprop vars, so that we create a shadow &#39;/ExponentialMovingAverage&#39;</span>
  <span class="c1"># variable for every trainable and moving average variable.</span>
  <span class="n">all_refs</span> <span class="o">=</span> <span class="n">ref_set</span><span class="p">(</span><span class="n">trainable_variables</span><span class="p">)</span> <span class="o">|</span> <span class="n">ref_set</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">moving_average_variables</span><span class="p">())</span>
  <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ema_decay_moving_vars</span><span class="p">:</span>
    <span class="n">all_refs</span> <span class="o">|=</span> <span class="n">ref_set</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;moving_vars&#39;</span><span class="p">))</span>
  <span class="n">all_refs</span> <span class="o">&amp;=</span> <span class="n">ref_set</span><span class="p">(</span><span class="n">model_var_list</span><span class="p">)</span>

  <span class="c1"># Remove TPU embedding variables since TPU embedding doesn&#39;t support EMA.</span>
  <span class="n">tpu_embedding_vars</span> <span class="o">=</span> <span class="p">(</span>
      <span class="n">tpu_embedding_layers</span><span class="o">.</span><span class="n">TpuEmbeddingCollection</span><span class="o">.</span><span class="n">Get</span><span class="p">()</span><span class="o">.</span><span class="n">table_variables</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">tpu_embedding_vars</span><span class="o">.</span><span class="n">Flatten</span><span class="p">():</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
        <span class="s1">&#39;Detected TPU embedding variables, and EMA does not apply to them. &#39;</span>
        <span class="sa">f</span><span class="s1">&#39;List of TPU embedding variables: </span><span class="si">{</span><span class="n">tpu_embedding_vars</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
    <span class="n">all_refs</span> <span class="o">-=</span> <span class="n">ref_set</span><span class="p">(</span><span class="n">tpu_embedding_vars</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

  <span class="n">all_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">deref</span><span class="p">()</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_refs</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">all_vars</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Variables for EMA: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">var</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">all_vars</span></div>


<div class="viewcode-block" id="BaseTask"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask">[docs]</a><span class="k">class</span> <span class="nc">BaseTask</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A single encoder/decoder task.</span>

<span class="sd">  One task usually consists of one InputGenerator, one train_op,</span>
<span class="sd">  a list of eval_metrics, etc.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseTask.Params"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Input generator Params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;encoder&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Encoder Params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;online_encoder&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Online Encoder Params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;decoder&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Decoder Params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;task_global_step&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;Whether or not to use task-specific global steps, which causes each &#39;</span>
        <span class="s1">&#39;task to use its own global_step instead of the true global_step. &#39;</span>
        <span class="s1">&#39;NOTE: this may be severely broken. Verify carefully!&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;defer_global_step_update&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;Whether or not to defer the global step update. This is used when &#39;</span>
        <span class="s1">&#39;doing gradient accumulation, which update the global step only when &#39;</span>
        <span class="s1">&#39;weights are updated. Currently this supports only true global step.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Params to control how this task should be trained.&#39;</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;ml_perf&#39;</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span> <span class="s1">&#39;MlPerf configuration.&#39;</span><span class="p">)</span>

    <span class="n">tp</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">train</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;start_up_delay_steps&#39;</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="s1">&#39;i-th replica starts training after &#39;</span>
        <span class="s1">&#39;i*(i+1)/2*start_up_delay_steps steps&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;max_steps&#39;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">10</span><span class="o">**</span><span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;Maximum number of training steps.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;tpu_steps_per_loop&#39;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;The number of training steps per &#39;</span>
        <span class="s1">&#39;training loop for TPUs. Note that this is not used by &#39;</span>
        <span class="s1">&#39;ExecutorTpu, which relies on ProgramSchedule.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;tpu_device_order_mode&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;A device_assignment_lib.DeviceOrderMode enum that determines whether &#39;</span>
        <span class="s1">&#39;to assign devices in a way that the order of replicas or &#39;</span>
        <span class="s1">&#39;model-parallel cores will form a ring or mesh, or let the library to &#39;</span>
        <span class="s1">&#39;choose. Default None to AUTO.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;tpu_computation_shape&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;A 4-element list that describes how virtual cores (which we specify &#39;</span>
        <span class="s1">&#39;in TF computation) should be mapped to one or more logical cores.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;vn_start_step&#39;</span><span class="p">,</span> <span class="mi">200000000</span><span class="p">,</span>
        <span class="s1">&#39;Step starting from which variational noise is added to &#39;</span>
        <span class="s1">&#39;params values during training.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;vn_std&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;Std of the variational noise.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;early_stop&#39;</span><span class="p">,</span> <span class="n">early_stop</span><span class="o">.</span><span class="n">EarlyStop</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
              <span class="s1">&#39;Early stopping based on dev-set performance.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;ema_decay&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s1">&#39;If &gt; 0, enable ExponentialMovingAverage during training &#39;</span>
        <span class="s1">&#39;with the give decay. &#39;</span>
        <span class="s1">&#39;Must be &lt; 1. Disabled if &lt;= 0. &#39;</span>
        <span class="s1">&#39;Note that TPU embedding does not support EMA, so if used together, &#39;</span>
        <span class="s1">&#39;there will be a mix of EMA and non-EMA variables in the model and the &#39;</span>
        <span class="s1">&#39;quality may be affected, so use them together at your own risk.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;ema_decay_moving_vars&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;If True, include variables from collection &quot;moving_vars&quot; in ema.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;init_from_checkpoint_rules&#39;</span><span class="p">,</span> <span class="p">{},</span>
        <span class="s1">&#39;If not None, a dictionary with keys corresponding to a checkpoint &#39;</span>
        <span class="s1">&#39;path and values corresponding to variable loading rules is expected. &#39;</span>
        <span class="s1">&#39;Each key is expected to be a path to a checkpoint from which to &#39;</span>
        <span class="s1">&#39;initialize part of the model. Variables are only loaded from this &#39;</span>
        <span class="s1">&#39;path during initialization and will override values provided by &#39;</span>
        <span class="s1">&#39;initialization.</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="s1">&#39;The corresponding values (loading_rules) are expected to be a tuple &#39;</span>
        <span class="s1">&#39;consisting of two list: loading rules, and ignore rules, respectively.&#39;</span>
        <span class="s1">&#39;The first list (loading rules) contains the list of variables &#39;</span>
        <span class="s1">&#39;which should be initialized from the checkpoint: each element in the &#39;</span>
        <span class="s1">&#39;list is a pair of strings. The first element is a regex and the &#39;</span>
        <span class="s1">&#39;second is a python format string. If a variable in the model matches &#39;</span>
        <span class="s1">&#39;a regex, we rename using the format string to determine the &#39;</span>
        <span class="s1">&#39;corresponding var in the checkpoint. If a model variable would match &#39;</span>
        <span class="s1">&#39;multiple loading rules, the first rule that matches is used.</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="s1">&#39;The second list (ignore rules) is a list of regexes which specify &#39;</span>
        <span class="s1">&#39;variables in the model which should not be initialized using the &#39;</span>
        <span class="s1">&#39;loading rules. Thus, if a variable in the model to be trained matches &#39;</span>
        <span class="s1">&#39;one of the rules in the loading rules, as well as one of the regular &#39;</span>
        <span class="s1">&#39;expressions in the ignore rules, the variable will not be initialized &#39;</span>
        <span class="s1">&#39;from the checkpoint, but will instead be initialized from the &#39;</span>
        <span class="s1">&#39;variable initalizer defined in the graph.&#39;</span>
        <span class="s1">&#39;Examples:&#39;</span>
        <span class="s1">&#39;{&quot;checkpoint_path&quot;: ([(&quot;(.*)&quot;, &quot;</span><span class="si">%s</span><span class="s1">&quot;)], [])} will initialize all the &#39;</span>
        <span class="s1">&#39;model parameters from the checkpoint_path.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;pruning_hparams_dict&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Pruning related hyperparameters. A dict &#39;</span>
        <span class="s1">&#39;with hyperparameter: value pairs. See google-research.model_pruning.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;enqueue_max_steps&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Max enqueue steps. -1 meaning no limit.&#39;</span>
        <span class="s1">&#39; This flag should be set for unit-test only.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;save_interval_seconds&#39;</span><span class="p">,</span> <span class="mi">60</span> <span class="o">*</span> <span class="mi">10</span><span class="p">,</span>
              <span class="s1">&#39;Generates a checkpoint roughly once every this many seconds.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;save_interval_steps&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;Generates a checkpoint roughly once every this many training &#39;</span>
        <span class="s1">&#39;steps. Supersedes save_interval_seconds if not None.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;save_max_to_keep&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span>
              <span class="s1">&#39;Maximum number of recent checkpoints to keep.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;save_keep_checkpoint_every_n_hours&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span>
              <span class="s1">&#39;How often to keep a checkpoint.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;async_checkpointing&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
              <span class="s1">&#39;Checkpointing asynchronously. Currently only support executor.&#39;</span><span class="p">)</span>

    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;summary_interval_steps&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span>
              <span class="s1">&#39;Generates a summary roughly once every this many steps.&#39;</span><span class="p">)</span>
    <span class="c1"># The following params must mirror those in Learner.Params().</span>
    <span class="c1"># TODO(rpang): migrate existing params to use learner and</span>
    <span class="c1"># delete legacy params.</span>
    <span class="c1"># LINT.IfChange</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;learner&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;One or a list of optimization programs. &#39;</span>
        <span class="s1">&#39;If None, uses a Learner created from the legacy params &#39;</span>
        <span class="s1">&#39;defined below: learning_rate, lr_schedule, optimizer, etc.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;l2_regularizer_weight&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;If not None, L2 regularization to apply to the weights. &#39;</span>
        <span class="s1">&#39;Otherwise, disable L2 regularization.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;l1_regularizer_weight&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;If not None, L1 regularization to apply to the weights. &#39;</span>
        <span class="s1">&#39;Otherwise, disable L1 regularization.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;learning rate to use.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;clip_gradient_norm_to_value&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s1">&#39;Clip gradient by global norm to this value. This is similar to &#39;</span>
        <span class="s1">&#39;the bahaviour of tf.clip_by_global_norm, if you are looking for &#39;</span>
        <span class="s1">&#39;tf.clip_by_norm refer to clip_gradient_single_norm_to_value. Note &#39;</span>
        <span class="s1">&#39;these are mutually exclusive.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;clip_gradient_single_norm_to_value&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s1">&#39;Clip gradient by single tensor norm to this value. This is &#39;</span>
        <span class="s1">&#39;similar to the bahaviour of tf.clip_by_norm. Note this is mutually &#39;</span>
        <span class="s1">&#39;exlusive to using clip_gradient_norm_to_value.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;grad_norm_to_clip_to_zero&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
              <span class="s1">&#39;Clip gradient to 0 if its norm exceeds this value.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;grad_norm_tracker&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Params for GradNormTracker.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">Adam</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span> <span class="s1">&#39;Params for the optimizer.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;lr_schedule&#39;</span><span class="p">,</span> <span class="n">schedule</span><span class="o">.</span><span class="n">ContinuousSchedule</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
              <span class="s1">&#39;Learning rate decay schedule.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;bprop_variable_filter&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;If set, only backprop variables whose names partially match &#39;</span>
        <span class="s1">&#39;this regexp (re.search).&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;bprop_variable_exclusion&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;If set, do not backprop variables whose names partially match &#39;</span>
        <span class="s1">&#39;this regexp (re.search).&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;grad_aggregation_method&#39;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">AggregationMethod</span><span class="o">.</span><span class="n">EXPERIMENTAL_TREE</span><span class="p">,</span>
        <span class="s1">&#39;Specifies the method used to combine gradient terms. Accepted &#39;</span>
        <span class="s1">&#39;values are constants defined in the class AggregationMethod.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;gate_gradients&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;If True, add a tuple around the gradients returned for an &#39;</span>
        <span class="s1">&#39;operations. This avoids some race conditions.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;colocate_gradients_with_ops&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
              <span class="s1">&#39;If True, try colocating gradients with the corresponding op.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;scale_gradients&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
              <span class="s1">&#39;Whether to apply gradients adjustment and scaling.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;learner_use_variable_scope&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;Create children of learner in tf.variable_scope. This may need &#39;</span>
        <span class="s1">&#39;to be set to False for compatibility with the existing &#39;</span>
        <span class="s1">&#39;checkpoints trained from legacy code. New models should always &#39;</span>
        <span class="s1">&#39;set this to True.&#39;</span><span class="p">)</span>
    <span class="c1"># LINT.ThenChange(learner.py)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;eval&#39;</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Params to control how this task should be evaled.&#39;</span><span class="p">)</span>
    <span class="n">ep</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">eval</span>
    <span class="n">ep</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;samples_per_summary&#39;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="s1">&#39;If &gt; 0, generates one summary after this many samples, at most. &#39;</span>
        <span class="s1">&#39;If == 0 or the dataset has fewer examples, evaluate the whole set.&#39;</span><span class="p">)</span>
    <span class="n">ep</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;decoder_samples_per_summary&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;If &gt; 0, each decoder summary will contain at most this many samples. &#39;</span>
        <span class="s1">&#39;If None, defaults to the actual value of `p.eval.samples_per_summary` &#39;</span>
        <span class="s1">&#39;for backwards compatibility.&#39;</span><span class="p">)</span>
    <span class="n">ep</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;load_checkpoint_from&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
        <span class="s1">&#39;If not Empty, specifies a location for the checkpoint that &#39;</span>
        <span class="s1">&#39;should be used for eval. One example format is a &#39;</span>
        <span class="s1">&#39;checkpoint directory of a training run.&#39;</span><span class="p">)</span>
    <span class="n">ep</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;start_eval_after&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
              <span class="s1">&#39;Start evaluation after specified number of steps.&#39;</span><span class="p">)</span>
    <span class="n">ep</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;start_decoder_after&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
              <span class="s1">&#39;Only decode checkpoints after this step.&#39;</span><span class="p">)</span>
    <span class="n">ep</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;eval_all_checkpoints&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;Compute evaluation metrics for every checkpoint saved by the Trainer.&#39;</span><span class="p">)</span>
    <span class="n">ep</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;decode_all_checkpoints&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;Compute decoder metrics for every checkpoint saved by the Trainer.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="BaseTask.UpdateTargetVocabSize"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.UpdateTargetVocabSize">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">UpdateTargetVocabSize</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">wpm_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Updates params with the vocab size and wpm model.</span>

<span class="sd">    Args:</span>
<span class="sd">      p: model params.</span>
<span class="sd">      vocab_size: size of the vocabulary.</span>
<span class="sd">      wpm_model: file name prefix pointing to a wordpiece model.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Model params updated with the vocab size and wpm model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dp</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">decoder</span>
    <span class="n">p</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">dp</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">UpdateTargetVocabSize</span><span class="p">(</span><span class="n">dp</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">wpm_model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">cls</span><span class="p">,</span> <span class="n">BaseTask</span><span class="p">)</span>
    <span class="c1"># Ensure global_step exists before calling super.</span>
    <span class="n">py_utils</span><span class="o">.</span><span class="n">GetOrCreateGlobalStepVar</span><span class="p">()</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_encoder</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_online_encoder</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_decoder</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_train_op</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_post_train_ops</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_eval_metrics</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_per_example</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Create the gradient mask,</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_gradient_mask</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">task_global_step</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">GetGlobalVariableScope</span><span class="p">()):</span>
        <span class="n">var_name</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_global_step&#39;</span>
        <span class="c1"># Create the variable immediately.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_CreateVariableInternal</span><span class="p">(</span>
            <span class="n">var_name</span><span class="p">,</span>
            <span class="n">base_layer</span><span class="o">.</span><span class="n">CreateVariableMeta</span><span class="p">(</span>
                <span class="n">var_params</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
                    <span class="p">[],</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                    <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">collections</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">GLOBAL_VARIABLES</span><span class="p">])))</span>
        <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="n">var_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_private_vars</span><span class="p">[</span><span class="n">var_name</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_private_vars</span><span class="p">[</span><span class="n">var_name</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetOrCreateGlobalStepVar</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="p">:</span>
      <span class="c1"># TODO(zhifengc): Consider a simpler way to ensure the input</span>
      <span class="c1"># generator stops after one epoch.</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">eval</span><span class="p">:</span>
        <span class="n">seq_inp</span> <span class="o">=</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">cls</span><span class="p">,</span>
                             <span class="n">base_input_generator</span><span class="o">.</span><span class="n">BaseInputGeneratorFromFiles</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
          <span class="k">if</span> <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">eval</span><span class="o">.</span><span class="n">samples_per_summary</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">&lt;</span>
                                                   <span class="n">p</span><span class="o">.</span><span class="n">eval</span><span class="o">.</span><span class="n">samples_per_summary</span><span class="p">):</span>
            <span class="n">p</span><span class="o">.</span><span class="n">eval</span><span class="o">.</span><span class="n">samples_per_summary</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">num_samples</span>
            <span class="c1"># If we know the dataset size and we want to evaluate the full</span>
            <span class="c1"># set, we need to coordinate the input generator to flush out</span>
            <span class="c1"># all samples so the evaler and decoder compute metrics on the</span>
            <span class="c1"># whole set for each summary step.</span>
            <span class="k">if</span> <span class="n">seq_inp</span><span class="p">:</span>
              <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">flush_every_n</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">num_samples</span>
          <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">eval</span><span class="o">.</span><span class="n">decoder_samples_per_summary</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span>
              <span class="n">p</span><span class="o">.</span><span class="n">eval</span><span class="o">.</span><span class="n">decoder_samples_per_summary</span> <span class="o">&gt;</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">num_samples</span><span class="p">):</span>
            <span class="n">p</span><span class="o">.</span><span class="n">eval</span><span class="o">.</span><span class="n">decoder_samples_per_summary</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">num_samples</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">eval_samples_per_summary</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">p</span><span class="o">.</span><span class="n">eval</span><span class="o">.</span><span class="n">samples_per_summary</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">eval_samples_per_summary</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">decoder_samples_per_summary</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">p</span><span class="o">.</span><span class="n">eval</span><span class="o">.</span><span class="n">decoder_samples_per_summary</span> <span class="o">=</span> <span class="p">(</span>
              <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">decoder_samples_per_summary</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">resettable</span><span class="p">:</span>
          <span class="c1"># Dataset size is unknown. Computes eval summary based on num_samples.</span>
          <span class="c1"># We require static dataset size for non-resettable inputs.</span>
          <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">eval</span><span class="o">.</span><span class="n">samples_per_summary</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">seq_inp</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">num_batcher_threads</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;input.num_batcher_threads &gt; 1 inside eval mode.  &#39;</span>
                             <span class="s1">&#39;The input generator may not iterate over exactly &#39;</span>
                             <span class="s1">&#39;one epoch per run&#39;</span><span class="p">)</span>
      <span class="n">input_params</span> <span class="o">=</span> <span class="n">input_policy</span><span class="o">.</span><span class="n">Apply</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;input_params: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">input_params</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="n">input_params</span><span class="p">)</span>

    <span class="n">tp</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">train</span>

    <span class="c1"># p.train can be None if this task is the teacher/student task in a</span>
    <span class="c1"># DistillationTask.</span>
    <span class="k">if</span> <span class="n">tp</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_SetLearnerFromLegacyParams</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">tp</span><span class="o">.</span><span class="n">learner</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tp</span><span class="o">.</span><span class="n">learner</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">CreateChildren</span><span class="p">(</span><span class="s1">&#39;learners&#39;</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">learner</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">CreateChildren</span><span class="p">(</span><span class="s1">&#39;learners&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">tp</span><span class="o">.</span><span class="n">learner</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_UpdateVnConfig</span><span class="p">()</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">tp</span> <span class="ow">and</span> <span class="n">tp</span><span class="o">.</span><span class="n">pruning_hparams_dict</span> <span class="ow">and</span>
        <span class="n">pruning_utils</span><span class="o">.</span><span class="n">UsePruningInterface</span><span class="p">(</span><span class="n">tp</span><span class="o">.</span><span class="n">pruning_hparams_dict</span><span class="p">)):</span>
      <span class="n">pruning_utils</span><span class="o">.</span><span class="n">PruningOp</span><span class="o">.</span><span class="n">Setup</span><span class="p">(</span><span class="n">tp</span><span class="o">.</span><span class="n">pruning_hparams_dict</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_step</span><span class="p">)</span>

<div class="viewcode-block" id="BaseTask.InstantiateVariables"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.InstantiateVariables">[docs]</a>  <span class="k">def</span> <span class="nf">InstantiateVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GlobalStepContext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span><span class="p">):</span>
      <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span></div>

<div class="viewcode-block" id="BaseTask._SetLearnerFromLegacyParams"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask._SetLearnerFromLegacyParams">[docs]</a>  <span class="k">def</span> <span class="nf">_SetLearnerFromLegacyParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tp</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets tp.learner based on legacy params.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">tp</span><span class="o">.</span><span class="n">learner</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">learner</span> <span class="o">=</span> <span class="n">learner</span><span class="o">.</span><span class="n">ExtractLearnerFromLegacyParams</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask.ComputePredictions"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.ComputePredictions">[docs]</a>  <span class="k">def</span> <span class="nf">ComputePredictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes predictions for `input_batch`.</span>

<span class="sd">    The output can be in the form of probablistic distributions, e.g., softmax</span>
<span class="sd">    logits for discrete outputs, mixture of logistics for continuous values, or</span>
<span class="sd">    regression values.</span>

<span class="sd">    For training/evaluation, the output will be used for computing loss and</span>
<span class="sd">    gradient updates, including comparing predicted distributions between</span>
<span class="sd">    teacher and student for distillation. During inference the output can be</span>
<span class="sd">    used to compute final outputs, perhaps with sampling.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing variable values of this task.</span>
<span class="sd">      input_batch: A `.NestedMap` object containing input tensors to this tower.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Predictions, either a single Tensor, a `.NestedMap`, or a namedtuple.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask.ComputeLoss"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.ComputeLoss">[docs]</a>  <span class="k">def</span> <span class="nf">ComputeLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes loss and other metrics for the given predictions.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing variable values of this task.</span>
<span class="sd">      predictions: The output of `ComputePredictions`.</span>
<span class="sd">      input_batch: A `.NestedMap` object containing input tensors to this tower.</span>

<span class="sd">    Returns:</span>
<span class="sd">      (dict, dict):</span>

<span class="sd">      - A dict containing str keys and (metric, weight) pairs as values, where</span>
<span class="sd">        one of the keys is expected to be &#39;loss&#39;.</span>
<span class="sd">      - A dict containing arbitrary tensors describing something about each</span>
<span class="sd">        training example, where the first dimension of each tensor is the batch</span>
<span class="sd">        index.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask.FilterPerExampleTensors"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.FilterPerExampleTensors">[docs]</a>  <span class="k">def</span> <span class="nf">FilterPerExampleTensors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">per_example</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return the per-example tensors ProcessFPropResults needs.</span>

<span class="sd">    By default we don&#39;t send any per-example tensors to ProcessFPropResults</span>
<span class="sd">    because some may be expensive to compute. Implement this method to let</span>
<span class="sd">    some of them pass through.</span>

<span class="sd">    Args:</span>
<span class="sd">      per_example: A dict of tensors returned as per-example tensors from FProp.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A dict containing a subset of the key/value pairs in per_example.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{}</span></div>

<div class="viewcode-block" id="BaseTask.ProcessFPropResults"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.ProcessFPropResults">[docs]</a>  <span class="k">def</span> <span class="nf">ProcessFPropResults</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">per_example</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called once for each train loop.</span>

<span class="sd">    BaseModel.ProcessFPropResults is also called on each loop, so you</span>
<span class="sd">    can put your implementation wherever it is most convenient for you.</span>

<span class="sd">    Be sure to implement BaseTask.FilterPerExampleTensors if you plan to use any</span>
<span class="sd">    per-example tensors in this method.</span>

<span class="sd">    Args:</span>
<span class="sd">      sess: a session.</span>
<span class="sd">      global_step: task global step. Since ProcessFPropResults is called after</span>
<span class="sd">        sess.run(train_op), this value will be p.train.tpu_steps_per_loop higher</span>
<span class="sd">        than the value in FProp.</span>
<span class="sd">      metrics: the metrics dict returned by FPropTower.</span>
<span class="sd">      per_example: the per_example dict returned by FPropTower.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">tp</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">train</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">tp</span><span class="o">.</span><span class="n">pruning_hparams_dict</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="k">if</span> <span class="n">pruning_utils</span><span class="o">.</span><span class="n">PruningOp</span><span class="o">.</span><span class="n">ApplyPythonUpdate</span><span class="p">():</span>
      <span class="n">pruning_utils</span><span class="o">.</span><span class="n">PruningOp</span><span class="o">.</span><span class="n">RunPythonUpdate</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">global_step</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask.FPropTower"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.FPropTower">[docs]</a>  <span class="k">def</span> <span class="nf">FPropTower</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Forward propagation through one tower of the model.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing variable values of this task</span>
<span class="sd">        copied to this tower&#39;s devices.</span>
<span class="sd">      input_batch: A `.NestedMap` object containing input tensors to this tower.</span>

<span class="sd">    Returns:</span>
<span class="sd">      (dict, dict):</span>

<span class="sd">      - A dict containing str keys and (metric, weight) pairs as values, where</span>
<span class="sd">        one of the keys is expected to be &#39;loss&#39;.</span>
<span class="sd">      - A dict containing arbitrary tensors describing something about each</span>
<span class="sd">        training example, where the first dimension of each tensor is the batch</span>
<span class="sd">        index.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ComputePredictions</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ComputeLoss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask.FProp"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Forward propagation.</span>

<span class="sd">    This default `FProp` implementation here supports batch splitting in</span>
<span class="sd">    synchronous and asynchronous training when sub-classes implement</span>
<span class="sd">    `FPropTower`.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      input_batch: The input batch. A `NestedMap` of tensors. Or, if input batch</span>
<span class="sd">        spiltting is used, a list of `NestedMap`, one for each split.</span>

<span class="sd">    Returns:</span>
<span class="sd">      (dict, dict):</span>

<span class="sd">      - A dict containing str keys and (metric, weight) pairs as values, where</span>
<span class="sd">        one of the keys is expected to be &#39;loss&#39;.</span>
<span class="sd">      - A dict containing arbitrary tensors describing something about each</span>
<span class="sd">        training example, where the first dimension of each tensor is the batch</span>
<span class="sd">        index.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;fprop&#39;</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span>
        <span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">),</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">TaskCallScope</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="k">with</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GlobalStepContext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span><span class="p">):</span>
        <span class="c1"># Always reset step seed at the start of a new global_step.</span>
        <span class="n">py_utils</span><span class="o">.</span><span class="n">ResetStepSeed</span><span class="p">()</span>
        <span class="n">metrics</span><span class="p">,</span> <span class="n">per_example</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_FPropSplitInputBatch</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_FPropResult</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">per_example</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">per_example</span></div>

<div class="viewcode-block" id="BaseTask._FPropTpu"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask._FPropTpu">[docs]</a>  <span class="k">def</span> <span class="nf">_FPropTpu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;tower_0_0&#39;</span><span class="p">):</span>
      <span class="n">metrics</span><span class="p">,</span> <span class="n">per_example</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">FPropTower</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">)</span>
      <span class="n">metrics</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightedAvgOfMetrics</span><span class="p">([</span><span class="n">metrics</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">per_example</span></div>

<div class="viewcode-block" id="BaseTask._FPropSplitInputBatch"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask._FPropSplitInputBatch">[docs]</a>  <span class="k">def</span> <span class="nf">_FPropSplitInputBatch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Splits the input batch on the input device.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">():</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_FPropTpu</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">)</span>

    <span class="n">num_splits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_splits_per_client</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_batch</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
      <span class="n">input_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_batch</span><span class="p">]</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_batch</span><span class="p">)</span> <span class="o">==</span> <span class="n">num_splits</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_batch</span><span class="p">),</span> <span class="n">num_splits</span><span class="p">)</span>

    <span class="c1"># dev_list_per_replica[i][j] is the i-th worker&#39;s j-th device.</span>
    <span class="n">dev_list_per_replica</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">available_devices</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="c1"># Asserts invariant of the total number of splits w.r.t.,</span>
    <span class="c1"># splits per worker.</span>
    <span class="n">splits_per_replica</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_splits_per_replica</span>
    <span class="k">assert</span> <span class="n">num_splits</span> <span class="o">==</span> <span class="n">splits_per_replica</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dev_list_per_replica</span><span class="p">),</span> <span class="p">(</span>
        <span class="n">num_splits</span><span class="p">,</span> <span class="n">splits_per_replica</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dev_list_per_replica</span><span class="p">))</span>

    <span class="n">all_metrics</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_per_example_tensors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">w_id</span><span class="p">,</span> <span class="n">w_devs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dev_list_per_replica</span><span class="p">):</span>
        <span class="c1"># Make local copy of the vars, shard on devices for this worker.</span>
        <span class="n">theta_local</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">CreateLocalTheta</span><span class="p">(</span>
            <span class="n">theta</span><span class="p">,</span> <span class="n">w_devs</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;worker </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">w_id</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">s_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">splits_per_replica</span><span class="p">):</span>
          <span class="c1"># s_id-th split for the w_id-th worker.</span>
          <span class="n">split_id</span> <span class="o">=</span> <span class="n">splits_per_replica</span> <span class="o">*</span> <span class="n">w_id</span> <span class="o">+</span> <span class="n">s_id</span>
          <span class="k">with</span> <span class="n">cluster_factory</span><span class="o">.</span><span class="n">SetModelSplit</span><span class="p">(</span><span class="n">split_id</span><span class="p">)</span> <span class="k">as</span> <span class="n">c</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">WorkerDeviceInModelSplit</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
              <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;tower_</span><span class="si">%d</span><span class="s1">_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">w_id</span><span class="p">,</span> <span class="n">s_id</span><span class="p">)):</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="n">input_batch</span><span class="p">[</span><span class="n">split_id</span><span class="p">]</span>
                <span class="n">metrics</span><span class="p">,</span> <span class="n">per_example</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">FPropTower</span><span class="p">(</span><span class="n">theta_local</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
          <span class="n">all_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
          <span class="n">all_per_example_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">per_example</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightedAvgOfMetrics</span><span class="p">(</span>
        <span class="n">all_metrics</span><span class="p">),</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ConcatPerExampleTensors</span><span class="p">(</span><span class="n">all_per_example_tensors</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask._FPropResult"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask._FPropResult">[docs]</a>  <span class="k">def</span> <span class="nf">_FPropResult</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">per_example</span><span class="p">):</span>
    <span class="c1"># Adds stats about the input batch.</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s1">&#39;num_samples_in_batch&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
      <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;num_samples_in_batch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">input_generator</span><span class="o">.</span><span class="n">GlobalBatchSize</span><span class="p">()),</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
    <span class="c1"># Generates summaries.</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">AddEvalMetric</span><span class="p">(</span>
          <span class="n">name</span><span class="p">,</span>
          <span class="n">value</span><span class="p">,</span>
          <span class="n">weight</span><span class="p">,</span>
          <span class="n">raise_if_already_added</span><span class="o">=</span><span class="ow">not</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">IsEagerMode</span><span class="p">())</span>
    <span class="n">per_example</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">FilterPerExampleTensors</span><span class="p">(</span><span class="n">per_example</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">per_example</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">AddPerExampleTensor</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="c1"># Loss.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">,</span> <span class="n">num_predictions</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">CheckNumerics</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_metrics</span> <span class="o">=</span> <span class="n">metrics</span>
    <span class="k">if</span> <span class="s1">&#39;num_predictions&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
      <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;num_predictions&#39;</span><span class="p">,</span> <span class="n">num_predictions</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask.GetInputBatch"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.GetInputBatch">[docs]</a>  <span class="k">def</span> <span class="nf">GetInputBatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Gets an input batch.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">():</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_generator</span><span class="o">.</span><span class="n">TpuDequeueBatch</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_generator</span><span class="o">.</span><span class="n">SplitInputBatch</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">num_splits_per_client</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask.FPropDefaultTheta"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.FPropDefaultTheta">[docs]</a>  <span class="k">def</span> <span class="nf">FPropDefaultTheta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls `FProp` with this layer&#39;s parameters.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">input_batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">input_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GetInputBatch</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask.AdjustGradients"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.AdjustGradients">[docs]</a>  <span class="k">def</span> <span class="nf">AdjustGradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vars_gradients</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Allow for custom gradient manipulation prior to clipping.&quot;&quot;&quot;</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;BaseTask.AdjustGradients&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">vars_gradients</span></div>

<div class="viewcode-block" id="BaseTask.PostTrainingLoop"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.PostTrainingLoop">[docs]</a>  <span class="k">def</span> <span class="nf">PostTrainingLoop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outfeed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Construct the post training loop op.</span>

<span class="sd">    Args:</span>
<span class="sd">      outfeed: a dict of tensors dequeued from TPU outfeed queue.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GlobalStepContext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_post_training_loop_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span>
          <span class="o">*</span><span class="p">[</span><span class="n">opt</span><span class="o">.</span><span class="n">ApplyPostTrainingLoop</span><span class="p">()</span> <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">learners</span><span class="p">])</span></div>

<div class="viewcode-block" id="BaseTask.BProp"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.BProp">[docs]</a>  <span class="k">def</span> <span class="nf">BProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GlobalStepContext</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span><span class="p">),</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">TaskCallScope</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_BPropForVariables</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask._BPropGenTrainOps"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask._BPropGenTrainOps">[docs]</a>  <span class="k">def</span> <span class="nf">_BPropGenTrainOps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vmap</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">add_summary</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Populates the train_ops dictionary in a backwards pass.&quot;&quot;&quot;</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">metrics</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metrics</span>

    <span class="n">bprop_variable_filters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_generator</span><span class="o">.</span><span class="n">GetBpropVariableFilters</span><span class="p">()</span>
    <span class="c1"># Only compute the mask if the variable filters are not empty.</span>
    <span class="k">if</span> <span class="n">bprop_variable_filters</span> <span class="o">!=</span> <span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">bprop_variable_filters</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_ComputeGradientMask</span><span class="p">(</span><span class="n">bprop_variable_filters</span><span class="p">)</span>
    <span class="n">train_ops</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># mapping from op name to op.</span>
    <span class="n">gradient_mask</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_gradient_mask</span><span class="p">:</span>
      <span class="c1"># TODO(neerajgaur): Change this to use source_selected from input_batch.</span>
      <span class="n">onehot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_generator</span><span class="o">.</span><span class="n">GetInputSourceOneHot</span><span class="p">()</span>
      <span class="n">gradient_mask</span> <span class="o">=</span> <span class="p">{</span>
          <span class="n">k</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">onehot</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_gradient_mask</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
      <span class="p">}</span>
    <span class="n">all_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">optimization</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">learners</span><span class="p">:</span>
      <span class="n">learner_name</span> <span class="o">=</span> <span class="n">optimization</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">name</span>
      <span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">train_ops</span><span class="p">[</span><span class="s1">&#39;train/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">learner_name</span><span class="p">],</span>
       <span class="n">eval_metrics</span><span class="p">)</span> <span class="o">=</span> <span class="n">optimization</span><span class="o">.</span><span class="n">Apply</span><span class="p">(</span>
           <span class="n">metrics</span><span class="p">,</span>
           <span class="n">vmap</span><span class="p">,</span>
           <span class="n">gradient_mask</span><span class="o">=</span><span class="n">gradient_mask</span><span class="p">,</span>
           <span class="n">gradient_adjuster</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">AdjustGradients</span><span class="p">)</span>
      <span class="n">all_losses</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">add_summary</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="ow">in</span> <span class="n">eval_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">AddEvalMetric</span><span class="p">(</span>
              <span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">learner_name</span><span class="p">,</span>
              <span class="n">value</span><span class="p">,</span>
              <span class="n">weight</span><span class="p">,</span>
              <span class="n">raise_if_already_added</span><span class="o">=</span><span class="ow">not</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">IsEagerMode</span><span class="p">())</span>

    <span class="n">relevant_bn_updates</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">FindRelevantBatchNormUpdates</span><span class="p">(</span>
        <span class="n">all_losses</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">BATCH_NORM_UPDATES</span><span class="p">))</span>
    <span class="n">train_ops</span><span class="p">[</span><span class="s1">&#39;bn_updates&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">relevant_bn_updates</span>

    <span class="n">var_update_ops</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">train_ops</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;var_update_ops&#39;</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="c1"># Post training step update.</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">var_update_ops</span><span class="p">):</span>
      <span class="n">post_step_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">PostTrainingStepUpdate</span><span class="p">()</span>

    <span class="n">train_ops</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">post_step_op</span><span class="p">]):</span>
      <span class="c1"># Get the op to update the weight masks and thresholds</span>
      <span class="n">mask_update_op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetMaskUpdateOp</span><span class="p">()</span>
      <span class="n">train_ops</span><span class="p">[</span><span class="s1">&#39;mask_updates&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_update_op</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">mask_update_op</span><span class="p">]):</span>
        <span class="n">true_global_step</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetOrCreateGlobalStepVar</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">colocate_with</span><span class="p">(</span><span class="n">true_global_step</span><span class="p">):</span>
          <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">defer_global_step_update</span><span class="p">:</span>
            <span class="n">increment_global_steps</span> <span class="o">=</span> <span class="n">true_global_step</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">increment_global_steps</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="n">true_global_step</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># TF2 will treat (tensor1 != tensor2) as a boolean tensor, so avoid</span>
        <span class="c1"># using inequality here.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">true_global_step</span><span class="p">:</span>
          <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">colocate_with</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span><span class="p">):</span>
            <span class="n">increment_global_steps</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span>
                <span class="n">increment_global_steps</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">train_ops</span><span class="p">[</span><span class="s1">&#39;global_step&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">increment_global_steps</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">IsEagerMode</span><span class="p">():</span>
      <span class="c1"># Some of the values could be a tf.no_op(), which returns None in eager</span>
      <span class="c1"># mode, so we don&#39;t want to check that when eager is enabled.</span>
      <span class="k">for</span> <span class="n">op_name</span><span class="p">,</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">train_ops</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">op</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Train op </span><span class="si">{</span><span class="n">op_name</span><span class="si">}</span><span class="s1"> is None.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_ops</span></div>

<div class="viewcode-block" id="BaseTask._BPropForVariables"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask._BPropForVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_BPropForVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vmap</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs the backward graph.&quot;&quot;&quot;</span>
    <span class="n">train_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_BPropGenTrainOps</span><span class="p">(</span><span class="n">vmap</span><span class="p">)</span>

    <span class="c1"># TODO(rpang): try to structure _train_op as:</span>
    <span class="c1">#   tf.cond(skip_step, &lt;only update skip stats&gt;, &lt;all updates&gt;)</span>
    <span class="c1"># so that we skip all other updates when a step is skipped.</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span>
        <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">train_ops</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;train_ops&#39;</span><span class="p">)]):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_post_train_ops</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;bprop&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask._ComputeGradientMask"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask._ComputeGradientMask">[docs]</a>  <span class="k">def</span> <span class="nf">_ComputeGradientMask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bprop_variable_filters</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute gradient mask for each variable and bprop_variable_filters.</span>

<span class="sd">    Note that per_input_gradient_mask[var][i] will be 1 if var matches</span>
<span class="sd">    bprop_variable_filter[i], 0 otherwise.</span>

<span class="sd">    Args:</span>
<span class="sd">      bprop_variable_filters: A list of regex bprop_variable_filters for each</span>
<span class="sd">        file pattern.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_gradient_mask</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>
    <span class="n">all_vars</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">all_vars</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_gradient_mask</span><span class="p">[</span><span class="n">var</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bprop_variable_filters</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bprop_variable_filters</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">bprop_variable_filters</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">var</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Keep gradient after filtering, regex: </span><span class="si">%s</span><span class="s1"> var: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
                          <span class="p">(</span><span class="n">bprop_variable_filters</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">var</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_gradient_mask</span><span class="p">[</span><span class="n">var</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bprop_variable_filters</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span></div>

<div class="viewcode-block" id="BaseTask.ApplyExponentialMovingAverage"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.ApplyExponentialMovingAverage">[docs]</a>  <span class="k">def</span> <span class="nf">ApplyExponentialMovingAverage</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ema</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wraps `self.train_op` with an op updating exponential moving average.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_create_variables_status</span> <span class="o">!=</span>
        <span class="n">base_layer</span><span class="o">.</span><span class="n">_CreateLayerVariablesStatus</span><span class="o">.</span><span class="n">COMPLETED</span><span class="p">):</span>  <span class="c1"># pylint: disable=protected-access</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s1">&#39;ApplyExponentialMovingAverage called before InstantiateVariables!&#39;</span><span class="p">)</span>
    <span class="c1"># TODO(rpang): raise an exception if this is called in the eval mode.</span>
    <span class="n">all_vars</span> <span class="o">=</span> <span class="n">_VariablesForEMA</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;moving_average&#39;</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_post_train_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ema</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">all_vars</span><span class="p">))</span></div>

  <span class="c1"># TODO(blee): Rename Decode-&gt;DecodeWithDefaultTheta, DecodeWithTheta-&gt;Decode.</span>
<div class="viewcode-block" id="BaseTask.Decode"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.Decode">[docs]</a>  <span class="k">def</span> <span class="nf">Decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs the inference graph for eval decoding.</span>

<span class="sd">    Args:</span>
<span class="sd">      input_batch: The input batch. A `NestedMap` of tensors. Or, if input batch</span>
<span class="sd">        spiltting is used, a list of `NestedMap`, one for each split.</span>

<span class="sd">    Returns:</span>
<span class="sd">      a dict of Tensors as decoder output.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">DecodeWithTheta</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask.DecodeWithTheta"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.DecodeWithTheta">[docs]</a>  <span class="k">def</span> <span class="nf">DecodeWithTheta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">input_batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs the inference graph for eval decoding with theta.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing variable values of this task.</span>
<span class="sd">      input_batch: The input batch. A `NestedMap` of tensors. Or, if input batch</span>
<span class="sd">        spiltting is used, a list of `NestedMap`, one for each split.</span>

<span class="sd">    Returns:</span>
<span class="sd">      a dict of Tensors as decoder output.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{}</span></div>

<div class="viewcode-block" id="BaseTask.Inference"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.Inference">[docs]</a>  <span class="k">def</span> <span class="nf">Inference</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs the inference graph.</span>

<span class="sd">    Each subgraph represents a public API for a part of the graph which can</span>
<span class="sd">    be operated independently. By convention, the subgraph named &#39;default&#39;</span>
<span class="sd">    should perform end to end inference via the input generator.</span>

<span class="sd">    Note that having distinct subgraphs (e.g. &#39;encoder&#39;, &#39;decoder&#39;) is</span>
<span class="sd">    not just a space optimization: when driving the graph externally in an</span>
<span class="sd">    online fashion, evaluation often needs to be broken into pieces. In this</span>
<span class="sd">    case, the graph will be constructed with only those pieces.</span>

<span class="sd">    Returns:</span>
<span class="sd">      An `inference_graph_pb2.InferenceGraph` message.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask.CreateDecoderMetrics"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.CreateDecoderMetrics">[docs]</a>  <span class="k">def</span> <span class="nf">CreateDecoderMetrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a dict of decoder metrics for `PostProcessDecodeOut` to update.</span>

<span class="sd">    Returns a dict mapping from string keys to `.BaseMetric` objects.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span></div>

<div class="viewcode-block" id="BaseTask.PostProcessDecodeOut"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.PostProcessDecodeOut">[docs]</a>  <span class="k">def</span> <span class="nf">PostProcessDecodeOut</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">decode_out_dict</span><span class="p">,</span> <span class="n">decode_metrics_dict</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Post-processes decoder out and updates contents of `decode_metrics_dict`.</span>

<span class="sd">    Args:</span>
<span class="sd">      decode_out_dict: A dictionary of Tensors fetched.</span>
<span class="sd">      decode_metrics_dict: A dict mapping from string key to `.BaseMetric`</span>
<span class="sd">        object as created by `CreateDecoderMetrics`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      output_key_value_pairs - a list of (key, value) pairs that can be saved</span>
<span class="sd">      (i.e. of type str, bytes, or unicode).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span></div>

<div class="viewcode-block" id="BaseTask.DecodeFinalize"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.DecodeFinalize">[docs]</a>  <span class="k">def</span> <span class="nf">DecodeFinalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">decode_finalize_args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Finalize any work for decoding.</span>

<span class="sd">    Args:</span>
<span class="sd">      decode_finalize_args: A DecodeFinalizeArgs namedtuple.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">decode_out_path</span> <span class="o">=</span> <span class="n">decode_finalize_args</span><span class="o">.</span><span class="n">decode_out_path</span>
    <span class="n">decode_out</span> <span class="o">=</span> <span class="n">decode_finalize_args</span><span class="o">.</span><span class="n">decode_out</span>
    <span class="k">if</span> <span class="n">decode_out</span><span class="p">:</span>
      <span class="n">decoder_lib</span><span class="o">.</span><span class="n">WriteKeyValuePairs</span><span class="p">(</span><span class="n">decode_out_path</span><span class="p">,</span> <span class="n">decode_out</span><span class="p">)</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;No loss is defined. Call FProp first.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">train_op</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_op</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
        <span class="s1">&#39;No train op is defined. Call BProp first.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_op</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">post_training_loop_op</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_training_loop_op</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
        <span class="s1">&#39;No post_training_loop_op op is defined. Call PostTrainingLoop first.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_training_loop_op</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">global_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">input_generator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">eval_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the evaluation metrics.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A map from metric name (a python string) to a tuple (value, weight).</span>
<span class="sd">      Both value and weight are scalar Tensors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_metrics</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">per_example_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns per-example outputs.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A map from tensor name (a python string) to a tensor, where the</span>
<span class="sd">      first dimension is the batch index of the training example corresponding</span>
<span class="sd">      to this output.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_example</span>

<div class="viewcode-block" id="BaseTask.AddEvalMetric"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.AddEvalMetric">[docs]</a>  <span class="k">def</span> <span class="nf">AddEvalMetric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">raise_if_already_added</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds a metric to the eval metrics.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: A python string. The name of the metric.</span>
<span class="sd">      value: A scalar Tensor.</span>
<span class="sd">      weight: A scalar Tensor.</span>
<span class="sd">      raise_if_already_added: If the metric already exists, raise a ValueError.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: if `name` is already defined.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_metrics</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">raise_if_already_added</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Metric </span><span class="si">%s</span><span class="s1"> has already been defined.&#39;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_eval_metrics</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTask.AddPerExampleTensor"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.AddPerExampleTensor">[docs]</a>  <span class="k">def</span> <span class="nf">AddPerExampleTensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_example</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">(</span>
    <span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">IsEagerMode</span><span class="p">():</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Metric </span><span class="si">%s</span><span class="s1"> has already been defined.&#39;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_per_example</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span></div>

<div class="viewcode-block" id="BaseTask._UpdateVnConfig"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask._UpdateVnConfig">[docs]</a>  <span class="k">def</span> <span class="nf">_UpdateVnConfig</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update vn config from the various vn flags.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">tp</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">train</span>
    <span class="k">if</span> <span class="n">tp</span><span class="p">:</span>
      <span class="n">vn_enabled</span> <span class="o">=</span> <span class="p">((</span><span class="n">tp</span><span class="o">.</span><span class="n">vn_std</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">vn</span> <span class="ow">and</span>
                    <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span><span class="p">))</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">vn_enabled</span><span class="p">):</span>
        <span class="n">p</span><span class="o">.</span><span class="n">vn</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">VariationalNoiseParams</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="c1"># vn.scale is dependent on global_step.</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;A value should not be specified for p.vn.scale. &#39;</span>
                           <span class="s1">&#39;It will be overwritten by p.train.vn_std.&#39;</span><span class="p">)</span>
        <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span> <span class="o">&gt;</span> <span class="n">tp</span><span class="o">.</span><span class="n">vn_start_step</span><span class="p">,</span>
                             <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="o">*</span> <span class="n">tp</span><span class="o">.</span><span class="n">vn_std</span></div>

<div class="viewcode-block" id="BaseTask._GetMaskUpdateOp"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask._GetMaskUpdateOp">[docs]</a>  <span class="k">def</span> <span class="nf">_GetMaskUpdateOp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns op to update masks and threshold variables for model pruning.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">tp</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">train</span>
    <span class="n">mask_update_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">no_op</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">tp</span><span class="o">.</span><span class="n">pruning_hparams_dict</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tp</span><span class="o">.</span><span class="n">pruning_hparams_dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
      <span class="n">pruning_hparams</span> <span class="o">=</span> <span class="n">pruning</span><span class="o">.</span><span class="n">get_pruning_hparams</span><span class="p">()</span><span class="o">.</span><span class="n">override_from_dict</span><span class="p">(</span>
          <span class="n">tp</span><span class="o">.</span><span class="n">pruning_hparams_dict</span><span class="p">)</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">pruning_utils</span><span class="o">.</span><span class="n">UsePruningInterface</span><span class="p">(</span><span class="n">tp</span><span class="o">.</span><span class="n">pruning_hparams_dict</span><span class="p">):</span>
        <span class="n">pruning_obj</span> <span class="o">=</span> <span class="n">pruning</span><span class="o">.</span><span class="n">Pruning</span><span class="p">(</span>
            <span class="n">pruning_hparams</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetGlobalStep</span><span class="p">())</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">add_summary</span><span class="p">:</span>
          <span class="n">pruning_obj</span><span class="o">.</span><span class="n">add_pruning_summaries</span><span class="p">()</span>
        <span class="n">mask_update_op</span> <span class="o">=</span> <span class="n">pruning_obj</span><span class="o">.</span><span class="n">conditional_mask_update_op</span><span class="p">()</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">pruning_utils</span><span class="o">.</span><span class="n">UsePruningInterface</span><span class="p">(</span><span class="n">tp</span><span class="o">.</span><span class="n">pruning_hparams_dict</span><span class="p">)</span> <span class="ow">and</span>
          <span class="n">pruning_utils</span><span class="o">.</span><span class="n">PruningOp</span><span class="o">.</span><span class="n">ApplyTensorflowUpdate</span><span class="p">()):</span>
        <span class="n">mask_update_op</span> <span class="o">=</span> <span class="n">pruning_utils</span><span class="o">.</span><span class="n">PruningOp</span><span class="o">.</span><span class="n">GetPruningUpdate</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">mask_update_op</span></div>

<div class="viewcode-block" id="BaseTask.Export"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseTask.Export">[docs]</a>  <span class="k">def</span> <span class="nf">Export</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_dir</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called by an eval job before evaluation.</span>

<span class="sd">    Can be used to write additional information to disk.</span>

<span class="sd">    Args:</span>
<span class="sd">      train_dir: Directory in which any additional files should be saved. This</span>
<span class="sd">        is also the same directory where checkpoints will be written.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span></div></div>


<div class="viewcode-block" id="BaseModel"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseModel">[docs]</a><span class="k">class</span> <span class="nc">BaseModel</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;The abstract model class. All models are sub-class of this class.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseModel.Params"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseModel.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Which python function generates the param. It includes &#39;</span>
        <span class="s1">&#39;the file name and lineno where the function is defined.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;cluster&#39;</span><span class="p">,</span> <span class="n">cluster_factory</span><span class="o">.</span><span class="n">Cluster</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
        <span class="s1">&#39;The training cluster. Individual layer may config differently&#39;</span>
        <span class="s1">&#39; based on training cluster it is running under.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;input&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Input generator Params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;build_data&#39;</span><span class="p">,</span> <span class="n">build_data</span><span class="o">.</span><span class="n">BuildData</span><span class="p">(),</span> <span class="s1">&#39;Build data of this binary.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Params to control how this model should be trained.&#39;</span><span class="p">)</span>

    <span class="n">tp</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">train</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;start_up_delay_steps&#39;</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="s1">&#39;i-th replica starts training after &#39;</span>
        <span class="s1">&#39;i*(i+1)/2*start_up_delay_steps steps&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;max_steps&#39;</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">10</span><span class="o">**</span><span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;Training max of 4M steps.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;tpu_steps_per_loop&#39;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;The number of training steps per &#39;</span>
              <span class="s1">&#39;training loop for TPUs.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;tpu_device_order_mode&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;A device_assignment_lib.DeviceOrderMode enum that determines whether &#39;</span>
        <span class="s1">&#39;to assign devices in a way that the order of replicas or &#39;</span>
        <span class="s1">&#39;model-parallel cores will form a ring or mesh, or let the library to &#39;</span>
        <span class="s1">&#39;choose. Default None to AUTO.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;tpu_computation_shape&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;A 4-element list that describes how virtual cores (which we specify &#39;</span>
        <span class="s1">&#39;in TF computation) should be mapped to one or more logical cores.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;ema_decay&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s1">&#39;If &gt; 0, enable ExponentialMovingAverage during training &#39;</span>
        <span class="s1">&#39;with the give decay. &#39;</span>
        <span class="s1">&#39;Must be &lt; 1. Disabled if &lt;= 0. &#39;</span>
        <span class="s1">&#39;Must be set consistent across all tasks.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;ema_decay_moving_vars&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;If True, include variables from collection &quot;moving_vars&quot; in ema. &#39;</span>
        <span class="s1">&#39;Must be set consistent across all tasks.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;init_from_checkpoint_rules&#39;</span><span class="p">,</span> <span class="p">{},</span>
              <span class="s1">&#39;See BaseTask documentation for details.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;early_stop&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
              <span class="s1">&#39;Early stopping based on dev-set performance.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;enqueue_max_steps&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Max enqueue steps. -1 meaning no limit.&#39;</span>
        <span class="s1">&#39; This flag should be set for unit-test only.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;save_interval_seconds&#39;</span><span class="p">,</span> <span class="mi">60</span> <span class="o">*</span> <span class="mi">10</span><span class="p">,</span>
              <span class="s1">&#39;Generates a checkpoint roughly once every this many seconds.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;save_interval_steps&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;Generates a checkpoint roughly once every this many training &#39;</span>
        <span class="s1">&#39;steps. Supersedes save_interval_seconds if not None.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;save_max_to_keep&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span>
              <span class="s1">&#39;Maximum number of recent checkpoints to keep.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;save_keep_checkpoint_every_n_hours&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span>
              <span class="s1">&#39;How often to keep a checkpoint.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;summary_interval_steps&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span>
              <span class="s1">&#39;Generates a checkpoint roughly once every this many steps.&#39;</span><span class="p">)</span>
    <span class="n">tp</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;async_checkpointing&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
              <span class="s1">&#39;Checkpointing asynchronously. Currently only support executor.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes this Model.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">cls</span><span class="p">,</span> <span class="n">BaseModel</span><span class="p">)</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Training parameters for </span><span class="si">%s</span><span class="s1">: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">cls</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">train</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetOrCreateGlobalStepVar</span><span class="p">()</span>

    <span class="n">tp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">train</span>
    <span class="k">if</span> <span class="n">tp</span><span class="o">.</span><span class="n">ema_decay</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">assert</span> <span class="n">tp</span><span class="o">.</span><span class="n">ema_decay</span> <span class="o">&lt;</span> <span class="mf">1.0</span>
      <span class="c1"># Use the global EMA if set (for multi-task training).</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_ema</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ExponentialMovingAverage</span><span class="p">()</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ema</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ema</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ExponentialMovingAverage</span><span class="p">(</span>
            <span class="n">decay</span><span class="o">=</span><span class="n">tp</span><span class="o">.</span><span class="n">ema_decay</span><span class="p">,</span> <span class="n">num_updates</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">global_step</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">assert</span> <span class="ow">not</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ExponentialMovingAverage</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_ema</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">global_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_step_var</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">ema</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ema</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">variables_for_ema</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_VariablesForEMA</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

<div class="viewcode-block" id="BaseModel.ConstructFPropBPropGraph"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseModel.ConstructFPropBPropGraph">[docs]</a>  <span class="k">def</span> <span class="nf">ConstructFPropBPropGraph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseModel.ConstructFPropGraph"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseModel.ConstructFPropGraph">[docs]</a>  <span class="k">def</span> <span class="nf">ConstructFPropGraph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseModel.ConstructPostTrainingLoop"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseModel.ConstructPostTrainingLoop">[docs]</a>  <span class="k">def</span> <span class="nf">ConstructPostTrainingLoop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outfeed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">tasks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a list of all tasks.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span>

<div class="viewcode-block" id="BaseModel.GetTask"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseModel.GetTask">[docs]</a>  <span class="k">def</span> <span class="nf">GetTask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_name</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return the task associated with &#39;task_name&#39;.</span>

<span class="sd">    Args:</span>
<span class="sd">      task_name: string, the name of the model task to be returned.</span>

<span class="sd">    Returns:</span>
<span class="sd">      An instance of `BaseTask`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseModel.ProcessFPropResults"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseModel.ProcessFPropResults">[docs]</a>  <span class="k">def</span> <span class="nf">ProcessFPropResults</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">per_example</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called once for each train loop.</span>

<span class="sd">    BaseTask.ProcessFPropResults is also called on each loop, so you</span>
<span class="sd">    can put your implementation wherever it is most convenient for you.</span>

<span class="sd">    Be sure to implement BaseTask.FilterPerExampleTensors if you plan to use any</span>
<span class="sd">    per-example tensors in this method.</span>

<span class="sd">    Args:</span>
<span class="sd">      sess: a session.</span>
<span class="sd">      global_step: model global step. Since ProcessFPropResults is called after</span>
<span class="sd">        sess.run(train_op), this value will be p.train.tpu_steps_per_loop higher</span>
<span class="sd">        than the value in FProp.</span>
<span class="sd">      metrics: the metrics dict returned by FPropTower.</span>
<span class="sd">      per_example: the per_example dict returned by FPropTower.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span></div>

<div class="viewcode-block" id="BaseModel.Export"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.BaseModel.Export">[docs]</a>  <span class="k">def</span> <span class="nf">Export</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_dir</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called by an eval job after evaluation.</span>

<span class="sd">    Can be used to write additional information to CNS.</span>

<span class="sd">    Args:</span>
<span class="sd">      train_dir: Directory in which any additional files should be saved. This</span>
<span class="sd">        is also the same directory where checkpoints will be written.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tasks</span><span class="p">:</span>
      <span class="n">task</span><span class="o">.</span><span class="n">Export</span><span class="p">(</span><span class="n">train_dir</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="SingleTaskBase"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.SingleTaskBase">[docs]</a><span class="k">class</span> <span class="nc">SingleTaskBase</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Represents a single task from a model.</span>

<span class="sd">  Subclasses must create a Task in self._task by the end of __init__.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">tasks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_task</span><span class="p">]</span>

<div class="viewcode-block" id="SingleTaskBase.GetTask"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.SingleTaskBase.GetTask">[docs]</a>  <span class="k">def</span> <span class="nf">GetTask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">task_name</span><span class="p">,</span> <span class="s1">&#39;Must not specify &gt;task_name&lt; for single-task model.&#39;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task</span></div>

<div class="viewcode-block" id="SingleTaskBase.SampleTask"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.SingleTaskBase.SampleTask">[docs]</a>  <span class="k">def</span> <span class="nf">SampleTask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">global_step</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task</span></div>

<div class="viewcode-block" id="SingleTaskBase.ConstructFPropBPropGraph"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.SingleTaskBase.ConstructFPropBPropGraph">[docs]</a>  <span class="k">def</span> <span class="nf">ConstructFPropBPropGraph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;ApplyExponentialMovingAverage on </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_task</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_task</span><span class="o">.</span><span class="n">ApplyExponentialMovingAverage</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_task</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_task</span><span class="o">.</span><span class="n">BProp</span><span class="p">()</span></div>

<div class="viewcode-block" id="SingleTaskBase.ConstructFPropGraph"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.SingleTaskBase.ConstructFPropGraph">[docs]</a>  <span class="k">def</span> <span class="nf">ConstructFPropGraph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_task</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">()</span></div>

<div class="viewcode-block" id="SingleTaskBase.ConstructPostTrainingLoop"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.SingleTaskBase.ConstructPostTrainingLoop">[docs]</a>  <span class="k">def</span> <span class="nf">ConstructPostTrainingLoop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outfeed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_task</span><span class="o">.</span><span class="n">PostTrainingLoop</span><span class="p">(</span><span class="n">outfeed</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="SingleTaskModel"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.SingleTaskModel">[docs]</a><span class="k">class</span> <span class="nc">SingleTaskModel</span><span class="p">(</span><span class="n">SingleTaskBase</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Model that consists of a single task.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="SingleTaskModel.Params"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.SingleTaskModel.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">task_params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;task&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;`InstantiableParams` object for a `BaseTask` or its derivatives.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">task_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># Copy over model parameters from the task parameters.</span>
      <span class="n">p</span><span class="o">.</span><span class="n">task</span> <span class="o">=</span> <span class="n">task_params</span>
      <span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="o">.</span><span class="n">CopyBaseParams</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
      <span class="n">tp</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">train</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">start_up_delay_steps</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">start_up_delay_steps</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">max_steps</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">tpu_steps_per_loop</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">tpu_steps_per_loop</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">tpu_device_order_mode</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">tpu_device_order_mode</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">tpu_computation_shape</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">tpu_computation_shape</span>
      <span class="c1"># init_from_checkpoint_rules does not need to be copied.</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">early_stop</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">early_stop</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">enqueue_max_steps</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">enqueue_max_steps</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">save_interval_seconds</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">save_interval_seconds</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">save_interval_steps</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">save_interval_steps</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">save_max_to_keep</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">save_max_to_keep</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">save_keep_checkpoint_every_n_hours</span> <span class="o">=</span> <span class="p">(</span>
          <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">save_keep_checkpoint_every_n_hours</span><span class="p">)</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">summary_interval_steps</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">summary_interval_steps</span>
      <span class="n">tp</span><span class="o">.</span><span class="n">async_checkpointing</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">async_checkpointing</span>

    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">cls</span><span class="p">,</span> <span class="n">SingleTaskModel</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">params</span><span class="o">.</span><span class="n">task</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>  <span class="c1"># Make a copy to avoid modifying the input.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">name</span>
    <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">name</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="p">:</span>
      <span class="k">assert</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">input</span>
      <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">input</span><span class="p">:</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Model input generator is not defined&#39;</span><span class="p">)</span>
      <span class="n">p</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">input</span>
    <span class="n">p</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ema_decay</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ema_decay</span>
    <span class="n">p</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ema_decay_moving_vars</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ema_decay_moving_vars</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;_task&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">task</span><span class="p">)</span>

<div class="viewcode-block" id="SingleTaskModel._CreateChildrenVariables"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.SingleTaskModel._CreateChildrenVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateChildrenVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Backwards compatibility: manually call child.InstantiateVariables()</span>
    <span class="c1"># outside of tf.variable_scope(p.name).</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_task</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateChildrenVariables</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="MultiTaskSubModel"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.MultiTaskSubModel">[docs]</a><span class="k">class</span> <span class="nc">MultiTaskSubModel</span><span class="p">(</span><span class="n">SingleTaskBase</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;&#39;Model&#39; consisting of a task from a multi-task model.</span>

<span class="sd">  The entire multi-task model is constructed, but otherwise this model</span>
<span class="sd">  appears to be a SingleTaskModel consisting of just one of the multi-task</span>
<span class="sd">  model&#39;s tasks.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="MultiTaskSubModel.Params"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.MultiTaskSubModel.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;multi_task_sub_model&#39;</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;task_name&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;The name of the task to execute from the &#39;</span>
             <span class="s1">&#39;enclosing model.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">shared_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">shared_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_task</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">children</span><span class="o">.</span><span class="n">Get</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">task_name</span><span class="p">)</span></div>


<div class="viewcode-block" id="MultiTaskModel"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.MultiTaskModel">[docs]</a><span class="k">class</span> <span class="nc">MultiTaskModel</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Model that consists of multiple tasks.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="MultiTaskModel.Params"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.MultiTaskModel.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;task_params&#39;</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
        <span class="s1">&#39;Params object mapping task name to `BaskTask`(or derivatives) &#39;</span>
        <span class="s1">&#39;Params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;task_probs&#39;</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
        <span class="s1">&#39;Params object mapping task name to the relative likelihood the &#39;</span>
        <span class="s1">&#39;task will be sampled during training.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;task_schedule&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Task schedule.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;task_global_step&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;Whether or not to use task-specific global steps, which causes each &#39;</span>
        <span class="s1">&#39;task to use its own global_step instead of the true global_step. &#39;</span>
        <span class="s1">&#39;NOTE: this may be severely broken. Verify carefully!&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;task_name_var_scope&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;Whether or not to use the task name as a variable scope. Note that &#39;</span>
        <span class="s1">&#39;this has been the default behavior for some time, but seems to be &#39;</span>
        <span class="s1">&#39;redundant since the individual tasks scope by their `name`.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;share_model_object&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;If true, during training we create the model object once and share &#39;</span>
        <span class="s1">&#39;it between all tasks.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="MultiTaskModel.TaskNames"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.MultiTaskModel.TaskNames">[docs]</a>  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">TaskNames</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">task_name</span> <span class="k">for</span> <span class="n">task_name</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">task_params</span><span class="o">.</span><span class="n">IterParams</span><span class="p">())</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">cls</span><span class="p">,</span> <span class="n">MultiTaskModel</span><span class="p">)</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">task_params</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>

    <span class="n">sorted_task_params</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
        <span class="p">(</span><span class="n">task_name</span><span class="p">,</span> <span class="n">task_params</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">task_name</span><span class="p">,</span> <span class="n">task_params</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">task_params</span><span class="o">.</span><span class="n">IterParams</span><span class="p">())</span>

    <span class="c1"># Pass input params to tasks.</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">task_name</span><span class="p">,</span> <span class="n">task_params</span> <span class="ow">in</span> <span class="n">sorted_task_params</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">task_params</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">)</span>
      <span class="k">assert</span> <span class="ow">not</span> <span class="n">task_params</span><span class="o">.</span><span class="n">input</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">task_params</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">Get</span><span class="p">(</span><span class="n">task_name</span><span class="p">)</span>
      <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
            <span class="s1">&#39;Missing input params for task </span><span class="si">%s</span><span class="s1"> !&#39;</span>
            <span class="s1">&#39;Check that you have the correct datasets &#39;</span>
            <span class="s1">&#39;passed to DefineMultitaskDatasets.&#39;</span><span class="p">,</span> <span class="n">task_name</span><span class="p">)</span>
        <span class="k">raise</span> <span class="n">e</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">task_global_step</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">task_name</span> <span class="o">==</span> <span class="n">task_params</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="p">(</span><span class="n">task_name</span><span class="p">,</span> <span class="n">task_params</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="n">task_params</span><span class="o">.</span><span class="n">task_global_step</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="nb">dir</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">input</span><span class="p">))</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="nb">dir</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">task_params</span><span class="p">))</span>

    <span class="c1"># For compatibility with older API (with p.task_probs)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">task_schedule</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">task_schedule</span> <span class="o">=</span> <span class="n">task_scheduler</span><span class="o">.</span><span class="n">ConstantScheduler</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">p</span><span class="o">.</span><span class="n">task_schedule</span><span class="o">.</span><span class="n">task_probs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">task_probs</span><span class="o">.</span><span class="n">IterParams</span><span class="p">()))</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ema_decay</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">task_name</span><span class="p">,</span> <span class="n">task_params</span> <span class="ow">in</span> <span class="n">sorted_task_params</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;ema_decay&#39;</span><span class="p">,</span> <span class="s1">&#39;ema_decay_moving_vars&#39;</span><span class="p">]:</span>
          <span class="k">if</span> <span class="n">task_params</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Get</span><span class="p">(</span><span class="n">field</span><span class="p">)</span> <span class="o">!=</span> <span class="n">p</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Get</span><span class="p">(</span><span class="n">field</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Params did not match for field </span><span class="si">%s</span><span class="s1"> in task </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
                             <span class="p">(</span><span class="n">field</span><span class="p">,</span> <span class="n">task_name</span><span class="p">))</span>

    <span class="c1"># CreateChild copies over global configs in p to individual task params,</span>
    <span class="c1"># which then gets propagated down to all sub-layers during</span>
    <span class="c1"># BaseTask._PropagateDownGlobalConfigs(), or through sub-sequent CreateChild</span>
    <span class="c1"># or CreateChildren calls.</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">task_name</span><span class="p">,</span> <span class="n">task_params</span> <span class="ow">in</span> <span class="n">sorted_task_params</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="n">task_name</span><span class="p">,</span> <span class="n">task_params</span><span class="p">)</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;task_schedule&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">task_schedule</span><span class="p">)</span>

<div class="viewcode-block" id="MultiTaskModel._CreateChildrenVariables"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.MultiTaskModel._CreateChildrenVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateChildrenVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">task_name</span><span class="p">,</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">task_names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tasks</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">task_name_var_scope</span><span class="p">:</span>
          <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">task_name</span><span class="p">):</span>
            <span class="n">task</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">task</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">task_schedule</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateChildrenVariables</span><span class="p">()</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">task_names</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">MultiTaskModel</span><span class="o">.</span><span class="n">TaskNames</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">tasks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_names</span><span class="p">]</span>

<div class="viewcode-block" id="MultiTaskModel.GetTask"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.MultiTaskModel.GetTask">[docs]</a>  <span class="k">def</span> <span class="nf">GetTask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task_name</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">task_name</span><span class="p">,</span> <span class="s1">&#39;Must specify &gt;task_name&lt; for multi-task model.&#39;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="n">task_name</span><span class="p">]</span></div>

<div class="viewcode-block" id="MultiTaskModel.SampleTask"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.MultiTaskModel.SampleTask">[docs]</a>  <span class="k">def</span> <span class="nf">SampleTask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">global_step</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a sampled task according to self.task_schedule.</span>

<span class="sd">    `self.task_schedule.cur_probs` will also be updated.</span>

<span class="sd">    Args:</span>
<span class="sd">      global_step: int. Current time step.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sampled_task</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_schedule</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span><span class="n">global_step</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Sampled task: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">sampled_task</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="n">sampled_task</span><span class="p">]</span></div>

<div class="viewcode-block" id="MultiTaskModel.ConstructFPropBPropGraph"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.MultiTaskModel.ConstructFPropBPropGraph">[docs]</a>  <span class="k">def</span> <span class="nf">ConstructFPropBPropGraph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">task_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_names</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">task_name</span><span class="p">):</span>
        <span class="n">task</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GetTask</span><span class="p">(</span><span class="n">task_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">:</span>
          <span class="n">task</span><span class="o">.</span><span class="n">ApplyExponentialMovingAverage</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">)</span>
        <span class="n">task</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">()</span>
        <span class="n">task</span><span class="o">.</span><span class="n">BProp</span><span class="p">()</span></div>

<div class="viewcode-block" id="MultiTaskModel.ConstructFPropGraph"><a class="viewcode-back" href="../../../lingvo.core.base_model.html#lingvo.core.base_model.MultiTaskModel.ConstructFPropGraph">[docs]</a>  <span class="k">def</span> <span class="nf">ConstructFPropGraph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">task_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_names</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">task_name</span><span class="p">):</span>
        <span class="n">task</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GetTask</span><span class="p">(</span><span class="n">task_name</span><span class="p">)</span>
        <span class="n">task</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">()</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2018.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>