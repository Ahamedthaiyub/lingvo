

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>lingvo.core.conv_layers_with_time_padding &mdash; Lingvo  documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> Lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../lingvo.html">lingvo package</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>lingvo.core.conv_layers_with_time_padding</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for lingvo.core.conv_layers_with_time_padding</h1><div class="highlight"><pre>
<span></span><span class="c1"># Lint as: python3</span>
<span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;Common conv layers.</span>

<span class="sd">WARNING: Strided convolutions are buggy. Consider using v2_padding=True.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">copy</span>

<span class="kn">import</span> <span class="nn">lingvo.compat</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">activations</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">base_layer</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">bn_layers</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">py_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">quant_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">symbolic</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">tshape</span>

<span class="n">ActivationLayer</span> <span class="o">=</span> <span class="n">activations</span><span class="o">.</span><span class="n">ActivationLayer</span>


<div class="viewcode-block" id="ComputeConvOutputShape"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.ComputeConvOutputShape">[docs]</a><span class="k">def</span> <span class="nf">ComputeConvOutputShape</span><span class="p">(</span><span class="n">in_shape</span><span class="p">,</span>
                           <span class="n">t_stride</span><span class="p">,</span>
                           <span class="n">f_stride</span><span class="p">,</span>
                           <span class="n">outc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                           <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes output shape for convolution and pooling layers.</span>

<span class="sd">  If `in_shape` is a dynamic shape, the output will be Tensors, while if</span>
<span class="sd">  `in_shape` is a list of ints then the output will also be a list of ints.</span>

<span class="sd">  Args:</span>
<span class="sd">    in_shape: A length 4 Tensor or list representing the input shape.</span>
<span class="sd">    t_stride: The stride along the time dimension.</span>
<span class="sd">    f_stride: The stride along the frequency dimension.</span>
<span class="sd">    outc: The expected output channel. If None, will use the input channel.</span>
<span class="sd">    padding: &#39;SAME&#39; or &#39;VALID&#39;.</span>

<span class="sd">  Returns:</span>
<span class="sd">    The expected output shape.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># In the order of batch, time, frequency, channel</span>
  <span class="n">n</span> <span class="o">=</span> <span class="n">in_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">in_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">f</span> <span class="o">=</span> <span class="n">in_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">in_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
  <span class="c1"># Last two dimensions has to be specified.</span>
  <span class="k">assert</span> <span class="n">f</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">c</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
  <span class="k">if</span> <span class="n">padding</span> <span class="o">==</span> <span class="s1">&#39;VALID&#39;</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">t</span><span class="p">:</span>
      <span class="n">t</span> <span class="o">-=</span> <span class="n">t_stride</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">f</span> <span class="o">-=</span> <span class="n">f_stride</span> <span class="o">-</span> <span class="mi">1</span>
  <span class="n">ot</span> <span class="o">=</span> <span class="n">t</span>
  <span class="k">if</span> <span class="n">ot</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ot</span> <span class="o">=</span> <span class="p">(</span><span class="n">ot</span> <span class="o">+</span> <span class="n">t_stride</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">t_stride</span>
  <span class="n">of</span> <span class="o">=</span> <span class="p">(</span><span class="n">f</span> <span class="o">+</span> <span class="n">f_stride</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">f_stride</span>
  <span class="k">if</span> <span class="n">outc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">outc</span> <span class="o">=</span> <span class="n">c</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">ot</span><span class="p">,</span> <span class="n">of</span><span class="p">,</span> <span class="n">outc</span><span class="p">]</span></div>


<div class="viewcode-block" id="ComputeConvOutputPadding"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.ComputeConvOutputPadding">[docs]</a><span class="k">def</span> <span class="nf">ComputeConvOutputPadding</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span>
                             <span class="n">window</span><span class="p">,</span>
                             <span class="n">stride</span><span class="p">,</span>
                             <span class="n">padding_algorithm</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span>
                             <span class="n">v2_padding</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes paddings for convolution and pooling output.</span>

<span class="sd">  WARNING: This implementation is buggy prefer using ComputeConvOutputPaddingV2.</span>

<span class="sd">  out_padding[i] == 1 iff any in_padding corresponding to that output is 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    paddings: The paddings tensor. It is expected to be of shape [batch, time].</span>
<span class="sd">    window: The size of the windows.</span>
<span class="sd">    stride: The time-stride between adjacent windows.</span>
<span class="sd">    padding_algorithm: &#39;SAME&#39; or &#39;VALID&#39;.</span>
<span class="sd">    v2_padding: Prefer setting to True. The default implementation is buggy for</span>
<span class="sd">      strided convolutions.</span>

<span class="sd">  Returns:</span>
<span class="sd">    out_padding, The new padding tensor of size [batch, ceil(time / stride)].</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">v2_padding</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">_ComputeConvOutputPaddingV2</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span>
                                       <span class="n">padding_algorithm</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">stride</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">paddings</span>

  <span class="c1"># Pad so input_length divides stride.</span>
  <span class="n">input_length</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">paddings</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">pad_len</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_length</span> <span class="o">+</span> <span class="n">stride</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">-</span> <span class="n">input_length</span>
  <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_len</span><span class="p">]],</span> <span class="n">constant_values</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
  <span class="n">out_padding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
      <span class="p">[</span><span class="n">window</span><span class="p">],</span>
      <span class="s1">&#39;MAX&#39;</span><span class="p">,</span>
      <span class="n">padding</span><span class="o">=</span><span class="n">padding_algorithm</span><span class="p">,</span>
      <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="n">stride</span><span class="p">],</span>
  <span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">out_padding</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="ComputeExplicitPaddingForCausalConv"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.ComputeExplicitPaddingForCausalConv">[docs]</a><span class="k">def</span> <span class="nf">ComputeExplicitPaddingForCausalConv</span><span class="p">(</span><span class="n">filter_shape</span><span class="p">,</span> <span class="n">dilation_rate</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes the explicit paddings for causal convolutions.</span>

<span class="sd">  Args:</span>
<span class="sd">    filter_shape: a sequence of length 4. Elements are in the order of height</span>
<span class="sd">      (time), width (frequency), in_channel, out_channel.</span>
<span class="sd">    dilation_rate: a pair of int: dilations on height and width axises.</span>

<span class="sd">  Returns:</span>
<span class="sd">    explicit_padding: a list of pairs in the form of :</span>
<span class="sd">      [[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]]</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">assert</span> <span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Only 1D causal convolutions supported.&#39;</span>
  <span class="c1"># Use VALID padding and shift the inputs to the right to ensure that the</span>
  <span class="c1"># first output only depends on the first input and so on. The output is</span>
  <span class="c1"># the same size as the input, as if the convolution used SAME padding.</span>
  <span class="c1"># The effective spatial filter width for dilated convolutions is</span>
  <span class="c1"># (kernel_width - 1) * dilation_rate + 1 as according to</span>
  <span class="c1"># https://www.tensorflow.org/api_docs/python/tf/nn/convolution.</span>
  <span class="n">causal_pad_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dilation_rate</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">explicit_padding</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">causal_pad_size</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
  <span class="k">return</span> <span class="n">explicit_padding</span></div>


<div class="viewcode-block" id="_ComputeConvOutputPaddingV2"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding._ComputeConvOutputPaddingV2">[docs]</a><span class="k">def</span> <span class="nf">_ComputeConvOutputPaddingV2</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span>
                                <span class="n">window</span><span class="p">,</span>
                                <span class="n">stride</span><span class="p">,</span>
                                <span class="n">padding_algorithm</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes paddings for convolution and pooling output.</span>

<span class="sd">  - If padding_algorithm=&#39;SAME&#39;: out_padding[i] == 0 if the in_padding</span>
<span class="sd">    corresponding to that output is 0. This prevents the output from shrinking</span>
<span class="sd">    unnecessarily when striding.</span>
<span class="sd">  - If padding algorithm=&#39;VALID&#39;: out_padding[i] == 1 iff any in_padding</span>
<span class="sd">    corresponding to that output is 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    paddings: The paddings tensor. It is expected to be of shape [batch, time].</span>
<span class="sd">    window: The size of the windows.</span>
<span class="sd">    stride: The time-stride between adjacent windows.</span>
<span class="sd">    padding_algorithm: &#39;SAME&#39; or &#39;VALID&#39;.</span>

<span class="sd">  Returns:</span>
<span class="sd">    out_padding, The new padding tensor of size [batch, ceil(time / stride)].</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">stride</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">padding_algorithm</span> <span class="o">==</span> <span class="s1">&#39;SAME&#39;</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">paddings</span>

  <span class="n">paddings</span><span class="p">,</span> <span class="n">slice_len</span> <span class="o">=</span> <span class="n">_PadForLengthCompatibleStridesV2</span><span class="p">(</span>
      <span class="n">paddings</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding_algorithm</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

  <span class="n">expanded_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">padding_algorithm</span> <span class="o">==</span> <span class="s1">&#39;SAME&#39;</span><span class="p">:</span>
    <span class="c1"># Using a strided conv1d of size 1x1 we find all non-padded positions for</span>
    <span class="c1"># the specified stride.</span>
    <span class="n">out_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv1d</span><span class="p">(</span>
        <span class="n">expanded_paddings</span><span class="p">,</span>
        <span class="n">filters</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">paddings</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;padding_conv&#39;</span><span class="p">)</span>
  <span class="k">elif</span> <span class="n">padding_algorithm</span> <span class="o">==</span> <span class="s1">&#39;VALID&#39;</span><span class="p">:</span>
    <span class="n">out_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span>
        <span class="n">expanded_paddings</span><span class="p">,</span> <span class="p">[</span><span class="n">window</span><span class="p">],</span>
        <span class="s1">&#39;MAX&#39;</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">padding_algorithm</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="n">stride</span><span class="p">])</span>
  <span class="n">out_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">out_paddings</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">slice_end</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">out_paddings</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">slice_len</span>
    <span class="n">out_paddings</span> <span class="o">=</span> <span class="n">out_paddings</span><span class="p">[:,</span> <span class="p">:</span><span class="n">slice_end</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">out_paddings</span></div>


<div class="viewcode-block" id="_PadForLengthCompatibleStridesV2"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding._PadForLengthCompatibleStridesV2">[docs]</a><span class="k">def</span> <span class="nf">_PadForLengthCompatibleStridesV2</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding_algorithm</span><span class="p">,</span>
                                     <span class="n">constant_values</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Pads tensor to make strided convolutions start in the first position.</span>

<span class="sd">  Tensorflow strided convolutions and Lingvo paddings are incompatible.</span>
<span class="sd">  Strided convolutions always end at the last index of the length dimension.</span>
<span class="sd">  Therefore, the output of a Lingvo padded tensor depends on the length</span>
<span class="sd">  dimension. Here we remove this dependency by pre-padding the tensor so that</span>
<span class="sd">  the first convolution starts in the first position.</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor: The tensor to prepare for convolution. [batch, time, ...].</span>
<span class="sd">    stride: The stride in the length dimension.</span>
<span class="sd">    padding_algorithm: &#39;SAME&#39; or &#39;VALID&#39;.</span>
<span class="sd">    constant_values: Value to pad 0. for data tensor and 1.0 for padding tensor.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple (tensor, padded_length) where tensor is the potentionally padded</span>
<span class="sd">    tensor and padded_length is the number paddings.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">padding_algorithm</span> <span class="o">==</span> <span class="s1">&#39;VALID&#39;</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="p">,</span> <span class="mi">0</span>

  <span class="n">input_length</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">tensor</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">pad_len</span> <span class="o">=</span> <span class="p">((</span><span class="n">input_length</span> <span class="o">//</span> <span class="n">stride</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">input_length</span>
  <span class="k">if</span> <span class="n">pad_len</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="p">,</span> <span class="mi">0</span>
  <span class="n">tensor</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">PadSequenceDimension</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">input_length</span> <span class="o">+</span> <span class="n">pad_len</span><span class="p">,</span>
                                         <span class="n">constant_values</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">pad_len</span></div>


<div class="viewcode-block" id="BaseConv2DLayerWithPadding"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.BaseConv2DLayerWithPadding">[docs]</a><span class="k">class</span> <span class="nc">BaseConv2DLayerWithPadding</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Abstract base class for 2D convolution layers.</span>

<span class="sd">  WARNING: Strided convolutions are buggy. Prefer using v2_padding=True.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseConv2DLayerWithPadding.Params"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.BaseConv2DLayerWithPadding.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;filter_shape&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="s1">&#39;Filter shape. Must be a sequence of length 4. Elements are in&#39;</span>
        <span class="s1">&#39; the order of height (time), width (frequency), in_channel,&#39;</span>
        <span class="s1">&#39; out_channel. For causal convolution, filter_shape[0]&#39;</span>
        <span class="s1">&#39; is the actual number of trained weights in the time dimension&#39;</span>
        <span class="s1">&#39; of the kernel.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;filter_stride&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="s1">&#39;Filter stride to use. Must be a pair of ints. The first int&#39;</span>
        <span class="s1">&#39; specifies the stride on the time dimension. The second int&#39;</span>
        <span class="s1">&#39; specifies the stride on the frequency dimension.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;dilation_rate&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="s1">&#39;If &gt; 1, dilation rate for atrous convolution. &#39;</span>
        <span class="s1">&#39;Must be a pair of ints. &#39;</span>
        <span class="s1">&#39;The first int specifies the dilation rate on the time dimension. &#39;</span>
        <span class="s1">&#39;The second int specifies the dilation rate on the frequency &#39;</span>
        <span class="s1">&#39;dimension. &#39;</span>
        <span class="s1">&#39;If any value of dilation_rate is &gt; 1, then all values of strides &#39;</span>
        <span class="s1">&#39;must be 1.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;weight_norm&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;If true, apply weight normalization to weights as proposed by&#39;</span>
        <span class="s1">&#39; Salimans and Kingma, 2016: https://arxiv.org/abs/1602.07868&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;partial_conv&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;If true, rescale positions near sequence&#39;</span>
        <span class="s1">&#39;boundaries as proposed in https://arxiv.org/abs/1811.11718&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;v2_padding&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Prefer setting to True. The default &#39;</span>
        <span class="s1">&#39;implementation is incorrect for strided convolutions.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span><span class="p">)</span>
    <span class="c1"># Dilation and stride can&#39;t be combined.</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span><span class="p">):</span>
      <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">)</span>

<div class="viewcode-block" id="BaseConv2DLayerWithPadding.OutputChannels"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.BaseConv2DLayerWithPadding.OutputChannels">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">OutputChannels</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The number of output channels for this conv layer.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">OutputChannels</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">input_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The number of input channels for this conv layer.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">filter_stride</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">filter_stride</span>

<div class="viewcode-block" id="BaseConv2DLayerWithPadding.OutShape"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.BaseConv2DLayerWithPadding.OutShape">[docs]</a>  <span class="k">def</span> <span class="nf">OutShape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_shape</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the output shape given the input shape.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">return</span> <span class="n">ComputeConvOutputShape</span><span class="p">(</span><span class="n">in_shape</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                  <span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseConv2DLayerWithPadding.FProp"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.BaseConv2DLayerWithPadding.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply convolution to inputs.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      inputs: The inputs tensor. It is expected to be of shape [batch, time,</span>
<span class="sd">        frequency, channel]. The time dimension corresponds to the height</span>
<span class="sd">        dimension as in images and the frequency dimension corresponds to the</span>
<span class="sd">        width dimension as in images.</span>
<span class="sd">      paddings: The paddings tensor, expected to be of shape [batch, time].</span>

<span class="sd">    Returns:</span>
<span class="sd">      outputs, out_paddings pair.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">([</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">assert_shape_match</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">paddings</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">assert_shape_match</span><span class="p">(</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">paddings</span><span class="p">),</span>
                  <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">.</span><span class="n">ToStatic</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span><span class="p">)]</span>
              <span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
      <span class="p">],</span> <span class="n">inputs</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">_ApplyPadding</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="n">padding_in</span><span class="p">):</span>
        <span class="n">padding_expanded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">padding_in</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tensor_in</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">padding_expanded</span><span class="p">)</span>

      <span class="c1"># Zeroing out padded inputs.</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">_ApplyPadding</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>

      <span class="c1"># Apply conv on &#39;inputs&#39;.</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">v2_padding</span><span class="p">:</span>
        <span class="n">padded_inputs</span><span class="p">,</span> <span class="n">slice_len</span> <span class="o">=</span> <span class="n">_PadForLengthCompatibleStridesV2</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;SAME&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ApplyConv</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">padded_inputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
          <span class="n">slice_end</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">out</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">slice_len</span>
          <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:,</span> <span class="p">:</span><span class="n">slice_end</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ApplyConv</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">partial_conv</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RescaleBoundary</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="c1"># NOTE: this may be slightly inaccurate when p.dilation_rate[0] &gt; 1.</span>
      <span class="c1"># But there&#39;s likely no real problems. Trying to set it gives an error:</span>
      <span class="c1"># pooling with SAME padding is not implemented for dilation_rate &gt; 1.</span>
      <span class="c1"># implementation. Consider updating it to be the actual shape.</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">v2_padding</span><span class="p">:</span>
        <span class="n">conv_padding</span> <span class="o">=</span> <span class="n">_ComputeConvOutputPaddingV2</span><span class="p">(</span>
            <span class="n">paddings</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">conv_padding</span> <span class="o">=</span> <span class="n">ComputeConvOutputPadding</span><span class="p">(</span>
            <span class="n">paddings</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

      <span class="c1"># Assuming padded nodes will be properly zero-ed out if necessary by</span>
      <span class="c1"># sub-sequent layers.</span>
      <span class="c1"># out = _ApplyPadding(out, conv_padding)</span>
      <span class="n">out</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span>
          <span class="n">out</span><span class="p">,</span> <span class="n">symbolic</span><span class="o">.</span><span class="n">ToStatic</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">OutShape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">))))</span>
      <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">conv_padding</span></div>

<div class="viewcode-block" id="BaseConv2DLayerWithPadding._RescaleBoundary"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.BaseConv2DLayerWithPadding._RescaleBoundary">[docs]</a>  <span class="k">def</span> <span class="nf">_RescaleBoundary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">in_paddings</span><span class="p">):</span>
    <span class="c1"># Rescale every output position by:</span>
    <span class="c1">#   (# input positions) / (# non-padding input positions)</span>
    <span class="c1"># where (# input positions) = filter_size.</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">in_mask</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">in_paddings</span>

    <span class="c1"># Compute the left and right implicity padding size used in &#39;SAME&#39; mode.</span>
    <span class="n">filter_t</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">effective_filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">filter_t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">left_pad_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">effective_filter_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">right_pad_size</span> <span class="o">=</span> <span class="n">effective_filter_size</span> <span class="o">//</span> <span class="mi">2</span>

    <span class="c1"># Compute the rescaling factor.</span>
    <span class="c1"># This expanded tensor has 1 on all valid positions, 0 on all padded ones,</span>
    <span class="c1"># which include both explicit padding provided by &#39;in_padding&#39;, and implicit</span>
    <span class="c1"># padding on boundaries.</span>
    <span class="n">in_mask_padded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">in_mask</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">left_pad_size</span><span class="p">,</span> <span class="n">right_pad_size</span><span class="p">]])</span>
    <span class="c1"># (# non-padding input positions) / (# input positions)</span>
    <span class="n">factor_inverse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span>
        <span class="n">in_mask_padded</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
        <span class="n">window_shape</span><span class="o">=</span><span class="p">(</span><span class="n">filter_t</span><span class="p">,),</span>
        <span class="n">pooling_type</span><span class="o">=</span><span class="s1">&#39;AVG&#39;</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">],),</span>
        <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;VALID&#39;</span><span class="p">,</span>
        <span class="n">dilations</span><span class="o">=</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>

    <span class="n">factor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reciprocal_no_nan</span><span class="p">(</span><span class="n">factor_inverse</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span> <span class="o">*</span> <span class="n">factor</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span></div>

<div class="viewcode-block" id="BaseConv2DLayerWithPadding._ApplyConv"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.BaseConv2DLayerWithPadding._ApplyConv">[docs]</a>  <span class="k">def</span> <span class="nf">_ApplyConv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">conv_input</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_EvaluateConvKernel</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">conv_input</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeCausalPadding</span><span class="p">())</span></div>

<div class="viewcode-block" id="BaseConv2DLayerWithPadding._MaybeCausalPadding"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.BaseConv2DLayerWithPadding._MaybeCausalPadding">[docs]</a>  <span class="k">def</span> <span class="nf">_MaybeCausalPadding</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the padding algorithm for tf.*conv2d api.</span>

<span class="sd">    The default value is &#39;SAME&#39; for non-causal layers. Causal layers may</span>
<span class="sd">      override and return a explicit padding.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="s1">&#39;SAME&#39;</span></div>

<div class="viewcode-block" id="BaseConv2DLayerWithPadding._EvaluateConvKernel"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.BaseConv2DLayerWithPadding._EvaluateConvKernel">[docs]</a>  <span class="k">def</span> <span class="nf">_EvaluateConvKernel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">conv_input</span><span class="p">,</span> <span class="n">padding_algorithm</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Evaluate the convolution kernel on input &#39;conv_input&#39;.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span></div></div>


<div class="viewcode-block" id="Conv2DLayerWithPadding"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.Conv2DLayerWithPadding">[docs]</a><span class="k">class</span> <span class="nc">Conv2DLayerWithPadding</span><span class="p">(</span><span class="n">BaseConv2DLayerWithPadding</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Conv2D layer.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="Conv2DLayerWithPadding.Params"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.Conv2DLayerWithPadding.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;bias&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Whether or not to apply a bias before activation.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="Conv2DLayerWithPadding._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.Conv2DLayerWithPadding._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">w_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">,</span>
        <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;_vars&#39;</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">w_pc</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">weight_norm</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
          <span class="s1">&#39;g&#39;</span><span class="p">,</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
              <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span>
              <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
              <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
              <span class="n">collections</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;_vars&#39;</span><span class="p">]))</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
      <span class="c1"># NOTE(jiahuiyu): bias is subject to LP regularization in this version.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
          <span class="s1">&#39;b&#39;</span><span class="p">,</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
              <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">],</span>
              <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
              <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
              <span class="n">collections</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;_vars&#39;</span><span class="p">]))</span></div>

<div class="viewcode-block" id="Conv2DLayerWithPadding.OutputChannels"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.Conv2DLayerWithPadding.OutputChannels">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">OutputChannels</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The number of output channels for this conv layer.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span></div>

<div class="viewcode-block" id="Conv2DLayerWithPadding._GetWeight"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.Conv2DLayerWithPadding._GetWeight">[docs]</a>  <span class="k">def</span> <span class="nf">_GetWeight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">weight_norm</span><span class="p">:</span>
      <span class="c1"># Normalize along the last dim (standard conv).</span>
      <span class="n">filter_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">l2_normalize</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
          <span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">g</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">filter_w</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">w</span>
    <span class="k">return</span> <span class="n">filter_w</span></div>

<div class="viewcode-block" id="Conv2DLayerWithPadding._ApplyConv"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.Conv2DLayerWithPadding._ApplyConv">[docs]</a>  <span class="k">def</span> <span class="nf">_ApplyConv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">conv_input</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_EvaluateConvKernel</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">conv_input</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeCausalPadding</span><span class="p">())</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
      <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span></div>

<div class="viewcode-block" id="Conv2DLayerWithPadding._EvaluateConvKernel"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.Conv2DLayerWithPadding._EvaluateConvKernel">[docs]</a>  <span class="k">def</span> <span class="nf">_EvaluateConvKernel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">padding_algorithm</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply convolution to inputs.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">filter_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetWeight</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
        <span class="n">inputs</span><span class="p">,</span>
        <span class="n">filter_w</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">,</span>
        <span class="n">dilations</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span><span class="p">,</span>
        <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NHWC&#39;</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">padding_algorithm</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="CausalConv2DLayerWithPadding"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.CausalConv2DLayerWithPadding">[docs]</a><span class="k">class</span> <span class="nc">CausalConv2DLayerWithPadding</span><span class="p">(</span><span class="n">Conv2DLayerWithPadding</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;2D conv layer with causal dependency on the time axis.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Only 1d causal convolution is supported.&#39;</span>

<div class="viewcode-block" id="CausalConv2DLayerWithPadding._MaybeCausalPadding"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.CausalConv2DLayerWithPadding._MaybeCausalPadding">[docs]</a>  <span class="k">def</span> <span class="nf">_MaybeCausalPadding</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">return</span> <span class="n">ComputeExplicitPaddingForCausalConv</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span><span class="p">)</span></div>

<div class="viewcode-block" id="CausalConv2DLayerWithPadding.zero_state"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.CausalConv2DLayerWithPadding.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the initial state given the batch size.</span>

<span class="sd">    Args:</span>
<span class="sd">      batch_size: the batch size.</span>

<span class="sd">    Returns:</span>
<span class="sd">      state0: A NestedMap of tensors including:</span>
<span class="sd">        - context: A Tensor of shape [b, filter_shape[0]-1, 1, c].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span>
        <span class="s1">&#39;zero_state() only supports 1d causal convolution.&#39;</span><span class="p">)</span>

    <span class="n">context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">]</span> <span class="o">+</span>
        <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]],</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span></div>

<div class="viewcode-block" id="CausalConv2DLayerWithPadding.StreamStep"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.CausalConv2DLayerWithPadding.StreamStep">[docs]</a>  <span class="k">def</span> <span class="nf">StreamStep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">state0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply a singele step of convolution to input_tensor.</span>

<span class="sd">    Only supports 1d causal convolution. Doesn&#39;t support dilation.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A NestedMap of layer params.</span>
<span class="sd">      inputs: A Tensor of shape [b, t, 1, c]</span>
<span class="sd">      paddings: A 0/1 valued tensor of shape [b, t].</span>
<span class="sd">      state0: A NestedMap of tensors of the same struct as returned by</span>
<span class="sd">        zero_state().</span>

<span class="sd">    Returns:</span>
<span class="sd">      outputs: A Tensor of shape [b, t, 1, c]</span>
<span class="sd">      padding: the same as input paddings.</span>
<span class="sd">      state1: A NestedMap of the same struct as input state</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span>
        <span class="s1">&#39;StreamStep only supports 1d causal convolution.&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">stride</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">stride</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">),</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s1">&#39;StreamStep doesn</span><span class="se">\&#39;</span><span class="s1">t support striding: </span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;StreamStep doesn</span><span class="se">\&#39;</span><span class="s1">t support dilation&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[:</span><span class="mi">2</span><span class="p">])</span>
      <span class="n">q</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">paddings</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

      <span class="n">concat_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
          <span class="p">[</span><span class="n">state0</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">inputs</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">AppendDims</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">))],</span>
          <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
          <span class="n">concat_inputs</span><span class="p">,</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_GetWeight</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span>
          <span class="n">strides</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">,</span>
          <span class="n">dilations</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span><span class="p">,</span>
          <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NHWC&#39;</span><span class="p">,</span>
          <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;VALID&#39;</span><span class="p">)</span>
      <span class="n">new_context</span> <span class="o">=</span> <span class="n">concat_inputs</span><span class="p">[:,</span> <span class="n">q</span><span class="p">:]</span>
      <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">context</span><span class="o">=</span><span class="n">new_context</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="DepthwiseConv2DLayer"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.DepthwiseConv2DLayer">[docs]</a><span class="k">class</span> <span class="nc">DepthwiseConv2DLayer</span><span class="p">(</span><span class="n">BaseConv2DLayerWithPadding</span><span class="p">,</span>
                           <span class="n">quant_utils</span><span class="o">.</span><span class="n">QuantizableLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Depthwise conv 2D layer.</span>

<span class="sd">  paper: https://arxiv.org/abs/1610.02357</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="DepthwiseConv2DLayer.Params"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.DepthwiseConv2DLayer.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="c1"># Redefine &#39;filter_shape&#39; since the semantic of shape elements is different</span>
    <span class="c1"># from regular Conv2D.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Delete</span><span class="p">(</span><span class="s1">&#39;filter_shape&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;filter_shape&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
        <span class="s1">&#39;Filter shape. Must be a sequence of length 4. Elements are in&#39;</span>
        <span class="s1">&#39; the order of height (time), width (frequency), in_channel,&#39;</span>
        <span class="s1">&#39; channel_multipliers. &#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;bias&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Whether or not to apply a bias before activation.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateAqtWeight</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetWeightShape</span><span class="p">(),</span> <span class="n">feature_axis</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<div class="viewcode-block" id="DepthwiseConv2DLayer._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.DepthwiseConv2DLayer._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">w_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">,</span>
        <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;_vars&#39;</span><span class="p">])</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">w_pc</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">weight_norm</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
          <span class="s1">&#39;g&#39;</span><span class="p">,</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
              <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]],</span>
              <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
              <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
              <span class="n">collections</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;_vars&#39;</span><span class="p">]))</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
      <span class="c1"># NOTE(jiahuiyu): bias is subject to LP regularization in this version.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
          <span class="s1">&#39;b&#39;</span><span class="p">,</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
              <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">],</span>
              <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
              <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
              <span class="n">collections</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;_vars&#39;</span><span class="p">]))</span></div>

<div class="viewcode-block" id="DepthwiseConv2DLayer.OutputChannels"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.DepthwiseConv2DLayer.OutputChannels">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">OutputChannels</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The number of output channels for this conv layer.&quot;&quot;&quot;</span>
    <span class="c1"># Depthwise convolution filter shape is:</span>
    <span class="c1">#   [..., in_channels, channel_multiplier].</span>
    <span class="k">return</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span></div>

<div class="viewcode-block" id="DepthwiseConv2DLayer._GetWeight"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.DepthwiseConv2DLayer._GetWeight">[docs]</a>  <span class="k">def</span> <span class="nf">_GetWeight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">weight_norm</span><span class="p">:</span>
      <span class="c1"># Normalize along the feature dimensions.</span>
      <span class="n">w_norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">l2_normalize</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="n">g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">theta</span><span class="o">.</span><span class="n">g</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
      <span class="k">return</span> <span class="n">w_norm</span> <span class="o">*</span> <span class="n">g</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">theta</span><span class="o">.</span><span class="n">w</span></div>

<div class="viewcode-block" id="DepthwiseConv2DLayer._GetWeightShape"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.DepthwiseConv2DLayer._GetWeightShape">[docs]</a>  <span class="k">def</span> <span class="nf">_GetWeightShape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The shape of the filter returned by _GetWeight.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span></div>

<div class="viewcode-block" id="DepthwiseConv2DLayer._ApplyConv"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.DepthwiseConv2DLayer._ApplyConv">[docs]</a>  <span class="k">def</span> <span class="nf">_ApplyConv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">conv_input</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_EvaluateConvKernel</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">conv_input</span><span class="p">,</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeCausalPadding</span><span class="p">())</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">bias</span><span class="p">:</span>
      <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span></div>

<div class="viewcode-block" id="DepthwiseConv2DLayer._EvaluateConvKernel"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.DepthwiseConv2DLayer._EvaluateConvKernel">[docs]</a>  <span class="k">def</span> <span class="nf">_EvaluateConvKernel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">padding_algorithm</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply convolution to inputs.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">filter_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetWeight</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">filter_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ToAqtConv</span><span class="p">(</span>
        <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">filter_w</span><span class="p">,</span> <span class="n">w_feature_axis</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">depthwise_conv2d</span><span class="p">(</span>
        <span class="n">inputs</span><span class="p">,</span>
        <span class="n">filter_w</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">dilations</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span><span class="p">,</span>
        <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NHWC&#39;</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">padding_algorithm</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">FromAqtConv</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">is_depthwise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="CausalDepthwiseConv2DLayer"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.CausalDepthwiseConv2DLayer">[docs]</a><span class="k">class</span> <span class="nc">CausalDepthwiseConv2DLayer</span><span class="p">(</span><span class="n">DepthwiseConv2DLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Depthwise conv layer with causal dependency on the time axis.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Only 1d causal convolution is supported.&#39;</span>

<div class="viewcode-block" id="CausalDepthwiseConv2DLayer._MaybeCausalPadding"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.CausalDepthwiseConv2DLayer._MaybeCausalPadding">[docs]</a>  <span class="k">def</span> <span class="nf">_MaybeCausalPadding</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">return</span> <span class="n">ComputeExplicitPaddingForCausalConv</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span><span class="p">)</span></div>

<div class="viewcode-block" id="CausalDepthwiseConv2DLayer.zero_state"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.CausalDepthwiseConv2DLayer.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the initial state given the batch size.</span>

<span class="sd">    Args:</span>
<span class="sd">      batch_size: the batch size.</span>

<span class="sd">    Returns:</span>
<span class="sd">      state0: A NestedMap of tensors including:</span>
<span class="sd">        - context: A Tensor of shape [b, filter_shape[0]-1, 1, c].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span>
        <span class="s1">&#39;zero_state() only supports 1d causal convolution.&#39;</span><span class="p">)</span>

    <span class="n">context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">]</span> <span class="o">+</span>
        <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]],</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span></div>

<div class="viewcode-block" id="CausalDepthwiseConv2DLayer.StreamStep"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.CausalDepthwiseConv2DLayer.StreamStep">[docs]</a>  <span class="k">def</span> <span class="nf">StreamStep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">state0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply a singele step of convolution to input_tensor.</span>

<span class="sd">    Only supports 1d causal convolution. Doesn&#39;t support dilation.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A NestedMap of layer params.</span>
<span class="sd">      inputs: A Tensor of shape [b, t, 1, c]</span>
<span class="sd">      paddings: A 0/1 valued tensor of shape [b, t].</span>
<span class="sd">      state0: A NestedMap of tensors of the same struct as returned by</span>
<span class="sd">        zero_state().</span>

<span class="sd">    Returns:</span>
<span class="sd">      outputs: A Tensor of shape [b, t, 1, c * channel_multiplier]</span>
<span class="sd">      padding: the same as input paddings.</span>
<span class="sd">      state1: A NestedMap of the same struct as input state</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span>
        <span class="s1">&#39;StreamStep only supports 1d causal convolution.&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_stride</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;StreamStep doesn</span><span class="se">\&#39;</span><span class="s1">t support striding&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;StreamStep doesn</span><span class="se">\&#39;</span><span class="s1">t support dilation&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[:</span><span class="mi">2</span><span class="p">])</span>
      <span class="n">q</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">paddings</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

      <span class="n">padded_inputs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ApplyPadding</span><span class="p">(</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">AppendDims</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">inputs</span><span class="p">)</span>

      <span class="n">concat_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">state0</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">padded_inputs</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">depthwise_conv2d</span><span class="p">(</span>
          <span class="n">concat_inputs</span><span class="p">,</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_GetWeight</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span>
          <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
          <span class="n">dilations</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
          <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NHWC&#39;</span><span class="p">,</span>
          <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;VALID&#39;</span><span class="p">)</span>
      <span class="n">new_context</span> <span class="o">=</span> <span class="n">concat_inputs</span><span class="p">[:,</span> <span class="n">q</span><span class="p">:]</span>
      <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">context</span><span class="o">=</span><span class="n">new_context</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="NormalizedDepthwiseConv2DLayer"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.NormalizedDepthwiseConv2DLayer">[docs]</a><span class="k">class</span> <span class="nc">NormalizedDepthwiseConv2DLayer</span><span class="p">(</span><span class="n">DepthwiseConv2DLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;DepthwiseConv2DLayer where weights are normalized over the time dim.</span>

<span class="sd">  https://arxiv.org/abs/1901.10430</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="NormalizedDepthwiseConv2DLayer.Params"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.NormalizedDepthwiseConv2DLayer.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;dropconnect_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
             <span class="s1">&#39;Prob at which DropConnect regularization is performed.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;deterministic_dropout&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Use determnisitc dropout or not.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;temperature&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span>
             <span class="s1">&#39;Temperature for the softmax normalization of the weights.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;weight_tiling_factor&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">&#39;Number of times weights are tiled over the input channels.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Only 1d convolution is supported.&#39;</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">temperature</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;Absolute zero temperature is not possible.&#39;</span>

<div class="viewcode-block" id="NormalizedDepthwiseConv2DLayer.OutputChannels"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.NormalizedDepthwiseConv2DLayer.OutputChannels">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">OutputChannels</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The number of output channels for this conv layer.&quot;&quot;&quot;</span>
    <span class="c1"># Depthwise convolution filter shape is:</span>
    <span class="c1"># [kernel_size, 1, in_channels, channel_multiplier].</span>
    <span class="k">return</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">weight_tiling_factor</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">input_channels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The number of output channels for this conv layer.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">return</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">weight_tiling_factor</span>

<div class="viewcode-block" id="NormalizedDepthwiseConv2DLayer._GetWeight"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.NormalizedDepthwiseConv2DLayer._GetWeight">[docs]</a>  <span class="k">def</span> <span class="nf">_GetWeight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">filter_w</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">w</span>

    <span class="c1"># First normalize filter_w over the temporal dimension here.</span>
    <span class="n">filter_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">filter_w</span> <span class="o">/</span> <span class="n">p</span><span class="o">.</span><span class="n">temperature</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Add dropconnect on the weights for regularization.</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">dropconnect_prob</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">deterministic_dropout</span><span class="p">:</span>
        <span class="n">filter_w</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">DeterministicDropout</span><span class="p">(</span>
            <span class="n">filter_w</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">dropconnect_prob</span><span class="p">,</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GenerateStepSeedPair</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">filter_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span>
            <span class="n">filter_w</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dropconnect_prob</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

    <span class="c1"># Tie the parameters of every subsequent number of weight_tiling_factor</span>
    <span class="c1"># channels.</span>
    <span class="n">filter_w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">filter_w</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">weight_tiling_factor</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">filter_w</span></div>

<div class="viewcode-block" id="NormalizedDepthwiseConv2DLayer._GetWeightShape"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.NormalizedDepthwiseConv2DLayer._GetWeightShape">[docs]</a>  <span class="k">def</span> <span class="nf">_GetWeightShape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The shape of the filter returned by _GetWeight.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">tiled_shape</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">)</span>
    <span class="n">tiled_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*=</span> <span class="n">p</span><span class="o">.</span><span class="n">weight_tiling_factor</span>
    <span class="k">return</span> <span class="n">tiled_shape</span></div>

<div class="viewcode-block" id="NormalizedDepthwiseConv2DLayer.FPropMeta"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.NormalizedDepthwiseConv2DLayer.FPropMeta">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">FPropMeta</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">):</span>
    <span class="n">py_utils</span><span class="o">.</span><span class="n">CheckShapes</span><span class="p">((</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">))</span>
    <span class="n">b</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">inputs</span>
    <span class="k">assert</span> <span class="n">f</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">oc</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">weight_tiling_factor</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">tshape</span><span class="o">.</span><span class="n">Shape</span><span class="p">([</span><span class="n">b</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">oc</span><span class="p">])</span>
    <span class="n">flops</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">t</span> <span class="o">*</span> <span class="n">f</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">oc</span> <span class="o">*</span> <span class="mi">5</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">flops</span><span class="o">=</span><span class="n">flops</span><span class="p">,</span> <span class="n">out_shapes</span><span class="o">=</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="CausalNormalizedDepthwiseConv2DLayer"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.CausalNormalizedDepthwiseConv2DLayer">[docs]</a><span class="k">class</span> <span class="nc">CausalNormalizedDepthwiseConv2DLayer</span><span class="p">(</span><span class="n">NormalizedDepthwiseConv2DLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Depthwise conv layer with causal dependency on the time axis.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="CausalNormalizedDepthwiseConv2DLayer._MaybeCausalPadding"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.CausalNormalizedDepthwiseConv2DLayer._MaybeCausalPadding">[docs]</a>  <span class="k">def</span> <span class="nf">_MaybeCausalPadding</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">return</span> <span class="n">ComputeExplicitPaddingForCausalConv</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">dilation_rate</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ConvBatchNormLayer"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.ConvBatchNormLayer">[docs]</a><span class="k">class</span> <span class="nc">ConvBatchNormLayer</span><span class="p">(</span><span class="n">bn_layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A wrapper around regular BatchNormLayer that pass around the ...</span>

<span class="sd">  paddings layers.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ConvBatchNormLayer.FProp"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.ConvBatchNormLayer.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">):</span>
    <span class="n">paddings_expanded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">bned</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings_expanded</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bned</span><span class="p">,</span> <span class="n">paddings</span></div></div>


<div class="viewcode-block" id="ConvCategoricalBN"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.ConvCategoricalBN">[docs]</a><span class="k">class</span> <span class="nc">ConvCategoricalBN</span><span class="p">(</span><span class="n">bn_layers</span><span class="o">.</span><span class="n">CategoricalBN</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A wrapper around regular CategoricalBN that pass around the ...</span>

<span class="sd">  paddings layers.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ConvCategoricalBN.FProp"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.ConvCategoricalBN.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">class_emb</span><span class="p">):</span>
    <span class="n">paddings_expanded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">bned</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings_expanded</span><span class="p">,</span> <span class="n">class_emb</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bned</span><span class="p">,</span> <span class="n">paddings</span></div></div>


<div class="viewcode-block" id="PaddingLayer"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.PaddingLayer">[docs]</a><span class="k">class</span> <span class="nc">PaddingLayer</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Zeros out padded positions.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="PaddingLayer.FProp"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.PaddingLayer.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">):</span>
    <span class="n">paddings_expanded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inputs</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">paddings_expanded</span><span class="p">),</span> <span class="n">paddings</span></div></div>


<div class="viewcode-block" id="GlobalPoolingLayer"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.GlobalPoolingLayer">[docs]</a><span class="k">class</span> <span class="nc">GlobalPoolingLayer</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Padding aware global pooling.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="GlobalPoolingLayer.Params"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.GlobalPoolingLayer.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;pooling_type&#39;</span><span class="p">,</span> <span class="s1">&#39;MAX&#39;</span><span class="p">,</span> <span class="s1">&#39;Pooling type: MAX|AVG&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="GlobalPoolingLayer.FProp"><a class="viewcode-back" href="../../../lingvo.core.conv_layers_with_time_padding.html#lingvo.core.conv_layers_with_time_padding.GlobalPoolingLayer.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply global spatial pooling to inputs.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      inputs: The inputs tensor. It is expected to be of shape [batch, time,</span>
<span class="sd">        frequency, channel]. The time dimension corresponds to the height</span>
<span class="sd">        dimension as in images and the frequency dimension corresponds to the</span>
<span class="sd">        width dimension as in images.</span>
<span class="sd">      paddings: The paddings tensor. It is expected to be of shape [batch,</span>
<span class="sd">        time]. Defaults to None, which means there no paddings.</span>

<span class="sd">    Returns:</span>
<span class="sd">      outputs, out_paddings pair.</span>
<span class="sd">       - outputs: has shape [batch, 1, 1, channel].</span>
<span class="sd">       - out_paddings: None or has shape [batch, 1].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">pooling_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;MAX&#39;</span><span class="p">,</span> <span class="s1">&#39;AVG&#39;</span><span class="p">],</span> <span class="n">p</span><span class="o">.</span><span class="n">pooling_type</span>
    <span class="n">b</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">ndims</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">paddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">paddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">mask</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">paddings</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">b</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">pooling_type</span> <span class="o">==</span> <span class="s1">&#39;AVG&#39;</span><span class="p">:</span>
      <span class="n">global_sum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">inputs</span> <span class="o">*</span> <span class="n">mask</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">f</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">f</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">count</span> <span class="o">=</span> <span class="n">f</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">out_feature</span> <span class="o">=</span> <span class="n">global_sum</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">p</span><span class="o">.</span><span class="n">pooling_type</span> <span class="o">==</span> <span class="s1">&#39;MAX&#39;</span><span class="p">:</span>
      <span class="n">large_negative</span> <span class="o">=</span> <span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">max</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="o">-</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
      <span class="n">padded_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where_v2</span><span class="p">(</span><span class="n">mask</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">large_negative</span><span class="p">)</span>
      <span class="n">out_feature</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">padded_inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">paddings</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">out_paddings</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">out_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">out_feature</span> <span class="o">*=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">out_paddings</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">out_feature</span><span class="p">,</span> <span class="n">out_paddings</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2018.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>