<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>lingvo.core.gshard_layers &mdash; Lingvo  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> Lingvo
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../lingvo.html">lingvo package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Lingvo</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>lingvo.core.gshard_layers</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for lingvo.core.gshard_layers</h1><div class="highlight"><pre>
<span></span><span class="c1"># Lint as: python3</span>
<span class="c1"># Copyright 2020 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;Layers and utilities that facilitate building MOE models.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">lingvo</span> <span class="kn">import</span> <span class="n">compat</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">activations</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">base_layer</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">conv_layers_with_time_padding</span> <span class="k">as</span> <span class="n">conv_layers</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">gshard_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">py_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">recurrent</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">tpu_summary</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">var_tmp_wrappers</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="c1"># pylint: disable=g-direct-tensorflow-import</span>
<span class="kn">from</span> <span class="nn">tensorflow.compiler.tf2xla.python</span> <span class="kn">import</span> <span class="n">xla</span>
<span class="kn">from</span> <span class="nn">tensorflow.compiler.xla.experimental.xla_sharding</span> <span class="kn">import</span> <span class="n">xla_sharding</span>
<span class="c1"># pylint: enable=g-direct-tensorflow-import</span>


<span class="n">Split</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span>
<span class="n">MeshSplit</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">MeshSplit</span>
<span class="n">ZigzagOrderOnDeviceMesh</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">ZigzagOrderOnDeviceMesh</span>
<span class="n">GetNonPod2dMesh</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">GetNonPod2dMesh</span>


<div class="viewcode-block" id="VarLayer"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.VarLayer">[docs]</a><span class="k">class</span> <span class="nc">VarLayer</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Container for variables.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="VarLayer.Params"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.VarLayer.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;weights&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;[(name, WeightParams)..] list.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;shared_var_collection_suffix&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;Weights created with collection name ending with &#39;</span>
        <span class="s1">&#39;p.shared_var_collection_suffix are shared.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="ow">or</span> <span class="s1">&#39;w&#39;</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="VarLayer._get_var_from_collection"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.VarLayer._get_var_from_collection">[docs]</a>  <span class="k">def</span> <span class="nf">_get_var_from_collection</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vp</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">collection</span> <span class="ow">in</span> <span class="n">vp</span><span class="o">.</span><span class="n">collections</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">shared_var_collection_suffix</span> <span class="ow">in</span> <span class="n">collection</span><span class="p">:</span>
        <span class="n">in_collection</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">collection</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">in_collection</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">in_collection</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="kc">None</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
      <span class="n">vp</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="k">if</span> <span class="n">vp</span><span class="o">.</span><span class="n">init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">vp</span><span class="o">.</span><span class="n">init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">params_init</span>
      <span class="c1"># Skip creation if it&#39;s already in some collection</span>
      <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">shared_var_collection_suffix</span> <span class="ow">or</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_get_var_from_collection</span><span class="p">(</span><span class="n">vp</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">vp</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">shared_var_collection_suffix</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>

<div class="viewcode-block" id="VarLayer.FProp"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.VarLayer.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">MaybeCastToFPropDtype</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span> <span class="ow">or</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="o">.</span><span class="n">fprop_dtype</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="o">.</span><span class="n">fprop_dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_params</span><span class="o">.</span><span class="n">fprop_dtype</span><span class="p">)</span>

    <span class="c1"># TODO(lepikhin): MoEBuilder.Embedding can not use &#39;-&gt;emb&#39; rule without</span>
    <span class="c1"># returning single element  of list of one element below.</span>
    <span class="n">retval</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">vp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
      <span class="c1"># Try to get the variable value from tf.collection.</span>
      <span class="n">var_value</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">shared_var_collection_suffix</span><span class="p">:</span>
        <span class="n">var_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_var_from_collection</span><span class="p">(</span><span class="n">vp</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">var_value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">var_value</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">var_value</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
        <span class="n">var_value</span> <span class="o">=</span> <span class="n">var_value</span><span class="o">.</span><span class="n">read_value</span><span class="p">()</span>
      <span class="n">retval</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MaybeCastToFPropDtype</span><span class="p">(</span><span class="n">var_value</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">retval</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">retval</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">retval</span></div></div>


<div class="viewcode-block" id="ShardedWeightParams"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.ShardedWeightParams">[docs]</a><span class="k">def</span> <span class="nf">ShardedWeightParams</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span>
                        <span class="n">init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">collections</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">tensor_split_dims_mapping</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns a hyperparams for a weight variable with optional XLA sharding.&quot;&quot;&quot;</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
      <span class="n">shape</span><span class="p">,</span>
      <span class="n">init</span><span class="p">,</span>
      <span class="n">dtype</span><span class="p">,</span>
      <span class="n">collections</span><span class="p">,</span>
      <span class="n">tensor_split_dims_mapping</span><span class="o">=</span><span class="n">tensor_split_dims_mapping</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">p</span></div>


<div class="viewcode-block" id="ShardedVarLayer"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.ShardedVarLayer">[docs]</a><span class="k">class</span> <span class="nc">ShardedVarLayer</span><span class="p">(</span><span class="n">VarLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Container for variables whose values sharded across different devices.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="ShardedVarLayer.Params"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.ShardedVarLayer.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Delete</span><span class="p">(</span><span class="s1">&#39;weights&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;weights&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;[(name, ShardedWeightParams)..] list.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;cast_to_fprop_dtype&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
             <span class="s1">&#39;Whether to cast variables to fprop_dtype&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="ShardedVarLayer.InstantiateVariables"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.ShardedVarLayer.InstantiateVariables">[docs]</a>  <span class="k">def</span> <span class="nf">InstantiateVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">def</span> <span class="nf">MaybeWeightSplit</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
      <span class="c1"># In-place annotate the variable (no sharding op). This makes sure that</span>
      <span class="c1"># in some backend implementation, even if the following sharding is</span>
      <span class="c1"># optimized away, the backend can still infer the variable sharding.</span>
      <span class="n">split_dims</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">tensor_split_dims_mapping</span>
      <span class="k">if</span> <span class="n">split_dims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Fix the rank difference between variable shape and annotation</span>
        <span class="c1"># due to variable shape prefix introduced in builder_layers.RepeatLayer.</span>
        <span class="n">shape_prefix_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">split_dims</span><span class="p">)</span>
        <span class="n">split_dims</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">shape_prefix_len</span> <span class="o">+</span> <span class="n">split_dims</span>
      <span class="n">gshard_utils</span><span class="o">.</span><span class="n">MeshSplit</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">p</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span> <span class="n">split_dims</span><span class="p">,</span> <span class="n">use_sharding_op</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
      <span class="n">MaybeWeightSplit</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span></div>

<div class="viewcode-block" id="ShardedVarLayer.FProp"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.ShardedVarLayer.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="c1"># TODO(huangyp, lepikhin): Maybe cast to fprop dtype as well.</span>
    <span class="k">def</span> <span class="nf">MaybeWeightSplitAndCastToFPropDtype</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">read_value</span><span class="p">()</span>
      <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

      <span class="c1"># We annotate the read value again because some backend implementation</span>
      <span class="c1"># may only look at the neighbors of the variable during compilation.</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">MeshSplit</span><span class="p">(</span>
          <span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">tensor_split_dims_mapping</span><span class="p">,</span> <span class="n">use_sharding_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">cast_to_fprop_dtype</span> <span class="ow">and</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span> <span class="ow">and</span>
          <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">p</span><span class="o">.</span><span class="n">fprop_dtype</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">fprop_dtype</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">fprop_dtype</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">x</span>

    <span class="n">retval</span> <span class="o">=</span> <span class="p">[</span><span class="n">MaybeWeightSplitAndCastToFPropDtype</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">retval</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">retval</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">retval</span></div></div>


<div class="viewcode-block" id="_ToTuple"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers._ToTuple">[docs]</a><span class="k">def</span> <span class="nf">_ToTuple</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span></div>


<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer">[docs]</a><span class="k">class</span> <span class="nc">LayerwiseShardablePipelinedLayer</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A layer that implements pipelining across stages.</span>

<span class="sd">  It creates a loop over microbatches around a loop-body layer. The loop body</span>
<span class="sd">  has a leading num_stages dimension in the input/output data (provided by the</span>
<span class="sd">  user, or created by this layer when Params().num_microbatches is provided) and</span>
<span class="sd">  weights (to achieve real pipeline parallelism). This leading dimension can</span>
<span class="sd">  be added in different ways:</span>

<span class="sd">  1) Defined manually in the wrapped layer Params().stage_parallel_body.</span>

<span class="sd">  2) Automatically vectorized via tf.vectorized_map() (or manual-auto sharding</span>
<span class="sd">  conversion) and VariableShapePrefixContext(). In this case, use</span>
<span class="sd">  Params().single_stage_body instead to define a single stage. Without</span>
<span class="sd">  Params().shard_stages_1d, This may fail if some ops or control flow patterns</span>
<span class="sd">  are not supported by tf.vectorized_map(); with Params().shard_stages_1d, it</span>
<span class="sd">  instead uses manual-auto sharding conversion and supports all computations.</span>

<span class="sd">  Supported features in different configurations:</span>
<span class="sd">    1) stage_parallel_body:</span>
<span class="sd">    Non-trainable variables are supported. This is not compatible with regular</span>
<span class="sd">    existing layers, and mostly used for testing purpose.</span>

<span class="sd">    2) single_stage_body + per_stage_vars=False + (shard_stages_1d=True or</span>
<span class="sd">    pipeline_stage_mesh_dim is not None):</span>
<span class="sd">    Non-trainable variables are supported. The implementation is reliable,</span>
<span class="sd">    because it does not depend on tf.vectorized_map.</span>

<span class="sd">    3) single_stage_body + per_stage_vars=False + (shard_stages_1d=False and</span>
<span class="sd">    pipeline_stage_mesh_dim is None):</span>
<span class="sd">    tf.vectorized_map will be used. Non-trainable variables are not supported.</span>
<span class="sd">    Use this option only for testing purpose.</span>

<span class="sd">    4) single_stage_body + per_stage_vars=True + shard_stages_1d=True:</span>
<span class="sd">    Non-trainable variables are not supported. Per-stage variables are defined</span>
<span class="sd">    separately. Sharding is applied differently to per-layer variables and the</span>
<span class="sd">    stacked variable for all stages, so it has resharding cost. If per-layer</span>
<span class="sd">    vars are not a hard requirement 2) is a better option.</span>

<span class="sd">    5) single_stage_body + per_stage_vars=True + (shard_stages_1d=False and</span>
<span class="sd">    pipeline_stage_mesh_dim is None):</span>
<span class="sd">    Non-trainable variables are not supported. Similar to 4), but sharding is</span>
<span class="sd">    provided by the user, which means the user needs to take care of different</span>
<span class="sd">    shardings on per-stage variables and stacked variables. Mostly for testing,</span>
<span class="sd">    and if per-layer vars are not a hard requirement 3) is a better option.</span>

<span class="sd">  It can run on a single core, or sharded using GShard annotations. If the stage</span>
<span class="sd">  dimension is sharded, GShard will produce a cross-core pipelining pattern.</span>

<span class="sd">  Inputs to LayerwiseShardablePipelinedLayer should have a leading</span>
<span class="sd">  num_microbatch dimension. Each microbatch will be send to each pipeline loop</span>
<span class="sd">  iteration.</span>

<span class="sd">  The high-level idea is to use a shifting buffer to communicate between stages,</span>
<span class="sd">  as shown below (although the real implementation uses recurrent.Recurrent() to</span>
<span class="sd">  manage accumulation buffers)::</span>

<span class="sd">      input = ...  # shape: [num_microbatches, ...]</span>
<span class="sd">      # Insert a num_stages dimension after num_microbatches, then pad to shape:</span>
<span class="sd">      #   [num_microbatches + num_stages - 1, num_stages, ...]</span>
<span class="sd">      padded_input = pad(expand_dim(input, 1), ...)</span>

<span class="sd">      # Shifting buffer</span>
<span class="sd">      state = tf.zeros([num_stages, ...])</span>

<span class="sd">      # Recurrent loop</span>
<span class="sd">      for i in range(num_microbatches + num_stages - 1):</span>
<span class="sd">        # shift state to the right by one stage</span>
<span class="sd">        shifted_state = tf.pad(state, [[1, 0], ...])[1:]</span>
<span class="sd">        in_mask = tf.equal(tf.range(num_stages), 0)</span>
<span class="sd">        stages_in = tf.where(in_mask, padded_input[i],  shifted_state)</span>
<span class="sd">        state = stage_parallel_body.FProp(theta.body, stages_in)</span>

<span class="sd">  The body&#39;s FProp function takes arguments (theta, args, kwargs). It must</span>
<span class="sd">  return the same structure as args, while kwargs are shared across all stages.</span>

<span class="sd">  Additionally, FPropFn can take run a specified function of the body, and it</span>
<span class="sd">  can have per-stage inputs/outputs that are modeled as padded_per_stage_states.</span>
<span class="sd">  These states must be padded (for bubbles) before calling this function using</span>
<span class="sd">  PadMicrobatches(), and have shapes [num_microbatches + num_stages - 1,</span>
<span class="sd">  num_stages, ...]. This allows a typical use case, decoding, to avoid data</span>
<span class="sd">  formatting inside the decoding loop. Note that the bubble iterations are</span>
<span class="sd">  located at different offsets across stages and will not be removed, so use</span>
<span class="sd">  this only when the state is not used outside thie pipelined layers.</span>


<span class="sd">  Circular pipeline feature: set circular_repeat &gt; 1, only supported for</span>
<span class="sd">  single_stage_body + per_stage_vars=False + shard_stages_1d=True. In this case,</span>
<span class="sd">  the layer count is expanded by circular_repeat times, and each variable will</span>
<span class="sd">  have 2 leading dimensions, with shape [num_stages, circular_repeat, ...].</span>
<span class="sd">  Logically, the layers are organized in the following order::</span>

<span class="sd">      circular_repeat_000_stage_0</span>
<span class="sd">      circular_repeat_000_stage_1</span>
<span class="sd">      circular_repeat_000_stage_2</span>
<span class="sd">      circular_repeat_000_stage_3</span>

<span class="sd">      circular_repeat_001_stage_0</span>
<span class="sd">      circular_repeat_001_stage_1</span>
<span class="sd">      circular_repeat_001_stage_2</span>
<span class="sd">      circular_repeat_001_stage_3</span>

<span class="sd">      ...</span>

<span class="sd">  For the same number of microbatches, this mode reduces bubble ratio by</span>
<span class="sd">  circular_repeat times, because each microbatch goes through the stages</span>
<span class="sd">  multiple times in a circular pattern.</span>

<span class="sd">  Stages communicate data via a rotating buffer of shape [num_stages, ...], in</span>
<span class="sd">  a recurrent loop that runs O(circular_repeat * num_stages) iterations. During</span>
<span class="sd">  each iteration, a circular_repeat ID is picked for each stage based on the</span>
<span class="sd">  iteration counter and the stage ID::</span>

<span class="sd">      # Divide num_microbatch into segments of size num_stages, then pad each</span>
<span class="sd">      # segment to circular_repeat * num_stages, so that input data are</span>
<span class="sd">      # interleaved with paddings of size (circular_repeat - 1) * num_stages,</span>
<span class="sd">      # e.g., for num_stages == 2 and circular_repeat 3</span>
<span class="sd">      #   [0, 1, _, _, _, _, 2, 3, _, _, _, _, 4, 5, ...]</span>
<span class="sd">      # These internal paddings correspond to processing data from previous</span>
<span class="sd">      # stages. In the end, add additional num_stages - 1 padding as bubbles.</span>

<span class="sd">      iterations = circular_repeat * num_microbatches + num_stages - 1</span>
<span class="sd">      input = ...  # shape: [num_microbatch, ...]</span>
<span class="sd">      padded_input = pad_as_above(input)  # shape [iterations, ...]</span>

<span class="sd">      # Insert a num_stages dimension after num_stages:</span>
<span class="sd">      #   [iterations, num_stages, ...]</span>
<span class="sd">      padded_input = pad(expand_dim(padded_input, 1), ...)</span>

<span class="sd">      # Rotating buffer</span>
<span class="sd">      state = tf.zeros([num_stages, ...])</span>

<span class="sd">      # Recurrent loop</span>
<span class="sd">      for i in range(iterations):</span>
<span class="sd">        # Rotate state to the right by one stage</span>
<span class="sd">        rotated_state = tf.concat([state[-1:], state[:-1]], axis=0)</span>
<span class="sd">        # Only the first stage during the initial num_stages iterations uses the</span>
<span class="sd">        # input data.</span>
<span class="sd">        in_mask = tf.range(num_stages) == 0 and t &lt; num_stages</span>
<span class="sd">        stages_in = tf.where(in_mask, inp, rotated_state)</span>
<span class="sd">        state = body.FProp(CircularRepeatIter(theta.body), stages_in)</span>

<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer.Params"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_stages&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Number of pipeline stages.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;stage_parallel_body&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;The param for the main network layer. Its input data should have &#39;</span>
        <span class="s1">&#39;a leading dimension that corresponds to num_stages, and its &#39;</span>
        <span class="s1">&#39;computation should be parallel along this dimension to achieve &#39;</span>
        <span class="s1">&#39;real pipeline parallelism.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;single_stage_body&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;The param for a single stage, which will be automatically vectorized &#39;</span>
        <span class="s1">&#39;into a stage-parallel computation.&#39;</span><span class="p">)</span>
    <span class="c1"># Only one of num_microbatches and microbatch_size is needed when the input</span>
    <span class="c1"># needs microbatching.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;num_microbatches&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;If not None, the input is not yet microbatched, and will be reshaped &#39;</span>
        <span class="s1">&#39;to [num_microbatches, microbatch_size] here.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;microbatch_size&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;If not None, the input is not yet microbatched, and will be reshaped &#39;</span>
        <span class="s1">&#39;to [num_microbatches, microbatch_size] here.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;shard_stages_1d&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;If True, 1D sharding annotation on num_stages devices will be added, &#39;</span>
        <span class="s1">&#39;and the implementation will not use vectorized_map (to avoid its &#39;</span>
        <span class="s1">&#39;limitations), but uses conversion between manual and auto sharding &#39;</span>
        <span class="s1">&#39;modes. Set to False for sharding on multiple dimensions.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;pipeline_stage_mesh_dim&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;The mesh dimension to shard the pipeline stage dimension. Set &#39;</span>
        <span class="s1">&#39;this only when shard_stages_1d is False. With this option, the &#39;</span>
        <span class="s1">&#39;wrapped body specifies its tensor sharding without the new stage dim.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;per_stage_vars&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;Use separate variables for each stage. With single_stage_body only.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;circular_repeat&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s1">&#39;If &gt; 1, it enables circular pipeline, and this is the number of &#39;</span>
        <span class="s1">&#39;repeats for each stage.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;unroll&#39;</span><span class="p">,</span> <span class="s1">&#39;eval_only&#39;</span><span class="p">,</span>
             <span class="s1">&#39;Unroll the layers: never, eval_only, always.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">unroll</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;never&#39;</span><span class="p">,</span> <span class="s1">&#39;eval_only&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># Circular pipeline only supported for single_stage_body without per-stage</span>
      <span class="c1"># vars, and with stage sharding.</span>
      <span class="k">assert</span> <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">stage_parallel_body</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span>
              <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shard_stages_1d</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">pipeline_stage_mesh_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">stage_parallel_body</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">single_stage_body</span> <span class="ow">is</span> <span class="kc">None</span>
      <span class="k">assert</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">per_stage_vars</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;body&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">stage_parallel_body</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">single_stage_body</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_stage_vars</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">):</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;body_iter_</span><span class="si">%05d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">single_stage_body</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;body&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">single_stage_body</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_vars</span> <span class="o">=</span> <span class="p">[]</span>

<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer._FindPerStageVarShardingDim"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer._FindPerStageVarShardingDim">[docs]</a>  <span class="k">def</span> <span class="nf">_FindPerStageVarShardingDim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Finds a sharding dimension for per-stage variables before stacking.</span>

<span class="sd">    Find a dimension to split variables. Per-stage variables do not have the</span>
<span class="sd">    leading stage dimension before stacking.</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: list of integers of the single-stage variable shape.</span>

<span class="sd">    Returns:</span>
<span class="sd">      An index of the found sharding dimension, or -1 if not found.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">per_stage_vars</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">shard_stages_1d</span>
    <span class="n">split_dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="n">min_padding_ratio</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)):</span>
      <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">-</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">%</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">)</span> <span class="o">%</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span>
      <span class="k">if</span> <span class="n">padding</span> <span class="o">&lt;</span> <span class="n">min_padding_ratio</span> <span class="o">*</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
        <span class="n">min_padding_ratio</span> <span class="o">=</span> <span class="n">padding</span> <span class="o">/</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">padding</span> <span class="o">&lt;=</span> <span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">:</span>
          <span class="n">split_dim</span> <span class="o">=</span> <span class="n">i</span>
    <span class="k">return</span> <span class="n">split_dim</span></div>

<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer._CreateChildrenVariables"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer._CreateChildrenVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateChildrenVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="k">with</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">MeshSplitDimPrefixContext</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">pipeline_stage_mesh_dim</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">stage_parallel_body</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_stage_vars</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">):</span>
              <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;iter_</span><span class="si">%05d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="s1">&#39;body_iter_</span><span class="si">%05d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">VariableShapePrefixContext</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">):</span>
              <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">VariableShapePrefixContext</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span><span class="p">):</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="o">.</span><span class="n">body</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>
              <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="o">.</span><span class="n">body</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateChildrenVariables</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_SplitVar</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">shard_stages_1d</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_stage_vars</span><span class="p">:</span>
          <span class="n">split_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_FindPerStageVarShardingDim</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">split_dim</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">split_dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">v</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span>
              <span class="n">v</span><span class="p">,</span> <span class="n">split_dim</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">,</span> <span class="n">use_sharding_op</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="k">elif</span> <span class="n">p</span><span class="o">.</span><span class="n">pipeline_stage_mesh_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">per_stage_vars</span>
        <span class="k">if</span> <span class="n">xla_sharding</span><span class="o">.</span><span class="n">get_op_sharding</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">op</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">v</span>
        <span class="c1"># If the var is not annotated, use MeshSplit on the stage dim.</span>
        <span class="k">return</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">MeshSplit</span><span class="p">(</span>
            <span class="n">v</span><span class="p">,</span>
            <span class="n">p</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span>
            <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">pipeline_stage_mesh_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">use_sharding_op</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">v</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_SplitVar</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_AddToNonTrainable</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">v</span><span class="o">.</span><span class="n">trainable</span><span class="p">:</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Non-trainable var in pipelined layer: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="c1"># TODO(yuanzx): support non-trainable vars for circular pipeline.</span>
        <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_AddToNonTrainable</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_vars</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">stage_parallel_body</span> <span class="ow">and</span> <span class="p">(</span>
        <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">shard_stages_1d</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">per_stage_vars</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
          <span class="s1">&#39;When using single_stage_body, non-trainable vars are only supported &#39;</span>
          <span class="s1">&#39;when per_stage_vars=False and shard_stages_1d=True.&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer.BodyFProp"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer.BodyFProp">[docs]</a>  <span class="k">def</span> <span class="nf">BodyFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">fn_name</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">control_out</span><span class="p">,</span> <span class="n">aux_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_BodyFPropInternal</span><span class="p">(</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">fn_name</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">outer_aux_loss_context</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">AuxLossContext</span><span class="o">.</span><span class="n">Current</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">outer_aux_loss_context</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">aux_loss</span> <span class="ow">in</span> <span class="n">aux_losses</span><span class="p">:</span>
        <span class="n">aux_loss</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">])</span>
        <span class="n">outer_aux_loss_context</span><span class="o">.</span><span class="n">AddLoss</span><span class="p">(</span><span class="n">aux_loss</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">control_out</span></div>

<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer.BodyFPropNoMicrobatching"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer.BodyFPropNoMicrobatching">[docs]</a>  <span class="k">def</span> <span class="nf">BodyFPropNoMicrobatching</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">fn_name</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">BodyFProp</span><span class="p">(</span>
        <span class="n">theta</span><span class="p">,</span>
        <span class="n">fn_name</span><span class="p">,</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>  <span class="c1"># iteration,</span>
        <span class="mi">1</span><span class="p">,</span>  <span class="c1"># num_microbatches</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer._MicrobatchAndRepeatIDs"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer._MicrobatchAndRepeatIDs">[docs]</a>  <span class="k">def</span> <span class="nf">_MicrobatchAndRepeatIDs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iteration</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns microbatch IDs and repeat IDs for each stage.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">stage_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">)</span>
    <span class="n">microbatch_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">iteration</span> <span class="o">-</span> <span class="n">stage_ids</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">repeat_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">microbatch_ids</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">),</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span><span class="p">)</span>
      <span class="n">segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">microbatch_ids</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">)</span>
      <span class="n">microbatch_ids</span> <span class="o">=</span> <span class="n">segment_id</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span>
          <span class="n">microbatch_ids</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">repeat_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">stage_ids</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">microbatch_ids</span><span class="p">,</span> <span class="n">repeat_id</span></div>

<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer._BodyFPropInternal"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer._BodyFPropInternal">[docs]</a>  <span class="k">def</span> <span class="nf">_BodyFPropInternal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">fn_name</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">,</span>
                         <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">wrappers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Wrap non-trainable vars with VarWrapperTrackAssign to track control</span>
    <span class="c1"># dependencies.</span>
    <span class="k">def</span> <span class="nf">_WrapWithTracking</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">v</span><span class="o">.</span><span class="n">trainable</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">v</span>
      <span class="n">wrapper</span> <span class="o">=</span> <span class="n">var_tmp_wrappers</span><span class="o">.</span><span class="n">VarWrapperTrackAssign</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
      <span class="n">wrappers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wrapper</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">wrapper</span>

    <span class="k">def</span> <span class="nf">_BodyFProp</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
      <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">TransformVarsTempContext</span><span class="p">(</span><span class="n">_WrapWithTracking</span><span class="p">):</span>
        <span class="c1"># Create an inner aux loss context, and extract the aux losses as extra</span>
        <span class="c1"># outputs so that the function can be vectorized.</span>
        <span class="k">with</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">AuxLossContext</span><span class="p">(</span><span class="n">reentrant</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">al_ctx</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_stage_vars</span><span class="p">:</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">body_iter_00000</span><span class="p">,</span> <span class="n">fn_name</span><span class="p">)(</span><span class="n">x</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">args</span><span class="p">,</span>
                                                          <span class="o">**</span><span class="n">x</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">outs</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">body</span><span class="p">,</span> <span class="n">fn_name</span><span class="p">)(</span><span class="n">x</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">x</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>
          <span class="k">if</span> <span class="ow">not</span> <span class="n">wrappers</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">outs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">al_ctx</span><span class="o">.</span><span class="n">aux_losses</span>
          <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span>
              <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">control_after_assigns</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">wrappers</span><span class="p">]):</span>
            <span class="n">control_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
          <span class="k">return</span> <span class="n">outs</span><span class="p">,</span> <span class="n">control_out</span><span class="p">,</span> <span class="n">al_ctx</span><span class="o">.</span><span class="n">aux_losses</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">stage_parallel_body</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">_BodyFProp</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">theta_args</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">shard_stages_1d</span><span class="p">:</span>
      <span class="n">device_mesh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">)</span>
      <span class="n">stage_mesh_dim</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">elif</span> <span class="n">p</span><span class="o">.</span><span class="n">pipeline_stage_mesh_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">device_mesh</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">device_mesh</span>
      <span class="n">stage_mesh_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">pipeline_stage_mesh_dim</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">device_mesh</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># Each stage should have its own seed.</span>
      <span class="n">seeds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetIncStepSeed</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">)])</span>
      <span class="n">seeds</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Replicate</span><span class="p">(</span><span class="n">seeds</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">_ToManual</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
          <span class="k">return</span> <span class="n">x</span>
        <span class="k">if</span> <span class="n">var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">sharding</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">GetMeshSplitSharding</span><span class="p">(</span>
              <span class="n">device_mesh</span><span class="p">,</span> <span class="p">[</span><span class="n">stage_mesh_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span>
              <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">proto</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>
          <span class="c1"># Partially specify that only dim 0 is annotated with sharding.</span>
          <span class="n">unspecified_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">sharding</span> <span class="o">=</span> <span class="n">xla_sharding</span><span class="o">.</span><span class="n">get_op_sharding</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
          <span class="n">unspecified_dims</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">to_manual</span> <span class="o">=</span> <span class="n">xla_sharding</span><span class="o">.</span><span class="n">auto_to_manual_spmd_partition</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">sharding</span><span class="p">,</span> <span class="n">single_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">unspecified_dims</span><span class="o">=</span><span class="n">unspecified_dims</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">to_manual</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_stage_vars</span><span class="p">:</span>
        <span class="n">manual_theta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_ToManual</span><span class="p">,</span> <span class="n">theta_args</span><span class="o">.</span><span class="n">theta</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">manual_theta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_ToManual</span><span class="p">,</span> <span class="n">theta_args</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">body</span><span class="o">.</span><span class="n">vars</span><span class="p">)</span>
      <span class="n">one_stage_theta_args</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">=</span><span class="n">manual_theta</span><span class="p">,</span>
          <span class="n">args</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_ToManual</span><span class="p">,</span> <span class="n">theta_args</span><span class="o">.</span><span class="n">args</span><span class="p">))</span>
      <span class="n">py_utils</span><span class="o">.</span><span class="n">ResetStepSeed</span><span class="p">(</span><span class="n">_ToManual</span><span class="p">(</span><span class="n">seeds</span><span class="p">))</span>

      <span class="k">def</span> <span class="nf">_ToManualReplicate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
          <span class="k">return</span> <span class="n">x</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">shard_stages_1d</span><span class="p">:</span>
          <span class="n">sharding</span> <span class="o">=</span> <span class="n">xla_sharding</span><span class="o">.</span><span class="n">Sharding</span><span class="o">.</span><span class="n">replicate</span><span class="p">()</span>
          <span class="k">return</span> <span class="n">xla_sharding</span><span class="o">.</span><span class="n">auto_to_manual_spmd_partition</span><span class="p">(</span>
              <span class="n">x</span><span class="p">,</span> <span class="n">sharding</span><span class="o">.</span><span class="n">proto</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="c1"># We do a broadcast first, then we can reuse _ToManual().</span>
          <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
          <span class="k">return</span> <span class="n">_ToManual</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

      <span class="n">stage_id</span> <span class="o">=</span> <span class="n">_ToManual</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">))</span>

      <span class="n">microbatch_ids</span><span class="p">,</span> <span class="n">repeat_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MicrobatchAndRepeatIDs</span><span class="p">(</span><span class="n">iteration</span><span class="p">)</span>
      <span class="n">microbatch_id</span> <span class="o">=</span> <span class="n">_ToManual</span><span class="p">(</span><span class="n">microbatch_ids</span><span class="p">)</span>
      <span class="n">repeat_id</span> <span class="o">=</span> <span class="n">_ToManual</span><span class="p">(</span><span class="n">repeat_ids</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">one_stage_theta_args</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="n">repeat_id</span><span class="p">],</span> <span class="n">one_stage_theta_args</span><span class="o">.</span><span class="n">theta</span><span class="p">)</span>

      <span class="n">microbatch_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">microbatch_id</span><span class="p">,</span> <span class="n">num_microbatches</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">_KwargSlice</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
          <span class="k">return</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">_ToManualReplicate</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="n">microbatch_id</span><span class="p">]</span>

      <span class="n">one_stage_theta_args</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_KwargSlice</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

      <span class="c1"># Wrap non-trainable vars with StackedVarWrapperWithManualSharding, in</span>
      <span class="c1"># case they are accessed directly in FProp (e.g., batch norm vars).</span>
      <span class="k">def</span> <span class="nf">_WrapWithManual</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">v</span><span class="o">.</span><span class="n">trainable</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">v</span>
        <span class="k">return</span> <span class="n">var_tmp_wrappers</span><span class="o">.</span><span class="n">StackedVarWrapperWithManualSharding</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

      <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">TransformVarsTempContext</span><span class="p">(</span><span class="n">_WrapWithManual</span><span class="p">):</span>
        <span class="c1"># Step seed should be incremented by p.num_stages.</span>
        <span class="k">with</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">StepSeedIncrementContext</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">):</span>
          <span class="k">with</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GlobalStepContext</span><span class="p">(</span>
              <span class="n">_ToManualReplicate</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetGlobalStep</span><span class="p">())):</span>
            <span class="c1"># If there are any internal annotations in the stage, they will be</span>
            <span class="c1"># subgrouped with manual partitioning on stage_mesh_dim.</span>
            <span class="k">with</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">ManualMeshDimContext</span><span class="p">(</span><span class="n">stage_mesh_dim</span><span class="p">):</span>
              <span class="n">one_stage_outputs</span><span class="p">,</span> <span class="n">control_out</span><span class="p">,</span> <span class="n">aux_losses</span> <span class="o">=</span> <span class="n">_BodyFProp</span><span class="p">(</span>
                  <span class="n">one_stage_theta_args</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">_ToAuto</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
          <span class="k">return</span> <span class="n">x</span>
        <span class="n">full_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">unspecified_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_shape</span><span class="p">)))</span>
        <span class="n">sharding</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">GetMeshSplitSharding</span><span class="p">(</span>
            <span class="n">device_mesh</span><span class="p">,</span> <span class="p">[</span><span class="n">stage_mesh_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">xla_sharding</span><span class="o">.</span><span class="n">manual_to_auto_spmd_partition</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span>
            <span class="n">sharding</span><span class="o">.</span><span class="n">proto</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span>
            <span class="n">full_shape</span><span class="o">=</span><span class="n">full_shape</span><span class="p">,</span>
            <span class="n">single_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">unspecified_dims</span><span class="o">=</span><span class="n">unspecified_dims</span><span class="p">)</span>

      <span class="c1"># Reset step seed to the last stage&#39;s final seed.</span>
      <span class="n">py_utils</span><span class="o">.</span><span class="n">ResetStepSeed</span><span class="p">(</span><span class="n">_ToAuto</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetStepSeed</span><span class="p">())[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
      <span class="c1"># Convert aux losses to per-stage vector losses.</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_ToAuto</span><span class="p">,</span> <span class="n">one_stage_outputs</span><span class="p">)</span>
      <span class="n">aux_losses</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_ToAuto</span><span class="p">,</span> <span class="n">aux_losses</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">control_out</span><span class="p">,</span> <span class="n">aux_losses</span>

    <span class="k">else</span><span class="p">:</span>
      <span class="n">stage_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">)</span>
      <span class="n">microbatch_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">iteration</span> <span class="o">-</span> <span class="n">stage_id</span><span class="p">,</span>
                                 <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">stage_id</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

      <span class="k">def</span> <span class="nf">_KwargSlice</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
          <span class="k">return</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">microbatch_id</span><span class="p">)</span>

      <span class="n">theta_args</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_KwargSlice</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">vectorized_map</span><span class="p">(</span>
          <span class="n">_BodyFProp</span><span class="p">,</span> <span class="n">theta_args</span><span class="p">,</span> <span class="n">fallback_to_while_loop</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_body</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A child layer to be used as the loop body.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_stage_vars</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">body_iter_00000</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">body</span>

<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer._unrolled_fprop"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer._unrolled_fprop">[docs]</a>  <span class="k">def</span> <span class="nf">_unrolled_fprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">fprop_inputs</span> <span class="o">=</span> <span class="n">args</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">layer_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_stage_vars</span><span class="p">:</span>
          <span class="n">layer_theta</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="s1">&#39;body_iter_</span><span class="si">%05d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer_idx</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>

          <span class="k">def</span> <span class="nf">_Slice</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">idx</span><span class="o">=</span><span class="n">layer_idx</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">t</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

          <span class="n">layer_theta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_Slice</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
        <span class="n">fprop_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_body</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">layer_theta</span><span class="p">,</span> <span class="o">*</span><span class="n">fprop_inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">fprop_outputs</span> <span class="o">=</span> <span class="n">_ToTuple</span><span class="p">(</span><span class="n">fprop_outputs</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">fprop_outputs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">fprop_inputs</span><span class="p">)</span>
        <span class="n">fprop_inputs</span> <span class="o">=</span> <span class="n">fprop_outputs</span>
      <span class="k">return</span> <span class="n">fprop_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">fprop_outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">fprop_outputs</span></div>

<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer.FProp"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">FPropFn</span><span class="p">(</span>
        <span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;FProp&#39;</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">padded_per_stage_states</span><span class="o">=</span><span class="p">[],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer.PadMicrobatches"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer.PadMicrobatches">[docs]</a>  <span class="k">def</span> <span class="nf">PadMicrobatches</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PadMicrobatchesInternal</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">pad_stages</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer._PadMicrobatchesInternal"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer._PadMicrobatchesInternal">[docs]</a>  <span class="k">def</span> <span class="nf">_PadMicrobatchesInternal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">pad_stages</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pads a microbatched input for bubble iterations.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
      <span class="k">return</span> <span class="n">inp</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">padding</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">pad_stages</span><span class="p">:</span>
        <span class="n">padding</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
      <span class="n">padded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># First pad the input to a multiple of p.num_stages.</span>
      <span class="k">if</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">-</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">]]</span>
        <span class="n">padding</span> <span class="o">+=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
      <span class="c1"># See the class documentation for padding the input for circular pipeline.</span>
      <span class="n">segmented_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span>
                        <span class="p">]</span> <span class="o">+</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
      <span class="n">segmented</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">segmented_shape</span><span class="p">)</span>
      <span class="n">padding</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
      <span class="n">padding</span> <span class="o">+=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">]]</span>
      <span class="k">if</span> <span class="n">pad_stages</span><span class="p">:</span>
        <span class="n">padding</span> <span class="o">+=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">padding</span> <span class="o">+=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
      <span class="n">padding</span> <span class="o">+=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
      <span class="n">padded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">segmented</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
      <span class="n">interleaved_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">]</span>
      <span class="n">interleaved_shape</span> <span class="o">+=</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
      <span class="n">interleaved</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">padded</span><span class="p">,</span> <span class="n">interleaved_shape</span><span class="p">)</span>
      <span class="n">bubble_padding</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">padded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">interleaved</span><span class="p">,</span> <span class="n">bubble_padding</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">shard_stages_1d</span><span class="p">:</span>
      <span class="n">padded</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">padded</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">,</span> <span class="n">use_sharding_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">padded</span></div>

<div class="viewcode-block" id="LayerwiseShardablePipelinedLayer.FPropFn"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.LayerwiseShardablePipelinedLayer.FPropFn">[docs]</a>  <span class="k">def</span> <span class="nf">FPropFn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">fn_name</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">padded_per_stage_states</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs forward pass on a specified function.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">unroll</span> <span class="o">==</span> <span class="s1">&#39;always&#39;</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">unroll</span> <span class="o">==</span> <span class="s1">&#39;eval_only&#39;</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unrolled_fprop</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_stage_vars</span><span class="p">:</span>
      <span class="n">all_iters</span> <span class="o">=</span> <span class="p">[</span><span class="n">theta</span><span class="p">[</span><span class="s1">&#39;body_iter_</span><span class="si">%05d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">)]</span>
      <span class="n">theta_body</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="k">lambda</span> <span class="o">*</span><span class="n">t</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">t</span><span class="p">)),</span>
                                         <span class="o">*</span><span class="n">all_iters</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">_PassthroughVarSharding</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="n">split_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_FindPerStageVarShardingDim</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="k">if</span> <span class="n">split_dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
          <span class="n">x</span> <span class="o">=</span> <span class="n">xla_sharding</span><span class="o">.</span><span class="n">replicate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">use_sharding_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="c1"># The stacked theta has a leading dim, so we use split_dim + 1.</span>
          <span class="n">x</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span>
              <span class="n">x</span><span class="p">,</span> <span class="n">split_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">,</span> <span class="n">use_sharding_op</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">shard_stages_1d</span><span class="p">:</span>
        <span class="c1"># Pass through the per-stage variables&#39; sharding to the stacked theta.</span>
        <span class="c1"># Later, this will be resharded on the leading stage dim. This explicit</span>
        <span class="c1"># resharding makes sure that resharding happens after the concat, and</span>
        <span class="c1"># concat partitioning is trivial on the pass-through dim.</span>
        <span class="n">theta_body</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_PassthroughVarSharding</span><span class="p">,</span> <span class="n">theta_body</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">theta_body</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">body</span>

    <span class="n">needs_microbatching</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_microbatches</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">num_microbatches</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">args</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">microbatch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">num_microbatches</span>
        <span class="k">assert</span> <span class="n">batch_size</span> <span class="o">%</span> <span class="n">p</span><span class="o">.</span><span class="n">microbatch_size</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="n">num_microbatches</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">//</span> <span class="n">p</span><span class="o">.</span><span class="n">microbatch_size</span>
        <span class="n">needs_microbatching</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">num_microbatches</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">num_microbatches</span>
      <span class="n">needs_microbatching</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">if</span> <span class="n">needs_microbatching</span><span class="p">:</span>

      <span class="k">def</span> <span class="nf">_ToMicrobatches</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
          <span class="k">return</span> <span class="n">x</span>
        <span class="n">x_shape</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">x_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="n">num_microbatches</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="c1"># We first put num_microbatches in the inner dimension then transpose</span>
        <span class="c1"># it. This allows the sharding on the batch (if any) to be propagated</span>
        <span class="c1"># to the microbatch dimension. We cannot shard the num_microbatches</span>
        <span class="c1"># dimension, since it&#39;s indexed by the loop iteration.</span>
        <span class="n">reshaped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">x_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">num_microbatches</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">]</span> <span class="o">+</span> <span class="n">x_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">reshaped</span><span class="p">,</span>
                            <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">reshaped</span><span class="o">.</span><span class="n">shape</span><span class="p">))))</span>

      <span class="n">args</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_ToMicrobatches</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
      <span class="n">kwargs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_ToMicrobatches</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_MaybeReplicateNumMicrobatches</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
      <span class="c1"># Mark the num_microbatches dim replicated.</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
        <span class="k">return</span> <span class="n">x</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">shard_stages_1d</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Replicate</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">pipeline_stage_mesh_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Partially specify that only dim 0 is replicated.</span>
        <span class="k">return</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">MeshSplit</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span>
            <span class="n">p</span><span class="o">.</span><span class="n">device_mesh</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">unspecified_dims</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">))))</span>
      <span class="k">return</span> <span class="n">x</span>

    <span class="c1"># Replicate the input as the layer is only sharded on the stage dimension.</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_MaybeReplicateNumMicrobatches</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_MaybeReplicateNumMicrobatches</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">shard_stages_1d</span><span class="p">:</span>

      <span class="k">def</span> <span class="nf">_SplitStages</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">)</span>

      <span class="n">theta_body</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_SplitStages</span><span class="p">,</span> <span class="n">theta_body</span><span class="p">)</span>

    <span class="c1"># Adds a `stages` dimension after the leading num_microbatches to the inputs</span>
    <span class="c1"># which will be sharded. Also pad the leading num_microbatches dimension by</span>
    <span class="c1"># num_stages - 1 to match loop iteration count, which corresponds to the</span>
    <span class="c1"># bubbles between forward and backward passes.</span>
    <span class="c1">#</span>
    <span class="c1"># Inputs are not the loop state: they are not changed during the loop. The</span>
    <span class="c1"># state (shifting buffer) does not have a num_microbatches dimension.</span>
    <span class="k">def</span> <span class="nf">_PadInput</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
        <span class="k">return</span> <span class="n">inp</span>
      <span class="c1"># Takes input tensor of shape [num_microbatches, ...] and returns padded</span>
      <span class="c1"># tensor of shape [num_iterations_with_bubbles, num_stages,  ...],</span>
      <span class="c1"># where num_stages is a new dimension.</span>
      <span class="n">with_new_dim</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">padded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PadMicrobatchesInternal</span><span class="p">(</span><span class="n">with_new_dim</span><span class="p">,</span> <span class="n">pad_stages</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">padded</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
      <span class="k">assert</span> <span class="n">padded</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span>
      <span class="k">return</span> <span class="n">padded</span>

    <span class="n">padded_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_PadInput</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
    <span class="n">padded_shapes</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">padded_inputs</span><span class="p">)</span>
    <span class="n">remove_first_dim</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">state_shapes</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">remove_first_dim</span><span class="p">,</span> <span class="n">padded_shapes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_ArgsToState</span><span class="p">(</span><span class="n">arg_list</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Returns a NestedMap from a list of FProp args.&quot;&quot;&quot;</span>
      <span class="n">state</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>
      <span class="c1"># Maintains a mapping from arg_idx to tensor. states cannot contain None</span>
      <span class="c1"># tensors.</span>
      <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">padded_inputs</span><span class="p">)):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg_list</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">):</span>
          <span class="c1"># Make sure each value in the NestedMap is a tensor.</span>
          <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">arg_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Each value in the input NestedMap must be a tensor.&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">arg_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">state</span><span class="p">[</span><span class="s1">&#39;_s</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="o">=</span> <span class="n">arg_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
      <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">_StateToArgs</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">shapes</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Returns a list of FProp args from a NestedMap.&quot;&quot;&quot;</span>
      <span class="n">arg_list</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">padded_inputs</span><span class="p">)):</span>
        <span class="n">attr</span> <span class="o">=</span> <span class="s1">&#39;_s</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
        <span class="n">arg_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="k">if</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">state</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">arg_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                              <span class="n">shapes</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
      <span class="k">return</span> <span class="n">arg_list</span>

    <span class="k">def</span> <span class="nf">_CellFn</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs_and_per_stage_states</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Recurrent cell function wrapper of body.FProp.&quot;&quot;&quot;</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs_and_per_stage_states</span><span class="o">.</span><span class="n">inputs</span>
      <span class="n">per_stage_states</span> <span class="o">=</span> <span class="n">inputs_and_per_stage_states</span><span class="o">.</span><span class="n">per_stage_states</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span>
                            <span class="n">per_stage_states</span><span class="p">,</span> <span class="n">padded_per_stage_states</span><span class="p">)</span>
      <span class="n">state0</span><span class="o">.</span><span class="n">iteration</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([])</span>
      <span class="n">state0</span><span class="o">.</span><span class="n">aux_loss</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([])</span>

      <span class="k">def</span> <span class="nf">_SelectInput</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="n">in_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
          <span class="c1"># The state is aligned to previous stage. We shift it to the right by</span>
          <span class="c1"># 1 stage. If the stage dimension is partitioned in GShard, this will</span>
          <span class="c1"># cause a collective-permute being added.</span>
          <span class="n">padding</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
          <span class="n">shifted_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">padding</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="c1"># Rotate the circular buffer. If the stage dimension is partitioned in</span>
          <span class="c1"># GShard, this will cause a collective-permute being added.</span>
          <span class="n">shifted_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span> <span class="n">state</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
          <span class="n">in_segment_offset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span>
                                          <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">)</span>
          <span class="n">in_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">in_mask</span><span class="p">,</span>
                                   <span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">in_segment_offset</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">))</span>

        <span class="n">in_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">in_mask</span><span class="p">,</span>
                             <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">in_mask</span><span class="p">,</span> <span class="n">shifted_state</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">shifted_state</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">shifted_state</span><span class="p">)</span>

      <span class="n">selected_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
          <span class="n">_SelectInput</span><span class="p">,</span> <span class="n">_StateToArgs</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">args</span><span class="p">,</span> <span class="n">state_shapes</span><span class="p">),</span>
          <span class="n">_StateToArgs</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">state_shapes</span><span class="p">))</span>

      <span class="c1"># Restore non-trainable vars to state0, because it can be called in the</span>
      <span class="c1"># backward pass.</span>
      <span class="n">assigns</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">s</span><span class="p">),</span>
                                      <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_vars</span><span class="p">,</span>
                                      <span class="n">state0</span><span class="o">.</span><span class="n">non_trainable_vars</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">_BodyFPropWithAuxLoss</span><span class="p">():</span>
        <span class="k">with</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">AuxLossContext</span><span class="p">(</span><span class="n">reentrant</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">al_ctx</span><span class="p">:</span>
          <span class="n">fprop_outputs</span><span class="p">,</span> <span class="n">ctrl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">BodyFProp</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">fn_name</span><span class="p">,</span> <span class="n">state0</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span>
                                               <span class="n">num_microbatches</span><span class="p">,</span>
                                               <span class="o">*</span><span class="n">selected_inputs</span><span class="p">,</span>
                                               <span class="o">*</span><span class="n">per_stage_states</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
          <span class="n">aux_losses</span> <span class="o">=</span> <span class="n">al_ctx</span><span class="o">.</span><span class="n">aux_losses</span>
        <span class="k">return</span> <span class="n">fprop_outputs</span><span class="p">,</span> <span class="n">ctrl</span><span class="p">,</span> <span class="n">aux_losses</span>

      <span class="k">if</span> <span class="n">assigns</span><span class="p">:</span>
        <span class="c1"># Group the dependencies into a single no_op to avoid quadratic number</span>
        <span class="c1"># of control edges.</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">assigns</span><span class="p">):</span>
          <span class="n">ctrl_before</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">no_op</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">ctrl_before</span><span class="p">]):</span>
          <span class="n">fprop_outputs</span><span class="p">,</span> <span class="n">ctrl</span><span class="p">,</span> <span class="n">aux_losses</span> <span class="o">=</span> <span class="n">_BodyFPropWithAuxLoss</span><span class="p">()</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">fprop_outputs</span><span class="p">,</span> <span class="n">ctrl</span><span class="p">,</span> <span class="n">aux_losses</span> <span class="o">=</span> <span class="n">_BodyFPropWithAuxLoss</span><span class="p">()</span>
      <span class="n">fprop_outputs</span> <span class="o">=</span> <span class="n">_ToTuple</span><span class="p">(</span><span class="n">fprop_outputs</span><span class="p">)</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">fprop_outputs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">selected_inputs</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">per_stage_states</span><span class="p">)</span>

      <span class="c1"># Passes fprop outputs to the next layer through state.</span>
      <span class="n">state1</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
          <span class="n">args</span><span class="o">=</span><span class="n">_ArgsToState</span><span class="p">(</span><span class="n">fprop_outputs</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">selected_inputs</span><span class="p">)]),</span>
          <span class="n">per_stage_states</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">fprop_outputs</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">selected_inputs</span><span class="p">):]),</span>
          <span class="n">iteration</span><span class="o">=</span><span class="n">state0</span><span class="o">.</span><span class="n">iteration</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>

      <span class="c1"># v and v0 are the new and old values for each stage with leading dim</span>
      <span class="c1"># num_stages. Selects v if it&#39;s a valid iteration and v0 if it&#39;s a bubble.</span>
      <span class="k">def</span> <span class="nf">_NewValueIfValidIter</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">v0</span><span class="p">):</span>
        <span class="n">mb_id</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MicrobatchAndRepeatIDs</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">iteration</span><span class="p">)</span>
        <span class="n">valid_iter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">mb_id</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">)))</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">ctrl</span><span class="p">]):</span>
          <span class="n">v1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">valid_iter</span><span class="p">,</span>
                           <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
            <span class="n">v1</span><span class="p">,</span> <span class="n">v0</span><span class="p">)</span>

      <span class="c1"># Pass state0.non_trainable_vars or updated values depending on whether</span>
      <span class="c1"># it is a bubble iteration.</span>
      <span class="n">state1</span><span class="o">.</span><span class="n">non_trainable_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
          <span class="n">_NewValueIfValidIter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_vars</span><span class="p">,</span>
          <span class="n">state0</span><span class="o">.</span><span class="n">non_trainable_vars</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">aux_losses</span><span class="p">:</span>
        <span class="n">aux_losses</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span>
            <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">state0</span><span class="o">.</span><span class="n">aux_loss</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">aux_losses</span><span class="p">])</span>
        <span class="n">state1</span><span class="o">.</span><span class="n">aux_loss</span> <span class="o">=</span> <span class="n">state0</span><span class="o">.</span><span class="n">aux_loss</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
            <span class="n">_NewValueIfValidIter</span><span class="p">(</span><span class="n">aux_losses</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">aux_losses</span><span class="p">)))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">state1</span><span class="o">.</span><span class="n">aux_loss</span> <span class="o">=</span> <span class="n">state0</span><span class="o">.</span><span class="n">aux_loss</span>
      <span class="k">return</span> <span class="n">state1</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="n">inputs_nmap</span> <span class="o">=</span> <span class="n">_ArgsToState</span><span class="p">(</span><span class="n">padded_inputs</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">_CreateInitState</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">inp</span><span class="p">)[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

      <span class="c1"># Add FProp arg list to state0.</span>
      <span class="n">state0</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
          <span class="n">args</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_CreateInitState</span><span class="p">,</span> <span class="n">inputs_nmap</span><span class="p">),</span>
          <span class="n">per_stage_states</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_CreateInitState</span><span class="p">,</span>
                                                 <span class="n">padded_per_stage_states</span><span class="p">),</span>
          <span class="n">iteration</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
          <span class="n">aux_loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
          <span class="n">non_trainable_vars</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span>
                                                   <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_vars</span><span class="p">))</span>
      <span class="n">final_non_trainable_var_values</span> <span class="o">=</span> <span class="kc">None</span>

      <span class="k">def</span> <span class="nf">_RestoreVarsToFinal</span><span class="p">():</span>
        <span class="k">assert</span> <span class="n">final_non_trainable_var_values</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">assigns</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_vars</span><span class="p">,</span>
                                        <span class="n">final_non_trainable_var_values</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">assigns</span><span class="p">):</span>
          <span class="k">return</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">no_op</span><span class="p">()]</span>

      <span class="c1"># Runs body.FProp k times using Recurrent where k = dim 0 of inputs_nmap.</span>
      <span class="n">accum</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">recurrent</span><span class="o">.</span><span class="n">Recurrent</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">=</span><span class="n">theta_body</span><span class="p">,</span>
          <span class="n">state0</span><span class="o">=</span><span class="n">state0</span><span class="p">,</span>
          <span class="n">inputs</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
              <span class="n">inputs</span><span class="o">=</span><span class="n">inputs_nmap</span><span class="p">,</span> <span class="n">per_stage_states</span><span class="o">=</span><span class="n">padded_per_stage_states</span><span class="p">),</span>
          <span class="n">cell_fn</span><span class="o">=</span><span class="n">_CellFn</span><span class="p">,</span>
          <span class="n">extras</span><span class="o">=</span><span class="p">{},</span>
          <span class="n">allow_implicit_capture</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">allow_implicit_capture</span><span class="p">,</span>
          <span class="n">allowed_tensor_captures</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_vars</span> <span class="o">+</span> <span class="p">[</span>
              <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
              <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">))</span>
          <span class="p">],</span>
          <span class="n">backward_cleanup</span><span class="o">=</span><span class="p">(</span><span class="n">_RestoreVarsToFinal</span>
                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_vars</span> <span class="k">else</span> <span class="kc">None</span><span class="p">))</span>

      <span class="c1"># Retrieves fprop outputs.</span>
      <span class="k">def</span> <span class="nf">_ExtractLastStage</span><span class="p">(</span><span class="n">outp</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">outp</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="c1"># See the class documuentation for circular pipeline.</span>
          <span class="n">bubble_removed</span> <span class="o">=</span> <span class="n">outp</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
          <span class="n">num_segments</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_microbatches</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span>
          <span class="n">segmented</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
              <span class="n">bubble_removed</span><span class="p">,</span>
              <span class="p">[</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">circular_repeat</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">]</span> <span class="o">+</span> <span class="n">outp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
          <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">segmented</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                      <span class="o">...</span><span class="p">],</span> <span class="p">[</span><span class="n">num_segments</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_stages</span><span class="p">]</span> <span class="o">+</span>
                            <span class="n">outp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])[:</span><span class="n">num_microbatches</span><span class="p">]</span>

      <span class="n">final_non_trainable_var_values</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">non_trainable_vars</span>
      <span class="n">output_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
          <span class="n">_ExtractLastStage</span><span class="p">,</span> <span class="n">_StateToArgs</span><span class="p">(</span><span class="n">accum</span><span class="o">.</span><span class="n">args</span><span class="p">,</span> <span class="n">padded_shapes</span><span class="p">))</span>
      <span class="n">output_per_stage_states</span> <span class="o">=</span> <span class="n">accum</span><span class="o">.</span><span class="n">per_stage_states</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_vars</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_RestoreVarsToFinal</span><span class="p">()):</span>
          <span class="n">output_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">output_tensors</span><span class="p">)</span>
          <span class="n">output_per_stage_states</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">output_per_stage_states</span><span class="p">)</span>

      <span class="n">aux_loss_context</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">AuxLossContext</span><span class="o">.</span><span class="n">Current</span><span class="p">()</span>
      <span class="k">if</span> <span class="n">aux_loss_context</span><span class="p">:</span>
        <span class="n">aux_loss_context</span><span class="o">.</span><span class="n">AddLoss</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">aux_loss</span><span class="p">)</span>

      <span class="n">output_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_MaybeReplicateNumMicrobatches</span><span class="p">,</span>
                                             <span class="n">output_tensors</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">needs_microbatching</span><span class="p">:</span>

        <span class="k">def</span> <span class="nf">_ToBatches</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
          <span class="n">x_shape</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
          <span class="n">transposed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_shape</span><span class="p">))))</span>
          <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">transposed</span><span class="p">,</span>
                            <span class="p">[</span><span class="n">num_microbatches</span> <span class="o">*</span> <span class="n">x_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">+</span> <span class="n">x_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>

        <span class="n">output_tensors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">_ToBatches</span><span class="p">,</span> <span class="n">output_tensors</span><span class="p">)</span>
      <span class="n">output_tensors</span> <span class="o">+=</span> <span class="n">output_per_stage_states</span>
      <span class="k">return</span> <span class="n">output_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_tensors</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="nb">tuple</span><span class="p">(</span>
          <span class="n">output_tensors</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="StateLayer"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.StateLayer">[docs]</a><span class="k">class</span> <span class="nc">StateLayer</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Abstract container for recurrent state for incremental decoding.</span>

<span class="sd">  It has two operation modes.</span>

<span class="sd">  During training, it does nothing. FProp(theta, x) is called with theta.t=None,</span>
<span class="sd">  and returns x unchanged.</span>

<span class="sd">  During decoding, it expects</span>

<span class="sd">    theta.t:      an int32 scalar.</span>
<span class="sd">    theta.state:  a tensor of shape `[batch, max_steps, ...]`.</span>
<span class="sd">    x:            a tensor of shape `[batch, 1, ...]`.</span>

<span class="sd">  Subclass must define the following functions:</span>
<span class="sd">    NewState(self, shape)</span>
<span class="sd">    _Step(theta, x).</span>

<span class="sd">  To construct initial state, call InitState classmethod on the root layer.</span>
<span class="sd">  InitState() will traverse root layer children recursively, will initialize</span>
<span class="sd">  internal state for each StateLayer instance, and will return a nested</span>
<span class="sd">  tuple of states.</span>

<span class="sd">  For incremental iteration the static methods work as follows::</span>

<span class="sd">    dec = builder.DecoderLayerStack(...).Instantiate()</span>
<span class="sd">    state0 = StateLayer.InitState(dec, shape=[tgt_batch, max_len])</span>
<span class="sd">    theta0 = StateLayer.UpdateTheta(dec, dec.theta, state0, t=0)</span>
<span class="sd">    # (FProp in nested StateLayer now has access to &#39;state0&#39; and &#39;t&#39;)</span>
<span class="sd">    dec.FProp(theta0, ...)</span>
<span class="sd">    # FProp will  modify theta0 in-place</span>
<span class="sd">    state1 = state0.copy()</span>
<span class="sd">    state1 = StateLayer.UpdateState(dec, theta0, state1)</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="StateLayer.Params"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.StateLayer.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;shape&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s1">&#39;batch, max_steps, etc. This is used to get the shape[2:] dims &#39;</span>
        <span class="s1">&#39;(a.k.a non-spatial dims) in InitState() and NewState(). The &#39;</span>
        <span class="s1">&#39;first 2 dims are actually ignored.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;use_xla_dynamic_update_slice&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;internal optimization&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span>
        <span class="s1">&#39;p.shape is used to get the shape[2:] dims (a.k.a non-spatial dims) in &#39;</span>
        <span class="s1">&#39;InitState() and NewState(), thus is expected to be at least rank2 (&#39;</span>
        <span class="sa">f</span><span class="s1">&#39;first 2 dims are actually ignored), but is </span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

<div class="viewcode-block" id="StateLayer.InitState"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.StateLayer.InitState">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">InitState</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns new state with leading shape=[batch, max_steps].&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">Rec</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>  <span class="c1"># pylint: disable=missing-docstring</span>
      <span class="n">state</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">StateLayer</span><span class="p">):</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">layer</span><span class="o">.</span><span class="n">children</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">NewState</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">state</span>
      <span class="k">for</span> <span class="n">c_name</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">children</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">c_state</span> <span class="o">=</span> <span class="n">Rec</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">c_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>
          <span class="n">state</span><span class="p">[</span><span class="n">c_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">c_state</span>
      <span class="k">return</span> <span class="n">state</span>

    <span class="n">state</span> <span class="o">=</span> <span class="n">Rec</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">state</span></div>

<div class="viewcode-block" id="StateLayer.UpdateTheta"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.StateLayer.UpdateTheta">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">UpdateTheta</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns theta with state.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">Rec</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>  <span class="c1"># pylint: disable=missing-docstring</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">StateLayer</span><span class="p">):</span>
        <span class="n">theta</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">state</span>
        <span class="n">theta</span><span class="o">.</span><span class="n">t</span> <span class="o">=</span> <span class="n">t</span>
        <span class="k">return</span>
      <span class="k">for</span> <span class="n">c_name</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">children</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">c_name</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
          <span class="n">Rec</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">theta</span><span class="p">[</span><span class="n">c_name</span><span class="p">],</span> <span class="n">state</span><span class="p">[</span><span class="n">c_name</span><span class="p">])</span>

    <span class="n">Rec</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">theta</span></div>

<div class="viewcode-block" id="StateLayer.UpdateState"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.StateLayer.UpdateState">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">UpdateState</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns updated state from theta.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">Rec</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>  <span class="c1"># pylint: disable=missing-docstring</span>
      <span class="k">for</span> <span class="n">c_name</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">children</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">StateLayer</span><span class="p">):</span>
          <span class="n">state</span><span class="p">[</span><span class="n">c_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="n">c_name</span><span class="p">]</span><span class="o">.</span><span class="n">state</span>
        <span class="k">elif</span> <span class="n">c_name</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
          <span class="n">Rec</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">theta</span><span class="p">[</span><span class="n">c_name</span><span class="p">],</span> <span class="n">state</span><span class="p">[</span><span class="n">c_name</span><span class="p">])</span>

    <span class="n">Rec</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">state</span></div>

<div class="viewcode-block" id="StateLayer.FProp"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.StateLayer.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">t</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">t</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">x</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Step</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></div>

<div class="viewcode-block" id="StateLayer.NewState"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.StateLayer.NewState">[docs]</a>  <span class="k">def</span> <span class="nf">NewState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns initial state.</span>

<span class="sd">    Args:</span>
<span class="sd">      shape:</span>
<span class="sd">        - [batch, max_steps] for beam_search_tpu_helper</span>
<span class="sd">        - [batch, beam, max_steps] for flat_beam_search.</span>

<span class="sd">    Returns:</span>
<span class="sd">      zero-initialized state tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="StateLayer._Step"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.StateLayer._Step">[docs]</a>  <span class="k">def</span> <span class="nf">_Step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;FProp in decoding mode.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span></div></div>


<div class="viewcode-block" id="MultiHeadAttentionStateLayer"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.MultiHeadAttentionStateLayer">[docs]</a><span class="k">class</span> <span class="nc">MultiHeadAttentionStateLayer</span><span class="p">(</span><span class="n">StateLayer</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;StateLayer specialization for multi-head attention.</span>

<span class="sd">  During decoding, it updates state `x_full[:, t, :] &lt;- x[:, 0, :]` and</span>
<span class="sd">  returns x_full. The shape of x_full is then `[batch, max_steps, ...]`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="n">_use_flat_beam_search</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="MultiHeadAttentionStateLayer.NewState"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.MultiHeadAttentionStateLayer.NewState">[docs]</a>  <span class="k">def</span> <span class="nf">NewState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns initial state.</span>

<span class="sd">    Args:</span>
<span class="sd">      shape:</span>
<span class="sd">        - [batch, max_steps] for beam_search_tpu_helper</span>
<span class="sd">        - [batch, beam, max_steps] for flat_beam_search.</span>

<span class="sd">    Returns:</span>
<span class="sd">      zero-initialized state tensor whose shape can be:</span>

<span class="sd">        - [batch, max_steps, ...]: beam_search_tpu_helper.</span>
<span class="sd">        - [batch, max_steps * beam, ...]: flat_beam_search and</span>
<span class="sd">          use_xla_dynamic_update_slice is True.</span>
<span class="sd">        - [max_steps, batch, beam, ...]: flat_beam_search and</span>
<span class="sd">          use_xla_dynamic_update_slice is False.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: the length of shape is not 2 or 3.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">fprop_dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
      <span class="c1"># For use with beam_search_tpu_helper batch_major_compute=1</span>
      <span class="n">shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
      <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">state</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
      <span class="c1"># For use with flat_beam_search</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_use_flat_beam_search</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">batch</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="n">max_steps</span> <span class="o">=</span> <span class="n">shape</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_xla_dynamic_update_slice</span><span class="p">:</span>
        <span class="n">state_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">max_steps</span> <span class="o">*</span> <span class="n">beam</span><span class="p">]</span>
        <span class="c1"># Need to remember beam_size to correctly map &#39;t&#39; argument of Fprop</span>
        <span class="c1"># to the combined (max_steps * beam) dimension.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_beam</span> <span class="o">=</span> <span class="n">beam</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">state_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">max_steps</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">beam</span><span class="p">]</span>
      <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Empty</span><span class="p">(</span><span class="n">state_shape</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="n">fprop_dtype</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">state</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;bad shape: </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">shape</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultiHeadAttentionStateLayer._Step"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.MultiHeadAttentionStateLayer._Step">[docs]</a>  <span class="k">def</span> <span class="nf">_Step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">t</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">t</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;state&#39;</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">state</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;p.name=</span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;state=</span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;x=</span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;t=</span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_flat_beam_search</span><span class="p">:</span>
      <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">state</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
      <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">y</span> <span class="o">=</span> <span class="n">state</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">state</span> <span class="o">+</span> <span class="n">z</span> <span class="o">*</span> <span class="n">x</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_flat_beam_search</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">use_xla_dynamic_update_slice</span><span class="p">:</span>
      <span class="n">state_slice_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
      <span class="n">update_slice_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
      <span class="k">if</span> <span class="n">update_slice_size</span> <span class="o">==</span> <span class="n">state_slice_size</span><span class="p">:</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">InplaceUpdate</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="c1"># With prefix decoding the first call to decoder can have</span>
        <span class="c1"># sequence length (N * beam_size) with N &gt; 1.</span>
        <span class="c1"># In this special case state tensor update is implemented as multiple</span>
        <span class="c1"># InplaceUpdate ops each for a slice [batch_size, beam_size].</span>
        <span class="n">div</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">update_slice_size</span> <span class="o">/</span> <span class="n">state_slice_size</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">update_slice_size</span> <span class="o">==</span> <span class="n">state_slice_size</span> <span class="o">*</span> <span class="n">div</span><span class="p">,</span> <span class="p">(</span><span class="n">update_slice_size</span><span class="p">,</span>
                                                             <span class="n">state_slice_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">div</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
          <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">InplaceUpdate</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;state*=</span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
      <span class="c1"># [T,B,L,...]</span>
      <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="c1"># [T, B, L, ...] -&gt; [B, T, L, ...]</span>
      <span class="n">perm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
      <span class="n">perm</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
      <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">perm</span><span class="p">)</span>
      <span class="c1"># [B, T, L, ...] -&gt; [B, T*L, ...]</span>
      <span class="n">y_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="n">y_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">y_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="nb">int</span><span class="p">(</span><span class="n">y_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])]</span>
      <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_shape</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_flat_beam_search</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">use_xla_dynamic_update_slice</span><span class="p">:</span>
      <span class="n">update_start_index</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="n">update_start_index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beam</span><span class="p">)</span>
      <span class="n">state</span> <span class="o">=</span> <span class="n">xla</span><span class="o">.</span><span class="n">dynamic_update_slice</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                                       <span class="n">update_start_index</span><span class="p">)</span>
      <span class="n">y</span> <span class="o">=</span> <span class="n">state</span>

    <span class="n">theta</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">state</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;y=</span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span></div></div>


<div class="viewcode-block" id="Conv1DStateLayer"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.Conv1DStateLayer">[docs]</a><span class="k">class</span> <span class="nc">Conv1DStateLayer</span><span class="p">(</span><span class="n">StateLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Container for recurrent state for incremental decoding of conv1d.</span>

<span class="sd">  At present (06/2021) it only supports flat_beam_search.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Conv1DStateLayer.Params"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.Conv1DStateLayer.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Delete</span><span class="p">(</span><span class="s1">&#39;use_xla_dynamic_update_slice&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="Conv1DStateLayer.NewState"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.Conv1DStateLayer.NewState">[docs]</a>  <span class="k">def</span> <span class="nf">NewState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns initial state.</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: [batch, beam, kernel_size].</span>

<span class="sd">    Returns:</span>
<span class="sd">      zero-initialized state tensor of shape [batch, kernel_size * beam, ...],</span>
<span class="sd">      with the underlying layout being the same as</span>
<span class="sd">      [batch, kernel_size, beam, ...].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>

    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">fprop_dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="n">batch</span><span class="p">,</span> <span class="n">beam</span><span class="p">,</span> <span class="n">max_steps</span> <span class="o">=</span> <span class="n">shape</span>
    <span class="c1"># Need to remember beam_size to correctly map &#39;t&#39; argument of Fprop</span>
    <span class="c1"># to the combined (max_steps * beam) dimension.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_beam</span> <span class="o">=</span> <span class="n">beam</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Empty</span><span class="p">(</span>
        <span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">max_steps</span> <span class="o">*</span> <span class="n">beam</span><span class="p">]</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="n">fprop_dtype</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">state</span></div>

<div class="viewcode-block" id="Conv1DStateLayer._Step"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.Conv1DStateLayer._Step">[docs]</a>  <span class="k">def</span> <span class="nf">_Step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Single step decode.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A NestedMap of layer weights.</span>
<span class="sd">      x:     A Tensor of shape [batch, beam * num_steps, ...] with the</span>
<span class="sd">        underlying layout being the same as [batch, num_steps, beam, ...].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A Tensor of the same shape as theta.state as returned by NewState(),</span>
<span class="sd">      a.k.a [batch, kernel_size * beam, ...].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">t</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">t</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">state</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;p.name=</span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;state=</span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;x=</span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;t=</span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

    <span class="c1"># left-shift state and append x.</span>
    <span class="n">new_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">state</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beam</span><span class="p">:],</span> <span class="n">x</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">theta</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">new_state</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">new_state</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;y=</span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span></div></div>


<div class="viewcode-block" id="OverrideLayer"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.OverrideLayer">[docs]</a><span class="k">class</span> <span class="nc">OverrideLayer</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Allows to override arbitrary tensors in the graph.</span>

<span class="sd">  If key is not set in the global context, FProp does nothing.</span>
<span class="sd">  Otherwise it returns value associated to &#39;key&#39;.</span>

<span class="sd">  To override a tensor during my_layer.FProp::</span>

<span class="sd">    OverrideLayer.Set(key, value)</span>
<span class="sd">    out_with_override = my_layer.FProp(...)</span>
<span class="sd">    OverrideLayer.Clear()</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="n">_OVERRIDE</span> <span class="o">=</span> <span class="p">{}</span>

<div class="viewcode-block" id="OverrideLayer.Params"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.OverrideLayer.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;key&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Context key&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="OverrideLayer.FProp"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.OverrideLayer.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">key</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_OVERRIDE</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_OVERRIDE</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">key</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">x</span></div>

<div class="viewcode-block" id="OverrideLayer.Set"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.OverrideLayer.Set">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Set</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="bp">cls</span><span class="o">.</span><span class="n">_OVERRIDE</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span></div>

<div class="viewcode-block" id="OverrideLayer.Clear"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.OverrideLayer.Clear">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Clear</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="bp">cls</span><span class="o">.</span><span class="n">_OVERRIDE</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="ReshapeInputLayer"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.ReshapeInputLayer">[docs]</a><span class="k">class</span> <span class="nc">ReshapeInputLayer</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Reshape input for MoE for training or using TPU.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="ReshapeInputLayer.Params"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.ReshapeInputLayer.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_groups&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Number of groups.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_devices&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Number of devices.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;model_dims&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;A list, the dimensions that M is reshaped into. If None, default&#39;</span>
        <span class="s1">&#39; to the last dimension of fprop inputs&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="ReshapeInputLayer.FProp"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.ReshapeInputLayer.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">unused_theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">segment_id</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">segment_id</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="c1"># Only reshape for tpu.</span>
    <span class="k">if</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">()</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">:</span>
      <span class="n">orig_inputs</span> <span class="o">=</span> <span class="n">inputs</span>
      <span class="c1"># input size in tokens</span>
      <span class="n">input_size</span> <span class="o">=</span> <span class="p">(</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">orig_inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">orig_inputs</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
      <span class="n">group_size</span><span class="p">,</span> <span class="n">rest</span> <span class="o">=</span> <span class="nb">divmod</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_groups</span><span class="p">)</span>
      <span class="k">assert</span> <span class="n">rest</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_groups</span><span class="p">)</span>
      <span class="n">model_dims</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dims</span> <span class="ow">or</span> <span class="p">[</span><span class="n">orig_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
          <span class="n">orig_inputs</span><span class="p">,</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_groups</span><span class="p">,</span> <span class="n">group_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">model_dims</span><span class="p">,</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;grouped_inputs&#39;</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_devices</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_devices</span><span class="p">)</span>
    <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[:</span><span class="mi">2</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span></div></div>


<div class="viewcode-block" id="SharedEmbeddingSoftmaxLayer"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.SharedEmbeddingSoftmaxLayer">[docs]</a><span class="k">class</span> <span class="nc">SharedEmbeddingSoftmaxLayer</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Shared weights for embemdding lookup and softmax.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="SharedEmbeddingSoftmaxLayer.Params"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.SharedEmbeddingSoftmaxLayer.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;vocab_size&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Num tokens in vocab.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;max_len&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Num of token in the sequence.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;embedding_dim&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Depth of the output.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;z_loss_coef&#39;</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="s1">&#39;Label smoothing.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_devices&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Number of devices for sharding.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;logits_abs_max&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Logits clipping.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;label_smoothing&#39;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s1">&#39;Label smoothing.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;use_tgt_labels_size_as_loss_denominator&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;False to use total number of non-padding tokens instead of &#39;</span>
        <span class="s1">&#39;fixed tgt_labels tensor size.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">emb_p</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(),</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">])</span>
    <span class="n">pos_emb_p</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(),</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">max_len</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;embedding&#39;</span><span class="p">,</span> <span class="n">emb_p</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;pos_emb&#39;</span><span class="p">,</span> <span class="n">pos_emb_p</span><span class="p">)</span>

<div class="viewcode-block" id="SharedEmbeddingSoftmaxLayer._MaybeSplit"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.SharedEmbeddingSoftmaxLayer._MaybeSplit">[docs]</a>  <span class="k">def</span> <span class="nf">_MaybeSplit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="kc">True</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_devices</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">x</span>
    <span class="k">return</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_devices</span><span class="p">)</span></div>

<div class="viewcode-block" id="SharedEmbeddingSoftmaxLayer.FProp"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.SharedEmbeddingSoftmaxLayer.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">ids</span><span class="p">,</span> <span class="n">segment_pos</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">fprop_dtype</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="n">ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
    <span class="n">segment_pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">segment_pos</span><span class="p">)</span>

    <span class="n">one_hot_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">fprop_dtype</span><span class="p">)</span>
    <span class="n">one_hot_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">one_hot_ids</span><span class="p">)</span>

    <span class="n">one_hot_pos</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">segment_pos</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">max_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">fprop_dtype</span><span class="p">)</span>
    <span class="n">one_hot_pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">one_hot_pos</span><span class="p">)</span>

    <span class="n">token_emb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;VH,BLV-&gt;BLH&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">embedding</span><span class="p">,</span> <span class="n">one_hot_ids</span><span class="p">)</span>
    <span class="n">token_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">token_emb</span><span class="p">)</span>

    <span class="n">pos_emb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;VH,BLV-&gt;BLH&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">pos_emb</span><span class="p">,</span> <span class="n">one_hot_pos</span><span class="p">)</span>
    <span class="n">pos_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">pos_emb</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">token_emb</span> <span class="o">+</span> <span class="n">pos_emb</span><span class="p">)</span></div>

<div class="viewcode-block" id="SharedEmbeddingSoftmaxLayer.ComputeLoss"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.SharedEmbeddingSoftmaxLayer.ComputeLoss">[docs]</a>  <span class="k">def</span> <span class="nf">ComputeLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">activation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">embedding_dim</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">softmax_weights</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">embedding</span>
    <span class="k">if</span> <span class="n">activation</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">softmax_weights</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
      <span class="n">softmax_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">softmax_weights</span><span class="p">,</span> <span class="n">activation</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;BLM,VM-&gt;BLV&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">softmax_weights</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">logits_abs_max</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="o">-</span><span class="n">p</span><span class="o">.</span><span class="n">logits_abs_max</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">logits_abs_max</span><span class="p">))</span>

    <span class="n">off_value</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span> <span class="o">/</span> <span class="n">p</span><span class="o">.</span><span class="n">vocab_size</span>
    <span class="n">on_value</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span> <span class="o">+</span> <span class="n">off_value</span>
    <span class="n">soft_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
            <span class="n">labels</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">on_value</span><span class="o">=</span><span class="n">on_value</span><span class="p">,</span> <span class="n">off_value</span><span class="o">=</span><span class="n">off_value</span><span class="p">))</span>
    <span class="n">xent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">))</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">soft_targets</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">))</span>
    <span class="n">soft_targets_xent</span> <span class="o">=</span> <span class="n">loss</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">z_loss_coef</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="n">log_z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_logsumexp</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">z_loss_inc</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">z_loss_coef</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">log_z</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">+=</span> <span class="n">z_loss_inc</span>

    <span class="n">non_padding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">not_equal</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)))</span>

    <span class="n">per_token_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">loss</span> <span class="o">*</span> <span class="n">non_padding</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">z_loss_coef</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="n">per_token_z_loss_inc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">z_loss_inc</span> <span class="o">*</span> <span class="n">non_padding</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_tgt_labels_size_as_loss_denominator</span><span class="p">:</span>
      <span class="c1"># E.g. loss is going to be tiny if inputs are not packed and only a</span>
      <span class="c1"># fraction of tgt_labels are non-padding.</span>
      <span class="n">loss_denom</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">non_padding</span><span class="p">))</span>
      <span class="n">per_example_loss_denom</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">non_padding</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">loss_denom</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">non_padding</span><span class="p">)</span>
      <span class="n">per_example_loss_denom</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">non_padding</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">per_token_loss</span><span class="p">)</span> <span class="o">/</span> <span class="n">loss_denom</span>
    <span class="n">avg_z_loss_inc</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">per_token_z_loss_inc</span><span class="p">)</span> <span class="o">/</span>
                      <span class="n">loss_denom</span><span class="p">)</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">z_loss_coef</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="mf">0.0</span>

    <span class="n">soft_targets_xent</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">soft_targets_xent</span> <span class="o">*</span> <span class="n">non_padding</span><span class="p">))</span> <span class="o">/</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">non_padding</span><span class="p">))</span>

    <span class="c1"># TODO(lepikhin): consider returning</span>
    <span class="c1">#   {&#39;loss&#39;: (unnormalized per_token_loss, tf.reduce_sum(non_padding))}</span>
    <span class="n">per_example_loss</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">per_token_loss</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">per_example_loss_denom</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;mean_xent&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">xent</span> <span class="o">*</span> <span class="n">non_padding</span><span class="p">))</span> <span class="o">/</span>
                      <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">non_padding</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">non_padding</span><span class="p">)),</span>
        <span class="s1">&#39;soft_targets_xent&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">soft_targets_xent</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">non_padding</span><span class="p">)),</span>
        <span class="s1">&#39;weight&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">non_padding</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">),</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">avg_loss</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
        <span class="s1">&#39;avg_z_loss_inc&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">avg_z_loss_inc</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">},</span> <span class="n">per_example_loss</span></div></div>


<div class="viewcode-block" id="CausalDepthwiseConv1DLayer"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.CausalDepthwiseConv1DLayer">[docs]</a><span class="k">class</span> <span class="nc">CausalDepthwiseConv1DLayer</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">BaseLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Causal depthwise 1d convolution.</span>

<span class="sd">  Only supports the case where channel_multiplier is 1.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="CausalDepthwiseConv1DLayer.Params"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.CausalDepthwiseConv1DLayer.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;kernel_size&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Spatial dimension filter size.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;model_dims&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;The channel dimension. For compatibility with &#39;</span>
        <span class="s1">&#39;gshard_builder.MoEBuilder.DepthwiseConvAutoregressive, the &#39;</span>
        <span class="s1">&#39;layout could be multi-dimensional, the product of which is &#39;</span>
        <span class="s1">&#39;the effective channel size.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;state_layer&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Set to Conv1DStateLayer.Params() for &#39;</span>
        <span class="s1">&#39;single-step fprop (e.g. autoregressive decoding).&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;compatible_with_mtf_ckpt&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;If creating vars to be compatible with Mesh Tf checkpoint, a.k.a &#39;</span>
        <span class="s1">&#39;DepthwiseConvAutoregressive() layer. When training new models this &#39;</span>
        <span class="s1">&#39;should be set to False.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="CausalDepthwiseConv1DLayer._Var"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.CausalDepthwiseConv1DLayer._Var">[docs]</a>  <span class="k">def</span> <span class="nf">_Var</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;For compatibility with Mesh TF ckpt.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">VarLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">fprop_dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">fprop_dtype</span><span class="p">,</span>
        <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">state_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;state_layer&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">state_layer</span><span class="p">)</span>

    <span class="c1"># If required to be compatible with Mesh TF, create VarLayers for vars.</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">compatible_with_mtf_ckpt</span><span class="p">:</span>
      <span class="n">model_dims</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dims</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_dims</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="n">model_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">model_dims</span><span class="p">]</span>

      <span class="k">def</span> <span class="nf">_GetScaleVar</span><span class="p">(</span><span class="n">shift_distance</span><span class="p">):</span>
        <span class="n">init_const</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="k">if</span> <span class="n">shift_distance</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.5</span> <span class="o">/</span> <span class="n">p</span><span class="o">.</span><span class="n">kernel_size</span>
        <span class="n">scale_var_weight_params</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
            <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">init_const</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">model_dims</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Var</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;w_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">shift_distance</span><span class="p">,</span>
            <span class="n">weights</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="n">scale_var_weight_params</span><span class="p">)])</span>

      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;w_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">_GetScaleVar</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>

<div class="viewcode-block" id="CausalDepthwiseConv1DLayer._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.CausalDepthwiseConv1DLayer._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">compatible_with_mtf_ckpt</span><span class="p">:</span>
      <span class="c1"># vars are created in sub VarLayer layers.</span>
      <span class="k">return</span>

    <span class="n">model_dims</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dims</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_dims</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
      <span class="n">model_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">model_dims</span><span class="p">]</span>

    <span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">model_dims</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_GetScaleInitConst</span><span class="p">(</span><span class="n">shift_distance</span><span class="p">):</span>
      <span class="c1"># The init vals are the reverse of that of DepthwiseConvAutoregressive()</span>
      <span class="c1"># since here W[0] is the W[-1] of DepthwiseConvAutoregressive().</span>
      <span class="n">val</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="k">if</span> <span class="n">shift_distance</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">else</span> <span class="mf">0.5</span> <span class="o">/</span> <span class="n">p</span><span class="o">.</span><span class="n">kernel_size</span>
      <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">model_dims</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>

    <span class="c1"># [kernel_size] + model_dims</span>
    <span class="n">init_const</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">_GetScaleInitConst</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">)],</span>
                          <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">init_const</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">init_const</span><span class="p">,</span>
                            <span class="n">filter_shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span><span class="p">)</span>

    <span class="n">w_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">filter_shape</span><span class="p">,</span>
        <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">init_const</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;_vars&#39;</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">w_pc</span><span class="p">)</span></div>

<div class="viewcode-block" id="CausalDepthwiseConv1DLayer._DoConv"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.CausalDepthwiseConv1DLayer._DoConv">[docs]</a>  <span class="k">def</span> <span class="nf">_DoConv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">padding</span><span class="p">):</span>
    <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetWeight</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

    <span class="c1"># [b, t, 1, d]</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">depthwise_conv2d</span><span class="p">(</span>
        <span class="n">inputs</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:],</span>
        <span class="n">w</span><span class="p">,</span>
        <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">dilations</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NHWC&#39;</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span></div>

<div class="viewcode-block" id="CausalDepthwiseConv1DLayer._GetWeight"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.CausalDepthwiseConv1DLayer._GetWeight">[docs]</a>  <span class="k">def</span> <span class="nf">_GetWeight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a [p.kernel_size, 1, channel_size, 1] rank4 Tensor.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">channel_size</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dims</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">channel_size</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
      <span class="n">channel_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">channel_size</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">compatible_with_mtf_ckpt</span><span class="p">:</span>
      <span class="n">ws</span> <span class="o">=</span> <span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;w_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">scale</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">)]</span>
      <span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">ws</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">w</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">w</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">channel_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span></div>

<div class="viewcode-block" id="CausalDepthwiseConv1DLayer.FProp"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.CausalDepthwiseConv1DLayer.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasRank</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="n">dilation</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">padding</span> <span class="o">=</span> <span class="n">conv_layers</span><span class="o">.</span><span class="n">ComputeExplicitPaddingForCausalConv</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_GetWeight</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dilation</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">state_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_layer</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">state_layer</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">state_layer</span><span class="p">,</span> <span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="c1"># Single-step, thus use &#39;VALID&#39; padding.</span>
          <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;VALID&#39;</span>

      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_DoConv</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="Top2GatingOnLogits"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.Top2GatingOnLogits">[docs]</a><span class="k">def</span> <span class="nf">Top2GatingOnLogits</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                       <span class="n">paddings</span><span class="p">,</span>
                       <span class="n">logits</span><span class="p">,</span>
                       <span class="n">num_devices</span><span class="p">,</span>
                       <span class="n">experts_dim</span><span class="p">,</span>
                       <span class="n">expert_capacity_dim</span><span class="p">,</span>
                       <span class="n">fprop_dtype</span><span class="p">,</span>
                       <span class="n">use_xla_sharding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">second_expert_policy</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span>
                       <span class="n">second_expert_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                       <span class="n">legacy_mtf_behavior</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">capacity_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                       <span class="n">importance</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                       <span class="n">mask_dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes Top-2 gating for Mixture-of-Experts.</span>

<span class="sd">  There are two expected usages of this function:</span>

<span class="sd">  1. used with xla_sharding. In this case, &#39;inputs&#39; corresponds to a sharded</span>
<span class="sd">     tensor across multiple tpu cores. The operations within this function are</span>
<span class="sd">     automatically sharded/replicated across tpu cores.</span>
<span class="sd">  2. used within other projects where&#39;inputs&#39; is always local to one tpu</span>
<span class="sd">     core. All computations below are carried out on one tpu core only. This</span>
<span class="sd">     function tries to dispatch examples across tpu cores in such a way that</span>
<span class="sd">     each expert is assigned no more than &#39;expert_capacity_dim&#39; number of</span>
<span class="sd">     examples.</span>

<span class="sd">  Below ` indicates common way of splitting along mesh dimension.</span>

<span class="sd">  Dimensions cheat sheet::</span>

<span class="sd">    G: group_dim</span>
<span class="sd">    S: group_size_dim</span>
<span class="sd">    E: number of experts</span>
<span class="sd">    C: capacity per expert</span>
<span class="sd">    M: model_dim (same as input_dim, same as output_dim)</span>
<span class="sd">    B: original batch_dim</span>
<span class="sd">    L: original sequence_length_dim</span>

<span class="sd">  Note that for local_dispatch original batch BLM is reshaped into GSM, each</span>
<span class="sd">  group `g = 0...G-1` is being dispatched independently.</span>

<span class="sd">  Args:</span>
<span class="sd">    inputs: G`SM Tensor.</span>
<span class="sd">    paddings: G`S Tensor.</span>
<span class="sd">    logits: G`SE Tensor.</span>
<span class="sd">    num_devices: number of MoE devices for local dispatch</span>
<span class="sd">    experts_dim: number of experts.</span>
<span class="sd">    expert_capacity_dim: number of examples per minibatch(group) per expert.</span>
<span class="sd">      Each example is typically a vector of size input_dim, representing</span>
<span class="sd">      embedded token or an element of Transformer layer output.</span>
<span class="sd">    fprop_dtype: activations datatype to use.</span>
<span class="sd">    use_xla_sharding: bool, True if this function is used for the xla_sharding</span>
<span class="sd">      case.</span>
<span class="sd">    second_expert_policy: &#39;all&#39;, &#39;sampling&#39; or &#39;random&#39;.</span>

<span class="sd">      - &#39;all&#39;: we greedily pick the 2nd expert.</span>
<span class="sd">      - &#39;sampling&#39;: we sample the 2nd expert from the softmax.</span>
<span class="sd">      - &#39;random&#39;: we optionally &#39;random&#39;-ize dispatch to second-best expert</span>
<span class="sd">        proportional to (weight / second_expert_threshold).</span>

<span class="sd">    second_expert_threshold: threshold for probability normalization for</span>
<span class="sd">      second_expert_policy == &#39;random&#39;.</span>
<span class="sd">    legacy_mtf_behavior: bool, True if to match legacy mtf behavior exactly.</span>
<span class="sd">    capacity_factor: if set, increases expert_capacity_dim to at least</span>
<span class="sd">      (group_size * capacity_factor) / experts_dim</span>
<span class="sd">      where `group_size` is the size of G dimension of `inputs`. If the</span>
<span class="sd">      value of expert_capacity_dim is already big enough no change is made.</span>
<span class="sd">    importance: input importance weights for routing (G`S Tensor or None).</span>
<span class="sd">    mask_dtype: using bfloat16 for fprop_dtype could be problematic for mask</span>
<span class="sd">      tensors, mask_dtype is a special dtype for such tensors.</span>

<span class="sd">  TODO(lepikhin): get rid of the legacy_mtf_behavior flag.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple (aux_loss, combine_tensor, dispatch_tensor).</span>

<span class="sd">    - aux_loss: auxiliary loss, for equalizing the expert assignment ratios.</span>
<span class="sd">    - combine_tensor: G`SEC Tensor for combining expert outputs.</span>
<span class="sd">    - dispatch_tensor: G`SEC Tensor, scattering/dispatching inputs to</span>
<span class="sd">      experts.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">mask_dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">mask_dtype</span> <span class="o">=</span> <span class="n">fprop_dtype</span>
  <span class="k">if</span> <span class="n">use_xla_sharding</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Sharding propagation should be sufficient and Splits &#39;</span>
                       <span class="s1">&#39;within Top2GatingOnLogits are generally redundant.&#39;</span><span class="p">)</span>
  <span class="k">del</span> <span class="n">inputs</span>  <span class="c1"># inputs is currently not used.</span>
  <span class="c1"># logits.dtype could be tf.float32</span>
  <span class="n">raw_gates</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>  <span class="c1"># along E dim</span>
  <span class="k">if</span> <span class="n">raw_gates</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">fprop_dtype</span><span class="p">:</span>
    <span class="n">raw_gates</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">raw_gates</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">capacity_factor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1"># Determine expert capacity automatically depedning on the input size.</span>
    <span class="n">group_size_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">auto_expert_capacity</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">group_size_dim</span> <span class="o">*</span> <span class="n">capacity_factor</span><span class="p">)</span> <span class="o">/</span> <span class="n">experts_dim</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">expert_capacity_dim</span> <span class="o">&lt;</span> <span class="n">auto_expert_capacity</span><span class="p">:</span>
      <span class="n">expert_capacity_dim</span> <span class="o">=</span> <span class="n">auto_expert_capacity</span>
      <span class="c1"># Round up to a multiple of 4 to avoid possible padding.</span>
      <span class="k">while</span> <span class="n">expert_capacity_dim</span> <span class="o">%</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">expert_capacity_dim</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
          <span class="s1">&#39;Setting expert_capacity_dim=</span><span class="si">%r</span><span class="s1"> (capacity_factor=</span><span class="si">%r</span><span class="s1"> &#39;</span>
          <span class="s1">&#39;group_size_dim=</span><span class="si">%r</span><span class="s1"> experts_dim=</span><span class="si">%r</span><span class="s1"> name_scope=</span><span class="si">%r</span><span class="s1">)&#39;</span><span class="p">,</span>
          <span class="n">expert_capacity_dim</span><span class="p">,</span> <span class="n">capacity_factor</span><span class="p">,</span> <span class="n">group_size_dim</span><span class="p">,</span> <span class="n">experts_dim</span><span class="p">,</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span><span class="o">.</span><span class="n">get_name_scope</span><span class="p">())</span>
    <span class="n">tpu_summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;expert_capacity&#39;</span><span class="p">,</span> <span class="n">expert_capacity_dim</span><span class="p">)</span>

  <span class="c1"># top first and second gate value and expert index for each input</span>
  <span class="c1">#</span>
  <span class="c1"># GSK Tensors, K=2</span>
  <span class="k">def</span> <span class="nf">_MaybeSplit</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">use_xla_sharding</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">x</span>

  <span class="k">def</span> <span class="nf">_CreateOverCapacityRatioSummary</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">position_in_expert</span><span class="p">,</span> <span class="n">capacity</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;over_capacity&#39;</span><span class="p">):</span>
      <span class="n">ge_capacity</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">mask</span> <span class="o">*</span> <span class="n">position_in_expert</span><span class="p">,</span> <span class="n">capacity</span><span class="p">)</span>
      <span class="n">over_capacity</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">ge_capacity</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
      <span class="n">over_capacity_ratio</span> <span class="o">=</span> <span class="n">over_capacity</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">mask</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
      <span class="n">py_utils</span><span class="o">.</span><span class="n">AddTpuSummaryTensor</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">over_capacity_ratio</span><span class="p">)</span>
      <span class="n">tpu_summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">over_capacity_ratio</span><span class="p">,</span> <span class="n">while_loop_reduce</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>

  <span class="c1"># As pointed out by zhifengc@ this method needs to be refactored. lepikhin@</span>
  <span class="c1"># and krikun@ will:</span>
  <span class="c1">#   - expand moe_spmd_test to compare Adafactor updates, slots on TPU</span>
  <span class="c1">#   including 2x2 with sharding</span>
  <span class="c1">#</span>
  <span class="c1">#   - add more tests for policy=&quot;random&quot;</span>
  <span class="c1">#</span>
  <span class="c1">#   - add single step test for full size WMT model on CPU</span>
  <span class="c1">#</span>
  <span class="c1"># and then break this function into modules.</span>
  <span class="c1">#</span>
  <span class="c1"># GS</span>
  <span class="n">index_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">raw_gates</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">index_1</span> <span class="o">=</span> <span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">index_1</span><span class="p">)</span>
  <span class="n">tpu_summary</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="s1">&#39;index_1&#39;</span><span class="p">,</span> <span class="n">index_1</span><span class="p">)</span>

  <span class="c1"># GSE</span>
  <span class="n">mask_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">index_1</span><span class="p">,</span> <span class="n">experts_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mask_dtype</span><span class="p">)</span>
  <span class="n">mask_1</span> <span class="o">=</span> <span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">mask_1</span><span class="p">)</span>
  <span class="n">density_1_proxy</span> <span class="o">=</span> <span class="n">raw_gates</span>

  <span class="k">if</span> <span class="n">importance</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">importance_is_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">mask_1</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">importance_is_one</span><span class="p">,</span> <span class="n">mask_1</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">density_1_proxy</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">importance_is_one</span><span class="p">,</span> <span class="n">density_1_proxy</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mask_1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
      <span class="n">importance</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">mask_1</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">importance</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">mask_1</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">paddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">nonpaddings</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">paddings</span>
      <span class="n">mask_1</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">nonpaddings</span><span class="p">,</span> <span class="n">mask_1</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">density_1_proxy</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">nonpaddings</span><span class="p">,</span> <span class="n">density_1_proxy</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">importance</span> <span class="o">=</span> <span class="n">nonpaddings</span>

  <span class="n">gate_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;...GSE,...GSE-&gt;...GS&#39;</span><span class="p">,</span> <span class="n">raw_gates</span><span class="p">,</span>
                     <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_1</span><span class="p">,</span> <span class="n">raw_gates</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
  <span class="n">gates_without_top_1</span> <span class="o">=</span> <span class="n">raw_gates</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_1</span><span class="p">,</span> <span class="n">raw_gates</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">second_expert_policy</span> <span class="o">==</span> <span class="s1">&#39;sampling&#39;</span><span class="p">:</span>
    <span class="c1"># We directly sample the 2nd expert index from the softmax over of the 2nd</span>
    <span class="c1"># expert by getting rid of the 1st expert already selected above. To do so,</span>
    <span class="c1"># we set a very negative value to the logit corresponding to the 1st expert.</span>
    <span class="c1"># Then we sample from the softmax (categorical) distribution using the</span>
    <span class="c1"># Gumbel max trick.</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">logits</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
    <span class="c1"># Generates standard Gumbel(0, 1) noise, GSE Tensors</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">noise</span><span class="p">))</span>
    <span class="n">very_negative_logits</span> <span class="o">=</span> <span class="n">_MaybeSplit</span><span class="p">(</span>
        <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span> <span class="o">*</span> <span class="n">logits</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">max</span> <span class="o">*</span>
         <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="o">-</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">logits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)))</span>
    <span class="c1"># Gets rid of the first expert by setting its logit to be very negative</span>
    <span class="n">updated_logits</span> <span class="o">=</span> <span class="n">_MaybeSplit</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask_1</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">very_negative_logits</span><span class="p">,</span> <span class="n">logits</span><span class="p">))</span>
    <span class="c1"># Adds the Gumbel noise to the updated logits</span>
    <span class="n">noised_logits</span> <span class="o">=</span> <span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">updated_logits</span> <span class="o">+</span> <span class="n">noise</span><span class="p">)</span>
    <span class="c1"># Picks the index of the largest noised logit as the 2nd expert. This is</span>
    <span class="c1"># equivalent to sampling from the softmax over the 2nd experts.</span>
    <span class="n">index_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">noised_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">index_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">gates_without_top_1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

  <span class="n">index_2</span> <span class="o">=</span> <span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">index_2</span><span class="p">)</span>
  <span class="n">mask_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">index_2</span><span class="p">,</span> <span class="n">experts_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mask_dtype</span><span class="p">)</span>
  <span class="n">mask_2</span> <span class="o">=</span> <span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">mask_2</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">paddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">importance_is_nonzero</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
    <span class="n">mask_2</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">importance_is_nonzero</span><span class="p">,</span> <span class="n">mask_2</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">gate_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;...GSE,...GSE-&gt;...GS&#39;</span><span class="p">,</span> <span class="n">gates_without_top_1</span><span class="p">,</span>
                     <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_2</span><span class="p">,</span> <span class="n">gates_without_top_1</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">legacy_mtf_behavior</span><span class="p">:</span>
    <span class="c1"># cl/298510175 moved this branch for gate_{1,2} denom calculation here.</span>
    <span class="c1">#</span>
    <span class="c1"># For policy=random, it&#39;s better to nomalize gate_{1,2} before taking</span>
    <span class="c1"># capacity  into account and before potentially dropping second expert.</span>
    <span class="c1">#</span>
    <span class="c1"># According to mean_xent:</span>
    <span class="c1">#   MoE_512_102xen_PolicyAll_298510175</span>
    <span class="c1">#   MoE_512_102xen_PolicyRandom_298510175</span>
    <span class="c1">#</span>
    <span class="c1"># vs pre-cl/298510175</span>
    <span class="c1">#   MoE_512_102xen_PolicyRandom</span>
    <span class="c1">#   MoE_512_102xen_PolicyAll</span>
    <span class="c1">#</span>
    <span class="c1"># it substantially improves policy=random with threshold=0.5 which</span>
    <span class="c1"># historically was better than policy=&quot;all&quot;</span>
    <span class="c1">#</span>
    <span class="c1"># Also confirmed this by decoding</span>
    <span class="c1">#   nmt_train/m4/data/es_en/test.txt</span>
    <span class="c1">#   nmt_train/m4/data/ru_en/test.txt</span>
    <span class="c1">#   nmt_train/m4/data/zh_en/test.txt</span>
    <span class="c1"># and improving BLEU</span>
    <span class="c1">#</span>
    <span class="c1"># moe_decode.MoE_512_102xen_PolicyRandom_298510175-160000.batch1024.beam4.c_dim4.ln0.8.rkv.mteval102</span>
    <span class="c1">#   0.421443</span>
    <span class="c1">#   0.327102</span>
    <span class="c1">#   0.315693</span>
    <span class="c1"># vs</span>
    <span class="c1"># moe_decode.feb18_non_fig_snapshot_2626_MoE_512_102xen_PolicyRandom-190000.batch1024.beam4.c_dim4.ln0.8.rkv.mteval102</span>
    <span class="c1">#   0.399232</span>
    <span class="c1">#   0.310606</span>
    <span class="c1">#   0.288229</span>
    <span class="c1">#</span>
    <span class="c1"># Additional comparison, see mean_xent with</span>
    <span class="c1"># legacy_mtf_behavior=False models</span>
    <span class="c1">#   3 - MoE_512_102xen_PolicyAll_LegacyFalse</span>
    <span class="c1">#   6 - MoE_512_102xen_PolicyRandom_LegacyFalse</span>
    <span class="c1"># shows that policy=&quot;random&quot; gets worse with legacy_mtf_behavior=False, and</span>
    <span class="c1"># is similar to pre-cl/298510175</span>
    <span class="c1">#   4 - MoE_512_102xen_PolicyRandom</span>
    <span class="c1">#</span>
    <span class="c1"># gate_1 can become 0 due to Expert being out of capacity.</span>
    <span class="c1">#</span>
    <span class="c1"># gate_2 can become 0 due to</span>
    <span class="c1">#   second_expert_policy == &#39;random&#39;</span>
    <span class="c1"># or &quot;out of capacity&quot; scenario.</span>
    <span class="c1">#</span>
    <span class="c1"># Here we renormalize regardless of cases above.</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="n">gate_1</span> <span class="o">+</span> <span class="n">gate_2</span> <span class="o">+</span> <span class="mf">1e-9</span>
    <span class="n">gate_1</span> <span class="o">/=</span> <span class="n">denom</span>
    <span class="n">gate_2</span> <span class="o">/=</span> <span class="n">denom</span>

  <span class="c1"># We reshape the mask as [X*S, E], and compute cumulative sums of</span>
  <span class="c1"># assignment indicators for each expert index e \in 0..E-1 independently.</span>
  <span class="c1"># First occurrence of assignment indicator is excluded, see exclusive=True</span>
  <span class="c1"># flag below.</span>
  <span class="c1">#</span>
  <span class="c1"># tf.cumsum over S dim: mask_1 is ...GSE tensor. Pontentially with outer_dim</span>
  <span class="c1"># O.</span>
  <span class="n">position_in_expert_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">mask_1</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>

  <span class="c1"># GS Tensor</span>
  <span class="n">capacity</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">expert_capacity_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">position_in_expert_1</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

  <span class="c1"># GE Tensor (reducing S out of GSE tensor mask_1)</span>
  <span class="c1"># density_1[:, e] represents assignment ratio (num assigned / total) to</span>
  <span class="c1"># expert e as top_1 expert without taking capacity into account.</span>
  <span class="k">assert</span> <span class="n">importance</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">fprop_dtype</span>
  <span class="k">if</span> <span class="n">legacy_mtf_behavior</span><span class="p">:</span>
    <span class="n">density_denom</span> <span class="o">=</span> <span class="mf">1.0</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">density_denom</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))[:,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-6</span>
  <span class="n">density_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_1</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">density_denom</span>
  <span class="c1"># density_1_proxy[:, e] represents mean of raw_gates for expert e, including</span>
  <span class="c1"># those of examples not assigned to e with top_k.</span>
  <span class="k">assert</span> <span class="n">density_1_proxy</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">fprop_dtype</span>
  <span class="n">density_1_proxy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">density_1_proxy</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">density_denom</span>

  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;aux_loss&#39;</span><span class="p">):</span>
    <span class="c1"># The MoE paper (https://arxiv.org/pdf/1701.06538.pdf) uses an aux loss of</span>
    <span class="c1"># reduce_mean(density_1_proxy * density_1_proxy). Here we replace one of</span>
    <span class="c1"># the density_1_proxy with the discrete density_1 following mesh_tensorflow.</span>
    <span class="n">aux_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">density_1_proxy</span> <span class="o">*</span> <span class="n">density_1</span><span class="p">)</span>  <span class="c1"># element-wise</span>
    <span class="n">aux_loss</span> <span class="o">*=</span> <span class="n">experts_dim</span> <span class="o">*</span> <span class="n">experts_dim</span>  <span class="c1"># const coefficient</span>

  <span class="c1"># Add the over capacity ratio for expert 1</span>
  <span class="n">_CreateOverCapacityRatioSummary</span><span class="p">(</span><span class="n">mask_1</span><span class="p">,</span> <span class="n">position_in_expert_1</span><span class="p">,</span> <span class="n">capacity</span><span class="p">,</span>
                                  <span class="s1">&#39;over_capacity_1_ratio&#39;</span><span class="p">)</span>

  <span class="n">mask_1</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">position_in_expert_1</span><span class="p">,</span> <span class="n">capacity</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">mask_1</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="n">position_in_expert_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;...GSE,...GSE-&gt;...GS&#39;</span><span class="p">,</span> <span class="n">position_in_expert_1</span><span class="p">,</span>
                                   <span class="n">mask_1</span><span class="p">)</span>

  <span class="c1"># How many examples in this sequence go to this expert</span>
  <span class="n">mask_1_count</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;...GSE-&gt;...GE&#39;</span><span class="p">,</span> <span class="n">mask_1</span><span class="p">)</span>
  <span class="c1"># [batch, group] - mostly ones, but zeros where something didn&#39;t fit</span>
  <span class="n">mask_1_flat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;...GSE-&gt;...GS&#39;</span><span class="p">,</span> <span class="n">mask_1</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">mask_1_count</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">mask_dtype</span>
  <span class="k">assert</span> <span class="n">mask_1_flat</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">mask_dtype</span>

  <span class="k">if</span> <span class="n">second_expert_policy</span> <span class="o">==</span> <span class="s1">&#39;all&#39;</span> <span class="ow">or</span> <span class="n">second_expert_policy</span> <span class="o">==</span> <span class="s1">&#39;sampling&#39;</span><span class="p">:</span>
    <span class="k">pass</span>
  <span class="k">elif</span> <span class="n">second_expert_policy</span> <span class="o">==</span> <span class="s1">&#39;random&#39;</span><span class="p">:</span>
    <span class="c1"># gate_2 is between 0 and 1, reminder:</span>
    <span class="c1">#</span>
    <span class="c1">#   raw_gates = tf.nn.softmax(logits)</span>
    <span class="c1">#   index_1 = tf.math.argmax(raw_gates, axis=-1, output_type=tf.int32)</span>
    <span class="c1">#   mask_1 = tf.one_hot(index_1, experts_dim, dtype=fprop_dtype)</span>
    <span class="c1">#   gate_1 = tf.einsum(&#39;GSE,GSE-&gt;GS&#39;, raw_gates, mask_1)</span>
    <span class="c1">#</span>
    <span class="c1"># E.g. if gate_2 exceeds second_expert_threshold, then we definitely</span>
    <span class="c1"># dispatch to second-best expert. Otherwise we dispatch with probability</span>
    <span class="c1"># proportional to (gate_2 / threshold).</span>
    <span class="c1">#</span>
    <span class="n">sampled_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span>
        <span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">gate_2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">gate_2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)),</span>
        <span class="p">(</span><span class="n">gate_2</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">second_expert_threshold</span><span class="p">,</span> <span class="mf">1e-9</span><span class="p">)))</span>
    <span class="n">gate_2</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">sampled_2</span><span class="p">,</span> <span class="n">gate_2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">mask_2</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">sampled_2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">mask_2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">second_expert_policy</span><span class="p">)</span>

  <span class="n">position_in_expert_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span>
      <span class="n">mask_2</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">mask_1_count</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>

  <span class="c1"># Add the over capacity ratio for expert 2</span>
  <span class="n">_CreateOverCapacityRatioSummary</span><span class="p">(</span><span class="n">mask_2</span><span class="p">,</span> <span class="n">position_in_expert_2</span><span class="p">,</span> <span class="n">capacity</span><span class="p">,</span>
                                  <span class="s1">&#39;over_capacity_2_ratio&#39;</span><span class="p">)</span>

  <span class="n">mask_2</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">position_in_expert_2</span><span class="p">,</span> <span class="n">capacity</span><span class="p">),</span> <span class="n">mask_2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="n">position_in_expert_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;...GSE,...GSE-&gt;...GS&#39;</span><span class="p">,</span> <span class="n">position_in_expert_2</span><span class="p">,</span>
                                   <span class="n">mask_2</span><span class="p">)</span>
  <span class="n">mask_2_flat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">mask_2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

  <span class="c1"># Equivalent non-einsum implementation:</span>
  <span class="c1">#</span>
  <span class="c1"># position_in_expert_2 *= mask_2</span>
  <span class="c1"># position_in_expert_2 = tf.reduce_sum(</span>
  <span class="c1">#     position_in_expert_2, axis=-1, name=&#39;position_in_expert_2&#39;)</span>

  <span class="n">gate_1</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_1_flat</span><span class="p">,</span> <span class="n">gate_1</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="n">gate_2</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_2_flat</span><span class="p">,</span> <span class="n">gate_2</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">legacy_mtf_behavior</span><span class="p">:</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="n">gate_1</span> <span class="o">+</span> <span class="n">gate_2</span>
    <span class="c1"># To avoid divide by 0.</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">denom</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">denom</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">denom</span><span class="p">))</span>
    <span class="n">gate_1</span> <span class="o">/=</span> <span class="n">denom</span>
    <span class="n">gate_2</span> <span class="o">/=</span> <span class="n">denom</span>

  <span class="c1"># GSC Tensor</span>
  <span class="k">assert</span> <span class="n">position_in_expert_1</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">mask_dtype</span>  <span class="c1"># could be float32 in tests</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">position_in_expert_1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
      <span class="n">expert_capacity_dim</span><span class="p">,</span>
      <span class="n">dtype</span><span class="o">=</span><span class="n">fprop_dtype</span><span class="p">,</span>
      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;one_hot_b_0&#39;</span><span class="p">)</span>
  <span class="c1"># GSE Tensor</span>
  <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">gate_1</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_1_flat</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="p">),</span>
                     <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
                         <span class="n">index_1</span><span class="p">,</span> <span class="n">experts_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">fprop_dtype</span><span class="p">)</span>
  <span class="c1"># GSEC Tensor</span>
  <span class="n">first_part_of_combine_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
      <span class="s1">&#39;...GSE,...GSC-&gt;...GSEC&#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;first_part_of_combine_tensor&#39;</span><span class="p">)</span>

  <span class="c1"># GSC Tensor</span>
  <span class="k">assert</span> <span class="n">position_in_expert_2</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">mask_dtype</span>  <span class="c1"># could be float32 in tests</span>
  <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">position_in_expert_2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
      <span class="n">expert_capacity_dim</span><span class="p">,</span>
      <span class="n">dtype</span><span class="o">=</span><span class="n">fprop_dtype</span><span class="p">,</span>
      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;one_hot_b_1&#39;</span><span class="p">)</span>
  <span class="c1"># GSE Tensor</span>
  <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">gate_2</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask_2_flat</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="p">),</span>
                     <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
                         <span class="n">index_2</span><span class="p">,</span> <span class="n">experts_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">fprop_dtype</span><span class="p">)</span>
  <span class="n">second_part_of_combine_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
      <span class="s1">&#39;...GSE,...GSC-&gt;...GSEC&#39;</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;second_part_of_combine_tensor&#39;</span><span class="p">)</span>

  <span class="c1"># GSEC Tensor</span>
  <span class="n">combine_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
      <span class="n">first_part_of_combine_tensor</span><span class="p">,</span>
      <span class="n">second_part_of_combine_tensor</span><span class="p">,</span>
      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;combine_tensor&#39;</span><span class="p">)</span>
  <span class="n">combine_tensor</span> <span class="o">=</span> <span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">combine_tensor</span><span class="p">)</span>

  <span class="c1"># GSEC Tensor</span>
  <span class="n">dispatch_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">combine_tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span> <span class="n">fprop_dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dispatch_tensor&#39;</span><span class="p">)</span>
  <span class="n">dispatch_tensor</span> <span class="o">=</span> <span class="n">_MaybeSplit</span><span class="p">(</span><span class="n">dispatch_tensor</span><span class="p">)</span>

  <span class="c1"># TODO(yonghui): compute and return per-group aux_loss.</span>
  <span class="k">return</span> <span class="n">aux_loss</span><span class="p">,</span> <span class="n">combine_tensor</span><span class="p">,</span> <span class="n">dispatch_tensor</span></div>


<div class="viewcode-block" id="Top2Gating"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.Top2Gating">[docs]</a><span class="k">def</span> <span class="nf">Top2Gating</span><span class="p">(</span><span class="n">w</span><span class="p">,</span>
               <span class="n">inputs</span><span class="p">,</span>
               <span class="n">paddings</span><span class="p">,</span>
               <span class="n">num_devices</span><span class="p">,</span>
               <span class="n">experts_dim</span><span class="p">,</span>
               <span class="n">expert_capacity_dim</span><span class="p">,</span>
               <span class="n">local_dispatch</span><span class="p">,</span>
               <span class="n">fprop_dtype</span><span class="p">,</span>
               <span class="n">use_xla_sharding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">second_expert_policy</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span>
               <span class="n">second_expert_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
               <span class="n">legacy_mtf_behavior</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">capacity_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">model_dim_reshape_segments</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">mask_dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">gating_logits_dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes Top-2 gating for Mixture-of-Experts.</span>

<span class="sd">  See Top2GatingOnLogits for more details.</span>

<span class="sd">  Note that for local_dispatch original batch BLM is reshaped into GSM, each</span>
<span class="sd">  group `g = 0...G-1` is being dispatched independently.</span>

<span class="sd">  Args:</span>
<span class="sd">    w: gating weights for each experts with shape ME. w was reshaped accordingly</span>
<span class="sd">        if model_dim_reshape_segments is not None,</span>
<span class="sd">    inputs: G`SM Tensor.</span>
<span class="sd">    paddings: G`S Tensor.</span>
<span class="sd">    num_devices: number of MoE devices for local dispatch</span>
<span class="sd">    experts_dim: number of experts.</span>
<span class="sd">    expert_capacity_dim: number of examples per minibatch(group) per expert.</span>
<span class="sd">      Each example is typically a vector of size input_dim, representing</span>
<span class="sd">      embedded token or an element of Transformer layer output.</span>
<span class="sd">    local_dispatch: whether dispatch is local to the group (G dim)</span>
<span class="sd">    fprop_dtype: activations datatype to use.</span>
<span class="sd">    use_xla_sharding: bool, True if this function is used for the xla_sharding</span>
<span class="sd">        case.</span>
<span class="sd">    second_expert_policy: &#39;all&#39; or &#39;random&#39;, we optionally &#39;random&#39;-ize dispatch</span>
<span class="sd">      to second-best expert proportional to (weight / second_expert_threshold).</span>
<span class="sd">    second_expert_threshold: threshold for probability normalization for</span>
<span class="sd">      second_expert_policy == &#39;random&#39;.</span>
<span class="sd">    legacy_mtf_behavior: True for legacy behavior with no re-normalization of</span>
<span class="sd">      expert assignment weights if we go over capacity or randomly decide to not</span>
<span class="sd">      dispatch to second expert.</span>
<span class="sd">    capacity_factor: if set, increases expert_capacity_dim to at least</span>
<span class="sd">      `(group_size * capacity_factor) / experts_dim`</span>
<span class="sd">      where `group_size` is the size of G dimension of `inputs`. If the</span>
<span class="sd">      value of expert_capacity_dim is already big enough no change is made.</span>
<span class="sd">    model_dim_reshape_segments: none or a list, reshaping model dimension M to</span>
<span class="sd">      that + [-1]</span>
<span class="sd">    mask_dtype: using bfloat16 for fprop_dtype could be problematic for mask</span>
<span class="sd">      tensors, mask_dtype is a special dtype for such tensors.</span>
<span class="sd">    gating_logits_dtype: using bfloat16 for fprop_dtype could be problematic for</span>
<span class="sd">      gating logits, gating_logits_dtype is a special dtype for such tensors.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple (dispatch_tensor, combine_tensor, aux_loss).</span>

<span class="sd">    - dispatch_tensor: G`SEC Tensor, scattering/dispatching inputs to</span>
<span class="sd">      experts.</span>
<span class="sd">    - combine_tensor: G`SEC Tensor.</span>
<span class="sd">      combining expert outputs.</span>
<span class="sd">    - aux_loss: auxiliary loss, equalizing the expert assignment ratios.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">orig_inputs</span> <span class="o">=</span> <span class="n">inputs</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">local_dispatch</span><span class="p">:</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">paddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

  <span class="k">if</span> <span class="n">gating_logits_dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">gating_logits_dtype</span> <span class="o">==</span> <span class="n">fprop_dtype</span><span class="p">:</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">EinsumWithModelDim</span><span class="p">(</span><span class="s1">&#39;GSM,ME-&gt;GSE&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span>
                                <span class="n">model_dim_reshape_segments</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">EinsumWithModelDim</span><span class="p">(</span>
        <span class="s1">&#39;GSM,ME-&gt;GSE&#39;</span><span class="p">,</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">gating_logits_dtype</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">gating_logits_dtype</span><span class="p">),</span>
        <span class="n">model_dim_reshape_segments</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;gating_logits_with_custom_dtype&#39;</span><span class="p">)</span>

  <span class="n">top1_expert_per_example</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

  <span class="n">tpu_summary</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="s1">&#39;top1_expert&#39;</span><span class="p">,</span> <span class="n">top1_expert_per_example</span><span class="p">)</span>

  <span class="n">aux_loss</span><span class="p">,</span> <span class="n">combine_tensor</span><span class="p">,</span> <span class="n">dispatch_tensor</span> <span class="o">=</span> <span class="n">Top2GatingOnLogits</span><span class="p">(</span>
      <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">,</span> <span class="n">experts_dim</span><span class="p">,</span> <span class="n">expert_capacity_dim</span><span class="p">,</span>
      <span class="n">fprop_dtype</span><span class="p">,</span> <span class="n">use_xla_sharding</span><span class="p">,</span> <span class="n">second_expert_policy</span><span class="p">,</span>
      <span class="n">second_expert_threshold</span><span class="p">,</span> <span class="n">legacy_mtf_behavior</span><span class="p">,</span> <span class="n">capacity_factor</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
      <span class="n">mask_dtype</span><span class="p">)</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">local_dispatch</span><span class="p">:</span>
    <span class="n">dispatch_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">dispatch_tensor</span><span class="p">,</span> <span class="n">orig_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">dispatch_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
    <span class="n">combine_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">combine_tensor</span><span class="p">,</span> <span class="n">orig_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">combine_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>

  <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
      <span class="n">combine_tensor</span><span class="o">=</span><span class="n">combine_tensor</span><span class="p">,</span>
      <span class="n">dispatch_tensor</span><span class="o">=</span><span class="n">dispatch_tensor</span><span class="p">,</span>
      <span class="n">aux_loss</span><span class="o">=</span><span class="n">aux_loss</span><span class="p">)</span></div>


<div class="viewcode-block" id="FeedForwardNetworksApplyGating"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.FeedForwardNetworksApplyGating">[docs]</a><span class="k">def</span> <span class="nf">FeedForwardNetworksApplyGating</span><span class="p">(</span><span class="n">gating</span><span class="p">,</span>
                                   <span class="n">inputs</span><span class="p">,</span>
                                   <span class="n">reshaped_inputs</span><span class="p">,</span>
                                   <span class="n">wi_split</span><span class="p">,</span>
                                   <span class="n">wo_split</span><span class="p">,</span>
                                   <span class="n">num_devices</span><span class="p">,</span>
                                   <span class="n">num_groups</span><span class="p">,</span>
                                   <span class="n">bi_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">bo_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                   <span class="n">device_mesh</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">gsm_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">egcm_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">gecm_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">gsec_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">eah_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">eam_split</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">model_dim_reshape_segments</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">use_glu</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                   <span class="n">activation_name</span><span class="o">=</span><span class="s1">&#39;RELU&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Apply top_2 gating to feedforward networks.</span>

<span class="sd">  Args:</span>
<span class="sd">    gating: returns from Top2Gating consisting of: dispatch_tensor, G`SEC</span>
<span class="sd">      Tensor, scattering/dispatching inputs to experts. combine_tensor, G`SEC</span>
<span class="sd">      Tensor, combining expert outputs. aux_loss. auxiliary loss, equalizing the</span>
<span class="sd">      expert assignment ratios</span>
<span class="sd">    inputs: G`SM Tensor.</span>
<span class="sd">    reshaped_inputs: G`SM Tensor.</span>
<span class="sd">    wi_split: First projection weights [E, M, H] of the feedforward networks.</span>
<span class="sd">    wo_split: Last projection weights [E, H, M] of the feedforward networks.</span>
<span class="sd">    num_devices: number of devices.</span>
<span class="sd">    num_groups: number of groups (generally matches to or proportional to</span>
<span class="sd">      num_devices).</span>
<span class="sd">    bi_split: First projection bias [E, 1, H] of the feedforward networks.</span>
<span class="sd">    bo_split: Last projection bias [E, 1, M] of the feedforward networks.</span>
<span class="sd">    dropout_rate: Dropout rate.</span>
<span class="sd">    device_mesh: Device mesh as a numpy ND array of device IDs. Split arguments</span>
<span class="sd">      must be set if device_mesh is not None.</span>
<span class="sd">    gsm_split: Mesh split for GSM tensors.</span>
<span class="sd">    egcm_split: Mesh split for EGCM tensors.</span>
<span class="sd">    gecm_split: Mesh split for GECM tensors.</span>
<span class="sd">    gsec_split: Mesh split for GSEC tensors.</span>
<span class="sd">    eah_split: Mesh split for EAH tensors.</span>
<span class="sd">    eam_split: Mesh split for EAM tensors.</span>
<span class="sd">    model_dim_reshape_segments: Reshaping model dimension M to that + [-1]</span>
<span class="sd">    use_glu: Whether to use the GLU expert, default to False.</span>
<span class="sd">    activation_name: Default: `RELU`. Activation function for feed-forward.</span>

<span class="sd">  Returns:</span>
<span class="sd">    outputs: G`SM Tensor.</span>
<span class="sd">    aux_loss: scalar auxiliary loss.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">gsm_split</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">egcm_split</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">gecm_split</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">gsec_split</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">eah_split</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">eam_split</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

  <span class="k">def</span> <span class="nf">_Einsum</span><span class="p">(</span><span class="n">eq</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">EinsumWithModelDim</span><span class="p">(</span><span class="n">eq</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">model_dim_reshape_segments</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_NewOrHistoricSplit</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t_split</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">device_mesh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;MeshSplit </span><span class="si">%s</span><span class="s1"> </span><span class="si">%s</span><span class="s1"> </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">device_mesh</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">t_split</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">MeshSplit</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">device_mesh</span><span class="p">,</span> <span class="n">t_split</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>

  <span class="c1"># dispatch_tensor: G`SEC</span>
  <span class="n">expert_inputs</span> <span class="o">=</span> <span class="n">_Einsum</span><span class="p">(</span>
      <span class="s1">&#39;GSEC,GSM-&gt;EGCM&#39;</span><span class="p">,</span>
      <span class="n">_NewOrHistoricSplit</span><span class="p">(</span><span class="n">gating</span><span class="o">.</span><span class="n">dispatch_tensor</span><span class="p">,</span> <span class="n">gsec_split</span><span class="p">),</span>
      <span class="n">_NewOrHistoricSplit</span><span class="p">(</span><span class="n">reshaped_inputs</span><span class="p">,</span> <span class="n">gsm_split</span><span class="p">),</span>
      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;expert_inputs_egcm&#39;</span><span class="p">)</span>
  <span class="n">expert_inputs</span> <span class="o">=</span> <span class="n">_NewOrHistoricSplit</span><span class="p">(</span><span class="n">expert_inputs</span><span class="p">,</span> <span class="n">egcm_split</span><span class="p">)</span>

  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="k">if</span> <span class="n">model_dim_reshape_segments</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">reshaped_inputs</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">reshaped_inputs</span><span class="p">)[</span><span class="mi">2</span><span class="p">:]</span>
  <span class="n">E</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">expert_inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

  <span class="c1"># combine_tensor: G`SEC</span>
  <span class="n">G</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">gating</span><span class="o">.</span><span class="n">combine_tensor</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="c1"># allow evaler/decoder to run.</span>
  <span class="k">del</span> <span class="n">num_groups</span>
  <span class="n">C</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">gating</span><span class="o">.</span><span class="n">combine_tensor</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">A</span> <span class="o">=</span> <span class="n">G</span> <span class="o">*</span> <span class="n">C</span>
  <span class="c1"># pylint: enable=invalid-name</span>

  <span class="c1"># Reshaping EGCM =&gt; EAM where A = G*C, e.g.</span>
  <span class="c1">#</span>
  <span class="c1"># with E=512, G=1024</span>
  <span class="c1">#</span>
  <span class="c1"># (512, 1024, 4, 1024) =&gt; (512, 4096, 1024)</span>
  <span class="n">expert_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
      <span class="n">expert_inputs</span><span class="p">,</span> <span class="p">[</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">expert_inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">A</span><span class="p">]</span> <span class="o">+</span> <span class="n">M</span><span class="p">,</span>
      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;expert_inputs_eam&#39;</span><span class="p">)</span>
  <span class="n">expert_inputs</span> <span class="o">=</span> <span class="n">_NewOrHistoricSplit</span><span class="p">(</span><span class="n">expert_inputs</span><span class="p">,</span> <span class="n">eam_split</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">use_glu</span><span class="p">:</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">_Einsum</span><span class="p">(</span><span class="s1">&#39;KEMH,EAM-&gt;KEAH&#39;</span><span class="p">,</span> <span class="n">wi_split</span><span class="p">,</span> <span class="n">expert_inputs</span><span class="p">)</span>
    <span class="n">o1</span><span class="p">,</span> <span class="n">o2</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">activations</span><span class="o">.</span><span class="n">GetFn</span><span class="p">(</span><span class="n">activation_name</span><span class="p">)(</span><span class="n">o1</span><span class="p">),</span> <span class="n">o2</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">_Einsum</span><span class="p">(</span><span class="s1">&#39;EAM,EMH-&gt;EAH&#39;</span><span class="p">,</span> <span class="n">expert_inputs</span><span class="p">,</span> <span class="n">wi_split</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;h_eah&#39;</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">_NewOrHistoricSplit</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">eah_split</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bi_split</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">h</span> <span class="o">+=</span> <span class="n">Split</span><span class="p">(</span><span class="n">bi_split</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
      <span class="n">h</span> <span class="o">=</span> <span class="n">Split</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>

    <span class="n">h</span> <span class="o">=</span> <span class="n">activations</span><span class="o">.</span><span class="n">GetFn</span><span class="p">(</span><span class="n">activation_name</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">dropout_rate</span><span class="p">:</span>
    <span class="c1"># we generally do not use stateless dropout in MoE since it introduces</span>
    <span class="c1"># large uint32 tensor broadcast (per dehao@ study)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>

  <span class="n">expert_outputs</span> <span class="o">=</span> <span class="n">_Einsum</span><span class="p">(</span>
      <span class="s1">&#39;EAH,EHM-&gt;EAM&#39;</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">wo_split</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;expert_outputs_eam&#39;</span><span class="p">)</span>
  <span class="n">expert_outputs</span> <span class="o">=</span> <span class="n">_NewOrHistoricSplit</span><span class="p">(</span><span class="n">expert_outputs</span><span class="p">,</span> <span class="n">eam_split</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">bo_split</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">expert_outputs</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">expert_outputs</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
    <span class="n">expert_outputs</span> <span class="o">+=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">bo_split</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
    <span class="n">expert_outputs</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">expert_outputs</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
  <span class="n">expert_outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">expert_outputs</span><span class="p">,</span> <span class="p">[</span><span class="n">E</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">C</span><span class="p">]</span> <span class="o">+</span> <span class="n">M</span><span class="p">)</span>

  <span class="c1"># same as tf.transpose</span>
  <span class="n">expert_outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
      <span class="n">_EinsumEqWithModelDim</span><span class="p">(</span><span class="s1">&#39;EGCM-&gt;GECM&#39;</span><span class="p">,</span> <span class="n">model_dim_reshape_segments</span><span class="p">),</span>
      <span class="n">expert_outputs</span><span class="p">,</span>
      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;expert_outputs_gecm&#39;</span><span class="p">)</span>

  <span class="n">combined_outputs</span> <span class="o">=</span> <span class="n">_Einsum</span><span class="p">(</span>
      <span class="s1">&#39;GSEC,GECM-&gt;GSM&#39;</span><span class="p">,</span>
      <span class="n">_NewOrHistoricSplit</span><span class="p">(</span><span class="n">gating</span><span class="o">.</span><span class="n">combine_tensor</span><span class="p">,</span> <span class="n">gsec_split</span><span class="p">),</span>
      <span class="n">_NewOrHistoricSplit</span><span class="p">(</span><span class="n">expert_outputs</span><span class="p">,</span> <span class="n">gecm_split</span><span class="p">),</span>
      <span class="n">name</span><span class="o">=</span><span class="s1">&#39;combined_outputs_gsm&#39;</span><span class="p">)</span>
  <span class="n">outputs</span> <span class="o">=</span> <span class="n">_NewOrHistoricSplit</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">combined_outputs</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)),</span> <span class="n">gsm_split</span><span class="p">)</span>
  <span class="n">aux_loss</span> <span class="o">=</span> <span class="n">gating</span><span class="o">.</span><span class="n">aux_loss</span>
  <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">aux_loss</span></div>


<div class="viewcode-block" id="GatherK"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.GatherK">[docs]</a><span class="k">def</span> <span class="nf">GatherK</span><span class="p">(</span><span class="n">selected_pos</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">num_devices</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Gather up to k elements from given tensors at selected pos under SPMD.</span>

<span class="sd">  Example::</span>

<span class="sd">    # Input</span>
<span class="sd">    k = 3</span>

<span class="sd">    selected_pos = [</span>
<span class="sd">        [0, 0, 1, 1],</span>
<span class="sd">        [0, 1, 1, 0],</span>
<span class="sd">        [0, 0, 0, 0],</span>
<span class="sd">        [1, 1, 1, 0],</span>
<span class="sd">        [1, 1, 1, 1],  # topk(k=3) largest indices are selected in this row.</span>
<span class="sd">    ]</span>

<span class="sd">    value_2d = [</span>
<span class="sd">        [1, 3, 5, 7],</span>
<span class="sd">        [9, 11, 13, 15],</span>
<span class="sd">        [17, 19, 21, 23],</span>
<span class="sd">        [25, 27, 29, 31],</span>
<span class="sd">        [33, 35, 37, 39],</span>
<span class="sd">    ]</span>

<span class="sd">    # Output:</span>
<span class="sd">    output = [</span>
<span class="sd">        [0, 5, 7],</span>
<span class="sd">        [0, 11, 13],</span>
<span class="sd">        [0, 0, 0],</span>
<span class="sd">        [25, 27, 29],</span>
<span class="sd">        [35, 37, 39],</span>
<span class="sd">    ]</span>

<span class="sd">    # Output padding:</span>
<span class="sd">    output_padding = [</span>
<span class="sd">        [1, 0, 0],</span>
<span class="sd">        [1, 0, 0],</span>
<span class="sd">        [1, 1, 1],</span>
<span class="sd">        [0, 0, 0],</span>
<span class="sd">        [0, 0, 0],</span>
<span class="sd">    ]</span>

<span class="sd">  Args:</span>
<span class="sd">    selected_pos: a 0/1 2D tf.int32 tensor of shape [batch, time].</span>
<span class="sd">    values: a list of tensors, the rank of each is at least rank=2. [batch,</span>
<span class="sd">      time, ...].</span>
<span class="sd">    k: a scalar tf.int32 tensor or a Python int. On TPU, k must be a</span>
<span class="sd">      compile-time constant.</span>
<span class="sd">    num_devices: number of TPU devices used in xla_sharding SPMD.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple (output, padding).</span>

<span class="sd">    - output: a list of tensors of shape [batch, k, ...].</span>
<span class="sd">    - padding: a 2D 0/1 tensor of shape [batch, k], &#39;1&#39;s are padded locations.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">global_batch</span><span class="p">,</span> <span class="n">seq_len</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">selected_pos</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">num_devices</span><span class="p">:</span>
    <span class="n">device_batch</span> <span class="o">=</span> <span class="n">global_batch</span> <span class="o">//</span> <span class="n">num_devices</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">device_batch</span> <span class="o">=</span> <span class="n">global_batch</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)):</span>
    <span class="c1"># Assert the first 2 dim of values[i] is [global_batch, seq_len]</span>
    <span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="p">[</span><span class="n">global_batch</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>
  <span class="c1"># indices are 1-based for now, to distinguish between padding and selected</span>
  <span class="c1"># locations.</span>
  <span class="n">indices</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="c1"># [1, seq_len]</span>
  <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="c1"># if 0, the position is not selected.</span>
  <span class="c1"># [1, seq_len] * [global_batch, seq_len] =&gt; [global_batch, t]</span>
  <span class="c1"># -- topk --&gt; [global_batch, k]</span>
  <span class="n">topk_indices</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span>
      <span class="n">indices</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">selected_pos</span><span class="p">,</span> <span class="n">indices</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">k</span><span class="p">)</span>

  <span class="c1"># [global_batch, k], sorted in ascending order.</span>
  <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">topk_indices</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
  <span class="c1"># [global_batch, k], padded positions are &#39;1&#39;s.</span>
  <span class="n">padding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="n">padding</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>

  <span class="c1"># [global_batch, k], zero_based_indices</span>
  <span class="n">mp_idx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">indices</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">mp_idx</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">mp_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>

  <span class="c1"># [device_batch, k]</span>
  <span class="k">if</span> <span class="n">num_devices</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">():</span>
    <span class="n">mp_idx</span> <span class="o">=</span> <span class="n">xla_sharding</span><span class="o">.</span><span class="n">auto_to_manual_spmd_partition</span><span class="p">(</span>
        <span class="n">mp_idx</span><span class="p">,</span> <span class="n">xla_sharding</span><span class="o">.</span><span class="n">get_op_sharding</span><span class="p">(</span><span class="n">mp_idx</span><span class="o">.</span><span class="n">op</span><span class="p">))</span>
  <span class="c1"># [device_batch, k, 1]</span>
  <span class="n">mp_idx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">mp_idx</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

  <span class="c1"># [device_batch]</span>
  <span class="n">batch_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">device_batch</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="c1"># [device_batch, 1, 1]</span>
  <span class="n">batch_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_ids</span><span class="p">,</span> <span class="p">[</span><span class="n">device_batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
  <span class="c1"># [device_batch, k, 1]</span>
  <span class="n">batch_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">batch_ids</span><span class="p">,</span> <span class="p">[</span><span class="n">device_batch</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

  <span class="c1"># [device_batch, k, 2]</span>
  <span class="n">final_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">batch_ids</span><span class="p">,</span> <span class="n">mp_idx</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

  <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
    <span class="c1"># Begin manually partition gather.</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">gshard_utils</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
    <span class="n">v_shape</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">num_devices</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">():</span>
      <span class="n">op_sharding</span> <span class="o">=</span> <span class="n">xla_sharding</span><span class="o">.</span><span class="n">get_op_sharding</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
      <span class="n">v</span> <span class="o">=</span> <span class="n">xla_sharding</span><span class="o">.</span><span class="n">auto_to_manual_spmd_partition</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">op_sharding</span><span class="p">)</span>
    <span class="c1"># Returns [global_batch, k, ...]</span>
    <span class="n">v_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">final_indices</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">num_devices</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">():</span>
      <span class="n">v_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">k</span>
      <span class="n">v_out</span> <span class="o">=</span> <span class="n">xla_sharding</span><span class="o">.</span><span class="n">manual_to_auto_spmd_partition</span><span class="p">(</span>
          <span class="n">v_out</span><span class="p">,</span> <span class="n">op_sharding</span><span class="p">,</span> <span class="n">full_shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="n">v_shape</span><span class="p">))</span>
    <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v_out</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">padding</span></div>


<div class="viewcode-block" id="GetSentenceEmbeddings"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.GetSentenceEmbeddings">[docs]</a><span class="k">def</span> <span class="nf">GetSentenceEmbeddings</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">segment_id</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns the average sentence embedding to gate by.</span>

<span class="sd">  Example::</span>

<span class="sd">    inputs: &lt;tf.Variable &#39;Variable:0&#39; shape=(10, 3) dtype=float64, numpy=</span>
<span class="sd">             array([[0.41258181, 0.61071571, 0.63777673],</span>
<span class="sd">                    [0.65571443, 0.54297766, 0.10288261],</span>
<span class="sd">                    [0.8577837 , 0.81915847, 0.61996602],</span>
<span class="sd">                    [0.46897136, 0.92662692, 0.32942232],</span>
<span class="sd">                    [0.60162383, 0.3385829 , 0.3408632 ],</span>
<span class="sd">                    [0.40774807, 0.86139635, 0.00927162],</span>
<span class="sd">                    [0.56126334, 0.51748817, 0.07791397],</span>
<span class="sd">                    [0.06595223, 0.95529216, 0.34458149],</span>
<span class="sd">                    [0.1238971 , 0.49897169, 0.25216722],</span>
<span class="sd">                    [0.11221774, 0.50284604, 0.84106974]])&gt;</span>
<span class="sd">    segment_id: &lt;tf.Variable &#39;Variable:0&#39; shape=(10,) dtype=int64,</span>
<span class="sd">                 numpy=array([1, 1, 2, 0, 0, 3, 3, 3, 3, 0])&gt;</span>

<span class="sd">  Args:</span>
<span class="sd">    inputs: G`SM Tensor.</span>
<span class="sd">    segment_id: G`S Tensor.</span>

<span class="sd">  Returns:</span>
<span class="sd">    sentence_embeddings: GSM Tensor that is an average of the input embeddings</span>
<span class="sd">    per segment.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">reshaped_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>

  <span class="c1"># We set num_segments to a large value so that shape is known at compile time.</span>
  <span class="n">max_segments</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">reshaped_inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="c1"># We change the padding to be max_segments - 1 instead of 0 because</span>
  <span class="c1"># tf.math.unsorted_segment_mean because it only accepts values between 1 and</span>
  <span class="c1"># max_segments.</span>
  <span class="n">modified_segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
      <span class="n">segment_id</span> <span class="o">+</span> <span class="n">max_segments</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">segment_id</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">segment_id</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span> <span class="o">-</span>
      <span class="mi">1</span><span class="p">,</span>
      <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">reshaped_segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">modified_segment_id</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

  <span class="c1"># Takes the mean of all segments, w/ 0s for the padding.</span>
  <span class="n">params</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">unsorted_segment_mean</span><span class="p">(</span><span class="n">reshaped_inputs</span><span class="p">,</span> <span class="n">reshaped_segment_id</span><span class="p">,</span>
                                    <span class="n">max_segments</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">reshaped_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">reshaped_inputs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="p">],</span>
                     <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">raw_sentence_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">modified_segment_id</span><span class="p">)</span>

  <span class="c1"># sentence_embedding: &lt;tf.Tensor: shape=(10, 3), dtype=float64, numpy=</span>
  <span class="c1">#                     array([[0.92657252, 0.40264503, 0.55494457],</span>
  <span class="c1">#                            [0.92657252, 0.40264503, 0.55494457],</span>
  <span class="c1">#                            [0.08002721, 0.02360659, 0.63688627],</span>
  <span class="c1">#                            [0.        , 0.        , 0.        ],</span>
  <span class="c1">#                            [0.        , 0.        , 0.        ],</span>
  <span class="c1">#                            [0.8138629 , 0.54451293, 0.48802852],</span>
  <span class="c1">#                            [0.8138629 , 0.54451293, 0.48802852],</span>
  <span class="c1">#                            [0.8138629 , 0.54451293, 0.48802852],</span>
  <span class="c1">#                            [0.8138629 , 0.54451293, 0.48802852],</span>
  <span class="c1">#                            [0.        , 0.        , 0.        ]])&gt;</span>
  <span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">raw_sentence_embeddings</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">sentence_embeddings</span></div>


<div class="viewcode-block" id="SentenceTop2Gating"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.SentenceTop2Gating">[docs]</a><span class="k">def</span> <span class="nf">SentenceTop2Gating</span><span class="p">(</span><span class="n">w</span><span class="p">,</span>
                       <span class="n">inputs</span><span class="p">,</span>
                       <span class="n">paddings</span><span class="p">,</span>
                       <span class="n">segment_id</span><span class="p">,</span>
                       <span class="n">num_devices</span><span class="p">,</span>
                       <span class="n">experts_dim</span><span class="p">,</span>
                       <span class="n">expert_capacity_dim</span><span class="p">,</span>
                       <span class="n">local_dispatch</span><span class="p">,</span>
                       <span class="n">fprop_dtype</span><span class="p">,</span>
                       <span class="n">use_xla_sharding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">second_expert_policy</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span>
                       <span class="n">second_expert_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                       <span class="n">legacy_mtf_behavior</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">embedding_type</span><span class="o">=</span><span class="s1">&#39;sentence&#39;</span><span class="p">,</span>
                       <span class="n">capacity_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes Top-2 sentence gating for Mixture-of-Experts.</span>

<span class="sd">  Instead of using the each token, this function uses embedding_type to return a</span>
<span class="sd">  sentence-wise embedding to create dispatch and combine tensors that gate</span>
<span class="sd">  the entire sentence.</span>

<span class="sd">  Note that for local_dispatch original batch BLM is reshaped into GSM, each</span>
<span class="sd">  group `g = 0...G-1` is being dispatched independently.</span>

<span class="sd">  Args:</span>
<span class="sd">    w: gating weights for each experts.</span>
<span class="sd">    inputs: G`SM Tensor.</span>
<span class="sd">    paddings: G`S Tensor.</span>
<span class="sd">    segment_id: G`SM Tensor used for differentiating different sentences in an</span>
<span class="sd">      input example.</span>
<span class="sd">    num_devices: number of MoE devices for local dispatch</span>
<span class="sd">    experts_dim: number of experts.</span>
<span class="sd">    expert_capacity_dim: number of examples per minibatch(group) per expert.</span>
<span class="sd">      Each example is typically a vector of size input_dim, representing</span>
<span class="sd">      embedded token or an element of Transformer layer output.</span>
<span class="sd">    local_dispatch: whether dispatch is local to the group (G dim)</span>
<span class="sd">    fprop_dtype: activations datatype to use.</span>
<span class="sd">    use_xla_sharding: bool, True if this function is used for the xla_sharding</span>
<span class="sd">      case.</span>
<span class="sd">    second_expert_policy: &#39;all&#39; or &#39;random&#39;, we optionally &#39;random&#39;-ize dispatch</span>
<span class="sd">      to second-best expert proportional to (weight / second_expert_threshold).</span>
<span class="sd">    second_expert_threshold: threshold for probability normalization for</span>
<span class="sd">      second_expert_policy == &#39;random&#39;.</span>
<span class="sd">    legacy_mtf_behavior: True for legacy behavior with no re-normalization of</span>
<span class="sd">      expert assignment weights if we go over capacity or randomly decide to not</span>
<span class="sd">      dispatch to second expert.</span>
<span class="sd">    embedding_type: &#39;sentence&#39; by default. Options: &#39;sentence&#39;. Setting this</span>
<span class="sd">      option calls GetSentenceEmbeddings.</span>
<span class="sd">    capacity_factor: if set, increases expert_capacity_dim to at least</span>
<span class="sd">      (group_size * capacity_factor) / experts_dim where `group_size` is the</span>
<span class="sd">      size of G dimension of `inputs`. If the value of expert_capacity_dim is</span>
<span class="sd">      already big enough no change is made.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple (dispatch_tensor, combine_tensor, aux_loss).</span>

<span class="sd">    - dispatch_tensor: G`SEC Tensor, scattering/dispatching inputs to</span>
<span class="sd">      experts.</span>
<span class="sd">    - combine_tensor: G`SEC Tensor.</span>
<span class="sd">      combining expert outputs.</span>
<span class="sd">    - aux_loss: auxiliary loss, equalizing the expert assignment ratios.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">assert</span> <span class="n">embedding_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;sentence&#39;</span><span class="p">]</span>
  <span class="n">orig_inputs</span> <span class="o">=</span> <span class="n">inputs</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">local_dispatch</span><span class="p">:</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">paddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

  <span class="k">if</span> <span class="n">embedding_type</span> <span class="o">==</span> <span class="s1">&#39;sentence&#39;</span><span class="p">:</span>
    <span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">GetSentenceEmbeddings</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">segment_id</span><span class="p">)</span>

  <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;GSM,ME-&gt;GSE&#39;</span><span class="p">,</span> <span class="n">sentence_embeddings</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
  <span class="n">aux_loss</span><span class="p">,</span> <span class="n">combine_tensor</span><span class="p">,</span> <span class="n">dispatch_tensor</span> <span class="o">=</span> <span class="n">Top2GatingOnLogits</span><span class="p">(</span>
      <span class="n">sentence_embeddings</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">,</span> <span class="n">experts_dim</span><span class="p">,</span>
      <span class="n">expert_capacity_dim</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="p">,</span> <span class="n">use_xla_sharding</span><span class="p">,</span> <span class="n">second_expert_policy</span><span class="p">,</span>
      <span class="n">second_expert_threshold</span><span class="p">,</span> <span class="n">legacy_mtf_behavior</span><span class="p">,</span> <span class="n">capacity_factor</span><span class="p">)</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">local_dispatch</span><span class="p">:</span>
    <span class="n">dispatch_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">dispatch_tensor</span><span class="p">,</span> <span class="n">orig_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">dispatch_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
    <span class="n">combine_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">combine_tensor</span><span class="p">,</span> <span class="n">orig_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">combine_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>

  <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
      <span class="n">combine_tensor</span><span class="o">=</span><span class="n">combine_tensor</span><span class="p">,</span>
      <span class="n">dispatch_tensor</span><span class="o">=</span><span class="n">dispatch_tensor</span><span class="p">,</span>
      <span class="n">aux_loss</span><span class="o">=</span><span class="n">aux_loss</span><span class="p">)</span></div>


<div class="viewcode-block" id="TaskTop2Gating"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.TaskTop2Gating">[docs]</a><span class="k">def</span> <span class="nf">TaskTop2Gating</span><span class="p">(</span><span class="n">w</span><span class="p">,</span>
                   <span class="n">inputs</span><span class="p">,</span>
                   <span class="n">paddings</span><span class="p">,</span>
                   <span class="n">task_embeddings</span><span class="p">,</span>
                   <span class="n">num_devices</span><span class="p">,</span>
                   <span class="n">experts_dim</span><span class="p">,</span>
                   <span class="n">expert_capacity_dim</span><span class="p">,</span>
                   <span class="n">local_dispatch</span><span class="p">,</span>
                   <span class="n">fprop_dtype</span><span class="p">,</span>
                   <span class="n">use_xla_sharding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">second_expert_policy</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span>
                   <span class="n">second_expert_threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                   <span class="n">legacy_mtf_behavior</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes Top-2 sentence gating for Mixture-of-Experts.</span>

<span class="sd">  Instead of using the each token, this function uses embedding_type to return a</span>
<span class="sd">  sentence-wise embedding to create dispatch and combine tensors that gate</span>
<span class="sd">  the entire sentence.</span>

<span class="sd">  Note that for local_dispatch original batch BLM is reshaped into GSM, each</span>
<span class="sd">  group `g = 0...G-1` is being dispatched independently.</span>

<span class="sd">  Args:</span>
<span class="sd">    w: gating weights for each experts.</span>
<span class="sd">    inputs: G`SM Tensor.</span>
<span class="sd">    paddings: G`S Tensor.</span>
<span class="sd">    task_embeddings: G`SM Tensor.</span>
<span class="sd">    num_devices: number of MoE devices for local dispatch</span>
<span class="sd">    experts_dim: number of experts.</span>
<span class="sd">    expert_capacity_dim: number of examples per minibatch(group) per expert.</span>
<span class="sd">      Each example is typically a vector of size input_dim, representing</span>
<span class="sd">      embedded token or an element of Transformer layer output.</span>
<span class="sd">    local_dispatch: whether dispatch is local to the group (G dim)</span>
<span class="sd">    fprop_dtype: activations datatype to use.</span>
<span class="sd">    use_xla_sharding: bool, True if this function is used for the xla_sharding</span>
<span class="sd">      case.</span>
<span class="sd">    second_expert_policy: &#39;all&#39; or &#39;random&#39;, we optionally &#39;random&#39;-ize dispatch</span>
<span class="sd">      to second-best expert proportional to (weight / second_expert_threshold).</span>
<span class="sd">    second_expert_threshold: threshold for probability normalization for</span>
<span class="sd">      second_expert_policy == &#39;random&#39;.</span>
<span class="sd">    legacy_mtf_behavior: True for legacy behavior with no re-normalization of</span>
<span class="sd">      expert assignment weights if we go over capacity or randomly decide to not</span>
<span class="sd">      dispatch to second expert.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple (dispatch_tensor, combine_tensor, aux_loss):</span>

<span class="sd">    - dispatch_tensor: G`SEC Tensor, scattering/dispatching inputs to</span>
<span class="sd">      experts.</span>
<span class="sd">    - combine_tensor: G`SEC Tensor.</span>
<span class="sd">      combining expert outputs.</span>
<span class="sd">    - aux_loss: auxiliary loss, equalizing the expert assignment ratios.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">orig_inputs</span> <span class="o">=</span> <span class="n">inputs</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">local_dispatch</span><span class="p">:</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">task_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">task_embeddings</span><span class="p">,</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">task_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">task_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">paddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

  <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;GSM,ME-&gt;GSE&#39;</span><span class="p">,</span> <span class="n">task_embeddings</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
  <span class="n">aux_loss</span><span class="p">,</span> <span class="n">combine_tensor</span><span class="p">,</span> <span class="n">dispatch_tensor</span> <span class="o">=</span> <span class="n">Top2GatingOnLogits</span><span class="p">(</span>
      <span class="n">task_embeddings</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">,</span> <span class="n">experts_dim</span><span class="p">,</span>
      <span class="n">expert_capacity_dim</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="p">,</span> <span class="n">use_xla_sharding</span><span class="p">,</span> <span class="n">second_expert_policy</span><span class="p">,</span>
      <span class="n">second_expert_threshold</span><span class="p">,</span> <span class="n">legacy_mtf_behavior</span><span class="p">)</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">local_dispatch</span><span class="p">:</span>
    <span class="n">dispatch_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">dispatch_tensor</span><span class="p">,</span> <span class="n">orig_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">dispatch_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
    <span class="n">combine_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">combine_tensor</span><span class="p">,</span> <span class="n">orig_inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">combine_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>

  <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
      <span class="n">combine_tensor</span><span class="o">=</span><span class="n">combine_tensor</span><span class="p">,</span>
      <span class="n">dispatch_tensor</span><span class="o">=</span><span class="n">dispatch_tensor</span><span class="p">,</span>
      <span class="n">aux_loss</span><span class="o">=</span><span class="n">aux_loss</span><span class="p">)</span></div>


<div class="viewcode-block" id="_EinsumEqWithModelDim"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers._EinsumEqWithModelDim">[docs]</a><span class="k">def</span> <span class="nf">_EinsumEqWithModelDim</span><span class="p">(</span><span class="n">equation</span><span class="p">,</span> <span class="n">model_dim_reshape_segments</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Adjust Einsum equation according to model_dim_reshape_segments.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">model_dim_reshape_segments</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">equation</span>
  <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">model_dim_reshape_segments</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">2</span>
  <span class="n">insert_chars</span> <span class="o">=</span> <span class="s1">&#39;N&#39;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">model_dim_reshape_segments</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="s1">&#39;NO&#39;</span>
  <span class="n">new_equation</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
  <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">equation</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">c</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">insert_chars</span>
    <span class="k">if</span> <span class="n">c</span> <span class="o">==</span> <span class="s1">&#39;M&#39;</span><span class="p">:</span>
      <span class="n">new_equation</span> <span class="o">+=</span> <span class="n">insert_chars</span>
    <span class="n">new_equation</span> <span class="o">+=</span> <span class="n">c</span>
  <span class="k">return</span> <span class="n">new_equation</span></div>


<div class="viewcode-block" id="EinsumWithModelDim"><a class="viewcode-back" href="../../../lingvo.core.gshard_layers.html#lingvo.core.gshard_layers.EinsumWithModelDim">[docs]</a><span class="k">def</span> <span class="nf">EinsumWithModelDim</span><span class="p">(</span><span class="n">equation</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">model_dim_reshape_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Einsum with adjusted equation according to model_dim_reshape_segments.</span>

<span class="sd">  It changes each dimension named &#39;M&#39; in the equation into two dimensions &#39;NM&#39;</span>
<span class="sd">  if model_dim_reshape_segments is set in the params. Therefore the original</span>
<span class="sd">  equation should not have &#39;N&#39;, and only use &#39;M&#39; when it is expected to be</span>
<span class="sd">  reshaped.</span>

<span class="sd">  For example, an input equation &#39;GSM,ME-&gt;GSE&#39; and model_dim_reshape_segments</span>
<span class="sd">  # [16, 4] will be rewritten into the new equation &#39;GSNOM,NOME-&gt;GSE&#39;.</span>

<span class="sd">  Args:</span>
<span class="sd">    equation: a string describing the contraction, in the same format as</span>
<span class="sd">      numpy.einsum.</span>
<span class="sd">    x: First input to einsum.</span>
<span class="sd">    y: second input to einsum.</span>
<span class="sd">    model_dim_reshape_segments: Reshaping model dimension M to that + [-1]</span>
<span class="sd">    name: optional name.</span>

<span class="sd">  Returns:</span>
<span class="sd">    tf.einsum(maybe_modified_equation, x, y)</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">model_dim_reshape_segments</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">equation</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">new_equation</span> <span class="o">=</span> <span class="n">_EinsumEqWithModelDim</span><span class="p">(</span><span class="n">equation</span><span class="p">,</span> <span class="n">model_dim_reshape_segments</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">new_equation</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>