

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>lingvo.core.rnn_cell &mdash; Lingvo  documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home" alt="Documentation Home"> Lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../lingvo.html">lingvo package</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>lingvo.core.rnn_cell</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for lingvo.core.rnn_cell</h1><div class="highlight"><pre>
<span></span><span class="c1"># Lint as: python3</span>
<span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;RNN cells (e.g., LSTM, GRU) that the Lingvo model uses.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">lingvo.compat</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">hyperparams</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">pruning_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">py_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">quant_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">summary_utils</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="kn">import</span> <span class="n">deprecation</span> <span class="k">as</span> <span class="n">tf_deprecation</span>  <span class="c1"># pylint: disable=g-direct-tensorflow-import</span>


<div class="viewcode-block" id="_HistogramSummary"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell._HistogramSummary">[docs]</a><span class="k">def</span> <span class="nf">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Adds a histogram summary for &#39;v&#39; into the default tf graph.&quot;&quot;&quot;</span>
  <span class="n">summary_utils</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span></div>


<span class="n">RNN_CELL_WT</span> <span class="o">=</span> <span class="s1">&#39;rnn_cell_weight_variable&#39;</span>


<div class="viewcode-block" id="RNNCell"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.RNNCell">[docs]</a><span class="k">class</span> <span class="nc">RNNCell</span><span class="p">(</span><span class="n">quant_utils</span><span class="o">.</span><span class="n">QuantizableLayer</span><span class="p">):</span>
  <span class="c1"># pylint: disable=line-too-long</span>
  <span class="sd">&quot;&quot;&quot;RNN cells.</span>

<span class="sd">  RNNCell represents recurrent state in a `.NestedMap`.</span>

<span class="sd">  `zero_state(theta, batch_size)` returns the initial state, which is defined</span>
<span class="sd">  by each subclass. From the state, each subclass defines `GetOutput()`</span>
<span class="sd">  to extract the output tensor.</span>

<span class="sd">  `RNNCell.FProp` defines the forward function::</span>

<span class="sd">      (theta, state0, inputs) -&gt; state1, extras</span>

<span class="sd">  All arguments and return values are `.NestedMap`. Each subclass defines</span>
<span class="sd">  what fields these `.NestedMap` are expected to have. `extras` is a</span>
<span class="sd">  `.NestedMap` containing some intermediate results `FProp` computes to</span>
<span class="sd">  facilitate the backprop.</span>

<span class="sd">  `zero_state(theta, batch_size)`, `state0` and `state1` are all compatible</span>
<span class="sd">  `.NestedMap` (see `.NestedMap.IsCompatible`).</span>
<span class="sd">  I.e., they have the same keys recursively. Furthermore, the corresponding</span>
<span class="sd">  tensors in these `.NestedMap` have the same shape and dtype.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># pylint: enable=line-too-long</span>

<div class="viewcode-block" id="RNNCell.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.RNNCell.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;inputs_arity&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">&#39;number of tensors expected for the inputs.act to FProp.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_input_nodes&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Number of input nodes.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;num_output_nodes&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s1">&#39;Number of output nodes. If num_hidden_nodes is 0, also used as &#39;</span>
        <span class="s1">&#39;cell size.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;reset_cell_state&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="p">(</span><span class="s1">&#39;Set True to support resetting cell state in scenarios where multiple &#39;</span>
         <span class="s1">&#39;inputs are packed into a single training example. The RNN layer &#39;</span>
         <span class="s1">&#39;should provide reset_mask inputs in addition to act and padding if &#39;</span>
         <span class="s1">&#39;this flag is set.&#39;</span><span class="p">))</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;zero_state_init_params&#39;</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">DefaultRNNCellStateInit</span><span class="p">(),</span>
        <span class="s1">&#39;Parameters that define how the initial state values are set &#39;</span>
        <span class="s1">&#39;for each cell. Must be one of the static functions defined in &#39;</span>
        <span class="s1">&#39;py_utils.RNNCellStateInit.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes RnnCell.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span><span class="p">,</span> <span class="p">(</span>
        <span class="s1">&#39;We do not support per step VN in RNN cells.&#39;</span><span class="p">)</span>

<div class="viewcode-block" id="RNNCell._VariableCollections"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.RNNCell._VariableCollections">[docs]</a>  <span class="k">def</span> <span class="nf">_VariableCollections</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">RNN_CELL_WT</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_vars&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">]</span></div>

<div class="viewcode-block" id="RNNCell.zero_state"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.RNNCell.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the initial state given the batch size.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="RNNCell.GetOutput"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.RNNCell.GetOutput">[docs]</a>  <span class="k">def</span> <span class="nf">GetOutput</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the output value given the current state.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="RNNCell.batch_size"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.RNNCell.batch_size">[docs]</a>  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Given the inputs, returns the batch size.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Abstract method&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="RNNCell.FProp"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.RNNCell.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Forward function.</span>

<span class="sd">    The default implementation here assumes the cell forward</span>
<span class="sd">    function is composed of two functions::</span>

<span class="sd">        _Gates(_Mix(theta, state0, inputs), theta, state0, inputs)</span>

<span class="sd">    The result of `_Mix` is stashed in `extras` to facilitate backprop.</span>

<span class="sd">    `_ResetState` is optionally applied if `reset_cell_state` is True. The RNN</span>
<span class="sd">    layer should provide `reset_mask` inputs in addition to other inputs.</span>
<span class="sd">    `reset_mask` inputs are expected to be 0 at timesteps where state0 should be</span>
<span class="sd">    reset to default (zeros) before running `_Mix()` and `_Gates()`, and 1</span>
<span class="sd">    otherwise. This is meant to support use cases like packed inputs, where</span>
<span class="sd">    multiple samples are fed in a single input example sequence, and need to be</span>
<span class="sd">    masked from each other. For example, if the two examples packed together</span>
<span class="sd">    are [&#39;good&#39;, &#39;day&#39;] -&gt; [&#39;guten-tag&#39;] and [&#39;thanks&#39;] -&gt; [&#39;danke&#39;]</span>
<span class="sd">    to produce [&#39;good&#39;, &#39;day&#39;, &#39;thanks&#39;] -&gt; [&#39;guten-tag&#39;, &#39;danke&#39;], the</span>
<span class="sd">    source reset_masks would be [1, 1, 0] and target reset masks would be</span>
<span class="sd">    [1, 0]. These ids are meant to enable masking computations for</span>
<span class="sd">    different examples from each other.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      state0: The previous recurrent state. A `.NestedMap`.</span>
<span class="sd">      inputs: The inputs to the cell. A `.NestedMap`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (state1, extras).</span>
<span class="sd">      - state1: The next recurrent state. A `.NestedMap`.</span>
<span class="sd">      - extras: Intermediate results to faciliate backprop. A `.NestedMap`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">inputs_arity</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">reset_cell_state</span><span class="p">:</span>
      <span class="n">state0_modified</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ResetState</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">DeepCopy</span><span class="p">(),</span> <span class="n">inputs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">state0_modified</span> <span class="o">=</span> <span class="n">state0</span>
    <span class="n">xmw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Mix</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">state0_modified</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
    <span class="n">state1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Gates</span><span class="p">(</span><span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0_modified</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">state1</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span></div>

<div class="viewcode-block" id="RNNCell._ZoneOut"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.RNNCell._ZoneOut">[docs]</a>  <span class="k">def</span> <span class="nf">_ZoneOut</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">prev_v</span><span class="p">,</span>
               <span class="n">cur_v</span><span class="p">,</span>
               <span class="n">padding_v</span><span class="p">,</span>
               <span class="n">zo_prob</span><span class="p">,</span>
               <span class="n">is_eval</span><span class="p">,</span>
               <span class="n">random_uniform</span><span class="p">,</span>
               <span class="n">qt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">qdomain</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply ZoneOut regularlization to cur_v.</span>

<span class="sd">    Implements ZoneOut regularization as described in</span>
<span class="sd">    https://arxiv.org/abs/1606.01305</span>

<span class="sd">    Args:</span>
<span class="sd">      prev_v: A tensor, values from the previous timestep.</span>
<span class="sd">      cur_v: A tensor, values from the current timestep.</span>
<span class="sd">      padding_v: A tensor, the paddings vector for the cur timestep.</span>
<span class="sd">      zo_prob: A float, probability at which to apply ZoneOut regularization.</span>
<span class="sd">      is_eval: A bool, whether or not in eval mode.</span>
<span class="sd">      random_uniform: a tensor of random uniform numbers. This can be None if</span>
<span class="sd">        zo_prob=0.0</span>
<span class="sd">      qt: A string, name of the qtensor for zone out math.</span>
<span class="sd">      qdomain: A string, name of the qdomain for quantized zone out math.</span>

<span class="sd">    Returns:</span>
<span class="sd">      cur_v after ZoneOut regularization has been applied.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">prev_v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">prev_v</span><span class="p">)</span>
    <span class="n">cur_v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">cur_v</span><span class="p">)</span>
    <span class="n">padding_v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">padding_v</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">zo_prob</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="c1"># Special case for when ZoneOut is not enabled.</span>
      <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ApplyPadding</span><span class="p">(</span><span class="n">padding_v</span><span class="p">,</span> <span class="n">cur_v</span><span class="p">,</span> <span class="n">prev_v</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">is_eval</span><span class="p">:</span>
      <span class="c1"># We take expectation in the eval mode.</span>
      <span class="c1">#</span>
      <span class="n">fns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fns</span>
      <span class="c1"># This quantized mixed operation should probably occur as fused kernel to</span>
      <span class="c1"># avoid quantized-math rounding errors. Current accuracy has not been</span>
      <span class="c1"># verified.</span>
      <span class="n">prev_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">QWeight</span><span class="p">(</span><span class="n">zo_prob</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">qdomain</span><span class="p">)</span>
      <span class="n">new_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">QWeight</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">prev_weight</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">qdomain</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">qt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mix_prev</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">prev_v</span><span class="p">),</span> <span class="n">prev_weight</span><span class="p">),</span> <span class="n">prev_v</span><span class="p">)</span>
        <span class="n">mix_curr</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">cur_v</span><span class="p">),</span> <span class="n">new_weight</span><span class="p">),</span> <span class="n">cur_v</span><span class="p">)</span>
        <span class="n">mix</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mix_prev</span><span class="p">,</span> <span class="n">mix_curr</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">mix_prev</span> <span class="o">=</span> <span class="n">fns</span><span class="o">.</span><span class="n">qmultiply</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">QWeight</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">prev_v</span><span class="p">),</span> <span class="n">prev_weight</span><span class="p">),</span> <span class="n">domain</span><span class="o">=</span><span class="n">qdomain</span><span class="p">),</span>
            <span class="n">prev_v</span><span class="p">,</span>
            <span class="n">qt</span><span class="o">=</span><span class="n">qt</span><span class="p">)</span>
        <span class="n">mix_curr</span> <span class="o">=</span> <span class="n">fns</span><span class="o">.</span><span class="n">qmultiply</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">QWeight</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">cur_v</span><span class="p">),</span> <span class="n">new_weight</span><span class="p">),</span> <span class="n">domain</span><span class="o">=</span><span class="n">qdomain</span><span class="p">),</span>
            <span class="n">cur_v</span><span class="p">,</span>
            <span class="n">qt</span><span class="o">=</span><span class="n">qt</span><span class="p">)</span>
        <span class="n">mix</span> <span class="o">=</span> <span class="n">fns</span><span class="o">.</span><span class="n">qadd</span><span class="p">(</span><span class="n">mix_prev</span><span class="p">,</span> <span class="n">mix_curr</span><span class="p">,</span> <span class="n">qt</span><span class="o">=</span><span class="n">qt</span><span class="p">)</span>

      <span class="c1"># If padding_v is 1, it always carries over the previous state.</span>
      <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ApplyPadding</span><span class="p">(</span><span class="n">padding_v</span><span class="p">,</span> <span class="n">mix</span><span class="p">,</span> <span class="n">prev_v</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">assert</span> <span class="n">random_uniform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
      <span class="n">random_uniform</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">random_uniform</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">prev_v</span><span class="p">))</span>
      <span class="n">zo_p</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">random_uniform</span> <span class="o">&lt;</span> <span class="n">zo_prob</span><span class="p">,</span> <span class="n">padding_v</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">zo_p</span> <span class="o">+=</span> <span class="n">padding_v</span>
      <span class="c1"># If padding_v is 1, we always carry over the previous state.</span>
      <span class="n">zo_p</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">zo_p</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
      <span class="n">zo_p</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">zo_p</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ApplyPadding</span><span class="p">(</span><span class="n">zo_p</span><span class="p">,</span> <span class="n">cur_v</span><span class="p">,</span> <span class="n">prev_v</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="LSTMCellSimple"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple">[docs]</a><span class="k">class</span> <span class="nc">LSTMCellSimple</span><span class="p">(</span><span class="n">RNNCell</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Simple LSTM cell.</span>

<span class="sd">  theta:</span>

<span class="sd">  - wm: the parameter weight matrix. All gates combined.</span>
<span class="sd">  - b: the combined bias vector.</span>

<span class="sd">  state:</span>

<span class="sd">  - m: the lstm output. [batch, cell_nodes]</span>
<span class="sd">  - c: the lstm cell state. [batch, cell_nodes]</span>

<span class="sd">  inputs:</span>

<span class="sd">  - act: a list of input activations. [batch, input_nodes]</span>
<span class="sd">  - padding: the padding. [batch, 1].</span>
<span class="sd">  - reset_mask: optional 0/1 float input to support packed input training.</span>
<span class="sd">    Shape [batch, 1]</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="LSTMCellSimple.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;num_hidden_nodes&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Number of projection hidden nodes &#39;</span>
        <span class="s1">&#39;(see https://arxiv.org/abs/1603.08042). &#39;</span>
        <span class="s1">&#39;Set to 0 to disable projection.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;cell_value_cap&#39;</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="s1">&#39;LSTM cell values are capped to be within &#39;</span>
        <span class="s1">&#39; [-cell_value_cap, +cell_value_cap] if the value is not None. &#39;</span>
        <span class="s1">&#39;It can be a scalar, a scalar tensor or None. When set to None, &#39;</span>
        <span class="s1">&#39;no capping is applied.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;forget_gate_bias&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;Bias to apply to the forget gate.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;output_nonlinearity&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
             <span class="s1">&#39;Whether or not to apply tanh non-linearity on lstm output.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;zo_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
             <span class="s1">&#39;If &gt; 0, applies ZoneOut regularization with the given prob.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;enable_lstm_bias&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;Enable the LSTM Cell bias.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;couple_input_forget_gates&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;Whether to couple the input and forget gates. Just like &#39;</span>
        <span class="s1">&#39;tf.contrib.rnn.CoupledInputForgetGateLSTMCell&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;apply_pruning&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Whether to prune the weights while &#39;</span>
             <span class="s1">&#39;training&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;apply_pruning_to_projection&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;Whether to prune the projection matrix while &#39;</span>
             <span class="s1">&#39;training&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;gradient_pruning&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Whether to gradient prune the model&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;bias_init&#39;</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
             <span class="s1">&#39;Initialization parameters for bias&#39;</span><span class="p">)</span>

    <span class="c1"># Non-default quantization behaviour.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">qdomain</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Quantization for the weights&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">qdomain</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;c_state&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Quantization for the c-state.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">qdomain</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;m_state&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Quantization for the m-state.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">qdomain</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;fullyconnected&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
                     <span class="s1">&#39;Quantization for fully connected node.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes LSTMCellSimple.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span>
                      <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span> <span class="ow">is</span> <span class="kc">None</span>

    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">qdomain</span><span class="o">.</span><span class="n">default</span> <span class="ow">is</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_timestep</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

<div class="viewcode-block" id="LSTMCellSimple._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># Define weights.</span>
    <span class="n">wm_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span>
            <span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span>
        <span class="p">],</span>
        <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;wm&#39;</span><span class="p">,</span> <span class="n">wm_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_pruning</span><span class="p">:</span>
      <span class="n">mask_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span><span class="n">wm_pc</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                      <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
                                      <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">threshold_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">([],</span>
                                           <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
                                           <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;mask&#39;</span><span class="p">,</span> <span class="n">mask_pc</span><span class="p">,</span> <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
          <span class="s1">&#39;threshold&#39;</span><span class="p">,</span> <span class="n">threshold_pc</span><span class="p">,</span> <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="c1"># for gradient based pruning</span>
      <span class="c1"># gradient and weight snapshots</span>
      <span class="n">grad_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span><span class="n">wm_pc</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                      <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
                                      <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">gradient_pruning</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;gradient&#39;</span><span class="p">,</span> <span class="n">grad_pc</span><span class="p">,</span> <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
            <span class="s1">&#39;old_weight&#39;</span><span class="p">,</span> <span class="n">grad_pc</span><span class="p">,</span> <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
            <span class="s1">&#39;old_old_weight&#39;</span><span class="p">,</span> <span class="n">grad_pc</span><span class="p">,</span> <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_hidden_nodes</span><span class="p">:</span>
      <span class="n">w_proj</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">],</span>
          <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;w_proj&#39;</span><span class="p">,</span> <span class="n">w_proj</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_pruning_to_projection</span><span class="p">:</span>
        <span class="n">proj_mask_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span><span class="n">w_proj</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                             <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
                                             <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">proj_threshold_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
            <span class="p">[],</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
            <span class="s1">&#39;proj_mask&#39;</span><span class="p">,</span> <span class="n">proj_mask_pc</span><span class="p">,</span> <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
            <span class="s1">&#39;proj_threshold&#39;</span><span class="p">,</span> <span class="n">proj_threshold_pc</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># for gradient based pruning</span>
        <span class="c1"># gradient and weight snapshots</span>
        <span class="n">proj_grad_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span><span class="n">w_proj</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                             <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
                                             <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">gradient_pruning</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;proj_gradient&#39;</span><span class="p">,</span> <span class="n">proj_grad_pc</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;proj_old_weight&#39;</span><span class="p">,</span> <span class="n">proj_grad_pc</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
              <span class="s1">&#39;proj_old_old_weight&#39;</span><span class="p">,</span> <span class="n">proj_grad_pc</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">enable_lstm_bias</span><span class="p">:</span>
      <span class="n">bias_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
          <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">bias_init</span><span class="p">,</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">bias_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_pruning</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">gradient_pruning</span><span class="p">:</span>
        <span class="n">pruning_utils</span><span class="o">.</span><span class="n">AddToPruningCollections</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">threshold</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">gradient</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">old_weight</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">old_old_weight</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">pruning_utils</span><span class="o">.</span><span class="n">AddToPruningCollections</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_hidden_nodes</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_pruning_to_projection</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">gradient_pruning</span><span class="p">:</span>
          <span class="n">pruning_utils</span><span class="o">.</span><span class="n">AddToPruningCollections</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">w_proj</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_mask</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_threshold</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_gradient</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_old_weight</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_old_old_weight</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">pruning_utils</span><span class="o">.</span><span class="n">AddToPruningCollections</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">w_proj</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_mask</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_threshold</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">TrackQTensor</span><span class="p">(</span>
        <span class="s1">&#39;zero_m&#39;</span><span class="p">,</span>
        <span class="s1">&#39;m_output&#39;</span><span class="p">,</span>
        <span class="s1">&#39;m_output_projection&#39;</span><span class="p">,</span>
        <span class="s1">&#39;m_zoneout&#39;</span><span class="p">,</span>
        <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;m_state&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">TrackQTensor</span><span class="p">(</span>
        <span class="s1">&#39;zero_c&#39;</span><span class="p">,</span>
        <span class="s1">&#39;mixed&#39;</span><span class="p">,</span>
        <span class="s1">&#39;c_couple_invert&#39;</span><span class="p">,</span>
        <span class="s1">&#39;c_input_gate&#39;</span><span class="p">,</span>
        <span class="s1">&#39;c_forget_gate&#39;</span><span class="p">,</span>
        <span class="s1">&#39;c_output_gate&#39;</span><span class="p">,</span>
        <span class="s1">&#39;c_zoneout&#39;</span><span class="p">,</span>
        <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;c_state&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">TrackQTensor</span><span class="p">(</span><span class="s1">&#39;add_bias&#39;</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;fullyconnected&#39;</span><span class="p">)</span>

    <span class="c1"># Collect some stats.</span>
    <span class="n">scope</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable_scope</span><span class="p">()</span>
    <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">couple_input_forget_gates</span><span class="p">:</span>
      <span class="n">i_i</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
          <span class="n">value</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
          <span class="n">value</span><span class="o">=</span><span class="n">w</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_i_g&#39;</span><span class="p">,</span> <span class="n">i_g</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_i_i&#39;</span><span class="p">,</span> <span class="n">i_i</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_f_g&#39;</span><span class="p">,</span> <span class="n">f_g</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_o_g&#39;</span><span class="p">,</span> <span class="n">o_g</span><span class="p">)</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">hidden_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_hidden_nodes</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">num_gates</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">3</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">couple_input_forget_gates</span> <span class="k">else</span> <span class="mi">4</span>

<div class="viewcode-block" id="LSTMCellSimple.batch_size"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple.batch_size">[docs]</a>  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="LSTMCellSimple.zero_state"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">zero_m</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="n">zero_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">is_inference</span><span class="p">:</span>
      <span class="n">zero_m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="s1">&#39;zero_m&#39;</span><span class="p">,</span> <span class="n">zero_m</span><span class="p">)</span>
      <span class="n">zero_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="s1">&#39;zero_c&#39;</span><span class="p">,</span> <span class="n">zero_c</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">zero_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">zero_c</span><span class="p">)</span></div>

<div class="viewcode-block" id="LSTMCellSimple._ResetState"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple._ResetState">[docs]</a>  <span class="k">def</span> <span class="nf">_ResetState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">state</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_mask</span> <span class="o">*</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span>
    <span class="n">state</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_mask</span> <span class="o">*</span> <span class="n">state</span><span class="o">.</span><span class="n">c</span>
    <span class="k">return</span> <span class="n">state</span></div>

<div class="viewcode-block" id="LSTMCellSimple.GetOutput"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple.GetOutput">[docs]</a>  <span class="k">def</span> <span class="nf">GetOutput</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span></div>

<div class="viewcode-block" id="LSTMCellSimple._GetBias"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple._GetBias">[docs]</a>  <span class="k">def</span> <span class="nf">_GetBias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Gets the bias vector to add.</span>

<span class="sd">    Includes adjustments like forget_gate_bias. Use this instead of the &#39;b&#39;</span>
<span class="sd">    variable directly as including adjustments in this way allows const-prop</span>
<span class="sd">    to eliminate the adjustments at inference time.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>

<span class="sd">    Returns:</span>
<span class="sd">      The bias vector.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">enable_lstm_bias</span><span class="p">:</span>
      <span class="n">b</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">b</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">forget_gate_bias</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="c1"># Apply the forget gate bias directly to the bias vector.</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">couple_input_forget_gates</span><span class="p">:</span>
        <span class="c1"># Normal 4 gate bias (i_i, i_g, f_g, o_g).</span>
        <span class="n">adjustment</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">forget_gate_bias</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="c1"># 3 gates with coupled input/forget (i_i, f_g, o_g).</span>
        <span class="n">adjustment</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">forget_gate_bias</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
      <span class="n">adjustment</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">adjustment</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">])</span>
      <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="n">adjustment</span>

    <span class="k">return</span> <span class="n">b</span></div>

<div class="viewcode-block" id="LSTMCellSimple._Mix"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple._Mix">[docs]</a>  <span class="k">def</span> <span class="nf">_Mix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">apply_pruning</span><span class="p">:</span>
      <span class="n">wm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">QWeight</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="s1">&#39;masked_weights&#39;</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">wm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">QWeight</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">wm</span><span class="p">)</span>
    <span class="n">concat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span> <span class="o">+</span> <span class="p">[</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Defer quantization until after adding in the bias to support fusing</span>
    <span class="c1"># matmul and bias add during inference.</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">concat</span><span class="p">,</span> <span class="n">wm</span><span class="p">)</span></div>

<div class="viewcode-block" id="LSTMCellSimple._Gates"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple._Gates">[docs]</a>  <span class="k">def</span> <span class="nf">_Gates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the new state.&quot;&quot;&quot;</span>
    <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RetrieveAndSplitGates</span><span class="p">(</span><span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GatesInternal</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span><span class="p">)</span></div>

<div class="viewcode-block" id="LSTMCellSimple._RetrieveAndSplitGates"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple._RetrieveAndSplitGates">[docs]</a>  <span class="k">def</span> <span class="nf">_RetrieveAndSplitGates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">QWeight</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_GetBias</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;fc&#39;</span><span class="p">)</span>
    <span class="n">xmw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fns</span><span class="o">.</span><span class="n">qadd</span><span class="p">(</span><span class="n">xmw</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;add_bias&#39;</span><span class="p">)</span>
    <span class="n">gates</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">xmw</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">couple_input_forget_gates</span><span class="p">:</span>
      <span class="n">gates</span> <span class="o">=</span> <span class="n">gates</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="n">gates</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">gates</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">gates</span></div>

<div class="viewcode-block" id="LSTMCellSimple._GatesInternal"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple._GatesInternal">[docs]</a>  <span class="k">def</span> <span class="nf">_GatesInternal</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">fns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fns</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">couple_input_forget_gates</span><span class="p">:</span>
      <span class="k">assert</span> <span class="n">i_g</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
      <span class="n">forget_gate</span> <span class="o">=</span> <span class="n">fns</span><span class="o">.</span><span class="n">qmultiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">f_g</span><span class="p">),</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;c_input_gate&#39;</span><span class="p">)</span>
      <span class="c1"># Sigmoid / tanh calls are not quantized under the assumption they share</span>
      <span class="c1"># the range with c_input_gate and c_forget_gate.</span>
      <span class="n">input_gate</span> <span class="o">=</span> <span class="n">fns</span><span class="o">.</span><span class="n">qmultiply</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">i_g</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">i_i</span><span class="p">),</span> <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;c_forget_gate&#39;</span><span class="p">)</span>
      <span class="n">new_c</span> <span class="o">=</span> <span class="n">fns</span><span class="o">.</span><span class="n">qadd</span><span class="p">(</span><span class="n">forget_gate</span><span class="p">,</span> <span class="n">input_gate</span><span class="p">,</span> <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;c_output_gate&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">assert</span> <span class="n">i_g</span> <span class="ow">is</span> <span class="kc">None</span>
      <span class="c1"># Sigmoid / tanh calls are not quantized under the assumption they share</span>
      <span class="c1"># the range with c_input_gate and c_forget_gate.</span>
      <span class="n">forget_gate</span> <span class="o">=</span> <span class="n">fns</span><span class="o">.</span><span class="n">qmultiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">f_g</span><span class="p">),</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;c_input_gate&#39;</span><span class="p">)</span>

      <span class="c1"># input_gate = tanh(i_i) - tanh(i_i) * tf.sigmoid(f_g)</span>
      <span class="c1"># equivalent to (but more stable in fixed point):</span>
      <span class="c1"># (1.0 - sigmoid(f_g)) * tanh(i_i)</span>
      <span class="n">tanh_i_i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">i_i</span><span class="p">)</span>
      <span class="n">input_gate</span> <span class="o">=</span> <span class="n">fns</span><span class="o">.</span><span class="n">qsubtract</span><span class="p">(</span>
          <span class="n">tanh_i_i</span><span class="p">,</span>
          <span class="n">fns</span><span class="o">.</span><span class="n">qmultiply</span><span class="p">(</span><span class="n">tanh_i_i</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">f_g</span><span class="p">),</span> <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;c_couple_invert&#39;</span><span class="p">),</span>
          <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;c_forget_gate&#39;</span><span class="p">)</span>

      <span class="n">new_c</span> <span class="o">=</span> <span class="n">fns</span><span class="o">.</span><span class="n">qadd</span><span class="p">(</span><span class="n">forget_gate</span><span class="p">,</span> <span class="n">input_gate</span><span class="p">,</span> <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;c_output_gate&#39;</span><span class="p">)</span>

    <span class="n">new_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ProcessNewC</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">new_c</span><span class="p">)</span>

    <span class="c1"># Clip the cell states to reasonable value.</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">new_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">new_c</span><span class="p">,</span> <span class="o">-</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">output_nonlinearity</span><span class="p">:</span>
      <span class="n">new_m</span> <span class="o">=</span> <span class="n">fns</span><span class="o">.</span><span class="n">qmultiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">o_g</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">new_c</span><span class="p">),</span> <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;m_output&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">new_m</span> <span class="o">=</span> <span class="n">fns</span><span class="o">.</span><span class="n">qmultiply</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">o_g</span><span class="p">),</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;m_output&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_hidden_nodes</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_pruning_to_projection</span><span class="p">:</span>
        <span class="n">w_proj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">QWeight</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">w_proj</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">proj_mask</span><span class="p">,</span> <span class="s1">&#39;masked_projection&#39;</span><span class="p">),</span>
            <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;m_state&#39;</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">w_proj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">QWeight</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">w_proj</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;m_state&#39;</span><span class="p">)</span>

      <span class="n">new_m</span> <span class="o">=</span> <span class="n">fns</span><span class="o">.</span><span class="n">qmatmul</span><span class="p">(</span><span class="n">new_m</span><span class="p">,</span> <span class="n">w_proj</span><span class="p">,</span> <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;m_output_projection&#39;</span><span class="p">)</span>

    <span class="c1"># Apply Zoneout.</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ApplyZoneOut</span><span class="p">(</span><span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">new_m</span><span class="p">)</span></div>

<div class="viewcode-block" id="LSTMCellSimple._ProcessNewC"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple._ProcessNewC">[docs]</a>  <span class="k">def</span> <span class="nf">_ProcessNewC</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">new_c</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">new_c</span></div>

<div class="viewcode-block" id="LSTMCellSimple._ApplyZoneOut"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimple._ApplyZoneOut">[docs]</a>  <span class="k">def</span> <span class="nf">_ApplyZoneOut</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">new_m</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply Zoneout and returns the updated states.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="k">assert</span> <span class="ow">not</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">(),</span> <span class="p">(</span>
          <span class="s1">&#39;LSTMCellSimple does not support zoneout on TPU. Switch to &#39;</span>
          <span class="s1">&#39;LSTMCellSimpleDeterministic instead.&#39;</span><span class="p">)</span>
      <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_c</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
      <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_m</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">new_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZoneOut</span><span class="p">(</span>
        <span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">,</span>
        <span class="n">new_c</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">QRPadding</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">),</span>
        <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">,</span>
        <span class="n">c_random_uniform</span><span class="p">,</span>
        <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;c_zoneout&#39;</span><span class="p">,</span>
        <span class="n">qdomain</span><span class="o">=</span><span class="s1">&#39;c_state&#39;</span><span class="p">)</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZoneOut</span><span class="p">(</span>
        <span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">,</span>
        <span class="n">new_m</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">QRPadding</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">),</span>
        <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">,</span>
        <span class="n">m_random_uniform</span><span class="p">,</span>
        <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;m_zoneout&#39;</span><span class="p">,</span>
        <span class="n">qdomain</span><span class="o">=</span><span class="s1">&#39;m_state&#39;</span><span class="p">)</span>
    <span class="n">new_c</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">new_m</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">new_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">new_c</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="LSTMCellGrouped"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellGrouped">[docs]</a><span class="k">class</span> <span class="nc">LSTMCellGrouped</span><span class="p">(</span><span class="n">RNNCell</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;LSTM cell with groups.</span>

<span class="sd">  Grouping: based on &quot;Factorization tricks for LSTM networks&quot;.</span>
<span class="sd">  https://arxiv.org/abs/1703.10722.</span>

<span class="sd">  Shuffling: adapted from &quot;ShuffleNet: An Extremely Efficient Convolutional</span>
<span class="sd">  Neural Network for Mobile Devices&quot;. https://arxiv.org/abs/1707.01083.</span>

<span class="sd">  theta:</span>

<span class="sd">  - groups: a list of child LSTM cells.</span>

<span class="sd">  state:</span>

<span class="sd">    A `.NestedMap` containing &#39;groups&#39;, a list of `.NestedMap`, each with:</span>

<span class="sd">    - m: the lstm output. [batch, cell_nodes // num_groups]</span>
<span class="sd">    - c: the lstm cell state. [batch, cell_nodes // num_groups]</span>

<span class="sd">  inputs:</span>

<span class="sd">  -  act: a list of input activations. [batch, input_nodes]</span>
<span class="sd">  -  padding: the padding. [batch, 1].</span>
<span class="sd">  -  reset_mask: optional 0/1 float input to support packed input training.</span>
<span class="sd">     Shape [batch, 1]</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="LSTMCellGrouped.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellGrouped.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">child_cell_cls</span><span class="o">=</span><span class="n">LSTMCellSimple</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;child_lstm_tpl&#39;</span><span class="p">,</span> <span class="n">child_cell_cls</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Template of child LSTM cells.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_hidden_nodes&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Number of hidden nodes.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;split_inputs&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;If true, split the inputs into N groups. &#39;</span>
        <span class="s1">&#39;If false, each group gets all inputs.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_groups&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Number of LSTM cell groups.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_shuffle_shards&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
             <span class="s1">&#39;If &gt; 1, number of shards for cross-group shuffling.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes LSTMCellGrouped.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">num_groups</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">num_shuffle_shards</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">%</span> <span class="n">p</span><span class="o">.</span><span class="n">num_groups</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">%</span> <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_shuffle_shards</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_groups</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>

    <span class="n">child_params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_groups</span><span class="p">):</span>
      <span class="n">child_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">child_lstm_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">child_p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;group_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span>
      <span class="k">assert</span> <span class="n">child_p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">==</span> <span class="mi">0</span>
      <span class="k">assert</span> <span class="n">child_p</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">==</span> <span class="mi">0</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">split_inputs</span><span class="p">:</span>
        <span class="n">child_p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">//</span> <span class="n">p</span><span class="o">.</span><span class="n">num_groups</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">child_p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span>
      <span class="n">child_p</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">//</span> <span class="n">p</span><span class="o">.</span><span class="n">num_groups</span>
      <span class="n">child_p</span><span class="o">.</span><span class="n">num_hidden_nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">num_hidden_nodes</span> <span class="o">//</span> <span class="n">p</span><span class="o">.</span><span class="n">num_groups</span>
      <span class="n">child_p</span><span class="o">.</span><span class="n">reset_cell_state</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">reset_cell_state</span>
      <span class="n">child_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">child_p</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChildren</span><span class="p">(</span><span class="s1">&#39;groups&#39;</span><span class="p">,</span> <span class="n">child_params</span><span class="p">)</span>

<div class="viewcode-block" id="LSTMCellGrouped.batch_size"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellGrouped.batch_size">[docs]</a>  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">batch_size</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span></div>

<div class="viewcode-block" id="LSTMCellGrouped.zero_state"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellGrouped.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">groups</span><span class="o">=</span><span class="p">[</span>
        <span class="n">child</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">child_theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">child</span><span class="p">,</span> <span class="n">child_theta</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>
    <span class="p">])</span></div>

  <span class="c1"># TODO(rpang): avoid split and concat between layers with the same number of</span>
  <span class="c1"># groups, if necessary.</span>
<div class="viewcode-block" id="LSTMCellGrouped.GetOutput"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellGrouped.GetOutput">[docs]</a>  <span class="k">def</span> <span class="nf">GetOutput</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># Assuming that GetOutput() is stateless, we can just use the first child.</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">child</span><span class="o">.</span><span class="n">GetOutput</span><span class="p">(</span><span class="n">child_state</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">child</span><span class="p">,</span> <span class="n">child_state</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="n">split_output</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Split each output to num_shuffle_shards.</span>
    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
      <span class="n">split_output</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">SplitRecursively</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_shuffle_shards</span><span class="p">))</span>
    <span class="c1"># Shuffle and concatenate shards.</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ConcatRecursively</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ShuffleShards</span><span class="p">(</span><span class="n">split_output</span><span class="p">))</span></div>

<div class="viewcode-block" id="LSTMCellGrouped.FProp"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellGrouped.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Forward function.</span>

<span class="sd">    Splits state0 and inputs into N groups (N=num_groups), runs child</span>
<span class="sd">    LSTM cells on each group, and concatenates the outputs with optional</span>
<span class="sd">    shuffling between groups.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      state0: The previous recurrent state. A `.NestedMap`.</span>
<span class="sd">      inputs: The inputs to the cell. A `.NestedMap`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (state1, extras).</span>
<span class="sd">      - state1: The next recurrent state. A list.</span>
<span class="sd">      - extras: An empty `.NestedMap`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">split_inputs</span><span class="p">:</span>
      <span class="n">split_inputs_act</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">SplitRecursively</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_groups</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">split_inputs_act</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_groups</span>
    <span class="n">state1</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">groups</span><span class="o">=</span><span class="p">[])</span>
    <span class="k">for</span> <span class="n">child</span><span class="p">,</span> <span class="n">child_theta</span><span class="p">,</span> <span class="n">child_state0</span><span class="p">,</span> <span class="n">child_inputs_act</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span> <span class="n">state0</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span> <span class="n">split_inputs_act</span><span class="p">):</span>
      <span class="n">child_inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
      <span class="n">child_inputs</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">child_inputs_act</span>
      <span class="n">child_state1</span><span class="p">,</span> <span class="n">child_extras</span> <span class="o">=</span> <span class="n">child</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">child_theta</span><span class="p">,</span> <span class="n">child_state0</span><span class="p">,</span>
                                               <span class="n">child_inputs</span><span class="p">)</span>
      <span class="k">assert</span> <span class="ow">not</span> <span class="n">child_extras</span>
      <span class="n">state1</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">child_state1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">state1</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span></div>

<div class="viewcode-block" id="LSTMCellGrouped._ShuffleShards"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellGrouped._ShuffleShards">[docs]</a>  <span class="k">def</span> <span class="nf">_ShuffleShards</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shards</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Shuffles shards across groups.</span>

<span class="sd">    Args:</span>
<span class="sd">      shards: a list of length num_shuffle_shards (S) * num_groups (G). The</span>
<span class="sd">        first S shards belong to group 0, the next S shards belong to group 1,</span>
<span class="sd">        etc.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A shuffled list of shards such that shards from each input group are</span>
<span class="sd">      scattered across output groups.</span>

<span class="sd">      For example, if we have 3 groups, each with 4 shards:</span>

<span class="sd">      | Group 0: 0_0, 0_1, 0_2, 0_3</span>
<span class="sd">      | Group 1: 1_0, 1_1, 1_2, 1_3</span>
<span class="sd">      | Group 2: 2_0, 2_1, 2_2, 2_3</span>

<span class="sd">      The shuffled output will be:</span>

<span class="sd">      | Group 0: 0_0, 1_1, 2_2, 0_3</span>
<span class="sd">      | Group 1: 1_0, 2_1, 0_2, 1_3</span>
<span class="sd">      | Group 2: 2_0, 0_1, 1_2, 2_3</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">shards</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_shuffle_shards</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_groups</span><span class="p">)</span>
    <span class="n">shuffled_shards</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">group_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_groups</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">shuffle_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_shuffle_shards</span><span class="p">):</span>
        <span class="n">shuffled_shards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shards</span><span class="p">[(</span>
            <span class="p">(</span><span class="n">group_i</span> <span class="o">+</span> <span class="n">shuffle_i</span><span class="p">)</span> <span class="o">%</span> <span class="n">p</span><span class="o">.</span><span class="n">num_groups</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_shuffle_shards</span> <span class="o">+</span>
                                      <span class="n">shuffle_i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">shuffled_shards</span></div></div>


<span class="c1"># TODO(yonghui): Merge this cell with the LSTMCellSimple cell.</span>
<div class="viewcode-block" id="LSTMCellSimpleDeterministic"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimpleDeterministic">[docs]</a><span class="k">class</span> <span class="nc">LSTMCellSimpleDeterministic</span><span class="p">(</span><span class="n">LSTMCellSimple</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Same as LSTMCellSimple, except this cell is completely deterministic.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="LSTMCellSimpleDeterministic.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimpleDeterministic.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="LSTMCellSimpleDeterministic._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimpleDeterministic._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lstm_step_counter&#39;</span><span class="p">,</span>
        <span class="n">var_params</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">([],</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                                         <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">vname</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">lstm_step_counter</span><span class="o">.</span><span class="n">name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_prng_seed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
        <span class="n">py_utils</span><span class="o">.</span><span class="n">GenerateSeedFromName</span><span class="p">(</span><span class="n">vname</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">random_seed</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_prng_seed</span> <span class="o">+=</span> <span class="n">p</span><span class="o">.</span><span class="n">random_seed</span></div>

<div class="viewcode-block" id="LSTMCellSimpleDeterministic.zero_state"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimpleDeterministic.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">zero_m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">),</span>
                      <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="n">zero_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span>
                      <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">is_inference</span><span class="p">:</span>
      <span class="n">zero_m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="s1">&#39;zero_m&#39;</span><span class="p">,</span> <span class="n">zero_m</span><span class="p">)</span>
      <span class="n">zero_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">QTensor</span><span class="p">(</span><span class="s1">&#39;zero_c&#39;</span><span class="p">,</span> <span class="n">zero_c</span><span class="p">)</span>

    <span class="c1"># The first random seed changes for different layers and training steps.</span>
    <span class="n">random_seed1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prng_seed</span> <span class="o">+</span> <span class="n">theta</span><span class="o">.</span><span class="n">lstm_step_counter</span>
    <span class="c1"># The second random seed changes for different unroll time steps.</span>
    <span class="n">random_seed2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">random_seeds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">random_seed1</span><span class="p">,</span> <span class="n">random_seed2</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">zero_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">zero_c</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">random_seeds</span><span class="p">)</span></div>

<div class="viewcode-block" id="LSTMCellSimpleDeterministic._ApplyZoneOut"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimpleDeterministic._ApplyZoneOut">[docs]</a>  <span class="k">def</span> <span class="nf">_ApplyZoneOut</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">new_m</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply Zoneout and returns the updated states.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">random_seed1</span> <span class="o">=</span> <span class="n">state0</span><span class="o">.</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">random_seed2</span> <span class="o">=</span> <span class="n">state0</span><span class="o">.</span><span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="c1"># Note(yonghui): It seems that currently TF only supports int64 as the</span>
      <span class="c1"># random seeds, however, TPU will support int32 as the seed.</span>
      <span class="c1"># TODO(yonghui): Fix me for TPU.</span>
      <span class="n">c_seed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">random_seed1</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">random_seed2</span><span class="p">])</span>
      <span class="n">m_seed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">random_seed1</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">random_seed2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
      <span class="k">if</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">():</span>
        <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">stateless_uniform</span><span class="p">(</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">new_c</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">c_seed</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
        <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">stateless_uniform</span><span class="p">(</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">new_m</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">m_seed</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">stateless_uniform</span><span class="p">(</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">new_c</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">c_seed</span><span class="p">)</span>
        <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">stateless_uniform</span><span class="p">(</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">new_m</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">m_seed</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">new_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZoneOut</span><span class="p">(</span>
        <span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">,</span>
        <span class="n">new_c</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">,</span>
        <span class="n">c_random_uniform</span><span class="p">,</span>
        <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;zero_c&#39;</span><span class="p">,</span>
        <span class="n">qdomain</span><span class="o">=</span><span class="s1">&#39;c_state&#39;</span><span class="p">)</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZoneOut</span><span class="p">(</span>
        <span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">,</span>
        <span class="n">new_m</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">,</span>
        <span class="n">m_random_uniform</span><span class="p">,</span>
        <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;zero_m&#39;</span><span class="p">,</span>
        <span class="n">qdomain</span><span class="o">=</span><span class="s1">&#39;m_state&#39;</span><span class="p">)</span>
    <span class="c1"># TODO(yonghui): stop the proliferation of tf.stop_gradient</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">random_seed1</span><span class="p">,</span> <span class="n">random_seed2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>
    <span class="n">new_c</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">new_m</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">r</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">r</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">new_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">new_c</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">)</span></div>

<div class="viewcode-block" id="LSTMCellSimpleDeterministic.PostTrainingStepUpdate"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LSTMCellSimpleDeterministic.PostTrainingStepUpdate">[docs]</a>  <span class="k">def</span> <span class="nf">PostTrainingStepUpdate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update the global_step value.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;step_counter&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">lstm_step_counter</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">lstm_step_counter</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetGlobalStep</span><span class="p">())</span></div></div>


<div class="viewcode-block" id="QuantizedLSTMCell"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QuantizedLSTMCell">[docs]</a><span class="k">class</span> <span class="nc">QuantizedLSTMCell</span><span class="p">(</span><span class="n">RNNCell</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Simplified LSTM cell used for quantized training.</span>

<span class="sd">  There is no forget_gate_bias, no output_nonlinearity and no bias. Right now</span>
<span class="sd">  only clipping is performed.</span>

<span class="sd">  theta:</span>

<span class="sd">  - wm: the parameter weight matrix. All gates combined.</span>
<span class="sd">  - cap: the cell value cap.</span>

<span class="sd">  state:</span>

<span class="sd">  - m: the lstm output. [batch, cell_nodes]</span>
<span class="sd">  - c: the lstm cell state. [batch, cell_nodes]</span>

<span class="sd">  inputs:</span>

<span class="sd">  - act: a list of input activations. [batch, input_nodes]</span>
<span class="sd">  - padding: the padding. [batch, 1].</span>
<span class="sd">  - reset_mask: optional 0/1 float input to support packed input training.</span>
<span class="sd">    [batch, 1]</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="QuantizedLSTMCell.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QuantizedLSTMCell.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;cc_schedule&#39;</span><span class="p">,</span> <span class="n">quant_utils</span><span class="o">.</span><span class="n">LinearClippingCapSchedule</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Clipping cap schedule.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes QuantizedLSTMCell.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;cc_schedule&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">cc_schedule</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_timestep</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

<div class="viewcode-block" id="QuantizedLSTMCell._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QuantizedLSTMCell._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="c1"># Define weights.</span>
    <span class="n">wm_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">],</span>
        <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;wm&#39;</span><span class="p">,</span> <span class="n">wm_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="n">scope</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable_scope</span><span class="p">()</span>
    <span class="c1"># Collect some stats</span>
    <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_i_i&#39;</span><span class="p">,</span> <span class="n">i_i</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_i_g&#39;</span><span class="p">,</span> <span class="n">i_g</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_f_g&#39;</span><span class="p">,</span> <span class="n">f_g</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_o_g&#39;</span><span class="p">,</span> <span class="n">o_g</span><span class="p">)</span></div>

<div class="viewcode-block" id="QuantizedLSTMCell.batch_size"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QuantizedLSTMCell.batch_size">[docs]</a>  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="QuantizedLSTMCell.zero_state"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QuantizedLSTMCell.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">zero_m</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="n">zero_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">zero_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">zero_c</span><span class="p">)</span></div>

<div class="viewcode-block" id="QuantizedLSTMCell.GetOutput"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QuantizedLSTMCell.GetOutput">[docs]</a>  <span class="k">def</span> <span class="nf">GetOutput</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span></div>

<div class="viewcode-block" id="QuantizedLSTMCell._ResetState"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QuantizedLSTMCell._ResetState">[docs]</a>  <span class="k">def</span> <span class="nf">_ResetState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">state</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_mask</span> <span class="o">*</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span>
    <span class="n">state</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_mask</span> <span class="o">*</span> <span class="n">state</span><span class="o">.</span><span class="n">c</span>
    <span class="k">return</span> <span class="n">state</span></div>

<div class="viewcode-block" id="QuantizedLSTMCell._Mix"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QuantizedLSTMCell._Mix">[docs]</a>  <span class="k">def</span> <span class="nf">_Mix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span> <span class="o">+</span> <span class="p">[</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">theta</span><span class="o">.</span><span class="n">wm</span><span class="p">)</span></div>

<div class="viewcode-block" id="QuantizedLSTMCell._Gates"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QuantizedLSTMCell._Gates">[docs]</a>  <span class="k">def</span> <span class="nf">_Gates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the new state.&quot;&quot;&quot;</span>
    <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">xmw</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">new_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">f_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">i_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">i_i</span><span class="p">)</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cc_schedule</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">cc_schedule</span><span class="p">,</span> <span class="n">new_c</span><span class="p">)</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">o_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">new_c</span>

    <span class="c1"># Respect padding.</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="n">state0</span><span class="o">.</span><span class="n">m</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span> <span class="o">+</span> <span class="n">new_m</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span> <span class="o">+</span> <span class="n">new_c</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>

    <span class="n">new_c</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">new_m</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">new_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">new_c</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="LayerNormalizedLSTMCell"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCell">[docs]</a><span class="k">class</span> <span class="nc">LayerNormalizedLSTMCell</span><span class="p">(</span><span class="n">RNNCell</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;DEPRECATED: use LayerNormalizedLSTMCellSimple instead.</span>

<span class="sd">  Simple LSTM cell with layer normalization.</span>

<span class="sd">  Implements normalization scheme as described in</span>
<span class="sd">  https://arxiv.org/pdf/1607.06450.pdf</span>

<span class="sd">  theta:</span>

<span class="sd">  - wm: the parameter weight matrix. All gates combined.</span>
<span class="sd">  - b: the combined bias vector.</span>

<span class="sd">  state:</span>

<span class="sd">  - m: the lstm output. [batch, cell_nodes]</span>
<span class="sd">  - c: the lstm cell state. [batch, cell_nodes]</span>

<span class="sd">  inputs:</span>

<span class="sd">  - act: a list of input activations. [batch, input_nodes]</span>
<span class="sd">  - padding: the padding. [batch, 1].</span>
<span class="sd">  - reset_mask: optional 0/1 float input to support packed input training.</span>
<span class="sd">    Shape [batch, 1]</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="LayerNormalizedLSTMCell.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCell.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;cell_value_cap&#39;</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="s1">&#39;LSTM cell values are capped to be within &#39;</span>
        <span class="s1">&#39; [-cell_value_cap, +cell_value_cap]. This can be a&#39;</span>
        <span class="s1">&#39; scalar or a scalar tensor.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;forget_gate_bias&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;Bias to apply to the forget gate.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;output_nonlinearity&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
             <span class="s1">&#39;Whether or not to apply tanh non-linearity on lstm output.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;zo_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
             <span class="s1">&#39;If &gt; 0, applies ZoneOut regularization with the given prob.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;layer_norm_epsilon&#39;</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="s1">&#39;Tiny value to guard rsqr against.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;cc_schedule&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Clipping cap schedule.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;use_fused_layernorm&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Whether to use fused layernorm.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="nd">@tf_deprecation</span><span class="o">.</span><span class="n">deprecated</span><span class="p">(</span>
      <span class="n">date</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
      <span class="n">instructions</span><span class="o">=</span><span class="s1">&#39;New models should use LayerNormalizedLSTMCellSimple.&#39;</span><span class="p">)</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes LayerNormalizedLSTMCell.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cell value cap must of type int or float!&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">cc_schedule</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;cc_schedule&#39;</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">cc_schedule</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_timestep</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateAqtWeight</span><span class="p">(</span>
        <span class="s1">&#39;rnn_aqt&#39;</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span>
            <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">+</span> <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">,</span>
            <span class="mi">4</span> <span class="o">*</span> <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>
        <span class="p">],</span>
        <span class="n">feature_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<div class="viewcode-block" id="LayerNormalizedLSTMCell._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCell._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="c1"># Define weights.</span>
    <span class="n">wm_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">],</span>
        <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;wm&#39;</span><span class="p">,</span> <span class="n">wm_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>
    <span class="c1"># This bias variable actually packs the initial lstm bias variables as</span>
    <span class="c1"># well as various layer norm scale and bias variables. We pack multiple</span>
    <span class="c1"># variables into one so that we can still unroll this lstm using the FRNN</span>
    <span class="c1"># layer defined in layers.py.</span>
    <span class="n">bias_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">],</span>
        <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">bias_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="c1"># Collect some stats</span>
    <span class="n">scope</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable_scope</span><span class="p">()</span>
    <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_i_i&#39;</span><span class="p">,</span> <span class="n">i_i</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_i_g&#39;</span><span class="p">,</span> <span class="n">i_g</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_f_g&#39;</span><span class="p">,</span> <span class="n">f_g</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_o_g&#39;</span><span class="p">,</span> <span class="n">o_g</span><span class="p">)</span></div>
    <span class="c1"># TODO(yonghui): Add more summaries here.</span>

<div class="viewcode-block" id="LayerNormalizedLSTMCell.batch_size"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCell.batch_size">[docs]</a>  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">hidden_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>

<div class="viewcode-block" id="LayerNormalizedLSTMCell.zero_state"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCell.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
        <span class="n">m</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">],</span>
                                    <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                    <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                    <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">),</span>
        <span class="n">c</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">],</span>
                                    <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                    <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                    <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">))</span></div>

<div class="viewcode-block" id="LayerNormalizedLSTMCell.GetOutput"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCell.GetOutput">[docs]</a>  <span class="k">def</span> <span class="nf">GetOutput</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span></div>

<div class="viewcode-block" id="LayerNormalizedLSTMCell._ResetState"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCell._ResetState">[docs]</a>  <span class="k">def</span> <span class="nf">_ResetState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">state</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_mask</span> <span class="o">*</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span>
    <span class="n">state</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_mask</span> <span class="o">*</span> <span class="n">state</span><span class="o">.</span><span class="n">c</span>
    <span class="k">return</span> <span class="n">state</span></div>

<div class="viewcode-block" id="LayerNormalizedLSTMCell._Mix"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCell._Mix">[docs]</a>  <span class="k">def</span> <span class="nf">_Mix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Input activations must be of list type!&#39;</span><span class="p">)</span>
    <span class="c1"># TODO(b/172580007): Support weight quantization for RNN. Right now we do</span>
    <span class="c1"># not support checkpointing vars for Recurrent cell, and setting AqtQdomain</span>
    <span class="c1"># for LayerNormalizedLSTM cell might run into errors.</span>
    <span class="n">wm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ToAqtWeight</span><span class="p">(</span><span class="s1">&#39;rnn_aqt&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">feature_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span> <span class="o">+</span> <span class="p">[</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">wm</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">FromAqtWeight</span><span class="p">(</span><span class="s1">&#39;rnn_aqt&#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">feature_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayerNormalizedLSTMCell._Gates"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCell._Gates">[docs]</a>  <span class="k">def</span> <span class="nf">_Gates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the new state.&quot;&quot;&quot;</span>
    <span class="c1"># Unpack the variables (weight and bias) into individual variables.</span>
    <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">def</span> <span class="nf">BiasSlice</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_dims</span><span class="p">,</span> <span class="n">start_ind</span><span class="p">):</span>
      <span class="n">s</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_dims</span><span class="p">):</span>
        <span class="n">s</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="n">start_ind</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">dim</span><span class="p">:</span><span class="n">start_ind</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dim</span><span class="p">])</span>
      <span class="n">start_ind</span> <span class="o">+=</span> <span class="n">dim</span> <span class="o">*</span> <span class="n">num_dims</span>
      <span class="k">return</span> <span class="n">s</span><span class="p">,</span> <span class="n">start_ind</span>

    <span class="c1"># Unpack the bias variable.</span>
    <span class="n">slice_start</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">bias_lstm</span><span class="p">,</span> <span class="n">slice_start</span> <span class="o">=</span> <span class="n">BiasSlice</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">slice_start</span><span class="p">)</span>
    <span class="n">ln_scale</span><span class="p">,</span> <span class="n">slice_start</span> <span class="o">=</span> <span class="n">BiasSlice</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">slice_start</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">slice_start</span> <span class="o">==</span> <span class="mi">8</span> <span class="o">*</span> <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>

    <span class="k">def</span> <span class="nf">_LayerNorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">last_dim</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Normalize the last dimension.&quot;&quot;&quot;</span>
      <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">use_fused_layernorm</span><span class="p">:</span>
        <span class="n">counts</span><span class="p">,</span> <span class="n">means_ss</span><span class="p">,</span> <span class="n">variance_ss</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sufficient_statistics</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="n">last_dim</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">normalize_moments</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">means_ss</span><span class="p">,</span> <span class="n">variance_ss</span><span class="p">,</span>
                                                 <span class="kc">None</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="n">last_dim</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">variance</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="n">last_dim</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">params</span><span class="o">.</span><span class="n">layer_norm_epsilon</span><span class="p">)</span>

    <span class="n">state_split</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">xmw</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
      <span class="n">state_split</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">_LayerNorm</span><span class="p">(</span><span class="n">state_split</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
          <span class="n">ln_scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">bias_lstm</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span> <span class="o">=</span> <span class="n">state_split</span>

    <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">forget_gate_bias</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="n">f_g</span> <span class="o">+=</span> <span class="n">params</span><span class="o">.</span><span class="n">forget_gate_bias</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">f_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">i_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">i_i</span><span class="p">)</span>

    <span class="c1"># Clip the cell states to reasonable value.</span>
    <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">cc_schedule</span><span class="p">:</span>
      <span class="n">cap</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cc_schedule</span><span class="o">.</span><span class="n">GetState</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">cc_schedule</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">cap</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">cell_value_cap</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">new_c</span><span class="p">,</span> <span class="o">-</span><span class="n">cap</span><span class="p">,</span> <span class="n">cap</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span><span class="p">:</span>
      <span class="n">new_m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">o_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">new_c</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">new_m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">o_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">new_c</span>

    <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">zo_prob</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_c</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
      <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_m</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">new_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZoneOut</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">zo_prob</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">,</span> <span class="n">c_random_uniform</span><span class="p">)</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZoneOut</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">new_m</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">zo_prob</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">,</span> <span class="n">m_random_uniform</span><span class="p">)</span>
    <span class="n">new_c</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">new_m</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">new_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">new_c</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="LayerNormalizedLSTMCellSimple"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellSimple">[docs]</a><span class="k">class</span> <span class="nc">LayerNormalizedLSTMCellSimple</span><span class="p">(</span><span class="n">LSTMCellSimple</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;An implementation of layer normalized LSTM based on LSTMCellSimple.</span>

<span class="sd">  Implements normalization scheme as described in</span>
<span class="sd">  https://arxiv.org/pdf/1607.06450.pdf</span>

<span class="sd">  theta:</span>

<span class="sd">  - wm: the parameter weight matrix. All gates combined.</span>
<span class="sd">  - b: the combined bias vector.</span>

<span class="sd">  state:</span>

<span class="sd">  - m: the lstm output. [batch, cell_nodes]</span>
<span class="sd">  - c: the lstm cell state. [batch, cell_nodes]</span>

<span class="sd">  inputs:</span>

<span class="sd">  - act: a list of input activations. [batch, input_nodes]</span>
<span class="sd">  - padding: the padding. [batch, 1].</span>
<span class="sd">  - reset_mask: optional 0/1 float input to support packed input training.</span>
<span class="sd">    Shape [batch, 1]</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="LayerNormalizedLSTMCellSimple.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellSimple.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;layer_norm_epsilon&#39;</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="s1">&#39;Tiny value to guard rsqr against.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="LayerNormalizedLSTMCellSimple._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellSimple._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes LayerNormalizedLSTMCellSimple.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="n">add_biases</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;add_bias_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">TrackQTensor</span><span class="p">(</span><span class="o">*</span><span class="n">add_biases</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;fullyconnected&#39;</span><span class="p">)</span>

    <span class="n">ln_scale_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
        <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;ln_scale&#39;</span><span class="p">,</span> <span class="n">ln_scale_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayerNormalizedLSTMCellSimple._Gates"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellSimple._Gates">[docs]</a>  <span class="k">def</span> <span class="nf">_Gates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the new state.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_LayerNorm</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Applies layer normalization on the last dimension of &#39;x&#39;.</span>

<span class="sd">      Args:</span>
<span class="sd">        x: activation tensor, where the last dimension represents channels.</span>

<span class="sd">      Returns:</span>
<span class="sd">        Layer normalized &#39;x&#39;, with the same shape as the input.</span>
<span class="sd">      &quot;&quot;&quot;</span>
      <span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">variance</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">layer_norm_epsilon</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">QWeight</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_GetBias</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;fc&#39;</span><span class="p">)</span>

    <span class="n">bs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ln_scales</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
        <span class="n">theta</span><span class="o">.</span><span class="n">ln_scale</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">gates</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">xmw</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span><span class="p">):</span>
      <span class="c1"># i_g is None when p.couple_input_forget_gates is True.</span>
      <span class="k">if</span> <span class="n">gates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">_LayerNorm</span><span class="p">(</span><span class="n">gates</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">ln_scales</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">gates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fns</span><span class="o">.</span><span class="n">qadd</span><span class="p">(</span><span class="n">gates</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">bs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">qt</span><span class="o">=</span><span class="s1">&#39;add_bias_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">couple_input_forget_gates</span><span class="p">:</span>
      <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span> <span class="o">=</span> <span class="n">gates</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span> <span class="o">=</span> <span class="n">gates</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="n">gates</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">gates</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GatesInternal</span><span class="p">(</span>
        <span class="n">theta</span><span class="o">=</span><span class="n">theta</span><span class="p">,</span>
        <span class="n">state0</span><span class="o">=</span><span class="n">state0</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
        <span class="n">i_i</span><span class="o">=</span><span class="n">i_i</span><span class="p">,</span>
        <span class="n">i_g</span><span class="o">=</span><span class="n">i_g</span><span class="p">,</span>
        <span class="n">f_g</span><span class="o">=</span><span class="n">f_g</span><span class="p">,</span>
        <span class="n">o_g</span><span class="o">=</span><span class="n">o_g</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="WeightNormalizedLSTMCellSimple"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.WeightNormalizedLSTMCellSimple">[docs]</a><span class="k">class</span> <span class="nc">WeightNormalizedLSTMCellSimple</span><span class="p">(</span><span class="n">LSTMCellSimple</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;An implementation of weight normalized LSTM based on LSTMCellSimple.</span>

<span class="sd">  Implements normalization scheme as described in</span>
<span class="sd">  https://arxiv.org/pdf/1602.07868.pdf</span>

<span class="sd">  theta:</span>

<span class="sd">  - wm: the parameter weight matrix. All gates combined.</span>
<span class="sd">  - b: the combined bias vector.</span>

<span class="sd">  state:</span>

<span class="sd">  - m: the lstm output. [batch, cell_nodes]</span>
<span class="sd">  - c: the lstm cell state. [batch, cell_nodes]</span>

<span class="sd">  inputs:</span>

<span class="sd">  - act: a list of input activations. [batch, input_nodes]</span>
<span class="sd">  - padding: the padding. [batch, 1].</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="WeightNormalizedLSTMCellSimple.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.WeightNormalizedLSTMCellSimple.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;weight_norm_epsilon&#39;</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="s1">&#39;Tiny value to guard rsqr against.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="WeightNormalizedLSTMCellSimple._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.WeightNormalizedLSTMCellSimple._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes LayerNormalizedLSTMCellSimple.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="n">add_biases</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;add_bias_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">TrackQTensor</span><span class="p">(</span><span class="o">*</span><span class="n">add_biases</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="s1">&#39;fullyconnected&#39;</span><span class="p">)</span>

    <span class="n">wn_scale_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
        <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">()</span> <span class="o">+</span>
        <span class="p">[</span><span class="n">py_utils</span><span class="o">.</span><span class="n">SKIP_LP_REGULARIZATION</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;wn_scale&#39;</span><span class="p">,</span> <span class="n">wn_scale_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span></div>

<div class="viewcode-block" id="WeightNormalizedLSTMCellSimple._Gates"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.WeightNormalizedLSTMCellSimple._Gates">[docs]</a>  <span class="k">def</span> <span class="nf">_Gates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes the new state.&quot;&quot;&quot;</span>

    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="c1"># Divide wm by it&#39;s L2 norm.</span>
    <span class="n">wm_sq_sum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">wm</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">normed_gates</span> <span class="o">=</span> <span class="n">xmw</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">wm_sq_sum</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">weight_norm_epsilon</span><span class="p">)</span>
    <span class="n">normed_gates</span> <span class="o">=</span> <span class="n">normed_gates</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">wn_scale</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_Gates</span><span class="p">(</span><span class="n">normed_gates</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="NormalizedLSTMCellSimple"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.NormalizedLSTMCellSimple">[docs]</a><span class="k">class</span> <span class="nc">NormalizedLSTMCellSimple</span><span class="p">(</span><span class="n">LSTMCellSimple</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;LSTM Cell that allows customzied normalization.</span>

<span class="sd">  theta:</span>

<span class="sd">  - wm: the parameter weight matrix. All gates combined.</span>
<span class="sd">  - b: the combined bias vector.</span>

<span class="sd">  state:</span>

<span class="sd">  - m: the lstm output. [batch, cell_nodes]</span>
<span class="sd">  - c: the lstm cell state. [batch, cell_nodes]</span>

<span class="sd">  inputs:</span>

<span class="sd">  - act: a list of input activations. [batch, input_nodes]</span>
<span class="sd">  - padding: the padding. [batch, 1].</span>
<span class="sd">  - reset_mask: optional 0/1 float input to support packed input training.</span>
<span class="sd">    Shape [batch, 1]</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="NormalizedLSTMCellSimple.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.NormalizedLSTMCellSimple.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;norm_layer_tpl&#39;</span><span class="p">,</span>
             <span class="n">layers</span><span class="o">.</span><span class="n">LayerNorm</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">),</span>
             <span class="s1">&#39;The normalization layer param&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># p.enable_lstm_bias and p.forget_gate_bias are not used in this cell.</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">forget_gate_bias</span> <span class="o">==</span> <span class="mf">0.0</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">enable_lstm_bias</span>
    <span class="n">gates_name</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;i_i&#39;</span><span class="p">,</span> <span class="s1">&#39;i_g&#39;</span><span class="p">,</span> <span class="s1">&#39;f_g&#39;</span><span class="p">,</span> <span class="s1">&#39;o_g&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">gate</span> <span class="ow">in</span> <span class="n">gates_name</span><span class="p">:</span>
      <span class="n">norm_layer_p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">norm_layer_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;norm_&#39;</span> <span class="o">+</span> <span class="n">gate</span><span class="p">,</span> <span class="n">norm_layer_p</span><span class="p">)</span>

<div class="viewcode-block" id="NormalizedLSTMCellSimple._Gates"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.NormalizedLSTMCellSimple._Gates">[docs]</a>  <span class="k">def</span> <span class="nf">_Gates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># Retrieve i_i, i_g, f_g, o_g</span>
    <span class="n">gates</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">xmw</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">couple_input_forget_gates</span><span class="p">:</span>
      <span class="n">gates</span> <span class="o">=</span> <span class="n">gates</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="kc">None</span><span class="p">,</span> <span class="n">gates</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">gates</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">gates_name</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;i_i&#39;</span><span class="p">,</span> <span class="s1">&#39;i_g&#39;</span><span class="p">,</span> <span class="s1">&#39;f_g&#39;</span><span class="p">,</span> <span class="s1">&#39;o_g&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">gate_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gates_name</span><span class="p">):</span>
      <span class="n">norm_layer_name</span> <span class="o">=</span> <span class="s1">&#39;norm_&#39;</span> <span class="o">+</span> <span class="n">gate_name</span>
      <span class="k">if</span> <span class="n">gates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">norm_layer_name</span><span class="p">)</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">norm_layer_name</span><span class="p">),</span> <span class="n">gates</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span> <span class="o">=</span> <span class="n">gates</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GatesInternal</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="LayerNormalizedLSTMCellLean"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellLean">[docs]</a><span class="k">class</span> <span class="nc">LayerNormalizedLSTMCellLean</span><span class="p">(</span><span class="n">RNNCell</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A very lean layer normalized LSTM cell.</span>

<span class="sd">  This version is around 20% faster on TPU than LayerNormalizedLSTMCellSimple as</span>
<span class="sd">  it avoids certain reshape ops which are not free on TPU.</span>

<span class="sd">  Note, this version doesn&#39;t support all the options as implemented in</span>
<span class="sd">  LayerNormalizedLSTMCellSimple, such as quantization, zoneout regularization</span>
<span class="sd">  and etc.</span>

<span class="sd">  For the overlapping options, an incomplete list of differences from</span>
<span class="sd">  LayerNormalizedLSTMCellSimple include:</span>
<span class="sd">  - c_state is layer-normalized for computing new_m (if enable_ln_on_c=True)</span>
<span class="sd">  - ln_scale has a fixed offset of 1.</span>

<span class="sd">  Please use the other version if you even need those options.</span>

<span class="sd">  state:</span>

<span class="sd">  - m: the lstm output. [batch, cell_nodes]</span>
<span class="sd">  - c: the lstm cell state. [batch, cell_nodes]</span>

<span class="sd">  inputs:</span>

<span class="sd">  - act: a list of input activations. [batch, input_nodes]</span>
<span class="sd">  - padding: the padding. [batch, 1].</span>
<span class="sd">  - reset_mask: optional 0/1 float input to support packed input training.</span>
<span class="sd">    Shape [batch, 1]</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="LayerNormalizedLSTMCellLean.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellLean.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;num_hidden_nodes&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Number of projection hidden nodes &#39;</span>
        <span class="s1">&#39;(see https://arxiv.org/abs/1603.08042). &#39;</span>
        <span class="s1">&#39;Set to 0 to disable projection.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;layer_norm_epsilon&#39;</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="s1">&#39;Tiny value to guard rsqrt against.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;enable_ln_on_c&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;Whether to apply layer normalization on state.c. &#39;</span>
        <span class="s1">&#39;If false, LayerNormalizedLSTMCellLean will behave exactly as &#39;</span>
        <span class="s1">&#39;LayerNormalizedLSTMCellSimple.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;cell_value_cap&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;LSTM cell values are capped to be within &#39;</span>
        <span class="s1">&#39; [-cell_value_cap, +cell_value_cap] if the value is not None. &#39;</span>
        <span class="s1">&#39;It can be a scalar, a scalar tensor or None. When set to None, &#39;</span>
        <span class="s1">&#39;no capping is applied.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;enable_lstm_bias&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Enable the LSTM Cell bias.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;bias_init&#39;</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
             <span class="s1">&#39;Initialization parameters for bias&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;use_ln_bias&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;If to include a bias term for layer norm.&#39;</span><span class="p">)</span>

    <span class="c1"># TODO(yonghui): Get rid of the following two params.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;output_nonlinearity&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
             <span class="s1">&#39;Whether or not to apply tanh non-linearity on lstm output.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;zo_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
             <span class="s1">&#39;If &gt; 0, applies ZoneOut regularization with the given prob.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes LayerNormalizedLSTMCellLean.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">output_nonlinearity</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span> <span class="o">==</span> <span class="mf">0.0</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span>
                                                       <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s1">&#39;p.cell_value_cap should be a int/float if not None, but got </span><span class="si">{}</span><span class="s1">&#39;</span>
          <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">))</span>

<div class="viewcode-block" id="LayerNormalizedLSTMCellLean._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellLean._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># Define weights.</span>
    <span class="n">wm_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
        <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;wm&#39;</span><span class="p">,</span> <span class="n">wm_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_hidden_nodes</span><span class="p">:</span>
      <span class="n">w_proj</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">],</span>
          <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;w_proj&#39;</span><span class="p">,</span> <span class="n">w_proj</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">enable_lstm_bias</span><span class="p">:</span>
      <span class="n">bias_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
          <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">bias_init</span><span class="p">,</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">bias_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="n">pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
        <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
    <span class="n">ln_gates</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;i_g&#39;</span><span class="p">,</span> <span class="s1">&#39;i_i&#39;</span><span class="p">,</span> <span class="s1">&#39;f_g&#39;</span><span class="p">,</span> <span class="s1">&#39;o_g&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">enable_ln_on_c</span><span class="p">:</span>
      <span class="n">ln_gates</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ln_name</span> <span class="ow">in</span> <span class="n">ln_gates</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;ln_scale_&#39;</span> <span class="o">+</span> <span class="n">ln_name</span><span class="p">,</span> <span class="n">pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_ln_bias</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;bias_&#39;</span> <span class="o">+</span> <span class="n">ln_name</span><span class="p">,</span> <span class="n">pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">hidden_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_hidden_nodes</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>

<div class="viewcode-block" id="LayerNormalizedLSTMCellLean.batch_size"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellLean.batch_size">[docs]</a>  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="LayerNormalizedLSTMCellLean.zero_state"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellLean.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">zero_m</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="n">zero_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">zero_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">zero_c</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayerNormalizedLSTMCellLean._ResetState"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellLean._ResetState">[docs]</a>  <span class="k">def</span> <span class="nf">_ResetState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">state</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_mask</span> <span class="o">*</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span>
    <span class="n">state</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_mask</span> <span class="o">*</span> <span class="n">state</span><span class="o">.</span><span class="n">c</span>
    <span class="k">return</span> <span class="n">state</span></div>

<div class="viewcode-block" id="LayerNormalizedLSTMCellLean.GetOutput"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellLean.GetOutput">[docs]</a>  <span class="k">def</span> <span class="nf">GetOutput</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span></div>

<div class="viewcode-block" id="LayerNormalizedLSTMCellLean._Mix"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellLean._Mix">[docs]</a>  <span class="k">def</span> <span class="nf">_Mix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="n">mixed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span> <span class="o">+</span> <span class="p">[</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">theta</span><span class="o">.</span><span class="n">wm</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mixed</span></div>

<div class="viewcode-block" id="LayerNormalizedLSTMCellLean._LayerNormGate"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellLean._LayerNormGate">[docs]</a>  <span class="k">def</span> <span class="nf">_LayerNormGate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">gate_name</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies layer normalization on the last dimension of &#39;x&#39;.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: a NestedMap of layer params.</span>
<span class="sd">      gate_name: the name of the gate, e.g., &#39;i_i&#39;, &#39;f_g&#39;, &#39;c&#39;, etc.</span>
<span class="sd">      x: activation tensor, where the last dimension represents channels.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Layer normalized &#39;x&#39;, with the same shape as the input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">gate_name</span> <span class="o">==</span> <span class="s1">&#39;c&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">enable_ln_on_c</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">x</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">centered</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">mean</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">centered</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">normed</span> <span class="o">=</span> <span class="n">centered</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">layer_norm_epsilon</span><span class="p">)</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="s1">&#39;ln_scale_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">gate_name</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.0</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_ln_bias</span><span class="p">:</span>
      <span class="n">bias</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="s1">&#39;bias_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">gate_name</span><span class="p">]</span>
      <span class="k">return</span> <span class="n">normed</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">bias</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">normed</span> <span class="o">*</span> <span class="n">scale</span></div>

<div class="viewcode-block" id="LayerNormalizedLSTMCellLean._Gates"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.LayerNormalizedLSTMCellLean._Gates">[docs]</a>  <span class="k">def</span> <span class="nf">_Gates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the new state.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">xmw</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">i_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_LayerNormGate</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;i_i&#39;</span><span class="p">,</span> <span class="n">i_i</span><span class="p">)</span>
    <span class="n">i_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_LayerNormGate</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;i_g&#39;</span><span class="p">,</span> <span class="n">i_g</span><span class="p">)</span>
    <span class="n">f_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_LayerNormGate</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;f_g&#39;</span><span class="p">,</span> <span class="n">f_g</span><span class="p">)</span>
    <span class="n">o_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_LayerNormGate</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;o_g&#39;</span><span class="p">,</span> <span class="n">o_g</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">enable_lstm_bias</span><span class="p">:</span>
      <span class="c1"># LayerNormalizedLSTMCellLean applies biases after LN.</span>
      <span class="n">biases</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">b</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
      <span class="n">i_i</span> <span class="o">+=</span> <span class="n">biases</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">i_g</span> <span class="o">+=</span> <span class="n">biases</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
      <span class="n">f_g</span> <span class="o">+=</span> <span class="n">biases</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
      <span class="n">o_g</span> <span class="o">+=</span> <span class="n">biases</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">f_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">i_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">i_i</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">new_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">new_c</span><span class="p">,</span> <span class="o">-</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">)</span>
    <span class="c1"># new_c_normed is only used for computing &#39;new_m&#39;. We use the un-normalized</span>
    <span class="c1"># new_cc as cell state to keep the residual property of lstm cell.</span>
    <span class="n">new_c_normed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_LayerNormGate</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="n">new_c</span><span class="p">)</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">o_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">new_c_normed</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_hidden_nodes</span><span class="p">:</span>
      <span class="n">new_m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">new_m</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">w_proj</span><span class="p">)</span>

    <span class="c1"># Now take care of padding.</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ApplyPadding</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">new_m</span><span class="p">,</span> <span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">)</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ApplyPadding</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">new_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">new_c</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="DoubleProjectionLSTMCell"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.DoubleProjectionLSTMCell">[docs]</a><span class="k">class</span> <span class="nc">DoubleProjectionLSTMCell</span><span class="p">(</span><span class="n">RNNCell</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A layer normalized LSTM cell that support input and output projections.</span>

<span class="sd">  Note, this version doesn&#39;t support all the options as implemented in</span>
<span class="sd">  LayerNormalizedLSTMCellSimple, like quantization, zoneout regularization,</span>
<span class="sd">  etc. Please use the other version if you need those options and do not need</span>
<span class="sd">  input projection.</span>

<span class="sd">  It also uses separate variables for weight matrices between gates</span>
<span class="sd">  (&#39;wm_{i_i, i_g, f_g, o_g}&#39;) instead of a single variable (&#39;wm&#39;). This allows</span>
<span class="sd">  the initialization to use the default GeoMeanXavier().</span>

<span class="sd">  state:</span>

<span class="sd">  - m: the lstm output. [batch, cell_nodes]</span>
<span class="sd">  - c: the lstm cell state. [batch, cell_nodes]</span>

<span class="sd">  inputs:</span>

<span class="sd">  - act: a list of input activations. [batch, input_nodes]</span>
<span class="sd">  - padding: the padding. [batch, 1].</span>
<span class="sd">  - reset_mask: optional 0/1 float input to support packed input training.</span>
<span class="sd">    Shape [batch, 1]</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="DoubleProjectionLSTMCell.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.DoubleProjectionLSTMCell.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;num_input_hidden_nodes&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s1">&#39;Project all inputs, include m, to a hidden vector this size before &#39;</span>
        <span class="s1">&#39;projecting to num_gates * |c|. Must be &gt; 0.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;num_hidden_nodes&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Number of projection hidden nodes &#39;</span>
        <span class="s1">&#39;(see https://arxiv.org/abs/1603.08042). &#39;</span>
        <span class="s1">&#39;Set to 0 to disable projection.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;layer_norm_epsilon&#39;</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="s1">&#39;Tiny value to guard rsqrt against.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;enable_ln_on_c&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
             <span class="s1">&#39;Whether to apply layer normalization on state.c.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">GeoMeanXavier</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="DoubleProjectionLSTMCell._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.DoubleProjectionLSTMCell._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">def</span> <span class="nf">_WeightInit</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
          <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
        <span class="s1">&#39;w_input_proj&#39;</span><span class="p">,</span>
        <span class="n">_WeightInit</span><span class="p">(</span>
            <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_input_hidden_nodes</span><span class="p">]),</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;w_output_proj&#39;</span><span class="p">,</span>
                        <span class="n">_WeightInit</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">]),</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">gate_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">gates</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
          <span class="s1">&#39;wm_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">gate_name</span><span class="p">,</span>
          <span class="n">_WeightInit</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">num_input_hidden_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="n">pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
        <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
    <span class="n">ln_gates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gates</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">enable_ln_on_c</span><span class="p">:</span>
      <span class="n">ln_gates</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ln_name</span> <span class="ow">in</span> <span class="n">ln_gates</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;ln_scale_&#39;</span> <span class="o">+</span> <span class="n">ln_name</span><span class="p">,</span> <span class="n">pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;bias_&#39;</span> <span class="o">+</span> <span class="n">ln_name</span><span class="p">,</span> <span class="n">pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">hidden_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_hidden_nodes</span>

<div class="viewcode-block" id="DoubleProjectionLSTMCell.batch_size"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.DoubleProjectionLSTMCell.batch_size">[docs]</a>  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">gates</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="s1">&#39;i_g&#39;</span><span class="p">,</span> <span class="s1">&#39;i_i&#39;</span><span class="p">,</span> <span class="s1">&#39;f_g&#39;</span><span class="p">,</span> <span class="s1">&#39;o_g&#39;</span><span class="p">]</span>

<div class="viewcode-block" id="DoubleProjectionLSTMCell.zero_state"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.DoubleProjectionLSTMCell.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">zero_m</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="n">zero_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">zero_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">zero_c</span><span class="p">)</span></div>

<div class="viewcode-block" id="DoubleProjectionLSTMCell._ResetState"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.DoubleProjectionLSTMCell._ResetState">[docs]</a>  <span class="k">def</span> <span class="nf">_ResetState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">state</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_mask</span> <span class="o">*</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span>
    <span class="n">state</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_mask</span> <span class="o">*</span> <span class="n">state</span><span class="o">.</span><span class="n">c</span>
    <span class="k">return</span> <span class="n">state</span></div>

<div class="viewcode-block" id="DoubleProjectionLSTMCell.GetOutput"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.DoubleProjectionLSTMCell.GetOutput">[docs]</a>  <span class="k">def</span> <span class="nf">GetOutput</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span></div>

<div class="viewcode-block" id="DoubleProjectionLSTMCell._ProcessInputProj"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.DoubleProjectionLSTMCell._ProcessInputProj">[docs]</a>  <span class="k">def</span> <span class="nf">_ProcessInputProj</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">input_proj</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">input_proj</span></div>

<div class="viewcode-block" id="DoubleProjectionLSTMCell._Mix"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.DoubleProjectionLSTMCell._Mix">[docs]</a>  <span class="k">def</span> <span class="nf">_Mix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="n">concat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span> <span class="o">+</span> <span class="p">[</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">input_proj</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">concat</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">w_input_proj</span><span class="p">)</span>
    <span class="n">input_proj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ProcessInputProj</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">input_proj</span><span class="p">)</span>
    <span class="n">gate_map</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">gate_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">gates</span><span class="p">:</span>
      <span class="n">g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">input_proj</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;wm_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">gate_name</span><span class="p">))</span>
      <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_LayerNormGate</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">gate_name</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>
      <span class="n">gate_map</span><span class="p">[</span><span class="n">gate_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">g</span>
    <span class="k">return</span> <span class="n">gate_map</span></div>

<div class="viewcode-block" id="DoubleProjectionLSTMCell._LayerNormGate"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.DoubleProjectionLSTMCell._LayerNormGate">[docs]</a>  <span class="k">def</span> <span class="nf">_LayerNormGate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">gate_name</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies layer normalization on the last dimension of &#39;x&#39;.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: a NestedMap of layer params.</span>
<span class="sd">      gate_name: the name of the gate, e.g., &#39;i_i&#39;, &#39;f_g&#39;, &#39;c&#39;, etc.</span>
<span class="sd">      x: activation tensor, where the last dimension represents channels.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Layer normalized &#39;x&#39;, with the same shape as the input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">gate_name</span> <span class="o">==</span> <span class="s1">&#39;c&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">enable_ln_on_c</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">x</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">centered</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">mean</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">centered</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">normed</span> <span class="o">=</span> <span class="n">centered</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">layer_norm_epsilon</span><span class="p">)</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="s1">&#39;ln_scale_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">gate_name</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.0</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="s1">&#39;bias_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">gate_name</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">normed</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">bias</span></div>

<div class="viewcode-block" id="DoubleProjectionLSTMCell._Gates"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.DoubleProjectionLSTMCell._Gates">[docs]</a>  <span class="k">def</span> <span class="nf">_Gates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the new state.&quot;&quot;&quot;</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">xmw</span><span class="p">[</span><span class="s1">&#39;f_g&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span>
        <span class="n">xmw</span><span class="p">[</span><span class="s1">&#39;i_g&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">xmw</span><span class="p">[</span><span class="s1">&#39;i_i&#39;</span><span class="p">])</span>
    <span class="n">new_c_normed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_LayerNormGate</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="n">new_c</span><span class="p">)</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">xmw</span><span class="p">[</span><span class="s1">&#39;o_g&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">new_c_normed</span><span class="p">)</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">new_m</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">w_output_proj</span><span class="p">)</span>

    <span class="c1"># Now take care of padding.</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ApplyPadding</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">new_m</span><span class="p">,</span> <span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">)</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ApplyPadding</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">new_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">new_c</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ConvLSTMCell"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.ConvLSTMCell">[docs]</a><span class="k">class</span> <span class="nc">ConvLSTMCell</span><span class="p">(</span><span class="n">RNNCell</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Convolution LSTM cells.</span>

<span class="sd">  theta:</span>

<span class="sd">  - wm: the parameter weight matrix. All gates combined.</span>
<span class="sd">  - b: the combined bias vector.</span>

<span class="sd">  state:</span>

<span class="sd">  - m: the lstm output. cell_shape</span>
<span class="sd">  - c: the lstm cell state. cell_shape</span>

<span class="sd">  inputs:</span>

<span class="sd">  - act: a list of input activations. input_shape.</span>
<span class="sd">  - padding: the padding. [batch].</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ConvLSTMCell.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.ConvLSTMCell.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;inputs_shape&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s1">&#39;The shape of the input. It should be a list/tuple of size four.&#39;</span>
        <span class="s1">&#39; Elements are in the order of batch, height, width, channel.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;cell_shape&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s1">&#39;The cell shape. It should be a list/tuple of size four.&#39;</span>
        <span class="s1">&#39; Elements are in the order of batch, height, width, channel.&#39;</span>
        <span class="s1">&#39; Height and width of cell_shape should match that of&#39;</span>
        <span class="s1">&#39; inputs_shape.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;filter_shape&#39;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s1">&#39;Shape of the convolution filter. This should be a pair, in the&#39;</span>
        <span class="s1">&#39; order height and width.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;cell_value_cap&#39;</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="s1">&#39;LSTM cell values are capped to be within &#39;</span>
        <span class="s1">&#39; [-cell_value_cap, +cell_value_cap]. This can be a&#39;</span>
        <span class="s1">&#39; scalar or a scalar tensor.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;output_nonlinearity&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
             <span class="s1">&#39;Whether or not to apply tanh non-linearity on lstm output.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;zo_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
             <span class="s1">&#39;If &gt; 0, applies ZoneOut regularization with the given prob.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes ConvLSTMCell.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">)</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">reset_cell_state</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;ConvLSTMCell currently doesnt &#39;</span>
                                         <span class="s1">&#39;support resetting cell state.&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">inputs_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">inputs_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span>

<div class="viewcode-block" id="ConvLSTMCell._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.ConvLSTMCell._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="n">in_channels</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">inputs_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">out_channels</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
    <span class="c1"># Define weights.</span>
    <span class="n">var_shape</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">p</span><span class="o">.</span><span class="n">filter_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">in_channels</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">out_channels</span>
    <span class="p">]</span>
    <span class="n">wm_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">var_shape</span><span class="p">,</span>
        <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;wm&#39;</span><span class="p">,</span> <span class="n">wm_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="n">bias_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span> <span class="o">*</span> <span class="n">out_channels</span><span class="p">],</span>
        <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">bias_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConvLSTMCell.batch_size"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.ConvLSTMCell.batch_size">[docs]</a>  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># There is no projection.</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">hidden_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">return</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<div class="viewcode-block" id="ConvLSTMCell.zero_state"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.ConvLSTMCell.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">height</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">inputs_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">width</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">inputs_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">out_channels</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
        <span class="n">m</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">]),</span>
            <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">),</span>
        <span class="n">c</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">]),</span>
            <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">))</span></div>

<div class="viewcode-block" id="ConvLSTMCell.GetOutput"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.ConvLSTMCell.GetOutput">[docs]</a>  <span class="k">def</span> <span class="nf">GetOutput</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span></div>

<div class="viewcode-block" id="ConvLSTMCell._Mix"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.ConvLSTMCell._Mix">[docs]</a>  <span class="k">def</span> <span class="nf">_Mix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="c1"># Concate on channels.</span>
    <span class="n">xm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span> <span class="o">+</span> <span class="p">[</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
    <span class="c1"># TODO(yonghui): Possibly change the data_format to NCHW to speed</span>
    <span class="c1"># up conv2d kernel on gpu.</span>
    <span class="n">xmw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">xm</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;SAME&#39;</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;NHWC&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xmw</span></div>

<div class="viewcode-block" id="ConvLSTMCell._Gates"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.ConvLSTMCell._Gates">[docs]</a>  <span class="k">def</span> <span class="nf">_Gates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the new state.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># Bias is applied to channels.</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">b</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">i_i</span><span class="p">,</span> <span class="n">i_g</span><span class="p">,</span> <span class="n">f_g</span><span class="p">,</span> <span class="n">o_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="n">xmw</span> <span class="o">+</span> <span class="n">bias</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">f_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">i_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">i_i</span><span class="p">)</span>
    <span class="c1"># Clip the cell states to reasonable value.</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">new_c</span><span class="p">,</span> <span class="o">-</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">output_nonlinearity</span><span class="p">:</span>
      <span class="n">new_m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">o_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">new_c</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">new_m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">o_g</span><span class="p">)</span> <span class="o">*</span> <span class="n">new_c</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span> <span class="o">*</span> <span class="n">padding</span> <span class="o">+</span> <span class="n">new_c</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">padding</span><span class="p">)</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="n">state0</span><span class="o">.</span><span class="n">m</span> <span class="o">*</span> <span class="n">padding</span> <span class="o">+</span> <span class="n">new_m</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">padding</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_c</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
      <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_m</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZoneOut</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">,</span>
                          <span class="n">c_random_uniform</span><span class="p">)</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZoneOut</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">new_m</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">,</span>
                          <span class="n">m_random_uniform</span><span class="p">)</span>
    <span class="n">new_c</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">new_m</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">new_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">new_c</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="SRUCell"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.SRUCell">[docs]</a><span class="k">class</span> <span class="nc">SRUCell</span><span class="p">(</span><span class="n">RNNCell</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;SRU cell.</span>

<span class="sd">  From this paper: https://arxiv.org/abs/1709.02755</span>

<span class="sd">  This is a simple implementation that can be used as a drop-in replacement for</span>
<span class="sd">  another RNN. It doesn&#39;t do the performance tricks that an SRU is capable of,</span>
<span class="sd">  like unrolling matrix computations over time. This is just a basic</span>
<span class="sd">  implementation. It does the 4-matrix implementation found in appendix C.</span>

<span class="sd">  theta:</span>

<span class="sd">  - wm: the parameter weight matrix. All gates combined.</span>
<span class="sd">  - b: the combined bias vector.</span>

<span class="sd">  state:</span>

<span class="sd">  - m: the sru output. [batch, cell_nodes]</span>
<span class="sd">  - c: the sru cell state. [batch, cell_nodes]</span>

<span class="sd">  inputs:</span>

<span class="sd">  - act: a list of input activations. [batch, input_nodes]</span>
<span class="sd">  - padding: the padding. [batch, 1].</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="SRUCell.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.SRUCell.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;num_hidden_nodes&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Number of projection hidden nodes &#39;</span>
        <span class="s1">&#39;(see https://arxiv.org/abs/1603.08042). &#39;</span>
        <span class="s1">&#39;Set to 0 to disable projection.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;cell_value_cap&#39;</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="s1">&#39;SRU cell values are capped to be within &#39;</span>
        <span class="s1">&#39; [-cell_value_cap, +cell_value_cap]. This can be a&#39;</span>
        <span class="s1">&#39; scalar or a scalar tensor.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;zo_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
             <span class="s1">&#39;If &gt; 0, applies ZoneOut regularization with the given prob.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;couple_input_forget_gates&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
             <span class="s1">&#39;Whether to couple the input and forget gates.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;apply_layer_norm&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Apply layer norm to the variables&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;layer_norm_epsilon&#39;</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="s1">&#39;Tiny value to guard rsqr against.&#39;</span>
        <span class="s1">&#39;value is necessary only if apply_layer_norm is True&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;apply_pruning&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Whether to prune the weights while&#39;</span>
             <span class="s1">&#39;training&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;apply_pruning_to_projection&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;Whether to prune the weights in the projection layer&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;gradient_pruning&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Whether to gradient prune the model&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;bias_init&#39;</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
             <span class="s1">&#39;Initialization parameters for bias&#39;</span><span class="p">)</span>
    <span class="c1"># Add cell-recursive vector into the SRU cells (arxiv.org/abs/1709.02755).</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;pointwise_peephole&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Whether c_{t-1} should be used to&#39;</span>
        <span class="s1">&#39;calculate gate values by aggregating gate calculations with its &#39;</span>
        <span class="s1">&#39;point-wise dot product with a weight vector.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;hidden_scaling_factor&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;scaling factor alpha for hidden layer. See details on alpha in&#39;</span>
        <span class="s1">&#39;section 3.2 of https://arxiv.org/pdf/1709.02755.pdf&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;uniform_heuristic_init&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;When set to True, initialize the weight params with uniform &#39;</span>
        <span class="s1">&#39;distribution of [-sqrt(3/hidden_nodes), +sqrt(3/hidden_nodes)], aka&#39;</span>
        <span class="s1">&#39;UniformUnitScaling. This initialization has proven to help NLP tasks&#39;</span>
        <span class="s1">&#39;in arxiv.org/abs/1709.02755. This impacts 1) input weight matrices for&#39;</span>
        <span class="s1">&#39;gates, 2) projection weight matrices, and 3) cell recursion vectors.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes SRUCell.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">reset_cell_state</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;SRUCell currently doesnt support &#39;</span>
                                         <span class="s1">&#39;resetting cell state.&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">uniform_heuristic_init</span><span class="p">:</span>
      <span class="c1"># Setting init = sqrt(3) / sqrt(hidden) * tf.uniform(-1, 1).</span>
      <span class="n">p</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span>
          <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">3.0</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_timestep</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

<div class="viewcode-block" id="SRUCell._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.SRUCell._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># Define weights.</span>
    <span class="n">wm_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
        <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;wm&#39;</span><span class="p">,</span> <span class="n">wm_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_pruning</span><span class="p">:</span>
      <span class="n">mask_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span><span class="n">wm_pc</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                      <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
                                      <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">threshold_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">([],</span>
                                           <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
                                           <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;mask&#39;</span><span class="p">,</span> <span class="n">mask_pc</span><span class="p">,</span> <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
          <span class="s1">&#39;threshold&#39;</span><span class="p">,</span> <span class="n">threshold_pc</span><span class="p">,</span> <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

      <span class="c1"># for gradient based pruning</span>
      <span class="c1"># gradient and weight snapshots</span>
      <span class="n">grad_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span><span class="n">wm_pc</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                      <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
                                      <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">gradient_pruning</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;gradient&#39;</span><span class="p">,</span> <span class="n">grad_pc</span><span class="p">,</span> <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
            <span class="s1">&#39;old_weight&#39;</span><span class="p">,</span> <span class="n">grad_pc</span><span class="p">,</span> <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
            <span class="s1">&#39;old_old_weight&#39;</span><span class="p">,</span> <span class="n">grad_pc</span><span class="p">,</span> <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">bias_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
        <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">bias_init</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">bias_pc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_hidden_nodes</span><span class="p">:</span>
      <span class="n">w_proj</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">],</span>
          <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;w_proj&#39;</span><span class="p">,</span> <span class="n">w_proj</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_pruning_to_projection</span><span class="p">:</span>
        <span class="n">proj_mask_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span><span class="n">w_proj</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                             <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
                                             <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">proj_threshold_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
            <span class="p">[],</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
            <span class="s1">&#39;proj_mask&#39;</span><span class="p">,</span> <span class="n">proj_mask_pc</span><span class="p">,</span> <span class="n">theta_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
            <span class="s1">&#39;proj_threshold&#39;</span><span class="p">,</span> <span class="n">proj_threshold_pc</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># for gradient based pruning</span>
        <span class="c1"># gradient and weight snapshots</span>
        <span class="n">proj_grad_pc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span><span class="n">w_proj</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                             <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
                                             <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">gradient_pruning</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;proj_gradient&#39;</span><span class="p">,</span> <span class="n">proj_grad_pc</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;proj_old_weight&#39;</span><span class="p">,</span> <span class="n">proj_grad_pc</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
              <span class="s1">&#39;proj_old_old_weight&#39;</span><span class="p">,</span> <span class="n">proj_grad_pc</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># TODO(yuansg): b/136014373 investigate the layer norm initialization and</span>
    <span class="c1"># implementation, try skipping LP regularization on layer norm and bias.</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_layer_norm</span><span class="p">:</span>
      <span class="n">f_t_ln_scale</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
          <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;f_t_ln_scale&#39;</span><span class="p">,</span> <span class="n">f_t_ln_scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>
      <span class="n">r_t_ln_scale</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
          <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;r_t_ln_scale&#39;</span><span class="p">,</span> <span class="n">r_t_ln_scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>
      <span class="n">c_t_ln_scale</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
          <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;c_t_ln_scale&#39;</span><span class="p">,</span> <span class="n">c_t_ln_scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">couple_input_forget_gates</span><span class="p">:</span>
        <span class="n">i_t_ln_scale</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
            <span class="n">init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;i_t_ln_scale&#39;</span><span class="p">,</span> <span class="n">i_t_ln_scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">pointwise_peephole</span><span class="p">:</span>
      <span class="n">f_t_vector_cell</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
          <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;f_t_vector_cell&#39;</span><span class="p">,</span> <span class="n">f_t_vector_cell</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>
      <span class="n">r_t_vector_cell</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
          <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;r_t_vector_cell&#39;</span><span class="p">,</span> <span class="n">r_t_vector_cell</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">couple_input_forget_gates</span><span class="p">:</span>
        <span class="n">i_t_vector_cell</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
            <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span><span class="s1">&#39;i_t_vector_cell&#39;</span><span class="p">,</span> <span class="n">i_t_vector_cell</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_pruning</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">gradient_pruning</span><span class="p">:</span>
        <span class="n">pruning_utils</span><span class="o">.</span><span class="n">AddToPruningCollections</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">threshold</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">gradient</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">old_weight</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">old_old_weight</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">pruning_utils</span><span class="o">.</span><span class="n">AddToPruningCollections</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_hidden_nodes</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_pruning_to_projection</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">gradient_pruning</span><span class="p">:</span>
          <span class="n">pruning_utils</span><span class="o">.</span><span class="n">AddToPruningCollections</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">w_proj</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_mask</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_threshold</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_gradient</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_old_weight</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_old_old_weight</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">pruning_utils</span><span class="o">.</span><span class="n">AddToPruningCollections</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">w_proj</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_mask</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">proj_threshold</span><span class="p">)</span>

    <span class="n">scope</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable_scope</span><span class="p">()</span>
    <span class="c1"># Collect some stats.</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">couple_input_forget_gates</span><span class="p">:</span>
      <span class="n">x_t2</span><span class="p">,</span> <span class="n">resized</span><span class="p">,</span> <span class="n">f_t</span><span class="p">,</span> <span class="n">r_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
          <span class="n">value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">x_t2</span><span class="p">,</span> <span class="n">resized</span><span class="p">,</span> <span class="n">i_t</span><span class="p">,</span> <span class="n">f_t</span><span class="p">,</span> <span class="n">r_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
          <span class="n">value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_gates</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_i_t&#39;</span><span class="p">,</span> <span class="n">i_t</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_x_t2&#39;</span><span class="p">,</span> <span class="n">x_t2</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_resized&#39;</span><span class="p">,</span> <span class="n">resized</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_f_t&#39;</span><span class="p">,</span> <span class="n">f_t</span><span class="p">)</span>
    <span class="n">_HistogramSummary</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">scope</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;/wm_r_t&#39;</span><span class="p">,</span> <span class="n">r_t</span><span class="p">)</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">hidden_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_hidden_nodes</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">num_gates</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">4</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">couple_input_forget_gates</span> <span class="k">else</span> <span class="mi">5</span>

<div class="viewcode-block" id="SRUCell.batch_size"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.SRUCell.batch_size">[docs]</a>  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="SRUCell.zero_state"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.SRUCell.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">zero_m</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="n">zero_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">zero_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">zero_c</span><span class="p">)</span></div>

<div class="viewcode-block" id="SRUCell.GetOutput"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.SRUCell.GetOutput">[docs]</a>  <span class="k">def</span> <span class="nf">GetOutput</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span></div>

<div class="viewcode-block" id="SRUCell.LayerNorm"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.SRUCell.LayerNorm">[docs]</a>  <span class="k">def</span> <span class="nf">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">gate_name</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">bias</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies layer normalization on the last dimension of &#39;x&#39;.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: a NestedMap of layer params.</span>
<span class="sd">      gate_name: the name of the gate, e.g., &#39;i_i&#39;, &#39;f_g&#39;, &#39;c&#39;, etc.</span>
<span class="sd">      x: activation tensor, where the last dimension represents channels.</span>
<span class="sd">      bias: the bias tensor of the gate.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Layer normalized &#39;x&#39;, with the same shape as the input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_layer_norm</span><span class="p">:</span>
      <span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">centered</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">mean</span>
      <span class="n">variance</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">centered</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">normed</span> <span class="o">=</span> <span class="n">centered</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">layer_norm_epsilon</span><span class="p">)</span>
      <span class="n">scale</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_ln_scale&#39;</span> <span class="o">%</span> <span class="n">gate_name</span><span class="p">]</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">normed</span> <span class="o">*</span> <span class="n">scale</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">bias</span></div>

<div class="viewcode-block" id="SRUCell._Mix"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.SRUCell._Mix">[docs]</a>  <span class="k">def</span> <span class="nf">_Mix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">apply_pruning</span><span class="p">:</span>
      <span class="n">wm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">mask</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">wm</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">wm</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">Matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">wm</span><span class="p">)</span></div>

<div class="viewcode-block" id="SRUCell._Gates"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.SRUCell._Gates">[docs]</a>  <span class="k">def</span> <span class="nf">_Gates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the new state.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">couple_input_forget_gates</span><span class="p">:</span>
      <span class="n">x_t2</span><span class="p">,</span> <span class="n">resized</span><span class="p">,</span> <span class="n">f_t</span><span class="p">,</span> <span class="n">r_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
          <span class="n">value</span><span class="o">=</span><span class="n">xmw</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">b_t2</span><span class="p">,</span> <span class="n">b_resized</span><span class="p">,</span> <span class="n">b_f</span><span class="p">,</span> <span class="n">b_r</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
          <span class="n">value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">b</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">pointwise_peephole</span><span class="p">:</span>
        <span class="n">f_t</span> <span class="o">=</span> <span class="n">f_t</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">f_t_vector_cell</span><span class="p">)</span>
      <span class="n">f_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;f_t&#39;</span><span class="p">,</span> <span class="n">f_t</span><span class="p">,</span> <span class="n">b_f</span><span class="p">)</span>
      <span class="n">f_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">f_t</span><span class="p">)</span>
      <span class="n">i_t</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">f_t</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">x_t2</span><span class="p">,</span> <span class="n">resized</span><span class="p">,</span> <span class="n">i_t</span><span class="p">,</span> <span class="n">f_t</span><span class="p">,</span> <span class="n">r_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
          <span class="n">value</span><span class="o">=</span><span class="n">xmw</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">b</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">b_t2</span><span class="p">,</span> <span class="n">b_resized</span><span class="p">,</span> <span class="n">b_i</span><span class="p">,</span> <span class="n">b_f</span><span class="p">,</span> <span class="n">b_r</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
          <span class="n">value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">b</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">pointwise_peephole</span><span class="p">:</span>
        <span class="n">f_t</span> <span class="o">=</span> <span class="n">f_t</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">f_t_vector_cell</span><span class="p">)</span>
        <span class="n">i_t</span> <span class="o">=</span> <span class="n">i_t</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">i_t_vector_cell</span><span class="p">)</span>
      <span class="n">f_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;f_t&#39;</span><span class="p">,</span> <span class="n">f_t</span><span class="p">,</span> <span class="n">b_f</span><span class="p">)</span>
      <span class="n">f_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">f_t</span><span class="p">)</span>
      <span class="n">i_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;i_t&#39;</span><span class="p">,</span> <span class="n">i_t</span><span class="p">,</span> <span class="n">b_i</span><span class="p">)</span>
      <span class="n">i_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">i_t</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">pointwise_peephole</span><span class="p">:</span>
      <span class="n">r_t</span> <span class="o">=</span> <span class="n">r_t</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">r_t_vector_cell</span><span class="p">)</span>
    <span class="n">r_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;r_t&#39;</span><span class="p">,</span> <span class="n">r_t</span><span class="p">,</span> <span class="n">b_r</span><span class="p">)</span>
    <span class="n">r_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">r_t</span><span class="p">)</span>

    <span class="n">c_t</span> <span class="o">=</span> <span class="n">f_t</span> <span class="o">*</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span> <span class="o">+</span> <span class="n">i_t</span> <span class="o">*</span> <span class="n">x_t2</span>
    <span class="n">c_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;c_t&#39;</span><span class="p">,</span> <span class="n">c_t</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">resized</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">resized</span><span class="p">,</span> <span class="n">b_resized</span><span class="p">)</span>
    <span class="n">x_t2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x_t2</span><span class="p">,</span> <span class="n">b_t2</span><span class="p">)</span>
    <span class="c1"># Clip the cell states to reasonable value.</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">c_t</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">c_t</span><span class="p">,</span> <span class="o">-</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">)</span>
    <span class="c1"># Calculate state outputs.</span>
    <span class="n">g_c_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">c_t</span><span class="p">)</span>
    <span class="c1"># Apply scaling factor if needed.</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">hidden_scaling_factor</span><span class="p">:</span>
      <span class="c1"># For the derivations of alpha please refer to variance computation of</span>
      <span class="c1"># hidden cells h with respect to the variance of input x in appendix A.3</span>
      <span class="c1"># https://arxiv.org/pdf/1709.02755.pdf.</span>
      <span class="n">alpha</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">bias_init</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="mf">2.0</span><span class="p">))</span>
    <span class="n">h_t</span> <span class="o">=</span> <span class="n">r_t</span> <span class="o">*</span> <span class="n">g_c_t</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">r_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">resized</span> <span class="o">*</span> <span class="n">alpha</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_hidden_nodes</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_pruning_to_projection</span><span class="p">:</span>
        <span class="n">w_proj</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">w_proj</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">proj_mask</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">w_proj</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">w_proj</span>
      <span class="n">h_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">h_t</span><span class="p">,</span> <span class="n">w_proj</span><span class="p">)</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ApplyZoneOut</span><span class="p">(</span><span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">c_t</span><span class="p">,</span> <span class="n">h_t</span><span class="p">)</span></div>

<div class="viewcode-block" id="SRUCell._ApplyZoneOut"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.SRUCell._ApplyZoneOut">[docs]</a>  <span class="k">def</span> <span class="nf">_ApplyZoneOut</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">new_m</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply ZoneOut and returns updated states.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="k">assert</span> <span class="ow">not</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">(),</span> <span class="p">(</span>
          <span class="s1">&#39;SRUCell does not support zoneout on TPU yet.&#39;</span><span class="p">)</span>
      <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_c</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
      <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_m</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">new_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZoneOut</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">,</span> <span class="n">c_random_uniform</span><span class="p">)</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZoneOut</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">new_m</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">,</span> <span class="n">m_random_uniform</span><span class="p">)</span>
    <span class="n">new_c</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">new_m</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">new_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">new_c</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="QRNNPoolingCell"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QRNNPoolingCell">[docs]</a><span class="k">class</span> <span class="nc">QRNNPoolingCell</span><span class="p">(</span><span class="n">RNNCell</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;This implements just the &quot;pooling&quot; part of a quasi-RNN or SRU.</span>

<span class="sd">  From these papers:</span>

<span class="sd">  - https://arxiv.org/abs/1611.01576</span>
<span class="sd">  - https://arxiv.org/abs/1709.02755</span>

<span class="sd">  The pooling part implements gates for recurrence. These architectures split</span>
<span class="sd">  the transform (conv or FC) from the gating/recurrent part. This cell can</span>
<span class="sd">  do either the quasi-RNN style or SRU style pooling operation based on params.</span>

<span class="sd">  If you want all of the functionality in one RNN cell, use `SRUCell` instead.</span>

<span class="sd">  theta:</span>

<span class="sd">    Has the trainable zero state. Other weights are done outside the recurrent</span>
<span class="sd">    loop.</span>

<span class="sd">  state:</span>

<span class="sd">  - m: the qrnn output. [batch, cell_nodes]</span>
<span class="sd">  - c: the qrnn cell state. [batch, cell_nodes]</span>

<span class="sd">  inputs:</span>

<span class="sd">  - act: a list of input activations. [batch, input_nodes * num_rnn_matrices]</span>
<span class="sd">  - padding: the padding. [batch, 1].</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="QRNNPoolingCell.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QRNNPoolingCell.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;cell_value_cap&#39;</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="s1">&#39;LSTM cell values are capped to be within &#39;</span>
        <span class="s1">&#39; [-cell_value_cap, +cell_value_cap] if the value is not None. &#39;</span>
        <span class="s1">&#39;It can be a scalar, a scalar tensor or None. When set to None, &#39;</span>
        <span class="s1">&#39;no capping is applied.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;zo_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
             <span class="s1">&#39;If &gt; 0, applies ZoneOut regularization with the given prob.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;pooling_formula&#39;</span><span class="p">,</span> <span class="s1">&#39;INVALID&#39;</span><span class="p">,</span>
             <span class="s1">&#39;Options: quasi_ifo, sru. Which pooling math to use&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes quasi-RNN Cell.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">reset_cell_state</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;QRNNPoolingCell currently doesnt &#39;</span>
                                         <span class="s1">&#39;support resetting cell state.&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">pooling_formula</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;quasi_ifo&#39;</span><span class="p">,</span> <span class="s1">&#39;sru&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span>
                      <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span> <span class="ow">is</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_timestep</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

<div class="viewcode-block" id="QRNNPoolingCell.batch_size"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QRNNPoolingCell.batch_size">[docs]</a>  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="QRNNPoolingCell.zero_state"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QRNNPoolingCell.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">zero_m</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="n">zero_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">zero_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">zero_c</span><span class="p">)</span></div>

<div class="viewcode-block" id="QRNNPoolingCell.GetOutput"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QRNNPoolingCell.GetOutput">[docs]</a>  <span class="k">def</span> <span class="nf">GetOutput</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span></div>

<div class="viewcode-block" id="QRNNPoolingCell._Mix"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QRNNPoolingCell._Mix">[docs]</a>  <span class="k">def</span> <span class="nf">_Mix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
    <span class="c1"># Just do identity. The convolution part of the QRNN has to be done earlier.</span>
    <span class="k">return</span> <span class="n">inputs</span><span class="o">.</span><span class="n">act</span></div>

<div class="viewcode-block" id="QRNNPoolingCell._Gates"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QRNNPoolingCell._Gates">[docs]</a>  <span class="k">def</span> <span class="nf">_Gates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xmw</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the new state.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">pooling_formula</span> <span class="o">==</span> <span class="s1">&#39;quasi_ifo&#39;</span><span class="p">:</span>
      <span class="n">z_t</span><span class="p">,</span> <span class="n">i_t</span><span class="p">,</span> <span class="n">f_t</span><span class="p">,</span> <span class="n">o_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
          <span class="n">value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">xmw</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="c1"># Quasi-RNN &quot;ifo&quot; pooling</span>
      <span class="n">c_t</span> <span class="o">=</span> <span class="n">f_t</span> <span class="o">*</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span> <span class="o">+</span> <span class="n">i_t</span> <span class="o">*</span> <span class="n">z_t</span>
      <span class="n">h_t</span> <span class="o">=</span> <span class="n">o_t</span> <span class="o">*</span> <span class="n">c_t</span>
    <span class="k">elif</span> <span class="n">p</span><span class="o">.</span><span class="n">pooling_formula</span> <span class="o">==</span> <span class="s1">&#39;sru&#39;</span><span class="p">:</span>
      <span class="n">x_t2</span><span class="p">,</span> <span class="n">resized</span><span class="p">,</span> <span class="n">f_t</span><span class="p">,</span> <span class="n">r_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
          <span class="n">value</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">xmw</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">c_t</span> <span class="o">=</span> <span class="n">f_t</span> <span class="o">*</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">f_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_t2</span>
      <span class="c1"># TODO(otaviogood): Optimization - Since state doesn&#39;t depend on these</span>
      <span class="c1"># ops, they can be moved outside the loop.</span>
      <span class="n">g_c_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">c_t</span><span class="p">)</span>
      <span class="n">h_t</span> <span class="o">=</span> <span class="n">r_t</span> <span class="o">*</span> <span class="n">g_c_t</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">r_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">resized</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid pooling_formula: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">pooling_formula</span><span class="p">)</span>

    <span class="n">new_c</span> <span class="o">=</span> <span class="n">c_t</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="n">h_t</span>

    <span class="c1"># Clip the cell states to reasonable value.</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">new_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">new_c</span><span class="p">,</span> <span class="o">-</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">)</span>

    <span class="c1"># Apply Zoneout.</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ApplyZoneOut</span><span class="p">(</span><span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">new_m</span><span class="p">)</span></div>

<div class="viewcode-block" id="QRNNPoolingCell._ApplyZoneOut"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.QRNNPoolingCell._ApplyZoneOut">[docs]</a>  <span class="k">def</span> <span class="nf">_ApplyZoneOut</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">new_m</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Apply Zoneout and returns the updated states.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_c</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
      <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_m</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">c_random_uniform</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">m_random_uniform</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">new_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZoneOut</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">,</span> <span class="n">c_random_uniform</span><span class="p">)</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZoneOut</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">new_m</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">,</span> <span class="n">m_random_uniform</span><span class="p">)</span>
    <span class="n">new_c</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">new_m</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">new_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">new_c</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="GRUCell"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.GRUCell">[docs]</a><span class="k">class</span> <span class="nc">GRUCell</span><span class="p">(</span><span class="n">RNNCell</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Gated Recurrent Unit cell.</span>

<span class="sd">  implemented: layer normalization, gru_biasing, gru_cell cap,</span>
<span class="sd">  not yet implemented: pruning, quantization, zone-out (enforced to 0.0 now)</span>
<span class="sd">  reference: https://arxiv.org/pdf/1412.3555.pdf</span>

<span class="sd">  theta:</span>

<span class="sd">  - w_n: the parameter weight matrix for the input block.</span>
<span class="sd">  - w_u: the parameter weight matrix for the update gate</span>
<span class="sd">  - w_r: the parameter weight matrix for the reset gate</span>
<span class="sd">  - b_n: the bias vector for the input block</span>
<span class="sd">  - b_u: the bias vector for the update gate</span>
<span class="sd">  - b_r: the bias vector for the reset gate</span>

<span class="sd">  state:</span>

<span class="sd">  - m: the GRU output. [batch, output_cell_nodes]</span>
<span class="sd">  - c: the GRU cell state. [batch, hidden_cell_nodes]</span>

<span class="sd">  inputs:</span>

<span class="sd">  - act: a list of input activations. [batch, input_nodes]</span>
<span class="sd">  - padding: the padding. [batch, 1].</span>
<span class="sd">  - reset_mask: optional 0/1 float input to support packed input training.</span>
<span class="sd">    Shape [batch, 1]</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="GRUCell.Params"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.GRUCell.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;num_hidden_nodes&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Number of projection hidden nodes &#39;</span>
        <span class="s1">&#39;(see https://arxiv.org/abs/1603.08042). &#39;</span>
        <span class="s1">&#39;Set to 0 to disable projection.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;cell_value_cap&#39;</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="s1">&#39;GRU cell values are capped to be within &#39;</span>
        <span class="s1">&#39; [-cell_value_cap, +cell_value_cap] if the value is not None. &#39;</span>
        <span class="s1">&#39;It can be a scalar, a scalar tensor or None. When set to None, &#39;</span>
        <span class="s1">&#39;no capping is applied.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;enable_gru_bias&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Enable the GRU Cell bias.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;bias_init&#39;</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
             <span class="s1">&#39;Initialization parameters for GRU Cell bias&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;zo_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span>
             <span class="s1">&#39;If &gt; 0, applies ZoneOut regularization with the given prob.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;apply_layer_norm&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;Apply layer norm to the variables&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;layer_norm_epsilon&#39;</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="s1">&#39;Tiny value to guard rsqr against.&#39;</span>
        <span class="s1">&#39;value is necessary only if apply_layer_norm is True&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes GRUCell.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span>
                      <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">zo_prob</span> <span class="o">==</span> <span class="mf">0.0</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_timestep</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

<div class="viewcode-block" id="GRUCell._CreateLayerVariables"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.GRUCell._CreateLayerVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateLayerVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateLayerVariables</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">def</span> <span class="nf">CreateVarHelper</span><span class="p">(</span><span class="n">variable_name</span><span class="p">,</span> <span class="n">shape_to_init</span><span class="p">,</span> <span class="n">params_to_init</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Utility function to initialize variables.</span>

<span class="sd">      Args:</span>
<span class="sd">        variable_name: the name of the variable</span>
<span class="sd">        shape_to_init: shape of the variables to be initialized.</span>
<span class="sd">        params_to_init: p.params_init, p.bias_init, or otherwise specified</span>
<span class="sd">      returns: initialized variable with name &quot;$variable_name&quot;</span>
<span class="sd">      &quot;&quot;&quot;</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">CreateVariable</span><span class="p">(</span>
          <span class="n">variable_name</span><span class="p">,</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightParams</span><span class="p">(</span>
              <span class="n">shape</span><span class="o">=</span><span class="n">shape_to_init</span><span class="p">,</span>
              <span class="n">init</span><span class="o">=</span><span class="n">params_to_init</span><span class="p">,</span>
              <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
              <span class="n">collections</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_VariableCollections</span><span class="p">()),</span> <span class="bp">self</span><span class="o">.</span><span class="n">AddVN</span><span class="p">)</span>

    <span class="c1"># Define weights.</span>
    <span class="c1"># Weight for block input</span>
    <span class="n">CreateVarHelper</span><span class="p">(</span><span class="s1">&#39;w_n&#39;</span><span class="p">,</span>
                    <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">)</span>
    <span class="c1"># Weight for update gate</span>
    <span class="n">CreateVarHelper</span><span class="p">(</span><span class="s1">&#39;w_u&#39;</span><span class="p">,</span>
                    <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">)</span>
    <span class="c1"># Weight for reset gate</span>
    <span class="n">CreateVarHelper</span><span class="p">(</span><span class="s1">&#39;w_r&#39;</span><span class="p">,</span>
                    <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">],</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_hidden_nodes</span><span class="p">:</span>
      <span class="c1"># Set up projection matrix</span>
      <span class="n">CreateVarHelper</span><span class="p">(</span><span class="s1">&#39;w_proj&#39;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">],</span>
                      <span class="n">p</span><span class="o">.</span><span class="n">params_init</span><span class="p">)</span>
      <span class="n">CreateVarHelper</span><span class="p">(</span><span class="s1">&#39;b_proj&#39;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">],</span> <span class="n">p</span><span class="o">.</span><span class="n">bias_init</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">enable_gru_bias</span><span class="p">:</span>
      <span class="c1"># Bias for the block input</span>
      <span class="n">CreateVarHelper</span><span class="p">(</span><span class="s1">&#39;b_n&#39;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span> <span class="n">p</span><span class="o">.</span><span class="n">bias_init</span><span class="p">)</span>
      <span class="c1"># Bias for update gate</span>
      <span class="n">CreateVarHelper</span><span class="p">(</span><span class="s1">&#39;b_u&#39;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span> <span class="n">p</span><span class="o">.</span><span class="n">bias_init</span><span class="p">)</span>
      <span class="c1"># Bias for the reset gate</span>
      <span class="n">CreateVarHelper</span><span class="p">(</span><span class="s1">&#39;b_r&#39;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">],</span> <span class="n">p</span><span class="o">.</span><span class="n">bias_init</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_layer_norm</span><span class="p">:</span>
      <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">layer_norm_epsilon</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
      <span class="n">ln_unit</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
      <span class="n">CreateVarHelper</span><span class="p">(</span><span class="s1">&#39;bn_ln_scale&#39;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span> <span class="n">ln_unit</span><span class="p">)</span>
      <span class="n">CreateVarHelper</span><span class="p">(</span><span class="s1">&#39;bu_ln_scale&#39;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">],</span> <span class="n">ln_unit</span><span class="p">)</span>
      <span class="n">CreateVarHelper</span><span class="p">(</span><span class="s1">&#39;br_ln_scale&#39;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">],</span> <span class="n">ln_unit</span><span class="p">)</span></div>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">output_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">hidden_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_hidden_nodes</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>

<div class="viewcode-block" id="GRUCell.batch_size"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.GRUCell.batch_size">[docs]</a>  <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="GRUCell.zero_state"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.GRUCell.zero_state">[docs]</a>  <span class="k">def</span> <span class="nf">zero_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">zero_m</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="n">zero_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">InitRNNCellState</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span>
                                       <span class="n">init</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">zero_state_init_params</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                       <span class="n">is_eval</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">zero_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">zero_c</span><span class="p">)</span></div>

<div class="viewcode-block" id="GRUCell._ResetState"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.GRUCell._ResetState">[docs]</a>  <span class="k">def</span> <span class="nf">_ResetState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">state</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_mask</span> <span class="o">*</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span>
    <span class="n">state</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reset_mask</span> <span class="o">*</span> <span class="n">state</span><span class="o">.</span><span class="n">c</span>
    <span class="k">return</span> <span class="n">state</span></div>

<div class="viewcode-block" id="GRUCell.GetOutput"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.GRUCell.GetOutput">[docs]</a>  <span class="k">def</span> <span class="nf">GetOutput</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">m</span></div>

<div class="viewcode-block" id="GRUCell.LayerNorm"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.GRUCell.LayerNorm">[docs]</a>  <span class="k">def</span> <span class="nf">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies layer normalization on the last dimension of &#39;x&#39;.</span>

<span class="sd">    Args:</span>
<span class="sd">      x: activation tensor, where the last dimension represents channels.</span>
<span class="sd">      scale: the scale tensor of the layer normalization</span>

<span class="sd">    Returns:</span>
<span class="sd">      Layer normalized &#39;x&#39;, with the same shape as the input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">centered</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">mean</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">centered</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">normed</span> <span class="o">=</span> <span class="n">centered</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">layer_norm_epsilon</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">normed</span> <span class="o">*</span> <span class="n">scale</span></div>

<div class="viewcode-block" id="GRUCell.FProp"><a class="viewcode-back" href="../../../lingvo.core.rnn_cell.html#lingvo.core.rnn_cell.GRUCell.FProp">[docs]</a>  <span class="k">def</span> <span class="nf">FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Forward function.</span>

<span class="sd">    GRU has coupled reset gate in the candidate actiavation function for output.</span>
<span class="sd">    See equation 5 and above in https://arxiv.org/pdf/1412.3555.pdf.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      state0: The previous recurrent state. A `.NestedMap`.</span>
<span class="sd">      inputs: The inputs to the cell. A `.NestedMap`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (state1, extras).</span>
<span class="sd">      - state1: The next recurrent state. A `.NestedMap`.</span>
<span class="sd">      - extras: Intermediate results to faciliate backprop. A `.NestedMap`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>

    <span class="c1"># Update all gates</span>
    <span class="c1"># Compute r_g. r_g has size [batch, output]</span>
    <span class="n">r_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span> <span class="o">+</span> <span class="p">[</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">theta</span><span class="o">.</span><span class="n">w_r</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_layer_norm</span><span class="p">:</span>
      <span class="n">r_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">r_g</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">br_ln_scale</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">enable_gru_bias</span><span class="p">:</span>
      <span class="n">r_g</span> <span class="o">=</span> <span class="n">r_g</span> <span class="o">+</span> <span class="n">theta</span><span class="o">.</span><span class="n">b_r</span>
    <span class="n">r_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">r_g</span><span class="p">)</span>

    <span class="c1"># Compute u_g and n_g. Both have size [batch, hidden].</span>
    <span class="c1"># u_g has size [batch, hidden]</span>
    <span class="n">u_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span> <span class="o">+</span> <span class="p">[</span><span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">theta</span><span class="o">.</span><span class="n">w_u</span><span class="p">)</span>
    <span class="c1"># size of n_g is [batch, hidden]</span>
    <span class="n">n_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">act</span> <span class="o">+</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">r_g</span><span class="p">,</span> <span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">)],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">theta</span><span class="o">.</span><span class="n">w_n</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">apply_layer_norm</span><span class="p">:</span>
      <span class="n">u_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">u_g</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">bu_ln_scale</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
      <span class="n">n_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">n_g</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">bn_ln_scale</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">enable_gru_bias</span><span class="p">:</span>  <span class="c1"># Add biases to u_g and n_g if needed</span>
      <span class="n">u_g</span> <span class="o">=</span> <span class="n">u_g</span> <span class="o">+</span> <span class="n">theta</span><span class="o">.</span><span class="n">b_u</span>
      <span class="n">n_g</span> <span class="o">=</span> <span class="n">n_g</span> <span class="o">+</span> <span class="n">theta</span><span class="o">.</span><span class="n">b_n</span>

    <span class="n">u_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">u_g</span><span class="p">)</span>
    <span class="n">n_g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">n_g</span><span class="p">)</span>

    <span class="n">new_c</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">u_g</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">)</span> <span class="o">+</span> <span class="n">u_g</span> <span class="o">*</span> <span class="n">n_g</span>

    <span class="c1"># Clip the cell states to reasonable value.</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">new_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">new_c</span><span class="p">,</span> <span class="o">-</span><span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">cell_value_cap</span><span class="p">)</span>

    <span class="c1"># Apply non-linear output is necessary</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="n">new_c</span>
    <span class="c1"># Apply projection matrix if necessary</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_hidden_nodes</span><span class="p">:</span>
      <span class="n">new_m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">new_m</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">w_proj</span><span class="p">)</span> <span class="o">+</span> <span class="n">theta</span><span class="o">.</span><span class="n">b_proj</span>
    <span class="c1"># Apply padding.</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ApplyPadding</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">new_m</span><span class="p">,</span> <span class="n">state0</span><span class="o">.</span><span class="n">m</span><span class="p">)</span>
    <span class="n">new_c</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">ApplyPadding</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">new_c</span><span class="p">,</span> <span class="n">state0</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">m</span><span class="o">=</span><span class="n">new_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">new_c</span><span class="p">),</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2018

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>