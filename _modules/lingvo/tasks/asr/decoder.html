

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>lingvo.tasks.asr.decoder &mdash; Lingvo  documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> Lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../lingvo.html">lingvo package</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>lingvo.tasks.asr.decoder</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for lingvo.tasks.asr.decoder</h1><div class="highlight"><pre>
<span></span><span class="c1"># Lint as: python3</span>
<span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;Decoders for the speech model.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">lingvo.compat</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">attention</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">base_decoder</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">cluster_factory</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">plot</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">py_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">recurrent</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">rnn_cell</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">summary_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">symbolic</span>
<span class="kn">from</span> <span class="nn">lingvo.tasks.asr</span> <span class="kn">import</span> <span class="n">contextualizer_base</span>
<span class="kn">from</span> <span class="nn">lingvo.tasks.asr</span> <span class="kn">import</span> <span class="n">decoder_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.tasks.asr</span> <span class="kn">import</span> <span class="n">fusion</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">font_manager</span>


<div class="viewcode-block" id="_ToTensorArray"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder._ToTensorArray">[docs]</a><span class="k">def</span> <span class="nf">_ToTensorArray</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">,</span> <span class="n">clear_after_read</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Create TensorArray from v, of size max_seq_length.&quot;&quot;&quot;</span>
  <span class="n">ta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">(</span>
      <span class="n">v</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">clear_after_read</span><span class="o">=</span><span class="n">clear_after_read</span><span class="p">)</span>
  <span class="n">ta</span> <span class="o">=</span> <span class="n">ta</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">ta</span></div>


<div class="viewcode-block" id="_NewTensorArray"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder._NewTensorArray">[docs]</a><span class="k">def</span> <span class="nf">_NewTensorArray</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Create empty TensorArray which can store max_seq_length elements.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span></div>


<div class="viewcode-block" id="AsrDecoderBase"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase">[docs]</a><span class="k">class</span> <span class="nc">AsrDecoderBase</span><span class="p">(</span><span class="n">base_decoder</span><span class="o">.</span><span class="n">BaseBeamSearchDecoder</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Base class for RNN-with-attention speech decoders.</span>

<span class="sd">  The decoder takes encoder_outputs, a NestedMap generated by the encoder, as</span>
<span class="sd">  input. The NestedMap is expected to contain the following fields:</span>

<span class="sd">    - &#39;encoded&#39;: encoded features</span>
<span class="sd">    - &#39;padding&#39;: padding for encoded features</span>

<span class="sd">  The decoder operates in a &#39;step-by-step&#39; fashion. The model encapsulates all</span>
<span class="sd">  information which should persist from one step to the next in the</span>
<span class="sd">  DecoderStepState NestedMap, which provides a &#39;misc_states&#39; NestedMap which can</span>
<span class="sd">  store arbitrary information required by the specific decoder sub-class.</span>

<span class="sd">  A &#39;step&#39; in training consists of the following sequence of steps which compute</span>
<span class="sd">  the outputs from the decoder given the current input target (and the state of</span>
<span class="sd">  the model after making the previous predictions):</span>

<span class="sd">  1. Compute the input target at the current time step::</span>

<span class="sd">      cur_target_info = self.TargetsToBeFedAtCurrentDecodeStep(...)</span>

<span class="sd">  2. Update state and compute outputs by running SingleDecodeStep::</span>

<span class="sd">      step_outs, new_state = self.SingleDecodeStep(...)</span>

<span class="sd">  3. Update state based on the logits computed at this step::</span>

<span class="sd">      new_state = self.PostStepDecoderStateUpdate(old_state, logits)</span>

<span class="sd">  4. Display summaries based on the accumulated information across all steps::</span>

<span class="sd">      self.AddAdditionalDecoderSummaries(seq_out_tas)</span>

<span class="sd">  Sub-classes can customize behavior by implementing the following functions,</span>
<span class="sd">  which will modify the behavior of the decoder:</span>

<span class="sd">  For beam search decoder:</span>
<span class="sd">    - _InitBeamSearchStateCallback</span>
<span class="sd">    - _PreBeamSearchStepCallback</span>
<span class="sd">    - _PostBeamSearchStepCallback</span>
<span class="sd">  For EMBR training:</span>
<span class="sd">    - ComputeHypsWithBeamSearch</span>

<span class="sd">  - MiscZeroState: NestedMap which represents the initial state for the</span>
<span class="sd">    &#39;misc_states&#39; in the DecoderStepState. The default implementation returns</span>
<span class="sd">    an empty NestedMap.</span>

<span class="sd">  - SingleDecodeStep: This corresponds to the computation which happens in each</span>
<span class="sd">    step of the model. The function should return the outputs of the decoder</span>
<span class="sd">    as well as the updated state.</span>

<span class="sd">  - PostStepDecoderStateUpdate: A function which updates the DecoderStepState</span>
<span class="sd">    after the output logits from the decoder have been computed. By default,</span>
<span class="sd">    this returns the DecoderStepState unchanged.</span>

<span class="sd">  - TargetsToBeFedAtCurrentDecodeStep: Returns a TargetInfo namedtuple, which</span>
<span class="sd">    represents information about the targets which should be input at the</span>
<span class="sd">    current step, as well as the output label which should be predicted.</span>
<span class="sd">    The default implementation uses the values in the batched &#39;targets&#39;</span>
<span class="sd">    provided by the InputGenerator.</span>

<span class="sd">  - AddAdditionalDecoderSummaries: A function which can be used to add any</span>
<span class="sd">    decoder specific information as part of the summaries displayed during</span>
<span class="sd">    training. By default this is a no-op.</span>

<span class="sd">  - CreateTargetInfoMisc: A function which can be used to store arbitrary</span>
<span class="sd">    information as required by a sub-classes in the target info arrays used</span>
<span class="sd">    to determine the current label at each step during training. By default,</span>
<span class="sd">    this creates an empty NestedMap.</span>

<span class="sd">  A few other functions that control how the decoder initializes and computes</span>
<span class="sd">  attention during the initial step, and during each step can also be</span>
<span class="sd">  modified, if need be:</span>

<span class="sd">  - _GetAttenContextDim: The dimensionality of the attention context vector.</span>
<span class="sd">  - _CreateAtten: Controls how the attention module is configured. Most</span>
<span class="sd">    subclasses will not have to change this unless it changes how attention</span>
<span class="sd">    works.</span>
<span class="sd">  - BaseZeroState: Returns initial state of RNNs, and attention.</span>
<span class="sd">  - _InitAttention: Initializes Tensors used by the attention module.</span>
<span class="sd">  - _GetInitialSeqStateTensorArrays: Get intitial tensor arrays for</span>
<span class="sd">    ComputePredictionsDynamic.</span>
<span class="sd">  - _GetNewAttenProbs: Update atten probs for a timestep and return the</span>
<span class="sd">    updated tensor array.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="c1"># DecoderStepState encapsulates everything that needs to persist from one</span>
  <span class="c1"># &#39;step&#39; of next label prediction to the next. This interface is also used</span>
  <span class="c1"># while performing inference in the model, so any changes here should be</span>
  <span class="c1"># undertaken with care. Although the presence of the fields listed below is</span>
  <span class="c1"># not enforced explicitly in the code, all sub-classes should use the same</span>
  <span class="c1"># structure.</span>
  <span class="c1">#</span>
  <span class="c1"># rnn_states: List of NestedMaps, corresponding to states of all RNNs in the</span>
  <span class="c1">#   decoder.</span>
  <span class="c1"># atten_context, atten_probs, atten_states: See attention.py for details.</span>
  <span class="c1"># misc_states: NestedMap, which can contain anything the decoder needs to</span>
  <span class="c1">#   persist from one step to another.</span>
  <span class="c1">#</span>
  <span class="c1"># DecoderStepState = py_utils.NestedMap(</span>
  <span class="c1">#   rnn_states=...,</span>
  <span class="c1">#   atten_context=...,</span>
  <span class="c1">#   atten_probs=...,</span>
  <span class="c1">#   atten_states=...,</span>
  <span class="c1">#   misc_states=...,</span>
  <span class="c1"># )</span>

  <span class="c1"># TargetInfo encapsulates information about the input target sequence</span>
  <span class="c1"># available during training.</span>
  <span class="c1"># These are only used during training, so sub-classes are free to add any</span>
  <span class="c1"># additional target specific information in the &#39;misc&#39; field, which can be</span>
  <span class="c1"># used to represent any model specific information.</span>
  <span class="c1"># misc: NestedMap, that can contain any model specific target information. By</span>
  <span class="c1">#   default, this is an empty NestedMap.</span>
  <span class="n">TargetInfo</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
      <span class="s1">&#39;TargetInfo&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="s1">&#39;emb&#39;</span><span class="p">,</span> <span class="s1">&#39;padding&#39;</span><span class="p">,</span> <span class="s1">&#39;misc&#39;</span><span class="p">])</span>

  <span class="c1"># SequenceOutTensorArrays encapsulates the various outputs generated as we</span>
  <span class="c1"># step through the decoder. These are used to display statistics during</span>
  <span class="c1"># training, and the information in these arrays can be used to modify the</span>
  <span class="c1"># decoder steps, e.g., by using previously predicted outputs to modify targets</span>
  <span class="c1"># fed at the next step in the ScheduledSampling decoder.</span>
  <span class="c1"># These are only used during training, so modifications to these to add</span>
  <span class="c1"># additional components are fine. In particular, the &#39;misc&#39; field is a list of</span>
  <span class="c1"># TensorArrays corresponding to the &#39;misc_states&#39; in the DecoderStepState</span>
  <span class="c1"># across all steps.</span>
  <span class="n">SequenceOutTensorArrays</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;SequenceOutTensorArrays&#39;</span><span class="p">,</span> <span class="p">[</span>
      <span class="s1">&#39;rnn_outs&#39;</span><span class="p">,</span>
      <span class="s1">&#39;step_outs&#39;</span><span class="p">,</span>
      <span class="s1">&#39;atten_probs&#39;</span><span class="p">,</span>
      <span class="s1">&#39;logits&#39;</span><span class="p">,</span>
      <span class="s1">&#39;fusion&#39;</span><span class="p">,</span>
      <span class="s1">&#39;misc&#39;</span><span class="p">,</span>
      <span class="s1">&#39;confidence_logits&#39;</span><span class="p">,</span>
  <span class="p">])</span>
  <span class="c1"># pylint: enable=invalid-name</span>

<div class="viewcode-block" id="AsrDecoderBase.Params"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;dropout_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;Prob at which we do dropout.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;emb&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span> <span class="s1">&#39;Embedding layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;emb_dim&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;dimension of the embedding layer.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;label_smoothing&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Label smoothing class.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;rnn_cell_tpl&#39;</span><span class="p">,</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
        <span class="s1">&#39;RNNCell params template. &#39;</span>
        <span class="s1">&#39;Can be a single param or &#39;</span>
        <span class="s1">&#39;a list of rnn_layers params, one for each layer.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;rnn_cell_dim&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;size of the rnn cells.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;rnn_cell_hidden_dim&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;internal size of the rnn cells. When &#39;</span>
        <span class="s1">&#39;set to &gt; 0 it enables a projection layer at the output of the &#39;</span>
        <span class="s1">&#39;rnn cell (see call to SetRnnCellNodes).&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;attention&#39;</span><span class="p">,</span> <span class="n">attention</span><span class="o">.</span><span class="n">AdditiveAttention</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Additive attention params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span> <span class="s1">&#39;Softmax params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;softmax_uses_attention&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
             <span class="s1">&#39;Controls whether attention is fed to the softmax or not.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;source_dim&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Dimension of the source encodings.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;atten_context_dim&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
             <span class="s1">&#39;Depth of the attention context vector output.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;attention_plot_font_properties&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Adds font properties for the given file if set. Required &#39;</span>
        <span class="s1">&#39;for displaying east-Asian character sets on plot axes.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;rnn_layers&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Number of rnn layers.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;residual_start&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s1">&#39;Start residual connections from this layer. For this and higher &#39;</span>
        <span class="s1">&#39;layers, the layer output is the sum of the RNN cell output and &#39;</span>
        <span class="s1">&#39;input; if the layer also normalizes its output, then the &#39;</span>
        <span class="s1">&#39;normalization is done over this sum. Set to 0 to disable &#39;</span>
        <span class="s1">&#39;residual connections.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;fusion&#39;</span><span class="p">,</span> <span class="n">fusion</span><span class="o">.</span><span class="n">NullFusion</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span> <span class="s1">&#39;Fusion class params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;parallel_iterations&#39;</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span>
             <span class="s1">&#39;Max number of iterations to run in parallel for while loop.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;per_token_avg_loss&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;Use per-token average loss when set to True (default); when set &#39;</span>
        <span class="s1">&#39;to False use sequence average loss (sum logP across tokens in an &#39;</span>
        <span class="s1">&#39;output sequence) and average across all sequences in the batch.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;token_normalized_per_seq_loss&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;Whether or not to normalize the per-sequence loss by the sequence &#39;</span>
        <span class="s1">&#39;length.&#39;</span><span class="p">)</span>
    <span class="c1"># Configs for scheduled sampling.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;min_ground_truth_prob&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s1">&#39;The min probability of using the ground truth as the previous &#39;</span>
        <span class="s1">&#39;prediction.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;min_prob_step&#39;</span><span class="p">,</span> <span class="mf">1e6</span><span class="p">,</span> <span class="s1">&#39;Step to reach min_ground_truth_prob.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;prob_decay_start_step&#39;</span><span class="p">,</span> <span class="mf">1e4</span><span class="p">,</span>
        <span class="s1">&#39;The step to starts linearly decrease the probability of sampling &#39;</span>
        <span class="s1">&#39;ground truth.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;use_while_loop_based_unrolling&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;Whether or not to use while loop based unrolling for training.&#39;</span>
        <span class="s1">&#39; If false, we use a functional while based unrolling.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;logit_types&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;logits&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">},</span>
        <span class="s1">&#39;A dict of logit_name -&gt; loss_weight. logit_name must be a field in &#39;</span>
        <span class="s1">&#39;the predictions NestedMap. loss_weight should add up to 1.0.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;use_unnormalized_logits_as_log_probs&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;If true, decoder beam search may return unnormalized logits as &#39;</span>
        <span class="s1">&#39;log_probs. Used for backwards-compatibility.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;contextualizer&#39;</span><span class="p">,</span> <span class="n">contextualizer_base</span><span class="o">.</span><span class="n">NullContextualizer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
        <span class="s1">&#39;A contextualizer that can be used&#39;</span>
        <span class="s1">&#39;to inject context into the decoder. The default NullContextualizer &#39;</span>
        <span class="s1">&#39;does not add parameters to the model nor changes the &#39;</span>
        <span class="s1">&#39;computation.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;focal_loss_alpha&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;The weighting factor alpha.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;focal_loss_gamma&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Tunable focusing parameter.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;adapter_layer_tpl&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">MultitaskAdapterLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Params for domain/language adatper layer.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;adapter_task_id_field&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;Setting this will enable the use of adapter layers. This is the name &#39;</span>
        <span class="s1">&#39;of the field in the encoder_outputs to extract the tasks IDs for &#39;</span>
        <span class="s1">&#39;adatper layers.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;confidence&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Additional confidence estimation module.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;lm_for_confidence&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;Use LM scores for confidence estimation.&#39;</span><span class="p">)</span>

    <span class="c1"># Set some reasonable default values.</span>
    <span class="c1"># Default config for the embedding layer.</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="mi">96</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb_dim</span> <span class="o">=</span> <span class="mi">96</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">max_num_shards</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="c1"># Default config for the rnn layer.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_tpl</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="c1"># Default config for the attention model.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">128</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">UniformSqrtDim</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">3.0</span><span class="p">))</span>
    <span class="c1"># Default config for the softmax part.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">vocab</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="c1"># LM config, if used.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">lm</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab</span>
    <span class="c1"># Other configs.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="mi">512</span>
    <span class="n">p</span><span class="o">.</span><span class="n">adapter_layer_tpl</span><span class="o">.</span><span class="n">data_format</span> <span class="o">=</span> <span class="s1">&#39;TBC&#39;</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="AsrDecoderBase.UpdateTargetVocabSize"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.UpdateTargetVocabSize">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">UpdateTargetVocabSize</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">wpm_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Updates params with the vocab size and wpm model.</span>

<span class="sd">    Args:</span>
<span class="sd">      p: model params.</span>
<span class="sd">      vocab_size: size of the vocabulary.</span>
<span class="sd">      wpm_model: file name prefix pointing to a wordpiece model.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Model params updated with the vocab size and wpm model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">vocab_size</span>
    <span class="n">p</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">lm</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">lm</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">UpdateTargetVocabSize</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">lm</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span>
                                                        <span class="n">wpm_model</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">vocab_size</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">min_ground_truth_prob</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># Move embedding lookup onto worker.</span>
      <span class="n">params</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">on_ps</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;Packed inputs are not yet supported for &#39;</span>
                                <span class="s1">&#39;AsrDecoderBase.&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_max_label_prob</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">min_ground_truth_prob</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_decay_interval</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">min_prob_step</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">prob_decay_start_step</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_decay_interval</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;min_prob_step (</span><span class="si">%d</span><span class="s1">) &lt;= prob_decay_start_step (</span><span class="si">%d</span><span class="s1">)&#39;</span> <span class="o">%</span>
                       <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">min_prob_step</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">prob_decay_start_step</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">attention_plot_font_properties</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_font_properties</span> <span class="o">=</span> <span class="n">font_manager</span><span class="o">.</span><span class="n">FontProperties</span><span class="p">(</span>
          <span class="n">fname</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">attention_plot_font_properties</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_font_properties</span> <span class="o">=</span> <span class="n">font_manager</span><span class="o">.</span><span class="n">FontProperties</span><span class="p">()</span>

    <span class="n">name</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;contextualizer&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">contextualizer</span><span class="p">)</span>
    <span class="n">atten_context_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetAttenContextDim</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">symbolic</span><span class="o">.</span><span class="n">IsExpr</span><span class="p">(</span><span class="n">atten_context_dim</span><span class="p">)</span> <span class="ow">or</span> <span class="n">atten_context_dim</span> <span class="o">&gt;</span> <span class="mi">0</span>

    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">emb_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;emb&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="p">)</span>

    <span class="n">params_rnn_cells</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">params_adapter_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">feat_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">emb_dim</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">rnn_layers</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_tpl</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_tpl</span><span class="p">)</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_layers</span>
        <span class="n">rnn_cell_params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_tpl</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">rnn_cell_params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">rnn_cell_params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
      <span class="n">rnn_cell_params</span><span class="o">.</span><span class="n">inputs_arity</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">decoder_utils</span><span class="o">.</span><span class="n">SetRnnCellNodes</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">rnn_cell_params</span><span class="p">)</span>
      <span class="n">rnn_cell_params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">feat_dim</span> <span class="o">+</span> <span class="n">atten_context_dim</span>
      <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">rnn_cell_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn_cell&#39;</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">rnn_cell_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn_cell_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span>
      <span class="n">feat_dim</span> <span class="o">=</span> <span class="n">rnn_cell_params</span><span class="o">.</span><span class="n">num_output_nodes</span>
      <span class="n">params_rnn_cells</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rnn_cell_params</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">adapter_task_id_field</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">adapter_p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">adapter_layer_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
        <span class="n">adapter_p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;adapter_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span>
        <span class="n">adapter_p</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">feat_dim</span>
        <span class="n">params_adapter_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">adapter_p</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChildren</span><span class="p">(</span><span class="s1">&#39;rnn_cell&#39;</span><span class="p">,</span> <span class="n">params_rnn_cells</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChildren</span><span class="p">(</span><span class="s1">&#39;adapters&#39;</span><span class="p">,</span> <span class="n">params_adapter_layers</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">feat_dim</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax_uses_attention</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">+=</span> <span class="n">atten_context_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">fusion</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">base_model_logits_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;fusion&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">fusion</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_CreateAtten</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;smoother&#39;</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span>
      <span class="k">elif</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">!=</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;label_smoothing.num_classes (</span><span class="si">{}</span><span class="s1">) does not match &#39;</span>
                         <span class="s1">&#39;softmax.num_classes (</span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                             <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span>
                             <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;smoother&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">confidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">confidence</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;confidence&#39;</span>
      <span class="c1"># Input to the confidence estimation module is:</span>
      <span class="c1"># pre-softmax feature, token embedding</span>
      <span class="c1"># softmax prob, top5 mean &amp; std</span>
      <span class="c1"># atten prob, top5 mean &amp; std</span>
      <span class="c1"># Refer to _ExtractConfidenceFeatures()</span>
      <span class="n">p</span><span class="o">.</span><span class="n">confidence</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">+</span> <span class="mi">6</span>
      <span class="c1"># When LM score is used, another input is LM prob</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">lm_for_confidence</span><span class="p">:</span>
        <span class="n">p</span><span class="o">.</span><span class="n">confidence</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;confidence&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">confidence</span><span class="p">)</span>

<div class="viewcode-block" id="AsrDecoderBase._CreateAtten"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._CreateAtten">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateAtten</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">query_dim</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">query_dim</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;atten&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase._GetAttenContextDim"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._GetAttenContextDim">[docs]</a>  <span class="k">def</span> <span class="nf">_GetAttenContextDim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">audio_context_dim</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">p</span><span class="o">.</span><span class="n">atten_context_dim</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">atten_context_dim</span> <span class="k">else</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">)</span>
    <span class="n">additional_context_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">contextualizer</span><span class="o">.</span><span class="n">GetContextDim</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">audio_context_dim</span> <span class="o">+</span> <span class="n">additional_context_dim</span></div>

<div class="viewcode-block" id="AsrDecoderBase._ApplyDropout"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._ApplyDropout">[docs]</a>  <span class="k">def</span> <span class="nf">_ApplyDropout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x_in</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">extra_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span> <span class="o">&lt;</span> <span class="mf">1.0</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">x_in</span>

    <span class="k">if</span> <span class="n">deterministic</span><span class="p">:</span>
      <span class="n">seeds</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GenerateStepSeedPair</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">extra_seed</span><span class="p">:</span>
        <span class="n">seeds</span> <span class="o">+=</span> <span class="n">extra_seed</span>
      <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">DeterministicDropout</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span><span class="p">,</span> <span class="n">seeds</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">seed</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">random_seed</span>
      <span class="k">if</span> <span class="n">seed</span> <span class="ow">and</span> <span class="n">extra_seed</span><span class="p">:</span>
        <span class="n">seed</span> <span class="o">+=</span> <span class="n">extra_seed</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase._InitAttention"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._InitAttention">[docs]</a>  <span class="k">def</span> <span class="nf">_InitAttention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Intializes attention and returns a NestedMap with those values.&quot;&quot;&quot;</span>
    <span class="n">packed_src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">atten</span><span class="o">.</span><span class="n">InitForSourcePacked</span><span class="p">(</span>
        <span class="n">theta</span><span class="o">.</span><span class="n">atten</span><span class="p">,</span>
        <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span><span class="p">,</span>  <span class="c1"># src</span>
        <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span><span class="p">,</span>  <span class="c1"># context</span>
        <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">contextualizer</span><span class="o">.</span><span class="n">InitAttention</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">contextualizer</span><span class="p">,</span> <span class="n">packed_src</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">packed_src</span></div>

<div class="viewcode-block" id="AsrDecoderBase._GetEncoderPaddings"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._GetEncoderPaddings">[docs]</a>  <span class="k">def</span> <span class="nf">_GetEncoderPaddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get Encoder Paddings from encoder_outputs.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">encoder_outputs</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="AsrDecoderBase.BaseZeroState"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.BaseZeroState">[docs]</a>  <span class="k">def</span> <span class="nf">BaseZeroState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                    <span class="n">theta</span><span class="p">,</span>
                    <span class="n">encoder_outputs</span><span class="p">,</span>
                    <span class="n">bs</span><span class="p">,</span>
                    <span class="n">misc_zero_states</span><span class="p">,</span>
                    <span class="n">per_step_source_padding</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns initial state of RNNs, and attention.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">rnn_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">rnn_layers</span><span class="p">):</span>
      <span class="n">rnn_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">bs</span><span class="p">))</span>

    <span class="n">packed_src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_InitAttention</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
    <span class="n">zero_atten_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">atten</span><span class="o">.</span><span class="n">ZeroAttentionState</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bs</span><span class="p">)</span>
    <span class="p">(</span><span class="n">atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">atten_states</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">atten</span><span class="o">.</span><span class="n">ComputeContextVectorWithSource</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">.</span><span class="n">atten</span><span class="p">,</span>
            <span class="n">packed_src</span><span class="p">,</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">Zeros</span><span class="p">([</span><span class="n">bs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span><span class="p">],</span>
                           <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)),</span>
            <span class="n">zero_atten_state</span><span class="p">,</span>
            <span class="n">per_step_source_padding</span><span class="o">=</span><span class="n">per_step_source_padding</span><span class="p">))</span>
    <span class="n">atten_context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">contextualizer</span><span class="o">.</span><span class="n">ZeroAttention</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">contextualizer</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span>
                                                      <span class="n">misc_zero_states</span><span class="p">,</span>
                                                      <span class="n">atten_context</span><span class="p">,</span> <span class="n">packed_src</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">rnn_states</span><span class="p">,</span> <span class="n">atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">atten_states</span><span class="p">,</span> <span class="n">packed_src</span></div>

<div class="viewcode-block" id="AsrDecoderBase.AddAdditionalDecoderSummaries"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.AddAdditionalDecoderSummaries">[docs]</a>  <span class="k">def</span> <span class="nf">AddAdditionalDecoderSummaries</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">seq_out_tas</span><span class="p">,</span>
                                    <span class="n">softmax_input</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Additional model-specific summaries which should be displayed.&quot;&quot;&quot;</span>
    <span class="k">pass</span></div>

<div class="viewcode-block" id="AsrDecoderBase.DecoderStepZeroState"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.DecoderStepZeroState">[docs]</a>  <span class="k">def</span> <span class="nf">DecoderStepZeroState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">target_ids</span><span class="p">,</span> <span class="n">bs</span><span class="p">):</span>
    <span class="n">misc_zero_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">MiscZeroState</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">target_ids</span><span class="p">,</span>
                                          <span class="n">bs</span><span class="p">)</span>
    <span class="n">rnn_states</span><span class="p">,</span> <span class="n">atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">atten_states</span><span class="p">,</span> <span class="n">packed_src</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">BaseZeroState</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span> <span class="n">misc_zero_states</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
        <span class="n">rnn_states</span><span class="o">=</span><span class="n">rnn_states</span><span class="p">,</span>
        <span class="n">atten_context</span><span class="o">=</span><span class="n">atten_context</span><span class="p">,</span>
        <span class="n">atten_probs</span><span class="o">=</span><span class="n">atten_probs</span><span class="p">,</span>
        <span class="n">atten_states</span><span class="o">=</span><span class="n">atten_states</span><span class="p">,</span>
        <span class="n">fusion_states</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">fusion</span><span class="p">,</span> <span class="n">bs</span><span class="p">),</span>
        <span class="n">misc_states</span><span class="o">=</span><span class="n">misc_zero_states</span><span class="p">),</span> <span class="n">packed_src</span></div>

<div class="viewcode-block" id="AsrDecoderBase._AddDecoderActivationsSummary"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._AddDecoderActivationsSummary">[docs]</a>  <span class="k">def</span> <span class="nf">_AddDecoderActivationsSummary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                    <span class="n">encoder_outputs</span><span class="p">,</span>
                                    <span class="n">targets</span><span class="p">,</span>
                                    <span class="n">atten_probs</span><span class="p">,</span>
                                    <span class="n">rnn_outs</span><span class="p">,</span>
                                    <span class="n">softmax_input</span><span class="p">,</span>
                                    <span class="n">additional_atten_probs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                    <span class="n">target_alignments</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds summary about decoder activations.</span>

<span class="sd">    For each of the args, a TensorArray can also be a Tensor representing</span>
<span class="sd">    the stacked array.</span>

<span class="sd">    Args:</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      targets: a NestedMap, usually input_batch.tgt.</span>
<span class="sd">      atten_probs: a TensorArray of max_target_length elements, each of shape</span>
<span class="sd">        [batch, max_source_length].</span>
<span class="sd">      rnn_outs: a list of TensorArray, one for each RNN layer. Each TensorArray</span>
<span class="sd">        has max_target_length elements, each of shape [batch, rnn_output_dim].</span>
<span class="sd">      softmax_input: a Tensor of shape [batch, max_target_length, vocab_size].</span>
<span class="sd">      additional_atten_probs: an optional list of (name, TensorArray) to display</span>
<span class="sd">        along with atten_probs.</span>
<span class="sd">      target_alignments: an optional Tensor of shape [batch, max_target_length]</span>
<span class="sd">        where every value is an int32 in the range of [1, max_source_length],</span>
<span class="sd">        representing number of source frames by which a target label should be</span>
<span class="sd">        emitted.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A finalized figure.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">source_encs</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span>
    <span class="n">source_paddings</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">add_summary</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="k">def</span> <span class="nf">_ToTensor</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">t</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">)</span> <span class="k">else</span> <span class="n">t</span>

    <span class="n">atten_probs</span> <span class="o">=</span> <span class="n">_ToTensor</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">)</span>
    <span class="n">rnn_outs</span> <span class="o">=</span> <span class="p">[</span><span class="n">_ToTensor</span><span class="p">(</span><span class="n">ta</span><span class="p">)</span> <span class="k">for</span> <span class="n">ta</span> <span class="ow">in</span> <span class="n">rnn_outs</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">additional_atten_probs</span><span class="p">:</span>
      <span class="n">additional_atten_probs</span> <span class="o">=</span> <span class="p">[</span>
          <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">_ToTensor</span><span class="p">(</span><span class="n">ta</span><span class="p">))</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">ta</span> <span class="ow">in</span> <span class="n">additional_atten_probs</span>
      <span class="p">]</span>

    <span class="n">num_cols</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">rnn_outs</span><span class="p">)</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plot</span><span class="o">.</span><span class="n">MatplotlibFigureSummary</span><span class="p">(</span>
        <span class="s1">&#39;decoder_example&#39;</span><span class="p">,</span>
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">2.3</span> <span class="o">*</span> <span class="p">(</span><span class="mi">3</span> <span class="o">+</span> <span class="n">num_cols</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">6</span><span class="p">),</span>
        <span class="n">max_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">subplot_grid_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">),</span>
        <span class="n">gridspec_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">width_ratios</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">num_cols</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">height_ratios</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>

    <span class="c1"># Attention needs a custom plot_func to allow for clean y-axis label for</span>
    <span class="c1"># very long transcripts</span>
    <span class="k">def</span> <span class="nf">PlotAttention</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">transcript</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
      <span class="n">plot</span><span class="o">.</span><span class="n">AddImage</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
      <span class="n">axes</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span>
          <span class="n">plot</span><span class="o">.</span><span class="n">ToUnicode</span><span class="p">(</span><span class="n">transcript</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Output token&#39;</span><span class="p">,</span>
          <span class="n">size</span><span class="o">=</span><span class="s1">&#39;x-small&#39;</span><span class="p">,</span>
          <span class="n">wrap</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">fontproperties</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_font_properties</span><span class="p">)</span>

    <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="s1">&#39;transcripts&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="n">transcript</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">transcripts</span><span class="p">[:</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

    <span class="n">srclen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">source_paddings</span><span class="p">[:,</span> <span class="n">index</span><span class="p">])),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">tgtlen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:])),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">PlotAttentionForOneExample</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">,</span>
                                   <span class="n">target_fig</span><span class="p">,</span>
                                   <span class="n">title</span><span class="p">,</span>
                                   <span class="n">alignments</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Plots attention for one example.&quot;&quot;&quot;</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Plotting attention for </span><span class="si">%s</span><span class="s1">: </span><span class="si">%s</span><span class="s1"> </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span>
                      <span class="n">atten_probs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">alignments</span><span class="p">)</span>
      <span class="n">atten_probs</span> <span class="o">=</span> <span class="n">atten_probs</span><span class="p">[:</span><span class="n">tgtlen</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="p">:</span><span class="n">srclen</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">alignments</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># [tgtlen].</span>
        <span class="n">alignment_positions</span> <span class="o">=</span> <span class="n">alignments</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:</span><span class="n">tgtlen</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="c1"># [tgtlen, srclen].</span>
        <span class="n">alignment_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">alignment_positions</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">srclen</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># The summary image will use red bars to represent target label</span>
        <span class="c1"># alignments and purple shades for attention probabilities.</span>
        <span class="n">atten_probs</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">atten_probs</span><span class="p">,</span>
                <span class="c1"># Overlay atten_probs and alignment_probs on the green channel</span>
                <span class="c1"># so that colors are visible on a white background.</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">atten_probs</span> <span class="o">+</span> <span class="n">alignment_probs</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span>
                <span class="n">alignment_probs</span>
            <span class="p">],</span>
            <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">target_fig</span><span class="o">.</span><span class="n">AddSubplot</span><span class="p">([</span><span class="n">transcript</span><span class="p">,</span> <span class="n">probs</span><span class="p">],</span> <span class="n">PlotAttention</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>

    <span class="n">PlotAttentionForOneExample</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;atten_probs&#39;</span><span class="p">)</span>
    <span class="c1"># rnn_outs and softmax_input have transposed shapes of [tgtlen, dim]</span>
    <span class="c1"># compared to source_encs [dim, srclen].</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rnn_outs</span><span class="p">)):</span>
      <span class="n">rnn_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">rnn_outs</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span><span class="n">tgtlen</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">fig</span><span class="o">.</span><span class="n">AddSubplot</span><span class="p">([</span><span class="n">rnn_out</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;rnn_outs/</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">AddSubplot</span><span class="p">([</span><span class="n">softmax_input</span><span class="p">[:</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:</span><span class="n">tgtlen</span><span class="p">,</span> <span class="p">:]],</span>
                   <span class="n">title</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;softmax_input&#39;</span><span class="p">)</span>
    <span class="n">source_encs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">source_encs</span><span class="p">[:</span><span class="n">srclen</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="p">:]),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">AddSubplot</span><span class="p">([</span><span class="n">source_encs</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;source_encs&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="sa">u</span><span class="s1">&#39;Encoder frame&#39;</span><span class="p">)</span>
    <span class="n">finalized_fig</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">Finalize</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">additional_atten_probs</span><span class="p">:</span>
      <span class="n">all_atten_probs</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;atten_probs&#39;</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">)]</span> <span class="o">+</span> <span class="n">additional_atten_probs</span>
      <span class="n">num_atten_images</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_atten_probs</span><span class="p">)</span>
      <span class="n">atten_fig</span> <span class="o">=</span> <span class="n">plot</span><span class="o">.</span><span class="n">MatplotlibFigureSummary</span><span class="p">(</span>
          <span class="s1">&#39;decoder_attention&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">num_atten_images</span><span class="p">),</span> <span class="n">max_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">probs</span> <span class="ow">in</span> <span class="n">all_atten_probs</span><span class="p">:</span>
        <span class="n">PlotAttentionForOneExample</span><span class="p">(</span>
            <span class="n">probs</span><span class="p">,</span> <span class="n">atten_fig</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">key</span><span class="p">,</span> <span class="n">alignments</span><span class="o">=</span><span class="n">target_alignments</span><span class="p">)</span>
      <span class="n">atten_fig</span><span class="o">.</span><span class="n">Finalize</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">finalized_fig</span></div>

<div class="viewcode-block" id="AsrDecoderBase._ComputeMetrics"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._ComputeMetrics">[docs]</a>  <span class="k">def</span> <span class="nf">_ComputeMetrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                      <span class="n">logits</span><span class="p">,</span>
                      <span class="n">target_labels</span><span class="p">,</span>
                      <span class="n">target_weights</span><span class="p">,</span>
                      <span class="n">target_probs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute loss and misc metrics.</span>

<span class="sd">    Args:</span>
<span class="sd">      logits: Tensor of shape [batch, time, num_classes].</span>
<span class="sd">      target_labels: Tensor of shape [batch, time].</span>
<span class="sd">      target_weights: Tensor of shape [batch, time].</span>
<span class="sd">      target_probs: Tensor of shape [batch, time, num_classes].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A (metrics, per_sequence_loss) pair.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">target_weights_sum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">target_weights</span><span class="p">)</span>
    <span class="c1"># add 0.000001 to avoid divide-by-zero.</span>
    <span class="n">target_weights_sum_eps</span> <span class="o">=</span> <span class="n">target_weights_sum</span> <span class="o">+</span> <span class="mf">0.000001</span>
    <span class="n">correct_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">target_labels</span><span class="p">),</span>
        <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="n">correct_next_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">correct_preds</span> <span class="o">*</span> <span class="n">target_weights</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span>
        <span class="n">correct_next_preds</span> <span class="o">/</span> <span class="n">target_weights_sum_eps</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fraction_of_correct_next_step_preds&#39;</span><span class="p">)</span>
    <span class="c1"># Pad zeros so that we can stack them.</span>
    <span class="n">per_example_loss</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">SoftmaxCrossEntropyFocalLoss</span><span class="p">(</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
        <span class="n">label_ids</span><span class="o">=</span><span class="n">target_labels</span><span class="p">,</span>
        <span class="n">label_probs</span><span class="o">=</span><span class="n">target_probs</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">focal_loss_alpha</span><span class="p">,</span>
        <span class="n">gamma</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">focal_loss_gamma</span><span class="p">)</span>

    <span class="n">per_sequence_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">per_example_loss</span> <span class="o">*</span> <span class="n">target_weights</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">per_token_avg_loss</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">per_sequence_loss</span><span class="p">)</span> <span class="o">/</span> <span class="n">target_weights_sum_eps</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">token_normalized_per_seq_loss</span><span class="p">:</span>
      <span class="n">per_seq_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">target_weights</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="c1"># +0.001 to avoid possible divide by 0.</span>
      <span class="n">per_sequence_loss</span> <span class="o">/=</span> <span class="p">(</span><span class="n">per_seq_length</span> <span class="o">+</span> <span class="mf">0.001</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_token_avg_loss</span><span class="p">:</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">per_token_avg_loss</span>
      <span class="n">loss_weight</span> <span class="o">=</span> <span class="n">target_weights_sum</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># per-sequence average loss</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">per_sequence_loss</span><span class="p">)</span>
      <span class="n">loss_weight</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">per_sequence_loss</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">loss_weight</span><span class="p">),</span>
        <span class="c1"># add log_pplx for compatibility with the mt/decoder.py</span>
        <span class="s1">&#39;log_pplx&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">per_token_avg_loss</span><span class="p">,</span> <span class="n">target_weights_sum</span><span class="p">),</span>
        <span class="s1">&#39;token_normed_prob&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">per_token_avg_loss</span><span class="p">),</span> <span class="n">target_weights_sum</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;fraction_of_correct_next_step_preds&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">accuracy</span><span class="p">,</span>
                                                      <span class="n">target_weights_sum</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">per_sequence_loss</span></div>

<div class="viewcode-block" id="AsrDecoderBase.InitDecoder"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.InitDecoder">[docs]</a>  <span class="k">def</span> <span class="nf">InitDecoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">dec_bs</span><span class="p">):</span>
    <span class="n">decoder_step_zero_state</span><span class="p">,</span> <span class="n">packed_src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">DecoderStepZeroState</span><span class="p">(</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">dec_bs</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">target_sos_id</span><span class="p">,</span>
        <span class="n">dec_bs</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">decoder_step_zero_state</span><span class="o">.</span><span class="n">rnn_states</span><span class="p">,</span>
            <span class="n">decoder_step_zero_state</span><span class="o">.</span><span class="n">atten_context</span><span class="p">,</span>
            <span class="n">decoder_step_zero_state</span><span class="o">.</span><span class="n">atten_probs</span><span class="p">,</span>
            <span class="n">decoder_step_zero_state</span><span class="o">.</span><span class="n">atten_states</span><span class="p">,</span>
            <span class="n">decoder_step_zero_state</span><span class="o">.</span><span class="n">fusion_states</span><span class="p">,</span>
            <span class="n">decoder_step_zero_state</span><span class="o">.</span><span class="n">misc_states</span><span class="p">,</span> <span class="n">packed_src</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase._InitBeamSearchStateCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._InitBeamSearchStateCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_InitBeamSearchStateCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
                                   <span class="n">num_hyps_per_beam</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;_InitBeamSearchStateCallback&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase._PreBeamSearchStepCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._PreBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_PreBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">step_ids</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span>
                                 <span class="n">num_hyps_per_beam</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;_PreBeamSearchStepCallback&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase._PostBeamSearchStepCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._PostBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_PostBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">new_step_ids</span><span class="p">,</span>
                                  <span class="n">states</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;_PostBeamSearchStepCallback&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase.ComputeLoss"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.ComputeLoss">[docs]</a>  <span class="k">def</span> <span class="nf">ComputeLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes loss metrics and per-sequence losses.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A NestedMap object containing weights&#39; values of this layer and its</span>
<span class="sd">        children layers.</span>
<span class="sd">      predictions: A NestedMap containing logits (and possibly other fields).</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one is</span>
<span class="sd">        trying to predict. Each tensor in targets is of shape [batch, time].</span>

<span class="sd">    Returns:</span>
<span class="sd">      (metrics, per_sequence_loss), where metrics is a dictionary containing</span>
<span class="sd">      metrics for the xent loss and prediction accuracy. per_sequence is a</span>
<span class="sd">      dictionary containing &#39;loss&#39;, a (-log(p)) vector of size [bs].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="k">if</span> <span class="s1">&#39;probs&#39;</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">:</span>
        <span class="n">target_probs</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">probs</span>
      <span class="k">elif</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">target_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">smoother</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">smoother</span><span class="p">,</span> <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">,</span>
                                           <span class="n">targets</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">target_probs</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">merged_metrics</span> <span class="o">=</span> <span class="p">{}</span>
      <span class="n">merged_per_sequence_loss</span> <span class="o">=</span> <span class="mf">0.</span>

      <span class="k">def</span> <span class="nf">AddToMetric</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">acc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)),</span>
                <span class="n">acc</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)))</span>

      <span class="k">for</span> <span class="n">logit_name</span><span class="p">,</span> <span class="n">loss_weight</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">logit_types</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">metrics</span><span class="p">,</span> <span class="n">per_sequence_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ComputeMetrics</span><span class="p">(</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">logit_name</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">targets</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span>
            <span class="n">target_probs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Merging metric </span><span class="si">%s</span><span class="s1">: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
          <span class="n">merged_metrics</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">logit_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
          <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">merged_metrics</span><span class="p">:</span>
            <span class="n">merged_metrics</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="n">shape</span><span class="o">=</span><span class="p">[],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)),</span>
                                 <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                                     <span class="n">shape</span><span class="o">=</span><span class="p">[],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)))</span>
          <span class="n">merged_metrics</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">AddToMetric</span><span class="p">(</span><span class="n">merged_metrics</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">loss_weight</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="n">merged_per_sequence_loss</span> <span class="o">+=</span> <span class="n">loss_weight</span> <span class="o">*</span> <span class="n">per_sequence_loss</span>
      <span class="k">return</span> <span class="n">merged_metrics</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">merged_per_sequence_loss</span><span class="p">}</span></div>

<div class="viewcode-block" id="AsrDecoderBase.CreateTargetInfoMisc"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.CreateTargetInfoMisc">[docs]</a>  <span class="k">def</span> <span class="nf">CreateTargetInfoMisc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a NestedMap corresponding to the &#39;misc&#39; field in TargetInfo.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;fst_bias_probs&#39;</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
          <span class="s1">&#39;fst_bias_probs&#39;</span><span class="p">:</span> <span class="n">targets</span><span class="o">.</span><span class="n">fst_bias_probs</span><span class="p">,</span>
      <span class="p">})</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span></div>

<div class="viewcode-block" id="AsrDecoderBase.ComputePredictions"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.ComputePredictions">[docs]</a>  <span class="k">def</span> <span class="nf">ComputePredictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes logits.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A NestedMap object containing weights values of this layer and its</span>
<span class="sd">        child layers.</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one is</span>
<span class="sd">        trying to predict. Each tensor in targets is of shape [batch, time].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A NestedMap object containing logit tensors as values, each of shape</span>
<span class="sd">      [target_batch, max_target_length, vocab_size]. One of the keys must be</span>
<span class="sd">      &#39;logits&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="s1">&#39;src_segment_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">contextualizer</span><span class="o">.</span><span class="n">SetContextMap</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">contextualizer</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">&#39;weights&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">targets</span> <span class="ow">and</span> <span class="s1">&#39;paddings&#39;</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">:</span>
      <span class="n">targets</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_while_loop_based_unrolling</span><span class="p">:</span>
      <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ComputePredictionsDynamic</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
                                                   <span class="n">targets</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ComputePredictionsFunctional</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
                                                      <span class="n">targets</span><span class="p">)</span>
    <span class="n">encoder_paddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetEncoderPaddings</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoder_paddings</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
      <span class="c1"># source_padding is of shape [time, batch]. Compute source_enc_len, which</span>
      <span class="c1"># is used for computing attention loss.</span>
      <span class="n">predictions</span><span class="o">.</span><span class="n">source_enc_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">encoder_paddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">if</span> <span class="s1">&#39;paddings&#39;</span> <span class="ow">in</span> <span class="n">targets</span><span class="p">:</span>
        <span class="n">source_batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">encoder_paddings</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">target_batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">multiplier</span> <span class="o">=</span> <span class="n">target_batch</span> <span class="o">//</span> <span class="n">source_batch</span>
        <span class="n">source_len</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">RepeatDim</span><span class="p">(</span>
            <span class="n">predictions</span><span class="o">.</span><span class="n">source_enc_len</span><span class="p">,</span> <span class="n">multiplier</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">target_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">target_source_length_ratio</span> <span class="o">=</span> <span class="n">target_len</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">source_len</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;avg_target_source_length_ratio&#39;</span><span class="p">,</span>
                             <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">target_source_length_ratio</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">predictions</span></div>

<div class="viewcode-block" id="AsrDecoderBase._GetInitialSeqStateTensorArrays"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._GetInitialSeqStateTensorArrays">[docs]</a>  <span class="k">def</span> <span class="nf">_GetInitialSeqStateTensorArrays</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">,</span>
                                      <span class="n">decoder_step_state_zero_fusion_flat</span><span class="p">,</span>
                                      <span class="n">decoder_step_state_zero_misc_flat</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get intitial tensor arrays for ComputePredictionsDynamic.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># TensorArrays for sequence outputs.</span>
    <span class="n">rnn_outs</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">_NewTensorArray</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;rnn</span><span class="si">%d</span><span class="s1">_outs&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span>
            <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">rnn_layers</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="n">step_outs</span> <span class="o">=</span> <span class="n">_NewTensorArray</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;step_outs&#39;</span><span class="p">,</span>
        <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="n">atten_probs</span> <span class="o">=</span> <span class="n">_NewTensorArray</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;atten_probs&#39;</span><span class="p">,</span>
        <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">_NewTensorArray</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">,</span>
        <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="n">fusion_array</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">_NewTensorArray</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fusion_states</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span>
            <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">decoder_step_state_zero_fusion_flat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">decoder_step_state_zero_fusion_flat</span><span class="p">))</span>
    <span class="p">]</span>
    <span class="n">misc</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">_NewTensorArray</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">&#39;misc_states</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span>
            <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">decoder_step_state_zero_misc_flat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">decoder_step_state_zero_misc_flat</span><span class="p">))</span>
    <span class="p">]</span>
    <span class="n">confidence_logits</span> <span class="o">=</span> <span class="n">_NewTensorArray</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;confidence_logits&#39;</span><span class="p">,</span>
        <span class="n">max_seq_length</span><span class="o">=</span><span class="n">max_seq_length</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">AsrDecoder</span><span class="o">.</span><span class="n">SequenceOutTensorArrays</span><span class="p">(</span>
        <span class="n">rnn_outs</span><span class="o">=</span><span class="n">rnn_outs</span><span class="p">,</span>
        <span class="n">step_outs</span><span class="o">=</span><span class="n">step_outs</span><span class="p">,</span>
        <span class="n">atten_probs</span><span class="o">=</span><span class="n">atten_probs</span><span class="p">,</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
        <span class="n">fusion</span><span class="o">=</span><span class="n">fusion_array</span><span class="p">,</span>
        <span class="n">misc</span><span class="o">=</span><span class="n">misc</span><span class="p">,</span>
        <span class="n">confidence_logits</span><span class="o">=</span><span class="n">confidence_logits</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase._GetNewAttenProbs"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._GetNewAttenProbs">[docs]</a>  <span class="k">def</span> <span class="nf">_GetNewAttenProbs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_out_tas</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update atten probs for a timestep and return the updated tensor array.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">seq_out_tas</span><span class="o">.</span><span class="n">atten_probs</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">atten_probs</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase._UpdateSequenceOutTensorArrays"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._UpdateSequenceOutTensorArrays">[docs]</a>  <span class="k">def</span> <span class="nf">_UpdateSequenceOutTensorArrays</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">step_outs</span><span class="p">,</span>
                                     <span class="n">seq_out_tas</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update SequenceOutTensorArrays at each time step.&quot;&quot;&quot;</span>
    <span class="n">new_rnn_outs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">seq_out_tas</span><span class="o">.</span><span class="n">rnn_outs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">decoder_step_state</span><span class="o">.</span><span class="n">rnn_states</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">seq_out_tas</span><span class="o">.</span><span class="n">rnn_outs</span><span class="p">)):</span>
      <span class="n">new_rnn_outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seq_out_tas</span><span class="o">.</span><span class="n">rnn_outs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
          <span class="n">time</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">rnn_states</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">m</span><span class="p">))</span>
    <span class="n">new_logits_ta</span> <span class="o">=</span> <span class="n">seq_out_tas</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">logits</span><span class="p">)</span>
    <span class="n">new_step_outs_ta</span> <span class="o">=</span> <span class="n">seq_out_tas</span><span class="o">.</span><span class="n">step_outs</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">step_outs</span><span class="p">)</span>
    <span class="n">new_atten_probs_ta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetNewAttenProbs</span><span class="p">(</span><span class="n">seq_out_tas</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span>
                                                <span class="n">decoder_step_state</span><span class="p">)</span>
    <span class="n">new_seq_outs_fusion_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">new_fusion_states_flat</span> <span class="o">=</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">fusion_states</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_fusion_states_flat</span><span class="p">)):</span>
      <span class="n">new_seq_outs_fusion_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seq_out_tas</span><span class="o">.</span><span class="n">fusion</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
          <span class="n">time</span><span class="p">,</span> <span class="n">new_fusion_states_flat</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="n">new_seq_outs_misc_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">new_misc_states_flat</span> <span class="o">=</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">misc_states</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_misc_states_flat</span><span class="p">)):</span>
      <span class="n">new_seq_outs_misc_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seq_out_tas</span><span class="o">.</span><span class="n">misc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
          <span class="n">time</span><span class="p">,</span> <span class="n">new_misc_states_flat</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">confidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">new_confidence_logits_ta</span> <span class="o">=</span> <span class="n">seq_out_tas</span><span class="o">.</span><span class="n">confidence_logits</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
          <span class="n">time</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">confidence_logits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># Fill the confidence field with softmax logits as a placeholder.</span>
      <span class="c1"># Note that this will not be used as it will not pass to `predictions`.</span>
      <span class="n">new_confidence_logits_ta</span> <span class="o">=</span> <span class="n">seq_out_tas</span><span class="o">.</span><span class="n">confidence_logits</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
          <span class="n">time</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">logits</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">AsrDecoder</span><span class="o">.</span><span class="n">SequenceOutTensorArrays</span><span class="p">(</span>
        <span class="n">rnn_outs</span><span class="o">=</span><span class="n">new_rnn_outs</span><span class="p">,</span>
        <span class="n">step_outs</span><span class="o">=</span><span class="n">new_step_outs_ta</span><span class="p">,</span>
        <span class="n">atten_probs</span><span class="o">=</span><span class="n">new_atten_probs_ta</span><span class="p">,</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">new_logits_ta</span><span class="p">,</span>
        <span class="n">fusion</span><span class="o">=</span><span class="n">new_seq_outs_fusion_states</span><span class="p">,</span>
        <span class="n">confidence_logits</span><span class="o">=</span><span class="n">new_confidence_logits_ta</span><span class="p">,</span>
        <span class="n">misc</span><span class="o">=</span><span class="n">new_seq_outs_misc_states</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase._GetAttenProbsFromSequenceOutTensorArrays"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._GetAttenProbsFromSequenceOutTensorArrays">[docs]</a>  <span class="k">def</span> <span class="nf">_GetAttenProbsFromSequenceOutTensorArrays</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">atten_probs</span><span class="o">.</span><span class="n">stack</span><span class="p">(),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span></div>

<div class="viewcode-block" id="AsrDecoderBase._GetPredictionFromSequenceOutTensorArrays"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._GetPredictionFromSequenceOutTensorArrays">[docs]</a>  <span class="k">def</span> <span class="nf">_GetPredictionFromSequenceOutTensorArrays</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seq_out_tas</span><span class="p">):</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
        <span class="c1"># softmax_input is of shape [time, batch, dim] for compatibility.</span>
        <span class="n">softmax_input</span><span class="o">=</span><span class="n">seq_out_tas</span><span class="o">.</span><span class="n">step_outs</span><span class="o">.</span><span class="n">stack</span><span class="p">(),</span>
        <span class="c1"># logits is of shape [batch, time, dim].</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">seq_out_tas</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">stack</span><span class="p">(),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
        <span class="n">attention</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
            <span class="n">probs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_GetAttenProbsFromSequenceOutTensorArrays</span><span class="p">(</span>
                <span class="n">seq_out_tas</span><span class="o">.</span><span class="n">atten_probs</span><span class="p">)))</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">confidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># confidence_logits is of shape [batch, time].</span>
      <span class="n">prediction</span><span class="o">.</span><span class="n">confidence_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
          <span class="n">seq_out_tas</span><span class="o">.</span><span class="n">confidence_logits</span><span class="o">.</span><span class="n">stack</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">prediction</span></div>

<div class="viewcode-block" id="AsrDecoderBase._GetInitialTargetInfo"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._GetInitialTargetInfo">[docs]</a>  <span class="k">def</span> <span class="nf">_GetInitialTargetInfo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">,</span> <span class="n">target_embs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">AsrDecoderBase</span><span class="o">.</span><span class="n">TargetInfo</span><span class="p">(</span>
        <span class="nb">id</span><span class="o">=</span><span class="n">_ToTensorArray</span><span class="p">(</span>
            <span class="s1">&#39;target_ids_ta&#39;</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">),</span>
            <span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">clear_after_read</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="n">label</span><span class="o">=</span><span class="n">_ToTensorArray</span><span class="p">(</span>
            <span class="s1">&#39;target_labels_ta&#39;</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span>
            <span class="n">max_seq_length</span><span class="p">,</span>
            <span class="n">clear_after_read</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="n">weight</span><span class="o">=</span><span class="n">_ToTensorArray</span><span class="p">(</span><span class="s1">&#39;target_weights_ta&#39;</span><span class="p">,</span>
                              <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">weights</span><span class="p">),</span> <span class="n">max_seq_length</span><span class="p">),</span>
        <span class="n">emb</span><span class="o">=</span><span class="n">_ToTensorArray</span><span class="p">(</span><span class="s1">&#39;target_embs_ta&#39;</span><span class="p">,</span>
                           <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">target_embs</span><span class="p">,</span>
                                        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">max_seq_length</span><span class="p">),</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">_ToTensorArray</span><span class="p">(</span>
            <span class="s1">&#39;target_paddings_ta&#39;</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">max_seq_length</span><span class="p">),</span>
        <span class="n">misc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">CreateTargetInfoMisc</span><span class="p">(</span><span class="n">targets</span><span class="p">),</span>
    <span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase.ComputePredictionsDynamic"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.ComputePredictionsDynamic">[docs]</a>  <span class="k">def</span> <span class="nf">ComputePredictionsDynamic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="c1"># Create TensorArrays corresponding to the targets to be used for</span>
      <span class="c1"># training.</span>
      <span class="n">dec_bs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

      <span class="n">target_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">emb</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
      <span class="n">target_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_embs</span><span class="p">,</span> <span class="p">[</span><span class="n">dec_bs</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">emb_dim</span><span class="p">])</span>
      <span class="n">target_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ApplyDropout</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">target_embs</span><span class="p">)</span>
      <span class="n">target_info_tas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetInitialTargetInfo</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">,</span>
                                                   <span class="n">target_embs</span><span class="p">)</span>

      <span class="c1"># Initialize all loop variables.</span>
      <span class="n">time</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="c1"># Decoder state.</span>
      <span class="n">decoder_step_state_zero</span><span class="p">,</span> <span class="n">packed_src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">DecoderStepZeroState</span><span class="p">(</span>
          <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">,</span> <span class="n">dec_bs</span><span class="p">)</span>
      <span class="n">decoder_step_state_zero_fusion_flat</span> <span class="o">=</span> <span class="p">(</span>
          <span class="n">decoder_step_state_zero</span><span class="o">.</span><span class="n">fusion_states</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
      <span class="n">decoder_step_state_zero_misc_flat</span> <span class="o">=</span> <span class="p">(</span>
          <span class="n">decoder_step_state_zero</span><span class="o">.</span><span class="n">misc_states</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

      <span class="c1"># TensorArrays for sequence outputs.</span>
      <span class="n">seq_out_tas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetInitialSeqStateTensorArrays</span><span class="p">(</span>
          <span class="n">max_seq_length</span><span class="p">,</span> <span class="n">decoder_step_state_zero_fusion_flat</span><span class="p">,</span>
          <span class="n">decoder_step_state_zero_misc_flat</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">_LoopContinue</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="p">,</span> <span class="n">target_info_tas</span><span class="p">,</span> <span class="n">seq_out_tas</span><span class="p">):</span>
        <span class="k">del</span> <span class="n">decoder_step_state</span><span class="p">,</span> <span class="n">target_info_tas</span><span class="p">,</span> <span class="n">seq_out_tas</span>
        <span class="k">return</span> <span class="n">time</span> <span class="o">&lt;</span> <span class="n">max_seq_length</span>

      <span class="k">def</span> <span class="nf">_LoopBody</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">old_decoder_step_state</span><span class="p">,</span> <span class="n">target_info_tas</span><span class="p">,</span> <span class="n">seq_out_tas</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes decoder outputs and updates decoder_step_state.&quot;&quot;&quot;</span>
        <span class="n">cur_target_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">TargetsToBeFedAtCurrentDecodeStep</span><span class="p">(</span>
            <span class="n">time</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">old_decoder_step_state</span><span class="p">,</span> <span class="n">target_info_tas</span><span class="p">,</span> <span class="n">seq_out_tas</span><span class="p">)</span>

        <span class="n">step_outs</span><span class="p">,</span> <span class="n">decoder_step_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">SingleDecodeStep</span><span class="p">(</span>
            <span class="n">theta</span><span class="p">,</span> <span class="n">packed_src</span><span class="p">,</span> <span class="n">cur_target_info</span><span class="p">,</span> <span class="n">old_decoder_step_state</span><span class="p">)</span>

        <span class="n">step_outs</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">fusion_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">.</span><span class="n">fusion</span><span class="p">,</span> <span class="n">old_decoder_step_state</span><span class="o">.</span><span class="n">fusion_states</span><span class="p">,</span> <span class="n">step_outs</span><span class="p">,</span>
            <span class="n">cur_target_info</span><span class="o">.</span><span class="n">id</span><span class="p">,</span> <span class="n">cur_target_info</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>

        <span class="c1"># Compute logits.</span>
        <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="p">[</span><span class="n">step_outs</span><span class="p">],</span>
            <span class="n">class_weights</span><span class="o">=</span><span class="n">cur_target_info</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span>
            <span class="n">class_ids</span><span class="o">=</span><span class="n">cur_target_info</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>

        <span class="n">decoder_step_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">PostStepDecoderStateUpdate</span><span class="p">(</span>
            <span class="n">decoder_step_state</span><span class="p">,</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">logits</span><span class="p">)</span>

        <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">ComputeLogitsWithLM</span><span class="p">(</span>
            <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">fusion_states</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">logits</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">confidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">lm_for_confidence</span><span class="p">:</span>
            <span class="n">lm_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
                <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">fusion_states</span><span class="o">.</span><span class="n">lm_output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">lm_output</span> <span class="o">=</span> <span class="kc">None</span>
          <span class="n">confidence_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ExtractConfidenceFeatures</span><span class="p">(</span>
              <span class="n">theta</span><span class="p">,</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">cur_target_info</span><span class="o">.</span><span class="n">label</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">decoder_step_state</span><span class="o">.</span><span class="n">atten_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
              <span class="n">lm_output</span><span class="o">=</span><span class="n">lm_output</span><span class="p">)</span>
          <span class="n">confidence_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
              <span class="p">[</span><span class="n">step_outs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">confidence_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
          <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">confidence_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">confidence</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">confidence</span><span class="p">,</span>
                                    <span class="n">tf</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">confidence_input</span><span class="p">)),</span>
              <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Update SequenceOutTensorArrays.</span>
        <span class="n">new_seq_out_tas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_UpdateSequenceOutTensorArrays</span><span class="p">(</span>
            <span class="n">decoder_step_state</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">step_outs</span><span class="p">,</span> <span class="n">seq_out_tas</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">logits</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">decoder_step_state</span><span class="p">,</span> <span class="s1">&#39;confidence_logits&#39;</span><span class="p">):</span>
          <span class="k">del</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">confidence_logits</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">time</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="p">,</span> <span class="n">target_info_tas</span><span class="p">,</span> <span class="n">new_seq_out_tas</span><span class="p">)</span>

      <span class="n">loop_vars</span> <span class="o">=</span> <span class="n">time</span><span class="p">,</span> <span class="n">decoder_step_state_zero</span><span class="p">,</span> <span class="n">target_info_tas</span><span class="p">,</span> <span class="n">seq_out_tas</span>
      <span class="c1"># NOTE(skyewm): this could be more specific, but for now don&#39;t verify</span>
      <span class="c1"># while_loop input/output shapes at all.</span>
      <span class="n">shape_invariants</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span>
                                               <span class="n">loop_vars</span><span class="p">)</span>

      <span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">target_info_tas</span><span class="p">,</span> <span class="n">seq_out_tas</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span>
          <span class="n">_LoopContinue</span><span class="p">,</span>
          <span class="n">_LoopBody</span><span class="p">,</span>
          <span class="n">loop_vars</span><span class="o">=</span><span class="n">loop_vars</span><span class="p">,</span>
          <span class="n">shape_invariants</span><span class="o">=</span><span class="n">shape_invariants</span><span class="p">,</span>
          <span class="n">parallel_iterations</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">parallel_iterations</span><span class="p">,</span>
          <span class="n">swap_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

      <span class="n">softmax_input</span> <span class="o">=</span> <span class="n">seq_out_tas</span><span class="o">.</span><span class="n">step_outs</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span>
      <span class="n">softmax_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">softmax_input</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">_AddDecoderActivationsSummary</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span>
                                         <span class="n">seq_out_tas</span><span class="o">.</span><span class="n">atten_probs</span><span class="p">,</span>
                                         <span class="n">seq_out_tas</span><span class="o">.</span><span class="n">rnn_outs</span><span class="p">,</span> <span class="n">softmax_input</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">AddAdditionalDecoderSummaries</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">seq_out_tas</span><span class="p">,</span>
                                         <span class="n">softmax_input</span><span class="p">)</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetPredictionFromSequenceOutTensorArrays</span><span class="p">(</span><span class="n">seq_out_tas</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase.ComputePredictionsFunctional"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.ComputePredictionsFunctional">[docs]</a>  <span class="k">def</span> <span class="nf">ComputePredictionsFunctional</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># Currently, scheduled sampling is not supported.</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">min_ground_truth_prob</span> <span class="o">==</span> <span class="mf">1.0</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="n">dec_bs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

      <span class="c1"># Decoder state.</span>
      <span class="n">state0</span><span class="p">,</span> <span class="n">packed_src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">DecoderStepZeroState</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
                                                     <span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">,</span> <span class="n">dec_bs</span><span class="p">)</span>

      <span class="n">atten_context_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetAttenContextDim</span><span class="p">()</span>
      <span class="n">rnn_output_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>
      <span class="n">out_dim</span> <span class="o">=</span> <span class="n">rnn_output_dim</span> <span class="o">+</span> <span class="n">atten_context_dim</span>
      <span class="n">state0</span><span class="o">.</span><span class="n">step_outs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">Zeros</span><span class="p">([</span><span class="n">dec_bs</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">],</span>
                                        <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
      <span class="n">target_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">emb</span><span class="p">,</span> <span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
      <span class="n">target_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ApplyDropout</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">target_embs</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
          <span class="nb">id</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">),</span>
          <span class="n">label</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span>
          <span class="n">weight</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">weights</span><span class="p">),</span>
          <span class="n">emb</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">target_embs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
          <span class="n">padding</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
          <span class="n">misc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">CreateTargetInfoMisc</span><span class="p">(</span><span class="n">targets</span><span class="p">),</span>
      <span class="p">)</span>

      <span class="c1"># If the theta in the recurrent loop contains fusion related variables,</span>
      <span class="c1"># it will allocate a large amount of memory even though it is not being</span>
      <span class="c1"># used and exceed current TPU HBM limit. Thus remove fusion theta from</span>
      <span class="c1"># the recurrent loop, and performs fusion outside the recurrent loop.</span>
      <span class="n">theta_no_fusion</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
      <span class="k">del</span> <span class="n">theta_no_fusion</span><span class="o">.</span><span class="n">fusion</span>
      <span class="n">recurrent_theta</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">=</span><span class="n">theta_no_fusion</span><span class="p">,</span> <span class="n">packed_src</span><span class="o">=</span><span class="n">packed_src</span><span class="p">)</span>
      <span class="n">state0_no_fusion</span> <span class="o">=</span> <span class="n">state0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
      <span class="k">del</span> <span class="n">state0_no_fusion</span><span class="o">.</span><span class="n">fusion_states</span>

      <span class="k">def</span> <span class="nf">RnnStep</span><span class="p">(</span><span class="n">recurrent_theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes one rnn step.&quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;single_decode_step&#39;</span><span class="p">):</span>
          <span class="n">step_outs</span><span class="p">,</span> <span class="n">state1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">SingleDecodeStep</span><span class="p">(</span>
              <span class="n">recurrent_theta</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
              <span class="n">recurrent_theta</span><span class="o">.</span><span class="n">packed_src</span><span class="p">,</span>
              <span class="n">inputs</span><span class="p">,</span>
              <span class="n">state0</span><span class="p">,</span>
              <span class="n">use_deterministic_random</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
          <span class="n">state1</span><span class="o">.</span><span class="n">step_outs</span> <span class="o">=</span> <span class="n">step_outs</span>
        <span class="c1"># TODO(syzhang, tsainath): Add SS into Functional Decoder, which</span>
        <span class="c1"># requires computing softmax logits.</span>
        <span class="n">state1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">PostStepDecoderStateUpdate</span><span class="p">(</span><span class="n">state1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">state1</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>

      <span class="n">accumulated_states</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">recurrent</span><span class="o">.</span><span class="n">Recurrent</span><span class="p">(</span><span class="n">recurrent_theta</span><span class="p">,</span>
                                                  <span class="n">state0_no_fusion</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
                                                  <span class="n">RnnStep</span><span class="p">)</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax_uses_attention</span><span class="p">:</span>
        <span class="n">step_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
            <span class="n">accumulated_states</span><span class="o">.</span><span class="n">step_outs</span><span class="p">,</span> <span class="p">[</span><span class="n">rnn_output_dim</span><span class="p">,</span> <span class="n">atten_context_dim</span><span class="p">],</span>
            <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">step_out</span> <span class="o">=</span> <span class="n">accumulated_states</span><span class="o">.</span><span class="n">step_outs</span>
      <span class="n">softmax_input</span><span class="p">,</span> <span class="n">state0</span><span class="o">.</span><span class="n">fusion_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">.</span><span class="n">fusion</span><span class="p">,</span> <span class="n">state0</span><span class="o">.</span><span class="n">fusion_states</span><span class="p">,</span> <span class="n">step_out</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
          <span class="n">inputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">misc</span><span class="p">)</span>
      <span class="c1"># TODO(syzhang): understand why we have to construct softmax outside the</span>
      <span class="c1"># recurrent loop; otherwise, the BProp numbers don&#39;t match.</span>
      <span class="n">seq_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ComputeLogits</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">softmax_input</span><span class="p">)</span>
      <span class="c1"># TODO(syzhang): supports AddAdditionalDecoderSummaries().</span>
      <span class="n">atten_states</span> <span class="o">=</span> <span class="n">accumulated_states</span><span class="o">.</span><span class="n">atten_states</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">atten_states</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">):</span>
        <span class="n">additional_atten_probs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span>
            <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">atten_states</span><span class="o">.</span><span class="n">FlattenItems</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;probs&#39;</span><span class="p">)</span>
        <span class="p">])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">additional_atten_probs</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">rnn_outs</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">cell</span><span class="o">.</span><span class="n">GetOutput</span><span class="p">(</span><span class="n">accumulated_states</span><span class="o">.</span><span class="n">rnn_states</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
          <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">)</span>
      <span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_AddDecoderActivationsSummary</span><span class="p">(</span>
          <span class="n">encoder_outputs</span><span class="p">,</span>
          <span class="n">targets</span><span class="p">,</span>
          <span class="n">accumulated_states</span><span class="o">.</span><span class="n">atten_probs</span><span class="p">,</span>
          <span class="n">rnn_outs</span><span class="p">,</span>
          <span class="n">softmax_input</span><span class="p">,</span>
          <span class="n">additional_atten_probs</span><span class="o">=</span><span class="n">additional_atten_probs</span><span class="p">,</span>
          <span class="n">target_alignments</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="s1">&#39;alignments&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
      <span class="c1"># seq_logits: [time, batch, num_classes].</span>
      <span class="n">adjusted_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">ComputeLogitsWithLM</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">fusion_states</span><span class="p">,</span>
                                                        <span class="n">seq_logits</span><span class="p">)</span>

      <span class="c1"># Forward confidence estimation module</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">confidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">lm_for_confidence</span><span class="p">:</span>
          <span class="n">lm_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">state0</span><span class="o">.</span><span class="n">fusion_states</span><span class="o">.</span><span class="n">lm_output</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">lm_output</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">confidence_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ExtractConfidenceFeatures</span><span class="p">(</span>
            <span class="n">theta</span><span class="p">,</span>
            <span class="n">targets</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">seq_logits</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">accumulated_states</span><span class="o">.</span><span class="n">atten_probs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
            <span class="n">lm_output</span><span class="o">=</span><span class="n">lm_output</span><span class="p">)</span>
        <span class="n">confidence_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">step_out</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">confidence_features</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">confidence_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">confidence</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">confidence</span><span class="p">,</span>
                                  <span class="n">tf</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">confidence_input</span><span class="p">)),</span>
            <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

      <span class="n">predictions</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
          <span class="c1"># Transpose to [batch, time, num_classes].</span>
          <span class="n">logits_without_bias</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">seq_logits</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
          <span class="n">logits</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">adjusted_logits</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
          <span class="c1"># softmax_input is of shape [time, batch, dim] for compatibility.</span>
          <span class="n">softmax_input</span><span class="o">=</span><span class="n">softmax_input</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">confidence</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># confidence_logits is of shape [batch, time], pre-sigmoid values</span>
        <span class="n">predictions</span><span class="o">.</span><span class="n">confidence_logits</span> <span class="o">=</span> <span class="n">confidence_logits</span>
      <span class="n">attention_map</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
          <span class="n">probs</span><span class="o">=</span><span class="n">accumulated_states</span><span class="o">.</span><span class="n">atten_probs</span><span class="p">,</span>
          <span class="n">contexts</span><span class="o">=</span><span class="n">accumulated_states</span><span class="o">.</span><span class="n">atten_context</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">additional_atten_probs</span><span class="p">:</span>
        <span class="n">attention_map</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
      <span class="c1"># Transpose attention probs from [target_length, batch, source_length] to</span>
      <span class="c1"># [batch, target_length, source_length].</span>
      <span class="n">predictions</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">attention_map</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span>
          <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
      <span class="k">return</span> <span class="n">predictions</span></div>

<div class="viewcode-block" id="AsrDecoderBase._ComputeLogits"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._ComputeLogits">[docs]</a>  <span class="k">def</span> <span class="nf">_ComputeLogits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">softmax_input</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvSoftmax</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">Logits</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">softmax_input</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># SoftmaxLayer.Logits() may not support 3-D inputs. So use FProp() with</span>
      <span class="c1"># fake labels.</span>
      <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="p">[</span><span class="n">softmax_input</span><span class="p">],</span>
          <span class="n">class_weights</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
              <span class="n">shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">softmax_input</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">softmax_input</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
          <span class="n">class_ids</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">softmax_input</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
      <span class="k">return</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">logits</span></div>

<div class="viewcode-block" id="AsrDecoderBase._ExtractConfidenceFeatures"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase._ExtractConfidenceFeatures">[docs]</a>  <span class="k">def</span> <span class="nf">_ExtractConfidenceFeatures</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                 <span class="n">theta</span><span class="p">,</span>
                                 <span class="n">labels</span><span class="p">,</span>
                                 <span class="n">logits</span><span class="p">,</span>
                                 <span class="n">atten_dists</span><span class="p">,</span>
                                 <span class="n">topk</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                 <span class="n">lm_output</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">target_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">emb</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">target_dists</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    <span class="n">target_probs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetSoftmaxProbsBySeqIndices</span><span class="p">(</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">target_top_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">target_dists</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">topk</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">target_top_prob_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
        <span class="n">target_top_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">target_top_prob_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_std</span><span class="p">(</span>
        <span class="n">target_top_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">atten_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">atten_dists</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">atten_top_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">atten_dists</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">topk</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">atten_top_prob_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
        <span class="n">atten_top_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">atten_top_prob_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_std</span><span class="p">(</span>
        <span class="n">atten_top_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">confidence_features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
        <span class="n">target_embs</span><span class="p">,</span> <span class="n">target_probs</span><span class="p">,</span> <span class="n">target_top_prob_mean</span><span class="p">,</span> <span class="n">target_top_prob_std</span><span class="p">,</span>
        <span class="n">atten_probs</span><span class="p">,</span> <span class="n">atten_top_prob_mean</span><span class="p">,</span> <span class="n">atten_top_prob_std</span>
    <span class="p">],</span>
                                    <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">lm_output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">lm_probs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetSoftmaxProbsBySeqIndices</span><span class="p">(</span>
          <span class="n">lm_output</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">confidence_features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">confidence_features</span><span class="p">,</span> <span class="n">lm_probs</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">confidence_features</span></div>

<div class="viewcode-block" id="AsrDecoderBase.SingleDecodeStep"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.SingleDecodeStep">[docs]</a>  <span class="k">def</span> <span class="nf">SingleDecodeStep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                       <span class="n">theta</span><span class="p">,</span>
                       <span class="n">packed_src</span><span class="p">,</span>
                       <span class="n">cur_target_info</span><span class="p">,</span>
                       <span class="n">decoder_step_state</span><span class="p">,</span>
                       <span class="n">per_step_src_padding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                       <span class="n">use_deterministic_random</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes one &#39;step&#39; of computation for the decoder.</span>

<span class="sd">    Must be implemented by sub-classes. Residual connections must also be taken</span>
<span class="sd">    care of in sub-classes.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A NestedMap object containing weights&#39; values of this layer and its</span>
<span class="sd">        children layers.</span>
<span class="sd">      packed_src: A NestedMap to represent the packed source tensors generated</span>
<span class="sd">        by the attention model.</span>
<span class="sd">      cur_target_info: TargetInfo namedtuple, which represents the targets which</span>
<span class="sd">        represents information about the target at this step. It is up to the</span>
<span class="sd">        various sub-classes to determine how to process the current target.</span>
<span class="sd">      decoder_step_state: DecoderStepState which encapsulates the state of the</span>
<span class="sd">        decoder before computing outputs at the current step.</span>
<span class="sd">      per_step_src_padding: Optional padding to be applied to the source_encs</span>
<span class="sd">        which overrides the default padding in source_paddings. Used, for</span>
<span class="sd">        example, by the Neural Transducer (NT) decoder.</span>
<span class="sd">      use_deterministic_random: whether to use deterministic random numbers when</span>
<span class="sd">        needed. Must be set to True if called from functional recurrent.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (step_out, new_decoder_state) which represent the outputs of the</span>
<span class="sd">      decoder (usually logits), and the new decoder state after processing the</span>
<span class="sd">      current step.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO(syzhang): unify the API to always pass in packed_src.</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Must be implemented by sub-classes.&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase.MiscZeroState"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.MiscZeroState">[docs]</a>  <span class="k">def</span> <span class="nf">MiscZeroState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">target_ids</span><span class="p">,</span> <span class="n">bs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns initial state for other miscellaneous states, if any.&quot;&quot;&quot;</span>
    <span class="n">misc_zero_state</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_label_prob</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">misc_zero_state</span><span class="o">.</span><span class="n">prev_predicted_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_ids</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">bs</span><span class="p">])</span>
      <span class="n">step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetGlobalStep</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">sampling_p</span> <span class="o">=</span> <span class="p">(</span><span class="n">step</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">prob_decay_start_step</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_decay_interval</span>
      <span class="n">groundtruth_p</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_label_prob</span> <span class="o">*</span> <span class="n">sampling_p</span><span class="p">)</span>
      <span class="n">groundtruth_p</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">groundtruth_p</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">min_ground_truth_prob</span><span class="p">)</span>
      <span class="n">groundtruth_p</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">groundtruth_p</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
      <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;ground_truth_sampling_probability&#39;</span><span class="p">,</span> <span class="n">groundtruth_p</span><span class="p">)</span>
      <span class="n">misc_zero_state</span><span class="o">.</span><span class="n">groundtruth_p</span> <span class="o">=</span> <span class="n">groundtruth_p</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">adapter_task_id_field</span><span class="p">:</span>
      <span class="c1"># encoder_outputs.encoded: [time, batch, dim]</span>
      <span class="n">source_bs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span><span class="p">,</span> <span class="mi">2</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
      <span class="c1"># Only task_ids of shape [batch] is supported</span>
      <span class="n">task_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
          <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">Get</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">adapter_task_id_field</span><span class="p">),</span> <span class="p">[</span><span class="n">source_bs</span><span class="p">])</span>
      <span class="n">multiplier</span> <span class="o">=</span> <span class="n">bs</span> <span class="o">//</span> <span class="n">source_bs</span>
      <span class="n">task_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">task_ids</span><span class="p">,</span> <span class="p">[</span><span class="n">multiplier</span><span class="p">])</span>
      <span class="n">misc_zero_state</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">adapter_task_id_field</span><span class="p">,</span> <span class="n">task_ids</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">misc_zero_state</span></div>

<div class="viewcode-block" id="AsrDecoderBase.TargetsToBeFedAtCurrentDecodeStep"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.TargetsToBeFedAtCurrentDecodeStep">[docs]</a>  <span class="k">def</span> <span class="nf">TargetsToBeFedAtCurrentDecodeStep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">time</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="p">,</span>
                                        <span class="n">target_info_tas</span><span class="p">,</span> <span class="n">seq_out_tas</span><span class="p">):</span>
    <span class="k">del</span> <span class="n">seq_out_tas</span>

    <span class="n">target_id</span> <span class="o">=</span> <span class="n">target_info_tas</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">target_info_tas</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">target_info_tas</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">time</span><span class="p">))</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">target_info_tas</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="n">target_info_tas</span><span class="o">.</span><span class="n">padding</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
    <span class="n">misc</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>

    <span class="c1"># Use different id and embedding for scheduled sampling.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_label_prob</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">dec_bs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">decoder_step_state</span><span class="o">.</span><span class="n">misc_states</span><span class="o">.</span><span class="n">prev_predicted_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">pick_groundtruth</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">([</span><span class="n">dec_bs</span><span class="p">],</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">random_seed</span><span class="p">),</span>
          <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">misc_states</span><span class="o">.</span><span class="n">groundtruth_p</span><span class="p">)</span>
      <span class="n">emb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
          <span class="n">pick_groundtruth</span><span class="p">,</span> <span class="n">target_info_tas</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">time</span><span class="p">),</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span>
              <span class="n">theta</span><span class="o">.</span><span class="n">emb</span><span class="p">,</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span>
                  <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">misc_states</span><span class="o">.</span><span class="n">prev_predicted_ids</span><span class="p">)))</span>
      <span class="n">target_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pick_groundtruth</span><span class="p">,</span> <span class="n">target_info_tas</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">time</span><span class="p">),</span>
                           <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">misc_states</span><span class="o">.</span><span class="n">prev_predicted_ids</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">AsrDecoderBase</span><span class="o">.</span><span class="n">TargetInfo</span><span class="p">(</span>
        <span class="nb">id</span><span class="o">=</span><span class="n">target_id</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
        <span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
        <span class="n">emb</span><span class="o">=</span><span class="n">emb</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">misc</span><span class="o">=</span><span class="n">misc</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoderBase.PostStepDecoderStateUpdate"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoderBase.PostStepDecoderStateUpdate">[docs]</a>  <span class="k">def</span> <span class="nf">PostStepDecoderStateUpdate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update decoder states and logits after SingleDecodeStep.</span>

<span class="sd">    Args:</span>
<span class="sd">      decoder_step_state: A NestedMap object which encapsulates decoder states.</span>
<span class="sd">      logits: a tensor, predicted logits.</span>

<span class="sd">    Returns:</span>
<span class="sd">      decoder_step_state.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: if scheduled sampling is used for functional unrolling or</span>
<span class="sd">                  if logits is None for while loop based unrolling.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">use_while_loop_based_unrolling</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">min_ground_truth_prob</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;SS is not yet supported&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">logits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;logits cannot be None&#39;</span><span class="p">)</span>
      <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span>

      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_label_prob</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">logits</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># log_probs: [bs, num_classes]</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
        <span class="c1"># log_prob_sample: [bs, 1]</span>
        <span class="n">log_prob_sample</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span>
            <span class="n">log_probs</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
        <span class="c1"># pred_ids: [bs]</span>
        <span class="n">pred_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">log_prob_sample</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="p">[</span><span class="n">bs</span><span class="p">])</span>
        <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">misc_states</span><span class="o">.</span><span class="n">prev_predicted_ids</span> <span class="o">=</span> <span class="n">pred_ids</span>
    <span class="k">return</span> <span class="n">decoder_step_state</span></div></div>


<div class="viewcode-block" id="AsrDecoder"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoder">[docs]</a><span class="k">class</span> <span class="nc">AsrDecoder</span><span class="p">(</span><span class="n">AsrDecoderBase</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Step-by-step decoder with LM fusion.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="AsrDecoder.Params"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoder.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;teacher_forcing&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;If True, at each RNN step we consume &#39;</span>
        <span class="s1">&#39;the previous target label.  If False, we instead consume zeros.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="AsrDecoder.AddAdditionalDecoderSummaries"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoder.AddAdditionalDecoderSummaries">[docs]</a>  <span class="k">def</span> <span class="nf">AddAdditionalDecoderSummaries</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">seq_out_tas</span><span class="p">,</span>
                                    <span class="n">softmax_input</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Add summaries not covered by the default activations summaries.</span>

<span class="sd">    Args:</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      targets: a NestedMap containing target info.</span>
<span class="sd">      seq_out_tas: a SequenceOutTensorArrays.</span>
<span class="sd">      softmax_input: a tensor of shape [batch, time, vocab_size].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">cluster_factory</span><span class="o">.</span><span class="n">Current</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">AddAdditionalDecoderSummaries</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span><span class="p">,</span>
                                                <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
                                                <span class="n">targets</span><span class="p">,</span> <span class="n">seq_out_tas</span><span class="p">,</span>
                                                <span class="n">softmax_input</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoder._ComputeAttention"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoder._ComputeAttention">[docs]</a>  <span class="k">def</span> <span class="nf">_ComputeAttention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                        <span class="n">theta</span><span class="p">,</span>
                        <span class="n">rnn_out</span><span class="p">,</span>
                        <span class="n">packed_src</span><span class="p">,</span>
                        <span class="n">attention_state</span><span class="p">,</span>
                        <span class="n">per_step_src_padding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">query_segment_id</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs attention and computes context vector.</span>

<span class="sd">    Can be overridden by a child class if attention is computed differently.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A NestedMap object containing weights for the attention layers.</span>
<span class="sd">        Expects a member named &#39;atten&#39;.</span>
<span class="sd">      rnn_out: A Tensor of shape [batch_size, query_dim]; output of the first</span>
<span class="sd">        layer of decoder RNN, which is the query vector used for attention.</span>
<span class="sd">      packed_src: A NestedMap returned by self.atten.InitForSourcePacked.</span>
<span class="sd">      attention_state: The attention state computed at the previous timestep.</span>
<span class="sd">        Varies with the type of attention, but is usually a Tensor or a</span>
<span class="sd">        NestedMap of Tensors of shape [batch_size, &lt;state_dim&gt;].</span>
<span class="sd">      per_step_src_padding: Source sequence padding to apply at this step.</span>
<span class="sd">      query_segment_id: a tensor of shape [batch_size].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple of 3 tensors:</span>

<span class="sd">      - The attention context vector: shaped [batch_size, context_dim].</span>
<span class="sd">      - The attention probability vector: shaped [batch_size, seq_len]</span>
<span class="sd">      - The attention state: A Tensor or a NestedMap of Tensors of shape</span>
<span class="sd">        [batch_size, &lt;state_dim&gt;].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">atten</span><span class="o">.</span><span class="n">ComputeContextVectorWithSource</span><span class="p">(</span>
        <span class="n">theta</span><span class="o">.</span><span class="n">atten</span><span class="p">,</span>
        <span class="n">packed_src</span><span class="p">,</span>
        <span class="n">rnn_out</span><span class="p">,</span>
        <span class="n">attention_state</span><span class="o">=</span><span class="n">attention_state</span><span class="p">,</span>
        <span class="n">per_step_source_padding</span><span class="o">=</span><span class="n">per_step_src_padding</span><span class="p">,</span>
        <span class="n">query_segment_id</span><span class="o">=</span><span class="n">query_segment_id</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoder.SingleDecodeStep"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoder.SingleDecodeStep">[docs]</a>  <span class="k">def</span> <span class="nf">SingleDecodeStep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                       <span class="n">theta</span><span class="p">,</span>
                       <span class="n">packed_src</span><span class="p">,</span>
                       <span class="n">cur_target_info</span><span class="p">,</span>
                       <span class="n">decoder_step_state</span><span class="p">,</span>
                       <span class="n">per_step_src_padding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                       <span class="n">use_deterministic_random</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decode one step.</span>

<span class="sd">    Note that the implementation of attention here follows the model in</span>
<span class="sd">    https://arxiv.org/pdf/1609.08144.pdf, detailed more in</span>
<span class="sd">    https://arxiv.org/pdf/1703.08581.pdf.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A NestedMap object containing weights&#39; values of this layer and its</span>
<span class="sd">        children layers.</span>
<span class="sd">      packed_src: A NestedMap to represent the packed source tensors generated</span>
<span class="sd">        by the attention model.</span>
<span class="sd">      cur_target_info: TargetInfo namedtuple, which represents the targets which</span>
<span class="sd">        represents information about the target at this step. It is up to the</span>
<span class="sd">        various sub-classes to determine how to process the current target.</span>
<span class="sd">      decoder_step_state: DecoderStepState which encapsulates the state of the</span>
<span class="sd">        decoder before computing outputs at the current step.</span>
<span class="sd">      per_step_src_padding: Optional padding to be applied to the source_encs</span>
<span class="sd">        which overrides the default padding in source_paddings. Used, for</span>
<span class="sd">        example, by the Neural Transducer (NT) decoder.</span>
<span class="sd">      use_deterministic_random: whether to use deterministic random numbers when</span>
<span class="sd">        needed. Must be set to True if called from functional recurrent.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (step_out, new_decoder_state) which represent the outputs of the</span>
<span class="sd">      decoder (usually logits), and the new decoder state after processing the</span>
<span class="sd">      current step.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">teacher_forcing</span><span class="p">:</span>
      <span class="n">prev_embs</span> <span class="o">=</span> <span class="n">cur_target_info</span><span class="o">.</span><span class="n">emb</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">prev_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">cur_target_info</span><span class="o">.</span><span class="n">emb</span><span class="p">)</span>

    <span class="n">misc_states</span> <span class="o">=</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">misc_states</span>
    <span class="n">new_rnn_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">new_rnn_states_0</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
        <span class="n">theta</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">rnn_states</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
            <span class="n">act</span><span class="o">=</span><span class="p">[</span><span class="n">prev_embs</span><span class="p">,</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">atten_context</span><span class="p">],</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">cur_target_info</span><span class="o">.</span><span class="n">padding</span><span class="p">))</span>
    <span class="n">new_rnn_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_rnn_states_0</span><span class="p">)</span>
    <span class="n">rnn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">GetOutput</span><span class="p">(</span><span class="n">new_rnn_states_0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">adapter_task_id_field</span><span class="p">:</span>
      <span class="c1"># rnn_out is [batch, dim], adapter layers requires [time, batch, dim]</span>
      <span class="n">rnn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adapters</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">adapters</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                       <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">rnn_out</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                                       <span class="n">misc_states</span><span class="o">.</span><span class="n">Get</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">adapter_task_id_field</span><span class="p">))</span>
      <span class="n">rnn_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">rnn_out</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="p">(</span><span class="n">new_atten_context</span><span class="p">,</span> <span class="n">new_atten_probs</span><span class="p">,</span>
     <span class="n">new_atten_states</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ComputeAttention</span><span class="p">(</span>
         <span class="n">theta</span><span class="p">,</span>
         <span class="n">rnn_out</span><span class="p">,</span>
         <span class="n">packed_src</span><span class="p">,</span>
         <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">atten_states</span><span class="p">,</span>
         <span class="n">per_step_src_padding</span><span class="o">=</span><span class="n">per_step_src_padding</span><span class="p">)</span>
    <span class="c1"># Here the attention context is being updated according to the</span>
    <span class="c1"># contextualizer (the default contextualizer is a no-op).</span>
    <span class="n">new_atten_context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">contextualizer</span><span class="o">.</span><span class="n">QueryAttention</span><span class="p">(</span>
        <span class="n">theta</span><span class="o">.</span><span class="n">contextualizer</span><span class="p">,</span> <span class="n">rnn_out</span><span class="p">,</span> <span class="n">misc_states</span><span class="p">,</span> <span class="n">new_atten_context</span><span class="p">,</span>
        <span class="n">packed_src</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cell</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="mi">1</span><span class="p">):</span>
      <span class="n">new_rnn_states_i</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">decoder_step_state</span><span class="o">.</span><span class="n">rnn_states</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
              <span class="n">act</span><span class="o">=</span><span class="p">[</span><span class="n">rnn_out</span><span class="p">,</span> <span class="n">new_atten_context</span><span class="p">],</span>
              <span class="n">padding</span><span class="o">=</span><span class="n">cur_target_info</span><span class="o">.</span><span class="n">padding</span><span class="p">))</span>
      <span class="n">new_rnn_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_rnn_states_i</span><span class="p">)</span>
      <span class="n">new_rnn_out</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">GetOutput</span><span class="p">(</span><span class="n">new_rnn_states_i</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">adapter_task_id_field</span><span class="p">:</span>
        <span class="n">new_rnn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adapters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">.</span><span class="n">adapters</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">new_rnn_out</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
            <span class="n">misc_states</span><span class="o">.</span><span class="n">Get</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">adapter_task_id_field</span><span class="p">))</span>
        <span class="n">new_rnn_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">new_rnn_out</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>
      <span class="n">new_rnn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ApplyDropout</span><span class="p">(</span>
          <span class="n">theta</span><span class="p">,</span>
          <span class="n">new_rnn_out</span><span class="p">,</span>
          <span class="n">deterministic</span><span class="o">=</span><span class="n">use_deterministic_random</span><span class="p">,</span>
          <span class="n">extra_seed</span><span class="o">=</span><span class="n">i</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">residual_start</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">rnn_out</span> <span class="o">+=</span> <span class="n">new_rnn_out</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">rnn_out</span> <span class="o">=</span> <span class="n">new_rnn_out</span>

    <span class="n">step_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">rnn_out</span><span class="p">,</span> <span class="n">new_atten_context</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">step_out</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
        <span class="n">rnn_states</span><span class="o">=</span><span class="n">new_rnn_states</span><span class="p">,</span>
        <span class="n">atten_context</span><span class="o">=</span><span class="n">new_atten_context</span><span class="p">,</span>
        <span class="n">atten_probs</span><span class="o">=</span><span class="n">new_atten_probs</span><span class="p">,</span>
        <span class="n">atten_states</span><span class="o">=</span><span class="n">new_atten_states</span><span class="p">,</span>
        <span class="n">misc_states</span><span class="o">=</span><span class="n">misc_states</span><span class="p">)</span></div>

<div class="viewcode-block" id="AsrDecoder._GetNumHypsForBeamSearch"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoder._GetNumHypsForBeamSearch">[docs]</a>  <span class="k">def</span> <span class="nf">_GetNumHypsForBeamSearch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns number of hypothesis times batch_size.</span>

<span class="sd">    This function can be overridden by a child class if the total number of</span>
<span class="sd">    hyps are to be computed in a different way, e.g., when the format of inputs</span>
<span class="sd">    change.</span>
<span class="sd">    Args:</span>
<span class="sd">      source_encs: A Tensor of [time, batch, dim] with source encodings.</span>
<span class="sd">      num_hyps_per_beam: Int, the number of hypothesis per example in the beam.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A Tensor with value batch * num_hyps_per_beam.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_hyps_per_beam</span></div>

<div class="viewcode-block" id="AsrDecoder._PostProcessAttenProbsForBeamSearch"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoder._PostProcessAttenProbsForBeamSearch">[docs]</a>  <span class="k">def</span> <span class="nf">_PostProcessAttenProbsForBeamSearch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the attention probabilities after optional post processing.</span>

<span class="sd">    This is a noop for the base class. But this function can be overridden</span>
<span class="sd">    by a child class, e.g., when the format of probabilities change.</span>
<span class="sd">    Args:</span>
<span class="sd">      atten_probs: A Tensor of [batch, source_len] dimension with atten probs.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A Tensor with processed atten_probs. The same as input in this case.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">atten_probs</span></div>

<div class="viewcode-block" id="AsrDecoder._InitBeamSearchStateCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoder._InitBeamSearchStateCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_InitBeamSearchStateCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
                                   <span class="n">num_hyps_per_beam</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">num_hyps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetNumHypsForBeamSearch</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span><span class="p">,</span>
                                             <span class="n">num_hyps_per_beam</span><span class="p">)</span>
    <span class="p">(</span><span class="n">rnn_states</span><span class="p">,</span> <span class="n">atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">atten_states</span><span class="p">,</span> <span class="n">fusion_states</span><span class="p">,</span>
     <span class="n">misc_states</span><span class="p">,</span> <span class="n">packed_src</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">InitDecoder</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
                                                 <span class="n">num_hyps</span><span class="p">)</span>
    <span class="c1"># Throw away packed_src. We re-compute it in _PreBeamSearchStepCallback</span>
    <span class="c1"># because we cannot pass &#39;packed_src&#39; through &#39;states&#39;. beam_search_helper</span>
    <span class="c1"># assumes that all Tensors in &#39;states&#39; have &#39;target_batch&#39; as the first</span>
    <span class="c1"># dimension.</span>
    <span class="k">del</span> <span class="n">packed_src</span>
    <span class="n">atten_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PostProcessAttenProbsForBeamSearch</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">)</span>
    <span class="n">all_atten_states</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;atten_context&#39;</span><span class="p">:</span> <span class="n">atten_context</span><span class="p">,</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">atten_probs</span><span class="p">,</span>
        <span class="s1">&#39;atten_states&#39;</span><span class="p">:</span> <span class="n">atten_states</span><span class="p">,</span>
    <span class="p">})</span>

    <span class="n">initial_results</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;log_probs&#39;</span><span class="p">:</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span><span class="p">],</span>
                         <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))),</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span>
            <span class="n">atten_probs</span><span class="p">,</span>
    <span class="p">})</span>
    <span class="n">other_states</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;time_step&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
        <span class="s1">&#39;rnn_states&#39;</span><span class="p">:</span> <span class="n">rnn_states</span><span class="p">,</span>
        <span class="s1">&#39;all_atten_states&#39;</span><span class="p">:</span> <span class="n">all_atten_states</span><span class="p">,</span>
        <span class="s1">&#39;fusion_states&#39;</span><span class="p">:</span> <span class="n">fusion_states</span><span class="p">,</span>
        <span class="s1">&#39;misc_states&#39;</span><span class="p">:</span> <span class="n">misc_states</span><span class="p">,</span>
    <span class="p">})</span>
    <span class="k">return</span> <span class="n">initial_results</span><span class="p">,</span> <span class="n">other_states</span></div>

<div class="viewcode-block" id="AsrDecoder._PreBeamSearchStepCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoder._PreBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_PreBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">step_ids</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span>
                                 <span class="n">num_hyps_per_beam</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">step_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">step_ids</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">emb</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">step_ids</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">prev_rnn_states</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">rnn_states</span>
    <span class="n">prev_atten_states</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">all_atten_states</span><span class="o">.</span><span class="n">atten_states</span>
    <span class="n">prev_atten_context</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">all_atten_states</span><span class="o">.</span><span class="n">atten_context</span>
    <span class="n">prev_atten_probs</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">all_atten_states</span><span class="o">.</span><span class="n">atten_probs</span>
    <span class="n">prev_fusion_states</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">fusion_states</span>
    <span class="n">prev_misc_states</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">misc_states</span>

    <span class="n">prev_decoder_step_state</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
        <span class="n">rnn_states</span><span class="o">=</span><span class="n">prev_rnn_states</span><span class="p">,</span>
        <span class="n">atten_context</span><span class="o">=</span><span class="n">prev_atten_context</span><span class="p">,</span>
        <span class="n">atten_probs</span><span class="o">=</span><span class="n">prev_atten_probs</span><span class="p">,</span>
        <span class="n">atten_states</span><span class="o">=</span><span class="n">prev_atten_states</span><span class="p">,</span>
        <span class="n">misc_states</span><span class="o">=</span><span class="n">prev_misc_states</span><span class="p">)</span>
    <span class="c1"># TODO(prabhavalkar): Must handle CreateMiscTargetInfo during beam search</span>
    <span class="c1"># eval.</span>
    <span class="n">cur_target_info</span> <span class="o">=</span> <span class="n">AsrDecoderBase</span><span class="o">.</span><span class="n">TargetInfo</span><span class="p">(</span>
        <span class="nb">id</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">step_ids</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
        <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">emb</span><span class="o">=</span><span class="n">embs</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">step_paddings</span><span class="p">,</span>
        <span class="n">misc</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">())</span>

    <span class="n">packed_src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_InitAttention</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
    <span class="n">step_out</span><span class="p">,</span> <span class="n">new_decoder_step_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">SingleDecodeStep</span><span class="p">(</span>
        <span class="n">theta</span><span class="p">,</span>
        <span class="n">packed_src</span><span class="p">,</span>
        <span class="n">cur_target_info</span><span class="o">=</span><span class="n">cur_target_info</span><span class="p">,</span>
        <span class="n">decoder_step_state</span><span class="o">=</span><span class="n">prev_decoder_step_state</span><span class="p">)</span>
    <span class="p">(</span><span class="n">atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">rnn_states</span><span class="p">,</span> <span class="n">atten_states</span><span class="p">,</span>
     <span class="n">misc_states</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">new_decoder_step_state</span><span class="o">.</span><span class="n">atten_context</span><span class="p">,</span>
                     <span class="n">new_decoder_step_state</span><span class="o">.</span><span class="n">atten_probs</span><span class="p">,</span>
                     <span class="n">new_decoder_step_state</span><span class="o">.</span><span class="n">rnn_states</span><span class="p">,</span>
                     <span class="n">new_decoder_step_state</span><span class="o">.</span><span class="n">atten_states</span><span class="p">,</span>
                     <span class="n">new_decoder_step_state</span><span class="o">.</span><span class="n">misc_states</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax_uses_attention</span><span class="p">:</span>
      <span class="c1"># [batch, dims]</span>
      <span class="n">softmax_input</span> <span class="o">=</span> <span class="n">step_out</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># Strip the attention context from the last dimension of softmax_input.</span>
      <span class="c1"># TODO(prabhavalkar): This currently assumes that the context is appended</span>
      <span class="c1"># to the end, see tf.concat in</span>
      <span class="c1"># AsrDecoderBase.ComputePredictionsFunctional().RnnStep().  Refactor the</span>
      <span class="c1"># code so as to remove this assumption.</span>
      <span class="n">atten_context_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_GetAttenContextDim</span><span class="p">()</span>
      <span class="n">rnn_output_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn_cell</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span>
      <span class="n">softmax_input</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
          <span class="n">step_out</span><span class="p">,</span> <span class="p">[</span><span class="n">rnn_output_dim</span><span class="p">,</span> <span class="n">atten_context_dim</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">softmax_input</span><span class="p">,</span> <span class="n">fusion_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">fusion</span><span class="p">,</span>
                                                     <span class="n">prev_fusion_states</span><span class="p">,</span>
                                                     <span class="n">softmax_input</span><span class="p">,</span>
                                                     <span class="n">cur_target_info</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                                                     <span class="n">cur_target_info</span><span class="o">.</span><span class="n">padding</span><span class="p">)</span>

    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ComputeLogits</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">softmax_input</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion</span><span class="o">.</span><span class="n">ComputeLogitsWithLM</span><span class="p">(</span>
        <span class="n">fusion_states</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">is_eval</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_unnormalized_logits_as_log_probs</span><span class="p">:</span>
      <span class="n">log_probs</span> <span class="o">=</span> <span class="n">logits</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>

    <span class="n">atten_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PostProcessAttenProbsForBeamSearch</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">)</span>
    <span class="n">bs_results</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">atten_probs</span><span class="p">,</span>
        <span class="s1">&#39;log_probs&#39;</span><span class="p">:</span> <span class="n">log_probs</span><span class="p">,</span>
    <span class="p">})</span>
    <span class="n">all_atten_states</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;atten_context&#39;</span><span class="p">:</span> <span class="n">atten_context</span><span class="p">,</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">atten_probs</span><span class="p">,</span>
        <span class="s1">&#39;atten_states&#39;</span><span class="p">:</span> <span class="n">atten_states</span><span class="p">,</span>
    <span class="p">})</span>
    <span class="n">new_states</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;time_step&#39;</span><span class="p">:</span> <span class="n">states</span><span class="o">.</span><span class="n">time_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s1">&#39;rnn_states&#39;</span><span class="p">:</span> <span class="n">rnn_states</span><span class="p">,</span>
        <span class="s1">&#39;all_atten_states&#39;</span><span class="p">:</span> <span class="n">all_atten_states</span><span class="p">,</span>
        <span class="s1">&#39;fusion_states&#39;</span><span class="p">:</span> <span class="n">fusion_states</span><span class="p">,</span>
        <span class="s1">&#39;misc_states&#39;</span><span class="p">:</span> <span class="n">misc_states</span><span class="p">,</span>
    <span class="p">})</span>
    <span class="k">return</span> <span class="n">bs_results</span><span class="p">,</span> <span class="n">new_states</span></div>

<div class="viewcode-block" id="AsrDecoder._PostBeamSearchStepCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.asr.decoder.html#lingvo.tasks.asr.decoder.AsrDecoder._PostBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_PostBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">new_step_ids</span><span class="p">,</span>
                                  <span class="n">states</span><span class="p">):</span>
    <span class="k">del</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">new_step_ids</span>
    <span class="k">return</span> <span class="n">states</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2018.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>