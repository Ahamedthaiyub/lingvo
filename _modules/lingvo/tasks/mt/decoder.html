

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>lingvo.tasks.mt.decoder &mdash; Lingvo  documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> Lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../lingvo.html">lingvo package</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>lingvo.tasks.mt.decoder</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for lingvo.tasks.mt.decoder</h1><div class="highlight"><pre>
<span></span><span class="c1"># Lint as: python3</span>
<span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1">#</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;Machine translation decoder.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">lingvo.compat</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">attention</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">base_decoder</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">batch_major_attention</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">layers_with_attention</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">model_helper</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">plot</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">py_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">quant_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">rnn_cell</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">rnn_layers</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="kn">import</span> <span class="n">summary_utils</span>


<div class="viewcode-block" id="MTBaseDecoder"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder">[docs]</a><span class="k">class</span> <span class="nc">MTBaseDecoder</span><span class="p">(</span><span class="n">base_decoder</span><span class="o">.</span><span class="n">BaseBeamSearchDecoder</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Base class for Lingvo MT decoders.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="MTBaseDecoder.Params"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;label_smoothing&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Label smoothing class.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span> <span class="s1">&#39;Softmax params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;per_word_avg_loss&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Compute loss averaged per word. If False &#39;</span>
        <span class="s1">&#39;loss is computed averaged per sequence.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;unidi_rnn_type&#39;</span><span class="p">,</span> <span class="s1">&#39;func&#39;</span><span class="p">,</span> <span class="s1">&#39;Options: func, native_cudnn. &#39;</span>
             <span class="s1">&#39;func: FRNN, native_cudnn: CuDNNLSTM.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;feed_attention_context_vec_to_softmax&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;Whether to concatenate attention context vector to rnn output&#39;</span>
             <span class="s1">&#39; before softmax.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;per_example_tensors&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Return per example tensors&#39;</span><span class="p">)</span>

    <span class="c1"># Default config for the softmax part.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">32000</span>  <span class="c1"># 32k</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_shards</span> <span class="o">=</span> <span class="mi">8</span>

    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;smoother&#39;</span>
      <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;smoother&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="p">)</span>

<div class="viewcode-block" id="MTBaseDecoder.UpdateTargetVocabSize"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder.UpdateTargetVocabSize">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">UpdateTargetVocabSize</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">wpm_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the params with the given vocab size and wpm model.</span>

<span class="sd">    Args:</span>
<span class="sd">      p: model params.</span>
<span class="sd">      vocab_size: size of the vocabulary.</span>
<span class="sd">      wpm_model: file name prefix pointing to a wordpiece model.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Model params updated with the vocab size and wpm model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">vocab_size</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="MTBaseDecoder._ComputeXentLoss"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder._ComputeXentLoss">[docs]</a>  <span class="k">def</span> <span class="nf">_ComputeXentLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                       <span class="n">theta</span><span class="p">,</span>
                       <span class="n">softmax_input</span><span class="p">,</span>
                       <span class="n">target_labels</span><span class="p">,</span>
                       <span class="n">target_weights</span><span class="p">,</span>
                       <span class="n">target_paddings</span><span class="p">,</span>
                       <span class="n">target_segment_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                       <span class="n">time_axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes cross-entropy loss given the softmax input, labels and weights.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this</span>
<span class="sd">        layer and its children layers.</span>
<span class="sd">      softmax_input: A tensor of shape [time, batch, p.softmax.input_dim].</span>
<span class="sd">      target_labels: A matrix of tf.int32. [time, batch].</span>
<span class="sd">      target_weights: A matrix of params.dtype. [time, batch].</span>
<span class="sd">      target_paddings: A matrix of params.dtype. [time, batch].</span>
<span class="sd">      target_segment_ids: A matrix of params.dtype. [time, batch].</span>
<span class="sd">      time_axis: If 0, the inputs are time-major: [time, batch, ...]; if 1, the</span>
<span class="sd">        inputs are batch-major: [batch, time, ...].</span>

<span class="sd">    Returns:</span>
<span class="sd">      The cross entropy loss.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">softmax_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">softmax_input</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="p">[</span><span class="n">softmax_input</span><span class="p">],</span>
          <span class="n">class_weights</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
          <span class="n">class_ids</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_labels</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># [time, batch, num_classes]</span>
      <span class="k">if</span> <span class="n">time_axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">target_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">smoother</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
                <span class="n">theta</span><span class="o">.</span><span class="n">smoother</span><span class="p">,</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">),</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">target_labels</span><span class="p">),</span>
                <span class="n">target_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">target_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">smoother</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">.</span><span class="n">smoother</span><span class="p">,</span> <span class="n">target_paddings</span><span class="p">,</span> <span class="n">target_labels</span><span class="p">,</span> <span class="n">target_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
      <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="p">[</span><span class="n">softmax_input</span><span class="p">],</span>
          <span class="n">class_weights</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
          <span class="n">class_probabilities</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_probs</span><span class="p">,</span>
                                         <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">xent_loss</span></div>

<div class="viewcode-block" id="MTBaseDecoder._ComputeSoftmaxMetrics"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder._ComputeSoftmaxMetrics">[docs]</a>  <span class="k">def</span> <span class="nf">_ComputeSoftmaxMetrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                             <span class="n">xent_loss</span><span class="p">,</span>
                             <span class="n">target_labels</span><span class="p">,</span>
                             <span class="n">target_weights</span><span class="p">,</span>
                             <span class="n">target_segment_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">time_axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes cross-entropy metrics given the cross-entropy loss.</span>

<span class="sd">    Args:</span>
<span class="sd">      xent_loss: The output of `_ComputeXentLoss`.</span>
<span class="sd">      target_labels: A matrix of tf.int32. [time, batch].</span>
<span class="sd">      target_weights: A matrix of params.dtype. [time, batch].</span>
<span class="sd">      target_segment_ids: A matrix of params.dtype. [time, batch].</span>
<span class="sd">      time_axis: If 0, the inputs are time-major: [time, batch, ...]; if 1, the</span>
<span class="sd">        inputs are batch-major: [batch, time, ...].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (metrics, per_example_tensors).</span>
<span class="sd">        metrics:</span>
<span class="sd">          A dictionary containing metrics for the xent loss and prediction</span>
<span class="sd">          accuracy.</span>
<span class="sd">        per_example_tensors:</span>
<span class="sd">          A dictionary of per-example tensors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_word_avg_loss</span><span class="p">:</span>
      <span class="n">final_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">avg_xent</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
      <span class="n">loss_weight</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">total_weight</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;num_predictions&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># NOTE: Per-sequence loss is the sum of each example&#39;s loss.  The</span>
      <span class="c1"># final loss for a training batch is the mean loss of sequences in</span>
      <span class="c1"># the batch.</span>
      <span class="c1"># [time, batch]</span>
      <span class="n">per_example_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">per_example_xent</span><span class="p">,</span>
                                    <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">))</span>
      <span class="n">per_sequence_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
          <span class="n">per_example_loss</span> <span class="o">*</span> <span class="n">target_weights</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">time_axis</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">target_segment_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
            <span class="s1">&#39;Need target segment ids for &#39;</span>
            <span class="s1">&#39;normalizing loss when training with packed inputs.&#39;</span><span class="p">)</span>
        <span class="n">num_samples_per_row</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">target_segment_ids</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">num_samples_per_row</span><span class="p">)</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">per_sequence_loss</span><span class="p">)</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
            <span class="n">num_samples</span><span class="p">,</span> <span class="n">per_sequence_loss</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">per_sequence_loss</span><span class="p">)</span>
      <span class="n">loss_weight</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">per_sequence_loss</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">final_loss</span><span class="p">,</span> <span class="n">loss_weight</span><span class="p">),</span>
        <span class="s1">&#39;log_pplx&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">avg_xent</span><span class="p">,</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">total_weight</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="n">per_example_tensors</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_example_tensors</span><span class="p">:</span>
      <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;per_example_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
          <span class="n">xent_loss</span><span class="o">.</span><span class="n">per_example_xent</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">))</span>
      <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;per_sequence_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
          <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;per_example_loss&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">target_weights</span><span class="p">,</span>
          <span class="n">axis</span><span class="o">=</span><span class="n">time_axis</span><span class="p">)</span>
      <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;per_sequence_loss&#39;</span><span class="p">]</span>
      <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
          <span class="n">xent_loss</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">0</span><span class="p">))</span>
      <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;log_probs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
          <span class="n">xent_loss</span><span class="o">.</span><span class="n">log_probs</span><span class="p">,</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">0</span><span class="p">))</span>

    <span class="c1"># NOTE: tf.argmax is not implemented for the JF backend, see b/36093673</span>
    <span class="c1"># Skip the fraction_of_correct_next_step_preds during training.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">:</span>
      <span class="n">logits</span> <span class="o">=</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">logits</span>
      <span class="n">correct_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_labels</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])),</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">correct_next_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
          <span class="n">correct_preds</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">target_weights</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
      <span class="n">num_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">target_weights</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
      <span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span>
          <span class="n">correct_next_preds</span> <span class="o">/</span> <span class="n">num_preds</span><span class="p">,</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fraction_of_correct_next_step_preds&#39;</span><span class="p">)</span>
      <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;fraction_of_correct_next_step_preds&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">num_preds</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">per_example_tensors</span></div>

<div class="viewcode-block" id="MTBaseDecoder._FPropSoftmax"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder._FPropSoftmax">[docs]</a>  <span class="k">def</span> <span class="nf">_FPropSoftmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                    <span class="n">theta</span><span class="p">,</span>
                    <span class="n">softmax_input</span><span class="p">,</span>
                    <span class="n">target_labels</span><span class="p">,</span>
                    <span class="n">target_weights</span><span class="p">,</span>
                    <span class="n">target_paddings</span><span class="p">,</span>
                    <span class="n">target_segment_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">time_axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes cross-entropy loss given the softmax input, labels and weights.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      softmax_input: A tensor of shape [time, batch, p.softmax.input_dim].</span>
<span class="sd">      target_labels: A matrix of tf.int32. [time, batch].</span>
<span class="sd">      target_weights: A matrix of params.dtype. [time, batch].</span>
<span class="sd">      target_paddings: A matrix of params.dtype. [time, batch].</span>
<span class="sd">      target_segment_ids: A matrix of params.dtype. [time, batch].</span>
<span class="sd">      time_axis: If 0, the inputs are time-major: [time, batch, ...]; if 1, the</span>
<span class="sd">        inputs are batch-major: [batch, time, ...].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (metrics, per_example_tensors).</span>
<span class="sd">        metrics:</span>
<span class="sd">          A dictionary containing metrics for the xent loss and prediction</span>
<span class="sd">          accuracy.</span>
<span class="sd">        per_example_tensors:</span>
<span class="sd">          A dictionary of per-example tensors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ComputeXentLoss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">softmax_input</span><span class="p">,</span> <span class="n">target_labels</span><span class="p">,</span>
                                      <span class="n">target_weights</span><span class="p">,</span> <span class="n">target_paddings</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ComputeSoftmaxMetrics</span><span class="p">(</span><span class="n">xent_loss</span><span class="p">,</span> <span class="n">target_labels</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">,</span>
                                       <span class="n">target_segment_ids</span><span class="p">,</span> <span class="n">time_axis</span><span class="o">=</span><span class="n">time_axis</span><span class="p">)</span></div>

<div class="viewcode-block" id="MTBaseDecoder.ComputeLoss"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder.ComputeLoss">[docs]</a>  <span class="k">def</span> <span class="nf">ComputeLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Populates a metrics dictionary based on the output of ComputePredictions.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: Nested map describing decoder model parameters.</span>
<span class="sd">      predictions: NestedMap describing the decoding process, requiring:</span>
<span class="sd">        .softmax_input: Tensor of shape [time, batch, params.softmax.input_dim].</span>
<span class="sd">      targets: NestedMap describing the target sequences.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Two dicts.</span>

<span class="sd">        - A map from metric name (a python string) to a tuple (value, weight).</span>
<span class="sd">          Both value and weight are scalar Tensors.</span>
<span class="sd">        - A map from name to arbitrary tensors, where the first dimension must</span>
<span class="sd">          be the batch index.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">segment_id</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
      <span class="n">segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">segment_ids</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">):</span>
      <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">softmax_input</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_FPropSoftmax</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span>
                              <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">weights</span><span class="p">),</span>
                              <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">),</span> <span class="n">segment_id</span><span class="p">)</span></div>

<div class="viewcode-block" id="MTBaseDecoder._TruncateTargetSequence"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder._TruncateTargetSequence">[docs]</a>  <span class="k">def</span> <span class="nf">_TruncateTargetSequence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Truncate padded time steps from all sequences.&quot;&quot;&quot;</span>
    <span class="c1"># The following tensors are all in the [batch, time] shape.</span>
    <span class="c1"># Let&#39;s make a copy of targets.</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">target_ids</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">ids</span>
    <span class="n">target_labels</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">labels</span>
    <span class="n">target_weights</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">weights</span>
    <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span>
    <span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">target_paddings</span><span class="p">,</span> <span class="mi">1</span><span class="p">))),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">)</span>
    <span class="c1"># Assert to make sure after max_seq_length, all are padded steps for all</span>
    <span class="c1"># sequences.</span>
    <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">([</span>
        <span class="n">py_utils</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">[:,</span> <span class="n">max_seq_length</span><span class="p">:]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">))</span>
    <span class="p">],</span> <span class="n">target_paddings</span><span class="p">)</span>
    <span class="n">target_ids</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">([</span>
        <span class="n">py_utils</span><span class="o">.</span><span class="n">AssertIdShape</span><span class="p">(</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_ids</span><span class="p">),</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_labels</span><span class="p">),</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">),</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">))</span>
    <span class="p">],</span> <span class="n">target_ids</span><span class="p">)</span>
    <span class="n">targets</span><span class="o">.</span><span class="n">ids</span> <span class="o">=</span> <span class="n">target_ids</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_seq_length</span><span class="p">]</span>
    <span class="n">targets</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">target_labels</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_seq_length</span><span class="p">]</span>
    <span class="n">targets</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">target_weights</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_seq_length</span><span class="p">]</span>
    <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span> <span class="o">=</span> <span class="n">target_paddings</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_seq_length</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">targets</span></div>

<div class="viewcode-block" id="MTBaseDecoder._AddAttenProbsSummary"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder._AddAttenProbsSummary">[docs]</a>  <span class="k">def</span> <span class="nf">_AddAttenProbsSummary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Add summary of attention probs.</span>

<span class="sd">    Args:</span>
<span class="sd">      source_paddings: source padding, of shape [src_len, src_batch].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">        predict. Each tensor in targets is of shape [tgt_batch, tgt_len].</span>
<span class="sd">      atten_probs: a list of attention probs, each element is of shape [tgt_len,</span>
<span class="sd">        tgt_batch, src_len].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">add_summary</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_AddAttenProbsImageSummary</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_AddAttenProbsHistogramSummary</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">)</span></div>

<div class="viewcode-block" id="MTBaseDecoder._AddAttenProbsHistogramSummary"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder._AddAttenProbsHistogramSummary">[docs]</a>  <span class="k">def</span> <span class="nf">_AddAttenProbsHistogramSummary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Add histogram summary of attention probs.</span>

<span class="sd">    Args:</span>
<span class="sd">      atten_probs: a list of attention probs, each element is of shape [tgt_len,</span>
<span class="sd">        tgt_batch, src_len].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">probs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">):</span>
      <span class="c1"># a prefix from the context will be used, which looks like</span>
      <span class="c1"># fprop/wmt14_en_de_transformer/tower_0_0/dec/</span>
      <span class="n">summary_utils</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;atten</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">probs</span><span class="p">)</span></div>

<div class="viewcode-block" id="MTBaseDecoder._AddAttenProbsImageSummary"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder._AddAttenProbsImageSummary">[docs]</a>  <span class="k">def</span> <span class="nf">_AddAttenProbsImageSummary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Add image summary of attention probs.</span>

<span class="sd">    Args:</span>
<span class="sd">      source_paddings: source padding, of shape [src_len, src_batch].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">        predict. Each tensor in targets is of shape [tgt_batch, tgt_len].</span>
<span class="sd">      atten_probs: a list of attention probs, each element is of shape [tgt_len,</span>
<span class="sd">        tgt_batch, src_len].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">PlotAttention</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">cur_atten_probs</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">set_x_label</span><span class="p">):</span>
      <span class="n">plot</span><span class="o">.</span><span class="n">AddImage</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">cur_atten_probs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
      <span class="n">axes</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">plot</span><span class="o">.</span><span class="n">ToUnicode</span><span class="p">(</span><span class="s1">&#39;Output sequence index&#39;</span><span class="p">),</span> <span class="n">wrap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">set_x_label</span><span class="p">:</span>
        <span class="n">axes</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">plot</span><span class="o">.</span><span class="n">ToUnicode</span><span class="p">(</span><span class="s1">&#39;Input sequence index&#39;</span><span class="p">),</span> <span class="n">wrap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">srclen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">source_paddings</span><span class="p">[:,</span> <span class="n">index</span><span class="p">])),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">tgtlen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:])),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">num_rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">plot</span><span class="o">.</span><span class="n">MatplotlibFigureSummary</span><span class="p">(</span>
        <span class="s1">&#39;decoder_example&#39;</span><span class="p">,</span>
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">num_rows</span><span class="p">),</span>
        <span class="n">max_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">subplot_grid_shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">as</span> <span class="n">fig</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">probs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">):</span>
        <span class="c1"># Extract first entry in batch of attention prob matrices</span>
        <span class="c1"># [tgt_len, src_len]</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[:,</span> <span class="n">index</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">probs</span><span class="p">[:</span><span class="n">tgtlen</span><span class="p">,</span> <span class="p">:</span><span class="n">srclen</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">AddSubplot</span><span class="p">([</span><span class="n">probs</span><span class="p">],</span>
                       <span class="n">PlotAttention</span><span class="p">,</span>
                       <span class="n">title</span><span class="o">=</span><span class="s1">&#39;atten_probs_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span>
                       <span class="n">set_x_label</span><span class="o">=</span><span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span></div>

<div class="viewcode-block" id="MTBaseDecoder._ExpandToNumHyps"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder._ExpandToNumHyps">[docs]</a>  <span class="k">def</span> <span class="nf">_ExpandToNumHyps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_enc_len</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Repeat each value according to num hyps.</span>

<span class="sd">    Args:</span>
<span class="sd">      source_enc_len: source encoder length; int [batch].</span>
<span class="sd">      num_hyps_per_beam: number of hypotheses</span>

<span class="sd">    Returns:</span>
<span class="sd">      New version of source_enc_len; int [batch * num_hyps_per_beam].</span>
<span class="sd">      Target_batch is (num_hyps_per_beam * batch).</span>
<span class="sd">      Example: src_enc_len = [3, 2, 1] and num_hyps_per_beam = 2</span>
<span class="sd">      --&gt; [3, 2, 1, 3, 2, 1]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">source_enc_len</span><span class="p">,</span> <span class="n">multiples</span><span class="o">=</span><span class="p">[</span><span class="n">num_hyps_per_beam</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">x</span></div></div>


<div class="viewcode-block" id="MTDecoderV1"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1">[docs]</a><span class="k">class</span> <span class="nc">MTDecoderV1</span><span class="p">(</span><span class="n">MTBaseDecoder</span><span class="p">,</span> <span class="n">quant_utils</span><span class="o">.</span><span class="n">QuantizableLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;MT decoder v1.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="MTDecoderV1.Params"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="c1"># Shared embedding.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;emb&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span> <span class="s1">&#39;Embedding layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;source_dim&#39;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;Dimension of the source encoding.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;attention&#39;</span><span class="p">,</span> <span class="n">attention</span><span class="o">.</span><span class="n">AdditiveAttention</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Additive attention params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;atten_rnn_cell_tpl&#39;</span><span class="p">,</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Attention RNNCell params template.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;rnn_cell_tpl&#39;</span><span class="p">,</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;RNNCell params template.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;rnn_cell_dim&#39;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;size of the rnn cells.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;rnn_layers&#39;</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;Number of rnn layers.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;residual_start&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;Start residual connections from this layer.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;atten_rnn_cls&#39;</span><span class="p">,</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">FRNNWithAttention</span><span class="p">,</span>
             <span class="s1">&#39;Which atten rnn cls to use.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;use_prev_atten_ctx&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;If True, all decoder layers use previous attention context as &#39;</span>
             <span class="s1">&#39;input. Otherwise, only first decoder layer uses previous &#39;</span>
             <span class="s1">&#39;attention context and the rest of the layers use current &#39;</span>
             <span class="s1">&#39;attention context.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;dropout_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;Prob at which we do dropout.&#39;</span><span class="p">)</span>
    <span class="c1"># Default value was mildly tuned. Could be further tuned in the future.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;qlogsoftmax_range_min&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mf">10.0</span><span class="p">,</span> <span class="s1">&#39;Quantization of the output of &#39;</span>
             <span class="s1">&#39;log softmax.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;use_zero_atten_state&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;To use zero attention state &#39;</span>
        <span class="s1">&#39;instead of computing attention with zero query vector.&#39;</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;cc_schedule&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Clipping cap schedule.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;init_step_ids&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;Initializes beam search with first target id instead of &lt;s&gt;.&#39;</span>
        <span class="s1">&#39;Use this when decoding starts with target_lang id intead of &lt;s&gt; &#39;</span>
        <span class="s1">&#39;token at time step 0. Make sure the training data has &#39;</span>
        <span class="s1">&#39;target_lang id as the first token in target sequence.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;disallow_misaligned_eos&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;When input contains multiple sentences, disallows EOS until &#39;</span>
        <span class="s1">&#39;the hypothesis contains at least the same number of sentences &#39;</span>
        <span class="s1">&#39;as the input source. Must also set p.sentence_boundary_token_id.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;sentence_boundary_token_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;None, or an int. The token id that separates different sentences.&#39;</span><span class="p">)</span>

    <span class="n">disable_vn</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">VariationalNoiseParams</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">default_params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.04</span><span class="p">)</span>

    <span class="c1"># Default config for the embedding.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">vn</span> <span class="o">=</span> <span class="n">disable_vn</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">32000</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">max_num_shards</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">default_params_init</span>

    <span class="c1"># Default config for the attention model.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">vn</span> <span class="o">=</span> <span class="n">disable_vn</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Filled in after dims are known.</span>
    <span class="c1"># Default config for the attention rnn cell.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">atten_rnn_cell_tpl</span><span class="o">.</span><span class="n">vn</span> <span class="o">=</span> <span class="n">disable_vn</span>
    <span class="n">p</span><span class="o">.</span><span class="n">atten_rnn_cell_tpl</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">default_params_init</span>
    <span class="c1"># Default config for the rnn cell.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_tpl</span><span class="o">.</span><span class="n">vn</span> <span class="o">=</span> <span class="n">disable_vn</span>
    <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_tpl</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">default_params_init</span>
    <span class="c1"># Default config for the softmax part.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">vn</span> <span class="o">=</span> <span class="n">disable_vn</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">32000</span>  <span class="c1"># 32k</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_shards</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">default_params_init</span>

    <span class="c1"># Default config for beam search.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">length_normalization</span> <span class="o">=</span> <span class="mf">0.2</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">coverage_penalty</span> <span class="o">=</span> <span class="mf">0.2</span>

    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="MTDecoderV1.UpdateTargetVocabSize"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1.UpdateTargetVocabSize">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">UpdateTargetVocabSize</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">wpm_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Updates the params with the input vocab_size and WPM model.</span>

<span class="sd">    Args:</span>
<span class="sd">      p: model params.</span>
<span class="sd">      vocab_size: size of the vocabulary.</span>
<span class="sd">      wpm_model: file name prefix pointing to a wordpiece model.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Model params updated with the vocab size and wpm model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">UpdateTargetVocabSize</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">disallow_misaligned_eos</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">sentence_boundary_token_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;When p.disallow_misaligned_eos is set, &#39;</span>
                       <span class="s1">&#39;must specify p.sentence_boundary_token_id.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">cls</span> <span class="o">==</span> <span class="n">layers</span><span class="o">.</span><span class="n">SharedSoftmaxLayer</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">cc_schedule</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">cc_schedule</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;cc_schedule&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">cc_schedule</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span><span class="p">:</span>
      <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;emb&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">query_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">packed_input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">params_init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span>
          <span class="mf">1.</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">query_dim</span><span class="p">),</span>
          <span class="n">seed</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
    <span class="n">atten_params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>

    <span class="n">params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">atten_rnn_cell_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
    <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;atten_rnn&#39;</span>
    <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">params</span><span class="o">.</span><span class="n">reset_cell_state</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
    <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span>
    <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span>
    <span class="n">atten_rnn_cell</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>

    <span class="n">params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">atten_rnn_cls</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;frnn_with_atten&#39;</span>
    <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">atten_rnn_cell</span>
    <span class="n">params</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">atten_params</span>
    <span class="n">params</span><span class="o">.</span><span class="n">output_prev_atten_ctx</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">use_prev_atten_ctx</span>
    <span class="n">params</span><span class="o">.</span><span class="n">packed_input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
    <span class="n">params</span><span class="o">.</span><span class="n">use_zero_atten_state</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">use_zero_atten_state</span>
    <span class="n">params</span><span class="o">.</span><span class="n">atten_context_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;frnn_with_atten&#39;</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

    <span class="c1"># TODO(zhifengc): Avoid this?</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">attention</span>

    <span class="n">rnn_layers_params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_layers</span><span class="p">):</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span>
      <span class="n">params</span><span class="o">.</span><span class="n">reset_cell_state</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
      <span class="n">rnn_cell_p</span> <span class="o">=</span> <span class="n">params</span>

      <span class="n">params</span> <span class="o">=</span> <span class="n">model_helper</span><span class="o">.</span><span class="n">CreateUnidirectionalRNNParams</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">rnn_cell_p</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;frnn</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span>
      <span class="n">params</span><span class="o">.</span><span class="n">packed_input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
      <span class="n">rnn_layers_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChildren</span><span class="p">(</span><span class="s1">&#39;frnn&#39;</span><span class="p">,</span> <span class="n">rnn_layers_params</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">feed_attention_context_vec_to_softmax</span><span class="p">:</span>
      <span class="k">assert</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span>
      <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

<div class="viewcode-block" id="MTDecoderV1._CreateChildrenVariables"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1._CreateChildrenVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateChildrenVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">():</span>
        <span class="n">emb_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">WorkerDeviceInModelSplit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">emb_device</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">emb_device</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">frnn</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">frnn</span><span class="p">:</span>
          <span class="n">frnn</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span><span class="p">:</span>
      <span class="c1"># Taking shared emb/softmax layer out of the decoder variable scope so</span>
      <span class="c1"># that it can also be shared by encoder if needed.</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;shared_emb&#39;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">AUTO_REUSE</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateChildrenVariables</span><span class="p">()</span></div>

<div class="viewcode-block" id="MTDecoderV1.ApplyDropout"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1.ApplyDropout">[docs]</a>  <span class="k">def</span> <span class="nf">ApplyDropout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span> <span class="o">&lt;</span> <span class="mf">1.0</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">x_in</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span><span class="p">)</span></div>

<div class="viewcode-block" id="MTDecoderV1.ApplyClipping"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1.ApplyClipping">[docs]</a>  <span class="k">def</span> <span class="nf">ApplyClipping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cc_schedule</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cc_schedule</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">cc_schedule</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">x</span></div>

  <span class="nd">@py_utils</span><span class="o">.</span><span class="n">NameScopeDecorator</span><span class="p">(</span><span class="s1">&#39;MTDecoderV1/ComputePredictions&#39;</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">ComputePredictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decodes `targets` given encoded source.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder. Expected to contain:</span>
<span class="sd">        encoded - source encoding, of shape [time, batch, depth].</span>
<span class="sd">        padding - source encoding&#39;s padding, of shape [time, batch].</span>
<span class="sd">        segment_id - (optional) source segment id, of shape [time, batch].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">        predict. Each tensor in targets is of shape [batch, time].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `.NestedMap` containing information about the decoding process. At a</span>
<span class="sd">      minimum, this should contain:</span>
<span class="sd">        softmax_input: Tensor of shape [time, batch, params.softmax.input_dim].</span>
<span class="sd">        attention: `.NestedMap` of attention distributions of shape [batch,</span>
<span class="sd">                   time, source_len].</span>
<span class="sd">        source_enc_len: Lengths of source sentences. Tensor of shape [batch].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">source_paddings</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span>
    <span class="n">time</span><span class="p">,</span> <span class="n">batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">source_encs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span><span class="p">,</span>
                                    <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">])</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="n">target_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
      <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasRank</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
      <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
        <span class="n">target_segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">segment_ids</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">target_segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">():</span>
        <span class="n">emb_device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">WorkerDeviceInModelSplit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">emb_device</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">target_ids</span><span class="p">)</span>

      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">emb_device</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span><span class="p">:</span>
          <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">emb</span><span class="p">,</span> <span class="n">target_ids</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
        <span class="n">summary_utils</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;input_emb&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyDropout</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_emb_out</span> <span class="o">=</span> <span class="n">inputs</span>

        <span class="c1"># Layer 0 intertwines with attention.</span>
        <span class="p">(</span><span class="n">accumulated_states</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span>
         <span class="n">side_info</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">AccumulateStates</span><span class="p">(</span>
             <span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="p">,</span>
             <span class="n">source_encs</span><span class="p">,</span>
             <span class="n">source_paddings</span><span class="p">,</span>
             <span class="n">inputs</span><span class="p">,</span>
             <span class="n">target_paddings</span><span class="p">,</span>
             <span class="n">src_segment_id</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="s1">&#39;segment_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
             <span class="n">segment_id</span><span class="o">=</span><span class="n">target_segment_id</span><span class="p">)</span>

        <span class="p">(</span><span class="n">atten_ctxs</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">PostProcessStates</span><span class="p">(</span>
            <span class="n">accumulated_states</span><span class="p">,</span> <span class="n">side_info</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_AddAttenProbsSummary</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="p">[</span><span class="n">atten_probs</span><span class="p">])</span>

        <span class="n">atten_ctxs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">atten_ctxs</span><span class="p">)</span>
        <span class="n">summary_utils</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;atten_ctxs&#39;</span><span class="p">,</span> <span class="n">atten_ctxs</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layer_theta</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frnn</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">frnn</span><span class="p">)):</span>
          <span class="c1"># Forward through Layer-(i + 1) because Layer-0 handled before.</span>
          <span class="n">ys</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
              <span class="n">layer_theta</span><span class="p">,</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">xs</span><span class="p">,</span> <span class="n">atten_ctxs</span><span class="p">],</span> <span class="mi">2</span><span class="p">),</span>
              <span class="n">target_paddings</span><span class="p">,</span>
              <span class="n">segment_id</span><span class="o">=</span><span class="n">target_segment_id</span><span class="p">)</span>
          <span class="n">ys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyDropout</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>
          <span class="k">if</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">p</span><span class="o">.</span><span class="n">residual_start</span><span class="p">:</span>
            <span class="n">xs</span> <span class="o">+=</span> <span class="n">ys</span>  <span class="c1"># Residual skip</span>
            <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">xs</span> <span class="o">=</span> <span class="n">ys</span>
          <span class="n">summary_utils</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;layer_out_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">feed_attention_context_vec_to_softmax</span><span class="p">:</span>
          <span class="n">xs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">xs</span><span class="p">,</span> <span class="n">atten_ctxs</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Get intermediate attention information</span>
        <span class="n">atten_states</span> <span class="o">=</span> <span class="n">accumulated_states</span><span class="o">.</span><span class="n">atten_state</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">atten_states</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">):</span>
          <span class="n">additional_atten_probs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
              <span class="p">[(</span><span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
               <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">atten_states</span><span class="o">.</span><span class="n">FlattenItems</span><span class="p">()</span>
               <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;probs&#39;</span><span class="p">)])</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">additional_atten_probs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">attention_map</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">accumulated_states</span><span class="o">.</span><span class="n">atten_probs</span><span class="p">)</span>
        <span class="n">attention_map</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">additional_atten_probs</span><span class="p">)</span>

        <span class="c1"># Transpose attention probs from [target_length, batch, source_length]</span>
        <span class="c1"># to [batch, target_length, source_length]</span>
        <span class="k">def</span> <span class="nf">_TransposeAttentions</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
          <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

        <span class="n">attention_map</span> <span class="o">=</span> <span class="n">attention_map</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span><span class="n">_TransposeAttentions</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
          <span class="n">source_enc_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
            <span class="n">softmax_input</span><span class="o">=</span><span class="n">xs</span><span class="p">,</span>
            <span class="n">attention</span><span class="o">=</span><span class="n">attention_map</span><span class="p">,</span>
            <span class="n">source_enc_len</span><span class="o">=</span><span class="n">source_enc_len</span><span class="p">)</span>

<div class="viewcode-block" id="MTDecoderV1.AddExtraDecodingInfo"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1.AddExtraDecodingInfo">[docs]</a>  <span class="k">def</span> <span class="nf">AddExtraDecodingInfo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds extra decoding information to encoded_outputs.</span>

<span class="sd">    Args:</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      targets: a NestedMap containing target input fields.</span>

<span class="sd">    Returns:</span>
<span class="sd">      encoder_ouputs with extra information used for decoding.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">init_step_ids</span><span class="p">:</span>
      <span class="n">encoder_outputs</span><span class="p">[</span><span class="s1">&#39;init_step_ids&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">encoder_outputs</span></div>

  <span class="nd">@py_utils</span><span class="o">.</span><span class="n">NameScopeDecorator</span><span class="p">(</span><span class="s1">&#39;MTDecoderV1/InitDecoder&#39;</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_InitDecoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">num_hyps</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns initial decoder states.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">          its children layers.</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      num_hyps: Scalar Tensor of type int, Number of hypothesis maintained in</span>
<span class="sd">          beam search, equal to beam_size * num_hyps_per_beam.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Tuple of initial model states. Also inserts &#39;packed_src&#39; to</span>
<span class="sd">      &#39;encoder_outputs&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">source_paddings</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span>
    <span class="n">time</span><span class="p">,</span> <span class="n">batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">source_encs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span><span class="p">,</span>
                                    <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">])</span>
    <span class="n">rnn_states</span> <span class="o">=</span> <span class="p">[</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">cell</span><span class="p">,</span>
                                             <span class="n">num_hyps</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">layer_theta</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frnn</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">frnn</span><span class="p">):</span>
      <span class="n">rnn_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">layer_theta</span><span class="p">,</span> <span class="n">num_hyps</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_zero_atten_state</span><span class="p">:</span>
      <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">packed_src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">InitForSourcePacked</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">atten</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span>
          <span class="n">source_paddings</span><span class="p">)</span>
      <span class="n">s_seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">context_dim</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span>
      <span class="n">atten_context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">context_dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">source_encs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">atten_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">ZeroAttentionState</span><span class="p">(</span><span class="n">s_seq_len</span><span class="p">,</span> <span class="n">num_hyps</span><span class="p">)</span>
      <span class="n">atten_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">s_seq_len</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">source_encs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">packed_src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">InitForSourcePacked</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">atten</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span>
          <span class="n">source_paddings</span><span class="p">)</span>

      <span class="n">src_seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">zero_atten_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">ZeroAttentionState</span><span class="p">(</span><span class="n">src_seq_len</span><span class="p">,</span> <span class="n">num_hyps</span><span class="p">)</span>

      <span class="p">(</span><span class="n">atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span>
       <span class="n">atten_states</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">ComputeContextVectorWithSource</span><span class="p">(</span>
           <span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">atten</span><span class="p">,</span>
           <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">packed_src</span><span class="p">,</span>
           <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)),</span>
           <span class="n">attention_state</span><span class="o">=</span><span class="n">zero_atten_state</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">atten_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">rnn_states</span><span class="p">,</span> <span class="n">atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">atten_states</span>

  <span class="nd">@py_utils</span><span class="o">.</span><span class="n">NameScopeDecorator</span><span class="p">(</span><span class="s1">&#39;MTDecoderV1/DecodeStep&#39;</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_DecodeStep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">embs</span><span class="p">,</span> <span class="n">step_paddings</span><span class="p">,</span>
                  <span class="n">prev_atten_context</span><span class="p">,</span> <span class="n">rnn_states</span><span class="p">,</span> <span class="n">prev_atten_states</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decode one step.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">new_rnn_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">new_rnn_states_0</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
        <span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">cell</span><span class="p">,</span> <span class="n">rnn_states</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
            <span class="n">act</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">embs</span><span class="p">,</span> <span class="n">prev_atten_context</span><span class="p">],</span> <span class="mi">1</span><span class="p">)],</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">step_paddings</span><span class="p">,</span>
            <span class="n">reset_mask</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">step_paddings</span><span class="p">)))</span>
    <span class="n">new_rnn_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_rnn_states_0</span><span class="p">)</span>
    <span class="n">rnn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">GetOutput</span><span class="p">(</span><span class="n">new_rnn_states_0</span><span class="p">)</span>
    <span class="n">cur_atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">atten_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">ComputeContextVectorWithSource</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">atten</span><span class="p">,</span>
            <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">packed_src</span><span class="p">,</span>
            <span class="n">rnn_out</span><span class="p">,</span>
            <span class="n">attention_state</span><span class="o">=</span><span class="n">prev_atten_states</span><span class="p">))</span>
    <span class="k">assert</span> <span class="n">atten_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_prev_atten_ctx</span><span class="p">:</span>
      <span class="n">atten_context</span> <span class="o">=</span> <span class="n">prev_atten_context</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">atten_context</span> <span class="o">=</span> <span class="n">cur_atten_context</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layer_theta</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frnn</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">frnn</span><span class="p">)):</span>
      <span class="n">new_rnn_states_i</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
          <span class="n">layer_theta</span><span class="o">.</span><span class="n">cell</span><span class="p">,</span> <span class="n">rnn_states</span><span class="p">[</span><span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">],</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
              <span class="n">act</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">rnn_out</span><span class="p">,</span> <span class="n">atten_context</span><span class="p">],</span> <span class="mi">1</span><span class="p">)],</span>
              <span class="n">padding</span><span class="o">=</span><span class="n">step_paddings</span><span class="p">,</span>
              <span class="n">reset_mask</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">step_paddings</span><span class="p">)))</span>
      <span class="n">new_rnn_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_rnn_states_i</span><span class="p">)</span>
      <span class="n">new_rnn_out</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">GetOutput</span><span class="p">(</span><span class="n">new_rnn_states_i</span><span class="p">)</span>
      <span class="k">if</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">p</span><span class="o">.</span><span class="n">residual_start</span><span class="p">:</span>
        <span class="n">rnn_out</span> <span class="o">+=</span> <span class="n">new_rnn_out</span>
        <span class="n">rnn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">rnn_out</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">rnn_out</span> <span class="o">=</span> <span class="n">new_rnn_out</span>
    <span class="c1"># Concatenating atten_context vec to rnn output before softmax might help</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">feed_attention_context_vec_to_softmax</span><span class="p">:</span>
      <span class="n">step_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">rnn_out</span><span class="p">,</span> <span class="n">atten_context</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">step_out</span> <span class="o">=</span> <span class="n">rnn_out</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">cur_atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">new_rnn_states</span><span class="p">,</span> <span class="n">step_out</span><span class="p">,</span>
            <span class="n">atten_states</span><span class="p">)</span>

<div class="viewcode-block" id="MTDecoderV1._GetAttentionInitState"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1._GetAttentionInitState">[docs]</a>  <span class="k">def</span> <span class="nf">_GetAttentionInitState</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Gets the attention initialization state.</span>

<span class="sd">    It is valid to call this after `_DecoderInit()`. Inference subclasses use</span>
<span class="sd">    this to split computation across subgraph boundaries.</span>

<span class="sd">    Returns:</span>
<span class="sd">      `.NestedMap` of attention source states.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">GetInitializationSourceState</span><span class="p">()</span></div>

<div class="viewcode-block" id="MTDecoderV1._SetAttentionInitState"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1._SetAttentionInitState">[docs]</a>  <span class="k">def</span> <span class="nf">_SetAttentionInitState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_init_state</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the attention initialization state.</span>

<span class="sd">    Args:</span>
<span class="sd">      new_init_state: `.NestedMap` compatible with that returned from</span>
<span class="sd">        `_GetAttentionSourceState`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">SetInitializationSourceState</span><span class="p">(</span><span class="n">new_init_state</span><span class="p">)</span></div>

<div class="viewcode-block" id="MTDecoderV1._InitBeamSearchStateCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1._InitBeamSearchStateCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_InitBeamSearchStateCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
                                   <span class="n">num_hyps_per_beam</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns initial beams search states.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: a NestedMap of parameters.</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      num_hyps_per_beam: An int, number hyps to keep for source sentence.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (initial_results, states).</span>
<span class="sd">        initial_results: a `.NestedMap` of initial results.</span>
<span class="sd">          atten_probs:</span>
<span class="sd">            The initial attention probs, of shape [tgt_batch, src_len].</span>
<span class="sd">        states: a `.NestedMap` of initial model states.</span>
<span class="sd">          rnn_states:</span>
<span class="sd">            Initial state of the RNN.</span>
<span class="sd">          atten_context:</span>
<span class="sd">            Initial attention context vector.</span>
<span class="sd">          atten_states:</span>
<span class="sd">            Initial attention state.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">num_beams</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">num_hyps</span> <span class="o">=</span> <span class="n">num_beams</span> <span class="o">*</span> <span class="n">num_hyps_per_beam</span>
    <span class="n">rnn_states</span><span class="p">,</span> <span class="n">init_atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">atten_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_InitDecoder</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">num_hyps</span><span class="p">))</span>

    <span class="n">initial_results</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
        <span class="n">log_probs</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span><span class="p">],</span>
                           <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)),</span>
        <span class="n">atten_probs</span><span class="o">=</span><span class="n">atten_probs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">init_step_ids</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="s1">&#39;init_step_ids&#39;</span><span class="p">):</span>
      <span class="n">initial_results</span><span class="p">[</span><span class="s1">&#39;step_ids&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_ExpandToNumHyps</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">init_step_ids</span><span class="p">,</span>
                                <span class="n">num_hyps_per_beam</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">states</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;time_step&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
        <span class="s1">&#39;rnn_states&#39;</span><span class="p">:</span> <span class="n">rnn_states</span><span class="p">,</span>
        <span class="s1">&#39;atten_context&#39;</span><span class="p">:</span> <span class="n">init_atten_context</span><span class="p">,</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">atten_probs</span><span class="p">,</span>
        <span class="s1">&#39;atten_states&#39;</span><span class="p">:</span> <span class="n">atten_states</span><span class="p">,</span>
    <span class="p">})</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">disallow_misaligned_eos</span><span class="p">:</span>
      <span class="n">states</span><span class="p">[</span><span class="s1">&#39;num_sentences&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">initial_results</span><span class="p">,</span> <span class="n">states</span></div>

  <span class="nd">@py_utils</span><span class="o">.</span><span class="n">NameScopeDecorator</span><span class="p">(</span><span class="s1">&#39;MTDecoderV1/PreBeamSearchStepCallback&#39;</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_PreBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">step_ids</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span>
                                 <span class="n">num_hyps_per_beam</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns logits for sampling ids and the next model states.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: a NestedMap of parameters.</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      step_ids: A tensor of shape [tgt_batch, 1].</span>
<span class="sd">      states: A `.NestedMap` of tensors representing states that the clients</span>
<span class="sd">          would like to keep track of for each of the active hyps.</span>
<span class="sd">      num_hyps_per_beam: Beam size.</span>
<span class="sd">    Returns:</span>
<span class="sd">      A tuple (results, out_states).</span>
<span class="sd">      results: A `.NestedMap` of beam search results.</span>
<span class="sd">        atten_probs:</span>
<span class="sd">          The updated attention probs, of shape [tgt_batch, src_len].</span>
<span class="sd">        log_probs:</span>
<span class="sd">          Log prob for each of the tokens in the target vocab. This is of shape</span>
<span class="sd">          [tgt_batch, vocab_size].</span>
<span class="sd">      out_states: A `.NestedMap`. The updated states.</span>
<span class="sd">        rnn_states:</span>
<span class="sd">          Last state of the RNN.</span>
<span class="sd">        atten_context:</span>
<span class="sd">          Updated attention context vector.</span>
<span class="sd">        atten_states:</span>
<span class="sd">          Updates attention states.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="n">prev_rnn_states</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="s1">&#39;rnn_states&#39;</span><span class="p">]</span>
    <span class="n">prev_atten_context</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="s1">&#39;atten_context&#39;</span><span class="p">]</span>
    <span class="n">prev_atten_probs</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="s1">&#39;atten_probs&#39;</span><span class="p">]</span>
    <span class="n">prev_atten_states</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="s1">&#39;atten_states&#39;</span><span class="p">]</span>
    <span class="n">step_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">step_ids</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span><span class="p">:</span>
      <span class="n">embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">step_ids</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">emb</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">step_ids</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">embs</span><span class="p">)</span>
    <span class="n">atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">rnn_states</span><span class="p">,</span> <span class="n">step_out</span><span class="p">,</span> <span class="n">atten_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_DecodeStep</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">embs</span><span class="p">,</span> <span class="n">step_paddings</span><span class="p">,</span>
                         <span class="n">prev_atten_context</span><span class="p">,</span> <span class="n">prev_rnn_states</span><span class="p">,</span>
                         <span class="n">prev_atten_states</span><span class="p">))</span>
    <span class="n">atten_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">prev_atten_probs</span><span class="p">))</span>

    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">Logits</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="p">[</span><span class="n">step_out</span><span class="p">])</span>
    <span class="n">log_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fns</span><span class="o">.</span><span class="n">qlogsoftmax</span><span class="p">(</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">qmin</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">qlogsoftmax_range_min</span><span class="p">,</span> <span class="n">qmax</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">disallow_misaligned_eos</span><span class="p">:</span>
      <span class="n">source_num_sentences</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
          <span class="n">encoder_outputs</span><span class="p">[</span><span class="s1">&#39;num_sentences&#39;</span><span class="p">],</span> <span class="n">multiples</span><span class="o">=</span><span class="p">[</span><span class="n">num_hyps_per_beam</span><span class="p">])</span>
      <span class="n">log_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_DisallowMisalignedEos</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">source_num_sentences</span><span class="p">,</span>
                                              <span class="n">states</span><span class="p">[</span><span class="s1">&#39;num_sentences&#39;</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_prev_atten_ctx</span><span class="p">:</span>
      <span class="n">cur_atten_probs</span> <span class="o">=</span> <span class="n">prev_atten_probs</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">cur_atten_probs</span> <span class="o">=</span> <span class="n">atten_probs</span>

    <span class="n">bs_results</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">cur_atten_probs</span><span class="p">,</span>  <span class="c1"># the probs exposed to beam search</span>
        <span class="s1">&#39;log_probs&#39;</span><span class="p">:</span> <span class="n">log_probs</span><span class="p">,</span>
    <span class="p">})</span>
    <span class="n">new_states</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;time_step&#39;</span><span class="p">:</span> <span class="n">states</span><span class="o">.</span><span class="n">time_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
        <span class="s1">&#39;rnn_states&#39;</span><span class="p">:</span> <span class="n">rnn_states</span><span class="p">,</span>
        <span class="s1">&#39;atten_context&#39;</span><span class="p">:</span> <span class="n">atten_context</span><span class="p">,</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">atten_probs</span><span class="p">,</span>  <span class="c1"># the updated attention probs</span>
        <span class="s1">&#39;atten_states&#39;</span><span class="p">:</span> <span class="n">atten_states</span><span class="p">,</span>
    <span class="p">})</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">disallow_misaligned_eos</span><span class="p">:</span>
      <span class="n">new_states</span><span class="p">[</span><span class="s1">&#39;num_sentences&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="s1">&#39;num_sentences&#39;</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">bs_results</span><span class="p">,</span> <span class="n">new_states</span>

<div class="viewcode-block" id="MTDecoderV1._PostBeamSearchStepCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1._PostBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_PostBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">new_step_ids</span><span class="p">,</span>
                                  <span class="n">states</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">disallow_misaligned_eos</span><span class="p">:</span>
      <span class="n">add</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">new_step_ids</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">sentence_boundary_token_id</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">states</span><span class="p">[</span><span class="s1">&#39;num_sentences&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
          <span class="n">add</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">states</span><span class="p">[</span><span class="s1">&#39;num_sentences&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">states</span></div>

<div class="viewcode-block" id="MTDecoderV1._DisallowMisalignedEos"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1._DisallowMisalignedEos">[docs]</a>  <span class="k">def</span> <span class="nf">_DisallowMisalignedEos</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">source_num_sentences</span><span class="p">,</span>
                             <span class="n">hyp_num_sentences</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Update &#39;log_probs&#39; to disallow misaligned EOS.</span>

<span class="sd">    Args:</span>
<span class="sd">      log_probs: encoder&#39;s log_probs output.</span>
<span class="sd">      source_num_sentences: shape [beam_size * num_hyps_per_beam], int32. The</span>
<span class="sd">        number of sentences in source.</span>
<span class="sd">      hyp_num_sentences: shape [beam_size * num_hyps_per_beam], int32. The</span>
<span class="sd">        number of sentences in hyp.</span>

<span class="sd">    Returns:</span>
<span class="sd">      The new log_probs (score used for beam search), which is reduced at</span>
<span class="sd">      EOS if the number of sentences in the hyp is insufficient such when</span>
<span class="sd">      compared to the number of sentences in the source.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">eos_id</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_eos_id</span>
    <span class="c1"># We replace log_probs with a sufficiently large negative value where</span>
    <span class="c1"># the current hyp contains fewer sentences than expected to disallow</span>
    <span class="c1"># eos in such misaligned cases.</span>
    <span class="n">large_negative_value</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">log_probs</span><span class="p">[:,</span> <span class="n">eos_id</span><span class="p">])</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
        <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">log_probs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="n">log_probs</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">max</span>
    <span class="n">eos_log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">source_num_sentences</span><span class="p">,</span> <span class="n">hyp_num_sentences</span><span class="p">),</span>
        <span class="n">large_negative_value</span><span class="p">,</span> <span class="n">log_probs</span><span class="p">[:,</span> <span class="n">eos_id</span><span class="p">])</span>
    <span class="n">eos_log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">eos_log_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">boundary_id</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">sentence_boundary_token_id</span>
    <span class="n">boundary_id_log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">source_num_sentences</span><span class="p">,</span> <span class="n">hyp_num_sentences</span><span class="p">),</span>
        <span class="n">large_negative_value</span><span class="p">,</span> <span class="n">log_probs</span><span class="p">[:,</span> <span class="n">boundary_id</span><span class="p">])</span>
    <span class="n">boundary_id_log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">boundary_id_log_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">new_log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
        <span class="p">[</span><span class="n">log_probs</span><span class="p">[:,</span> <span class="p">:</span><span class="n">eos_id</span><span class="p">],</span> <span class="n">eos_log_probs</span><span class="p">,</span> <span class="n">log_probs</span><span class="p">[:,</span> <span class="n">eos_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]],</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">new_log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
        <span class="n">new_log_probs</span><span class="p">[:,</span> <span class="p">:</span><span class="n">boundary_id</span><span class="p">],</span> <span class="n">boundary_id_log_probs</span><span class="p">,</span>
        <span class="n">new_log_probs</span><span class="p">[:,</span> <span class="n">boundary_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="p">],</span>
                              <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_log_probs</span></div></div>


<div class="viewcode-block" id="TransformerDecoder"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder">[docs]</a><span class="k">class</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">MTBaseDecoder</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Transformer decoder.</span>

<span class="sd">  Implements the decoder of Transformer model:</span>
<span class="sd">  https://arxiv.org/abs/1706.03762.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="TransformerDecoder.Params"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;token_emb&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Token embedding layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;position_emb&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">PositionalEmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Position embedding layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;source_dim&#39;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;Dimension of encoder outputs.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;model_dim&#39;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;Model dimension that applies to embedding &#39;</span>
             <span class="s1">&#39;layers and all Transformer layers.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_trans_layers&#39;</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;Number of Transformer layers.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;trans_tpl&#39;</span><span class="p">,</span> <span class="n">layers_with_attention</span><span class="o">.</span><span class="n">TransformerLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
        <span class="s1">&#39;Transformer layer params. &#39;</span>
        <span class="s1">&#39; Can be a list. num_trans_layers should be divisible by &#39;</span>
        <span class="s1">&#39;len(trans_tpl).&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;input_dropout_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;Prob at which we do input dropout.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;is_transparent&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;If set, expects a tensor of shape &#39;</span>
        <span class="s1">&#39;[time, batch, source_dim, num_trans_layers] as source encodings.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;add_multiheaded_attention_scalar_summary&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;If set, will include scalar summaries for multi-headed attention&#39;</span>
        <span class="s1">&#39; to visualize the sparsity statistics of attention weights.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;ln_tpl&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNorm</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span> <span class="s1">&#39;Layer norm default params&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;ln_output&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;If True, layer normalization is applied to the &#39;</span>
        <span class="s1">&#39;final output of the decoder.&#39;</span><span class="p">)</span>

    <span class="c1"># TODO(miachen): Extend this to more general logic of adding multiple</span>
    <span class="c1"># embedding fields.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;task_emb&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Task embedding layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;init_step_ids&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;Initializes beam search with first target id instead of &lt;s&gt;.&#39;</span>
        <span class="s1">&#39;Use this when decoder has target language token intead of &lt;s&gt; &#39;</span>
        <span class="s1">&#39;token at time step 0.&#39;</span>
        <span class="s1">&#39;Make sure the training is done in similar manner.&#39;</span><span class="p">)</span>
    <span class="c1"># MASS pretraining related (https://github.com/microsoft/MASS)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;use_lang_dependent_atten&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;If True, attention between &#39;</span>
        <span class="s1">&#39;encoder and decoder is language dependent.&#39;</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;zero_token_embs_first_time_step&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;If True, the first time step uses zeros as the post-emb lookup.&#39;</span><span class="p">)</span>

    <span class="c1"># Default config for the token embedding.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">32000</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">max_num_shards</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span>
        <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">))</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">scale_sqrt_depth</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Default config for the position embedding.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>

    <span class="c1"># Default config for the transformer layers.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_atten_tpl</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_atten_tpl</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_fflayer_tpl</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_fflayer_tpl</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">2048</span>

    <span class="c1"># Default config for beam search.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">length_normalization</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">coverage_penalty</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">batch_major_state</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">cls</span> <span class="o">==</span> <span class="n">layers</span><span class="o">.</span><span class="n">SharedSoftmaxLayer</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_token_emb_vocab_size</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_token_emb_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_token_emb_vocab_size</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">vocab_size</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_token_emb_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_emb_vocab_size</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_emb_dim</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">embedding_dim</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_emb_dim</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
          <span class="s1">&#39;token_emb.embedding_dim != model_dim (</span><span class="si">%s</span><span class="s1"> vs. </span><span class="si">%s</span><span class="s1">), &#39;</span>
          <span class="s1">&#39;creating a projection!&#39;</span><span class="p">)</span>
      <span class="n">proj_p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">proj_p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;emb_proj&#39;</span>
      <span class="n">proj_p</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span>
      <span class="n">proj_p</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;emb_proj&#39;</span><span class="p">,</span> <span class="n">proj_p</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_lang_dependent_atten</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">task_emb</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">num_aux_atten_post_proj</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">task_emb</span><span class="o">.</span><span class="n">vocab_size</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;token_emb&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;position_emb&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">position_emb</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">task_emb</span><span class="p">:</span>
      <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">task_emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_emb_dim</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;task_emb&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">task_emb</span><span class="p">)</span>

    <span class="n">dropout_tpl</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">DropoutLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">dropout_tpl</span><span class="o">.</span><span class="n">keep_prob</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">input_dropout_prob</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;input_dropout&#39;</span><span class="p">,</span> <span class="n">dropout_tpl</span><span class="p">)</span>

    <span class="n">params_trans_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
      <span class="n">denom</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span> <span class="o">%</span> <span class="n">denom</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span> <span class="o">//</span> <span class="n">denom</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="p">:</span>
          <span class="n">params</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
          <span class="n">params_trans_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
        <span class="n">params_trans_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">params_trans_layers</span><span class="p">):</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;trans_layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span>
      <span class="n">params</span><span class="o">.</span><span class="n">packed_input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
      <span class="n">params</span><span class="o">.</span><span class="n">has_aux_atten</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">mask_self_atten</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Initialize decoder output layer norm</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">ln_output</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">ln_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;dec_out_ln&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;layer_norm_out&#39;</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChildren</span><span class="p">(</span><span class="s1">&#39;trans&#39;</span><span class="p">,</span> <span class="n">params_trans_layers</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

<div class="viewcode-block" id="TransformerDecoder._CreateChildrenVariables"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._CreateChildrenVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateChildrenVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span><span class="p">:</span>
      <span class="c1"># Taking shared emb/softmax layer out of the decoder variable scope so</span>
      <span class="c1"># that it can also be shared by encoder if needed.</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;shared_emb&#39;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">AUTO_REUSE</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateChildrenVariables</span><span class="p">()</span></div>

<div class="viewcode-block" id="TransformerDecoder._RemoveEOSProbs"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._RemoveEOSProbs">[docs]</a>  <span class="k">def</span> <span class="nf">_RemoveEOSProbs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">source_enc_len</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Remove the attention probs on EOS symbol and renormalize.</span>

<span class="sd">    Args:</span>
<span class="sd">      p: decoder params.</span>
<span class="sd">      probs: attention probs matrix; float [batch, target_len, source_len].</span>
<span class="sd">      source_enc_len: source encoder length; int [batch].</span>

<span class="sd">    Returns:</span>
<span class="sd">      probs with value on last actual token (EOS token) replaced by 0 and</span>
<span class="sd">      renormalized so that final dim (src_len) sums to 1 again; float</span>
<span class="sd">      [batch, target_len, source_len].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">probs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">source_enc_len</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">source_enc_len</span><span class="p">,</span> <span class="p">[</span><span class="n">batch</span><span class="p">])</span>

    <span class="c1"># Set -1 values</span>
    <span class="n">target_len</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">probs</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">replacements</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">probs</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">target_len</span><span class="p">],</span>
                           <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">index_0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">index_0</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">target_len</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">index_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">index_1</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">target_len</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">index_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">index_1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">index_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">source_enc_len</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># Note the -1</span>
    <span class="n">index_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">index_2</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">index_2</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">target_len</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">index</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">index_0</span><span class="p">,</span> <span class="n">index_1</span><span class="p">,</span> <span class="n">index_2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Original update matrix contained -1 values. Change all to 1 except for</span>
    <span class="c1"># those positions coming from scatter which will be 0.</span>
    <span class="n">updates</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">scatter_nd</span><span class="p">(</span>
        <span class="n">index</span><span class="p">,</span> <span class="n">updates</span><span class="o">=</span><span class="n">replacements</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">probs</span><span class="p">))</span>
    <span class="n">updates</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">probs</span> <span class="o">*</span> <span class="n">updates</span>

    <span class="c1"># Normalize to that probs sum to 1.</span>
    <span class="c1"># Add eps to sum to deal with case where all probs except last one are 0.</span>
    <span class="c1"># In this case then, attention probs will not sum to 1 but this seems still</span>
    <span class="c1"># better then evenly distributing attention probs in this case.</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">+=</span> <span class="n">epsilon</span>
    <span class="n">res</span> <span class="o">/=</span> <span class="n">s</span>
    <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="TransformerDecoder._ZeroOutFirstTimeStep"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._ZeroOutFirstTimeStep">[docs]</a>  <span class="k">def</span> <span class="nf">_ZeroOutFirstTimeStep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_embs</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">target_time</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Zeroes out the first time step.</span>

<span class="sd">    Args:</span>
<span class="sd">      token_embs:  [batch, time, model_dim] embeding lookups</span>
<span class="sd">      batch: Batch size scalar</span>
<span class="sd">      target_time: Target sequence length scalar.</span>

<span class="sd">    Returns:</span>
<span class="sd">      modified token_embs with the first time step zeroed out.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="n">zero_out_index</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># [[[0]]]</span>
    <span class="n">zero_out_index</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">zero_out_index</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># [[0]...[target_time-1]]</span>
    <span class="n">time_steps</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">target_time</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">condition</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">zero_out_index</span><span class="p">,</span> <span class="n">time_steps</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span><span class="p">]))</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">token_embs</span> <span class="o">*</span> <span class="n">mask</span></div>

<div class="viewcode-block" id="TransformerDecoder._FProp"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._FProp">[docs]</a>  <span class="k">def</span> <span class="nf">_FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decodes `targets` given encoded source.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder. Expected to contain:</span>
<span class="sd">        encoded - source encoding. When `p.is_transparent` is False, it is a</span>
<span class="sd">        tensor of shape [time, batch, depth]. When `p.is_transparent` is True,</span>
<span class="sd">        it is a tensor of shape [time, batch, depth, num_trans_layers] if</span>
<span class="sd">        `self.do_eval` is True, and a list of `num_trans_layers` tensors of</span>
<span class="sd">        shape [time, batch, depth] if `self.do_eval` is False.  padding - source</span>
<span class="sd">        encoding&#39;s padding, of shape [time, batch]. segment_id - source segment</span>
<span class="sd">        id, of shape [time, batch].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">        predict. Each tensor in targets is of shape [batch, time].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `.NestedMap` containing output of last decoder layer and attention probs</span>

<span class="sd">      - softmax_input: Tensor of shape [time, batch, params.softmax.input_dim].</span>
<span class="sd">      - attention: `.NestedMap` of attention distributions of shape</span>
<span class="sd">        [batch, target_length, source_length].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">source_encs</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span>
    <span class="n">source_paddings</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span>
    <span class="n">src_segment_id</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="s1">&#39;segment_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">time</span><span class="p">,</span> <span class="n">batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">is_transparent</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">:</span>
        <span class="n">source_encs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span>
            <span class="n">source_encs</span><span class="p">,</span> <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">])</span>
        <span class="n">source_encs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">source_encs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">source_encs</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">):</span>
          <span class="n">source_encs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                             <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">source_encs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">,</span> <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">])</span>
      <span class="n">source_encs</span> <span class="o">=</span> <span class="p">[</span><span class="n">source_encs</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="c1"># [batch, time]</span>
      <span class="n">target_ids</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">ids</span>
      <span class="c1"># [time, batch]</span>
      <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">)</span>
      <span class="n">target_segment_pos</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">target_segment_id</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
        <span class="n">target_segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">segment_ids</span><span class="p">)</span>
        <span class="n">target_segment_pos</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">segment_pos</span>
        <span class="k">assert</span> <span class="n">src_segment_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;Need to provide src_segment_id &#39;</span>
                                            <span class="s1">&#39;for packed input.&#39;</span><span class="p">)</span>

      <span class="c1"># Embedding layer</span>
      <span class="c1"># [batch, time, model_dim]</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span><span class="p">:</span>
        <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">token_emb</span><span class="p">,</span> <span class="n">target_ids</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">target_ids</span><span class="p">)</span>

      <span class="n">target_batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">target_time</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_ids</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">zero_token_embs_first_time_step</span><span class="p">:</span>
        <span class="c1"># For models that do not use an explicit start-of-sequence token</span>
        <span class="c1"># with associated embedding, but instead use zeros.</span>
        <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ZeroOutFirstTimeStep</span><span class="p">(</span><span class="n">token_embs</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span>
                                                <span class="n">target_time</span><span class="p">)</span>

      <span class="c1"># [1, time, model_dim]</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
        <span class="n">posit_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">FPropWithPosition</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">.</span><span class="n">position_emb</span><span class="p">,</span> <span class="n">target_segment_pos</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">posit_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">position_emb</span><span class="p">,</span> <span class="n">target_time</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>

      <span class="c1"># [time, batch, model_dim]</span>
      <span class="n">input_embs</span> <span class="o">=</span> <span class="n">token_embs</span> <span class="o">+</span> <span class="n">posit_embs</span>

      <span class="n">atten_idx</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">task_emb</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_lang_dependent_atten</span><span class="p">:</span>
          <span class="n">atten_idx</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">task_ids</span>
          <span class="c1"># Works for both packed and unpacked inputs.</span>
          <span class="n">atten_idx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">atten_idx</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">input_embs</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">task_emb</span><span class="p">,</span> <span class="n">targets</span><span class="o">.</span><span class="n">task_ids</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_emb_dim</span><span class="p">:</span>
        <span class="n">input_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_proj</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">emb_proj</span><span class="p">,</span> <span class="n">input_embs</span><span class="p">)</span>

      <span class="n">input_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">input_embs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
      <span class="n">input_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dropout</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">input_dropout</span><span class="p">,</span> <span class="n">input_embs</span><span class="p">)</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
        <span class="n">src_enc_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">num_hyps_per_beam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">div</span><span class="p">(</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">src_enc_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ExpandToNumHyps</span><span class="p">(</span><span class="n">src_enc_len</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="p">)</span>

      <span class="n">layer_in</span> <span class="o">=</span> <span class="n">input_embs</span>
      <span class="n">per_layer_attn_probs</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layer_theta</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trans</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">trans</span><span class="p">)):</span>
        <span class="n">extra_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layers_with_attention</span><span class="o">.</span><span class="n">TransformerWithContextLayer</span><span class="p">):</span>
          <span class="c1"># If the encoder contains encodings for the context and the</span>
          <span class="c1"># transformer layer in the decoder is able to attend to it, we pass</span>
          <span class="c1"># them to the transformer layer.</span>
          <span class="n">extra_kwargs</span><span class="p">[</span><span class="s1">&#39;tertiary_vecs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">context_encoded</span>
          <span class="n">extra_kwargs</span><span class="p">[</span><span class="s1">&#39;tertiary_paddings&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">context_padding</span>
        <span class="c1"># [time, batch, model_dim]</span>
        <span class="n">layer_out</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
            <span class="n">layer_theta</span><span class="p">,</span>
            <span class="n">layer_in</span><span class="p">,</span>
            <span class="n">target_paddings</span><span class="p">,</span>
            <span class="n">source_encs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">source_paddings</span><span class="p">,</span>
            <span class="n">source_segment_id</span><span class="o">=</span><span class="n">target_segment_id</span><span class="p">,</span>
            <span class="n">aux_segment_id</span><span class="o">=</span><span class="n">src_segment_id</span><span class="p">,</span>
            <span class="n">atten_idx</span><span class="o">=</span><span class="n">atten_idx</span><span class="p">,</span>
            <span class="o">**</span><span class="n">extra_kwargs</span><span class="p">)</span>
        <span class="n">layer_in</span> <span class="o">=</span> <span class="n">layer_out</span>
        <span class="n">pl_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
          <span class="c1"># For packed inputs we are currently not removing the EOS token.</span>
          <span class="n">per_layer_attn_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pl_probs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="c1"># Remove attention weight on last (EOS) token and re-normalize</span>
          <span class="c1"># so that last dimension sums to 1. See b/129097156.</span>
          <span class="c1"># Original probs shape: [trg time, batch, src time]</span>
          <span class="n">norma_atten_probs_3d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RemoveEOSProbs</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">pl_probs</span><span class="p">,</span> <span class="n">src_enc_len</span><span class="p">)</span>
          <span class="n">per_layer_attn_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">norma_atten_probs_3d</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">ln_output</span><span class="p">:</span>
        <span class="n">layer_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_out</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">layer_norm_out</span><span class="p">,</span> <span class="n">layer_out</span><span class="p">)</span>

      <span class="c1"># per_layer_attn_probs shape: [batch, trg time, src time]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_AddAttenProbsSummary</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">per_layer_attn_probs</span><span class="p">)</span>

      <span class="c1"># Aggregate per-layer attention probs.</span>
      <span class="n">aggregated_atten_probs</span> <span class="o">=</span> <span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span><span class="n">per_layer_attn_probs</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">per_layer_attn_probs</span><span class="p">))</span>

      <span class="n">attention_map</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">aggregated_atten_probs</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
          <span class="n">softmax_input</span><span class="o">=</span><span class="n">layer_out</span><span class="p">,</span> <span class="n">attention</span><span class="o">=</span><span class="n">attention_map</span><span class="p">)</span></div>

<div class="viewcode-block" id="TransformerDecoder.AddExtraDecodingInfo"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder.AddExtraDecodingInfo">[docs]</a>  <span class="k">def</span> <span class="nf">AddExtraDecodingInfo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds extra decoding information to encoded_outputs.</span>

<span class="sd">    Args:</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      targets: a NestedMap containing target input fields.</span>

<span class="sd">    Returns:</span>
<span class="sd">      encoder_ouputs with extra information used for decoding.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">task_emb</span><span class="p">:</span>
      <span class="n">encoder_outputs</span><span class="p">[</span><span class="s1">&#39;target_task_ids&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">task_ids</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">init_step_ids</span><span class="p">:</span>
      <span class="n">encoder_outputs</span><span class="p">[</span><span class="s1">&#39;init_step_ids&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">encoder_outputs</span></div>

<div class="viewcode-block" id="TransformerDecoder.ExtendStep"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder.ExtendStep">[docs]</a>  <span class="k">def</span> <span class="nf">ExtendStep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">new_ids</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">prefix_states</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Extend prefix as represented by `prefix_states` by one more step.</span>

<span class="sd">    This function is expected to be called during fast decoding of Transformer</span>
<span class="sd">    models.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder, containing:</span>

<span class="sd">        - encoded: source encoding, of shape [time, batch, depth]. Can be [time,</span>
<span class="sd">          bs, depth, num_trans_layers] if is_transparent is set.</span>
<span class="sd">        - padding: source encoding&#39;s padding, of shape [time, batch].</span>
<span class="sd">      new_ids: new input ids, of shape [batch].</span>
<span class="sd">      t: a scalar, the current time step, 0-based.</span>
<span class="sd">      prefix_states: a `.NestedMap` representing the prefix that has already</span>
<span class="sd">        been decoded.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (last_decoder_out, prefix_states, atten_probs), where</span>
<span class="sd">      last_decoder_out is the output of the last decoder layer of</span>
<span class="sd">      shape [batch, model_dim], `prefix_states` is the update prefix states,</span>
<span class="sd">      and atten_probs contains attention in shape [batch, src_len] for the</span>
<span class="sd">      given target position.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">source_paddings</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span>
    <span class="n">time</span><span class="p">,</span> <span class="n">batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">is_transparent</span><span class="p">:</span>
      <span class="n">source_encs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span>
          <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span><span class="p">,</span>
          <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">])</span>
      <span class="n">source_encs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">source_encs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">source_encs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span><span class="p">,</span>
                                      <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">])</span>
      <span class="n">source_encs</span> <span class="o">=</span> <span class="p">[</span><span class="n">source_encs</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="c1"># Embedding layer</span>
      <span class="c1"># [batch, time, model_dim]</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_share_sm_emb</span><span class="p">:</span>
        <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">token_emb</span><span class="p">,</span> <span class="n">new_ids</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">new_ids</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">zero_token_embs_first_time_step</span><span class="p">:</span>
        <span class="c1"># For models that do not use an explicit start-of-sequence token</span>
        <span class="c1"># with associated embedding, but instead use zeros.</span>
        <span class="n">zeros</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">token_embs</span><span class="p">)</span>
        <span class="n">token_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">zeros</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">token_embs</span><span class="p">)</span>

      <span class="c1"># [time, model_dim]</span>
      <span class="n">posit_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">position_emb</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span><span class="p">),</span> <span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
          <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span><span class="p">])</span>
      <span class="n">input_embs</span> <span class="o">=</span> <span class="n">token_embs</span> <span class="o">+</span> <span class="n">posit_embs</span>

      <span class="c1"># Infer num_hyps_per_beam: new_ids has orig_batch_size * num_hyps_per_beam</span>
      <span class="c1"># source_paddings has orig_batch_size.</span>
      <span class="n">num_hyps_per_beam</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">div</span><span class="p">(</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">new_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>

      <span class="n">atten_idx</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">task_emb</span><span class="p">:</span>
        <span class="n">task_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ExpandToNumHyps</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">target_task_ids</span><span class="p">,</span>
                                         <span class="n">num_hyps_per_beam</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_lang_dependent_atten</span><span class="p">:</span>
          <span class="n">atten_idx</span> <span class="o">=</span> <span class="n">task_ids</span>
        <span class="n">input_embs</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">task_emb</span><span class="p">,</span> <span class="n">task_ids</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_emb_dim</span><span class="p">:</span>
        <span class="n">input_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_proj</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">emb_proj</span><span class="p">,</span> <span class="n">input_embs</span><span class="p">)</span>

      <span class="n">input_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dropout</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">input_dropout</span><span class="p">,</span> <span class="n">input_embs</span><span class="p">)</span>
      <span class="c1"># Make a copy of the input.</span>
      <span class="n">out_prefix_states</span> <span class="o">=</span> <span class="n">prefix_states</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="n">prefix_states</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

      <span class="n">layer_in</span> <span class="o">=</span> <span class="n">input_embs</span>

      <span class="c1"># Infer true source encoder length from the padding.</span>
      <span class="n">src_enc_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

      <span class="c1"># Need to expand src_enc_len to reflect multiple hypotheses.</span>
      <span class="n">src_enc_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ExpandToNumHyps</span><span class="p">(</span><span class="n">src_enc_len</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="p">)</span>

      <span class="n">atten_probs</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layer_theta</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trans</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">trans</span><span class="p">)):</span>
        <span class="n">extra_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layers_with_attention</span><span class="o">.</span><span class="n">TransformerWithContextLayer</span><span class="p">):</span>
          <span class="c1"># If the encoder contains encodings for the context and the</span>
          <span class="c1"># transformer layer in the decoder is able to attend to it, we pass</span>
          <span class="c1"># them to the transformer layer.</span>
          <span class="n">extra_kwargs</span><span class="p">[</span><span class="s1">&#39;tertiary_vecs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">context_encoded</span>
          <span class="n">extra_kwargs</span><span class="p">[</span><span class="s1">&#39;tertiary_paddings&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">context_padding</span>
        <span class="c1"># [time, batch, model_dim]</span>
        <span class="n">layer_prefix_states</span> <span class="o">=</span> <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">layer_out</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">updated_prefix_states</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">ExtendStep</span><span class="p">(</span>
            <span class="n">layer_theta</span><span class="p">,</span>
            <span class="n">layer_in</span><span class="p">,</span>
            <span class="n">layer_prefix_states</span><span class="p">,</span>
            <span class="n">source_encs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">source_paddings</span><span class="p">,</span>
            <span class="n">t</span><span class="o">=</span><span class="n">t</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;tpu_beam_search&#39;</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">atten_idx</span><span class="o">=</span><span class="n">atten_idx</span><span class="p">,</span>
            <span class="o">**</span><span class="n">extra_kwargs</span><span class="p">)</span>
        <span class="n">out_prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">updated_prefix_states</span>
        <span class="n">layer_in</span> <span class="o">=</span> <span class="n">layer_out</span>
        <span class="c1"># Enforce shape: [batch, src_len]</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># Remove attention weight on last (EOS) token and re-normalize</span>
        <span class="c1"># so that last dimension sums to 1. See b/129097156.</span>
        <span class="n">probs_3d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">probs_3d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RemoveEOSProbs</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">probs_3d</span><span class="p">,</span> <span class="n">src_enc_len</span><span class="p">)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">probs_3d</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">atten_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">ln_output</span><span class="p">:</span>
        <span class="n">layer_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm_out</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">layer_norm_out</span><span class="p">,</span> <span class="n">layer_out</span><span class="p">)</span>

      <span class="c1"># Aggregate per-layer attention probs.</span>
      <span class="n">aggregated_atten_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">layer_out</span><span class="p">,</span> <span class="n">out_prefix_states</span><span class="p">,</span> <span class="n">aggregated_atten_probs</span></div>

<div class="viewcode-block" id="TransformerDecoder.ComputePredictions"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder.ComputePredictions">[docs]</a>  <span class="k">def</span> <span class="nf">ComputePredictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decodes `targets` given encoded source.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder. Expected to contain:</span>

<span class="sd">        encoded - source encoding, of shape [time, batch, depth]. Can be [time,</span>
<span class="sd">                  batch, depth, num_layers] if is_transparent is set.</span>

<span class="sd">        padding - source encoding&#39;s padding, of shape [time, batch].</span>
<span class="sd">        segment_id - source segment id, of shape [time, batch].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">        predict. Each tensor in targets is of shape [batch, time].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `.NestedMap` containing output of last decoder layer and attention probs</span>

<span class="sd">      - softmax_input: Tensor of shape [time, batch, params.softmax.input_dim].</span>
<span class="sd">      - attention: `.NestedMap` of attention distributions of shape</span>
<span class="sd">        [batch, time, source_len].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_FProp</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span></div>

<div class="viewcode-block" id="TransformerDecoder.SampleSequenceDecode"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder.SampleSequenceDecode">[docs]</a>  <span class="k">def</span> <span class="nf">SampleSequenceDecode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decode via sampling from softmax at each step.</span>

<span class="sd">    Args:</span>
<span class="sd">      encoder_outputs: the outputs of the encoder.</span>

<span class="sd">    Returns:</span>
<span class="sd">      BeamSearchDecodeOutput, same as what BeamSearchDecode returns.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">non_tpu</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s1">&#39;tpu_beam_search&#39;</span>

    <span class="k">def</span> <span class="nf">InitCallback</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Wrapper for _InitBeamSearchStateCallback for sequence sampler.</span>

<span class="sd">      The main change is to ensure state tensors have fixed shapes.</span>

<span class="sd">      Args:</span>
<span class="sd">        theta: A `.NestedMap` object containing weights&#39; values of this layer</span>
<span class="sd">          and its children layers.</span>
<span class="sd">        encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">        num_hyps_per_beam: An int, number hyps to keep for source sentence.</span>

<span class="sd">      Returns:</span>
<span class="sd">        A NestedMap of</span>

<span class="sd">          - initial_results: a `.NestedMap` of initial results.</span>
<span class="sd">          - states: a `.NestedMap` of initial model states.</span>
<span class="sd">      &quot;&quot;&quot;</span>
      <span class="n">init_results</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_InitBeamSearchStateCallback</span><span class="p">(</span>
          <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">non_tpu</span><span class="p">:</span>
        <span class="n">prefix_states</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="s1">&#39;prefix_states&#39;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">):</span>
          <span class="n">key</span> <span class="o">=</span> <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">][</span><span class="s1">&#39;key&#39;</span><span class="p">]</span>
          <span class="n">value</span> <span class="o">=</span> <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span>
          <span class="n">key_shapes</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
          <span class="n">bs</span> <span class="o">=</span> <span class="n">key_shapes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
          <span class="n">atten_dim</span> <span class="o">=</span> <span class="n">key_shapes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
          <span class="n">zeros</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span> <span class="n">atten_dim</span><span class="p">],</span>
                           <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
          <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">][</span><span class="s1">&#39;key&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">key</span><span class="p">,</span> <span class="n">zeros</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
          <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">value</span><span class="p">,</span> <span class="n">zeros</span><span class="p">],</span>
                                                                 <span class="mi">0</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">init_results</span><span class="p">,</span> <span class="n">states</span>

    <span class="k">def</span> <span class="nf">PreBeamSearchCallback</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span>
                              <span class="n">encoder_outputs</span><span class="p">,</span>
                              <span class="n">step_ids</span><span class="p">,</span>
                              <span class="n">states</span><span class="p">,</span>
                              <span class="n">num_hyps_per_beam</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Wrapper for _PreBeamSearchStepCallback for sequence sampler.</span>

<span class="sd">      The main change is to ensure state tensors have fixed shapes.</span>

<span class="sd">      Args:</span>
<span class="sd">        theta: A `.NestedMap` object containing weights&#39; values of this layer</span>
<span class="sd">          and its children layers.</span>
<span class="sd">        encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">        step_ids: A tensor of shape [tgt_batch, 1].</span>
<span class="sd">        states: A `.NestedMap` of tensors representing states that the clients</span>
<span class="sd">          would like to keep track of for each of the active hyps.</span>
<span class="sd">        num_hyps_per_beam: Beam size.</span>

<span class="sd">      Returns:</span>
<span class="sd">        A NestedMap of</span>

<span class="sd">          - results: A `.NestedMap` of beam search results.</span>
<span class="sd">          - out_states: A `.NestedMap`. The updated states.</span>
<span class="sd">      &quot;&quot;&quot;</span>

      <span class="k">if</span> <span class="n">non_tpu</span><span class="p">:</span>
        <span class="c1"># Strip off paddings.</span>
        <span class="n">prefix_states</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="s1">&#39;prefix_states&#39;</span><span class="p">]</span>
        <span class="n">target_time</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">time_step</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">):</span>
          <span class="n">key</span> <span class="o">=</span> <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">][</span><span class="s1">&#39;key&#39;</span><span class="p">]</span>
          <span class="n">val</span> <span class="o">=</span> <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span>
          <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">][</span><span class="s1">&#39;key&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span>
              <span class="n">key</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">target_time</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
          <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span>
              <span class="n">val</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">target_time</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

      <span class="n">bs_results</span><span class="p">,</span> <span class="n">new_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PreBeamSearchStepCallback</span><span class="p">(</span>
          <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">step_ids</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">non_tpu</span><span class="p">:</span>
        <span class="c1"># Add back paddings (to maintain paddings shape).</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_states</span><span class="o">.</span><span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_0&#39;</span><span class="p">][</span><span class="s1">&#39;key&#39;</span><span class="p">])[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_states</span><span class="o">.</span><span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_0&#39;</span><span class="p">][</span><span class="s1">&#39;key&#39;</span><span class="p">])[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">pad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span> <span class="o">-</span> <span class="n">new_states</span><span class="o">.</span><span class="n">time_step</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span> <span class="n">dim</span><span class="p">],</span>
                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">):</span>
          <span class="n">key</span> <span class="o">=</span> <span class="n">new_states</span><span class="o">.</span><span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">][</span><span class="s1">&#39;key&#39;</span><span class="p">]</span>
          <span class="n">val</span> <span class="o">=</span> <span class="n">new_states</span><span class="o">.</span><span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span>
          <span class="n">new_states</span><span class="o">.</span><span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">][</span><span class="s1">&#39;key&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
              <span class="p">[</span><span class="n">key</span><span class="p">,</span> <span class="n">pad</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
          <span class="n">new_states</span><span class="o">.</span><span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
              <span class="p">[</span><span class="n">val</span><span class="p">,</span> <span class="n">pad</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

      <span class="k">return</span> <span class="n">bs_results</span><span class="p">,</span> <span class="n">new_states</span>

    <span class="n">random_seed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[],</span> <span class="n">maxval</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">31</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_sequence_sampler</span><span class="o">.</span><span class="n">Sample</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">random_seed</span><span class="p">,</span> <span class="n">InitCallback</span><span class="p">,</span>
        <span class="n">PreBeamSearchCallback</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PostBeamSearchStepCallback</span><span class="p">)</span>
    <span class="n">bs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># Only need to make sure topk_hyps has the right shape</span>
    <span class="c1"># [bs, num_hyps_per_beam], where num_hyps_per_beam=1 for sampling.</span>
    <span class="c1"># TODO(yuancao): Support sampling multiple sequences and remove</span>
    <span class="c1"># num_hyps_per_beam constraint.</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">num_hyps_per_beam</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_hyps</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">bs</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">)</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_ids</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">ids</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">sample</span><span class="o">.</span><span class="n">paddings</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_lens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">sample</span><span class="o">.</span><span class="n">topk_scores</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">logits</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span> <span class="o">*</span>
        <span class="n">weights</span><span class="p">,</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sample</span></div>

<div class="viewcode-block" id="TransformerDecoder._InitBeamSearchStateCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._InitBeamSearchStateCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_InitBeamSearchStateCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
                                   <span class="n">num_hyps_per_beam</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns initial beams search states.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      num_hyps_per_beam: An int, number hyps to keep for source sentence.</span>
<span class="sd">    Returns:</span>
<span class="sd">      A tuple (initial_results, states).</span>
<span class="sd">        initial_results: a `.NestedMap` of initial results.</span>
<span class="sd">          atten_probs:</span>
<span class="sd">            The initial attention probs, of shape [tgt_batch, src_len].</span>
<span class="sd">        states: a `.NestedMap` of initial model states.</span>
<span class="sd">          source_encs:</span>
<span class="sd">            A tensor of shape [src_batch, src_len, source_dim].</span>
<span class="sd">          source_paddings:</span>
<span class="sd">            A tensor of shape [src_batch, src_len].</span>
<span class="sd">          target_ids:</span>
<span class="sd">            Initial empty list of decoded ids. [num_hyps, 0].</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="n">source_encs</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span>
    <span class="n">num_hyps</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_hyps_per_beam</span>
    <span class="n">source_len</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Dummy attention probs</span>
    <span class="n">atten_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">source_len</span><span class="p">])</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
        <span class="n">source_len</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">initial_results</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
        <span class="n">log_probs</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span><span class="p">],</span>
                           <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)),</span>
        <span class="n">atten_probs</span><span class="o">=</span><span class="n">atten_probs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">init_step_ids</span><span class="p">:</span>
      <span class="n">initial_results</span><span class="p">[</span><span class="s1">&#39;step_ids&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_ExpandToNumHyps</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">init_step_ids</span><span class="p">,</span>
                                <span class="n">num_hyps_per_beam</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">num_hyps</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
      <span class="n">atten_hidden_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tr_atten_tpl</span><span class="o">.</span><span class="n">atten_hidden_dim</span>
      <span class="k">assert</span> <span class="p">[</span><span class="n">tpl</span><span class="o">.</span><span class="n">tr_atten_tpl</span><span class="o">.</span><span class="n">atten_hidden_dim</span> <span class="k">for</span> <span class="n">tpl</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span>
             <span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">atten_hidden_dim</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                 <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="p">),</span> <span class="s1">&#39;atten_hidden_dim must match&#39;</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">atten_hidden_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_atten_tpl</span><span class="o">.</span><span class="n">atten_hidden_dim</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">atten_hidden_dim</span><span class="p">:</span>
      <span class="n">atten_hidden_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;tpu_beam_search&#39;</span><span class="p">:</span>
      <span class="n">seq_len</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">seq_len</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">prefix_states</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">):</span>
      <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">]</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
          <span class="s1">&#39;key&#39;</span><span class="p">:</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">atten_hidden_dim</span><span class="p">],</span>
                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)),</span>
          <span class="s1">&#39;value&#39;</span><span class="p">:</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">atten_hidden_dim</span><span class="p">],</span>
                       <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)),</span>
      <span class="p">})</span>

    <span class="k">return</span> <span class="n">initial_results</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;prefix_states&#39;</span><span class="p">:</span> <span class="n">prefix_states</span><span class="p">,</span>
        <span class="s1">&#39;time_step&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="p">})</span></div>

<div class="viewcode-block" id="TransformerDecoder._PreBeamSearchStepCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._PreBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_PreBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">step_ids</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span>
                                 <span class="n">num_hyps_per_beam</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns logits for sampling ids and the next model states.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: a NestedMap computed by encoder.</span>
<span class="sd">      step_ids: A tensor of shape [tgt_batch, 1].</span>
<span class="sd">      states: A `.NestedMap` of tensors representing states that the clients</span>
<span class="sd">          would like to keep track of for each of the active hyps.</span>
<span class="sd">      num_hyps_per_beam: Beam size.</span>
<span class="sd">    Returns:</span>
<span class="sd">      A tuple (results, out_states).</span>
<span class="sd">        results: A `.NestedMap` of beam search results.</span>
<span class="sd">          atten_probs:</span>
<span class="sd">            The updated attention probs, of shape [tgt_batch, src_len].</span>
<span class="sd">          log_probs:</span>
<span class="sd">            Log prob for each of the tokens in the target vocab. This is of</span>
<span class="sd">            shape [tgt_batch, vocab_size].</span>
<span class="sd">        out_states: A `.NestedMap`. The updated states.</span>
<span class="sd">           source_encs:</span>
<span class="sd">             A tensor of shape [src_batch, src_len, source_dim].</span>
<span class="sd">           source_paddings:</span>
<span class="sd">             A tensor of shape [src_batch, src_len].</span>
<span class="sd">           target_ids:</span>
<span class="sd">             Updated list of decoded ids. [num_hyps, Num of decoded ids].</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="n">target_time</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">time_step</span>
    <span class="n">prefix_states</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">prefix_states</span>

    <span class="n">new_states</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

    <span class="n">layer_out</span><span class="p">,</span> <span class="n">updated_prefix_states</span><span class="p">,</span> <span class="n">atten_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ExtendStep</span><span class="p">(</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">step_ids</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">target_time</span><span class="p">,</span>
        <span class="n">prefix_states</span><span class="p">)</span>

    <span class="n">new_states</span><span class="o">.</span><span class="n">prefix_states</span> <span class="o">=</span> <span class="n">updated_prefix_states</span>
    <span class="n">new_states</span><span class="o">.</span><span class="n">time_step</span> <span class="o">=</span> <span class="n">target_time</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="n">softmax_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">layer_out</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span><span class="p">])</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">Logits</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="p">[</span><span class="n">softmax_input</span><span class="p">])</span>

    <span class="n">num_hyps</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">step_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># [time * batch, num_classes] -&gt; [time, batch, num_classes]</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hyps</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span><span class="p">))</span>
    <span class="c1"># [time, batch, num_classes] -&gt; [batch, time, num_classes]</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Only return logits for the last ids</span>
    <span class="n">log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">bs_results</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">atten_probs</span><span class="p">,</span>
        <span class="s1">&#39;log_probs&#39;</span><span class="p">:</span> <span class="n">log_probs</span><span class="p">,</span>
    <span class="p">})</span>

    <span class="k">return</span> <span class="n">bs_results</span><span class="p">,</span> <span class="n">new_states</span></div>

<div class="viewcode-block" id="TransformerDecoder._PostBeamSearchStepCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._PostBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_PostBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">new_step_ids</span><span class="p">,</span>
                                  <span class="n">states</span><span class="p">):</span>
    <span class="c1"># There is nothing to do here.</span>
    <span class="k">return</span> <span class="n">states</span></div>

<div class="viewcode-block" id="TransformerDecoder._AddAttenProbsScalarSummary"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._AddAttenProbsScalarSummary">[docs]</a>  <span class="k">def</span> <span class="nf">_AddAttenProbsScalarSummary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Add scalar summary of multi-headed transformer attention probs.</span>

<span class="sd">    This summary is primarily used to show statistics of the multi-headed</span>
<span class="sd">    attention that reveals potential sparsity related properties. The</span>
<span class="sd">    multi-headed attention probability tensors are exposed by</span>
<span class="sd">    `MultiHeadedAttention.ComputeContextVectorWithSource` with the name</span>
<span class="sd">    `multi_headed_atten_prob`. The following statistics are summarized:</span>

<span class="sd">    - 1_v_2: margin of the largest value vs. the 2nd largest</span>
<span class="sd">    - 1_v_3: similar, but vs the 3rd largest</span>
<span class="sd">    - mean: mean of the attention probs. NOTE: the sequences in a mini-batch</span>
<span class="sd">        are not always of the same length. The attention probability for the</span>
<span class="sd">        padded time index in target sequences are removed. However, the padding</span>
<span class="sd">        for the source sequences are left unchanged. As a result, the atten</span>
<span class="sd">        probs vectors will have some extra zero entries, so the mean calculated</span>
<span class="sd">        here will be smaller than the true mean.</span>
<span class="sd">    - source_padding_ratio: as explained above, the source paddings are not</span>
<span class="sd">        handled when computing the mean. This summary show the average ratio</span>
<span class="sd">        of time-steps that are padded values in the source sequences, to give</span>
<span class="sd">        a reference of roughly how much the mean summarized above should be</span>
<span class="sd">        adjusted.</span>
<span class="sd">    - 1_v_mean: margin of the largest value vs the mean value.</span>
<span class="sd">    - sum: the sum of the attention prob vectors. Should always be 1, for sanity</span>
<span class="sd">        check only.</span>

<span class="sd">    The quantity above are computed for each sequence in the mini-batch, each</span>
<span class="sd">    valid (target) sequence index, and each attention head, and then the</span>
<span class="sd">    average value is reported to the tensorboard as a scalar summary.</span>

<span class="sd">    Args:</span>
<span class="sd">      source_paddings: source padding, of shape [src_len, src_batch].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">        predict. Each tensor in targets is of shape [tgt_batch, tgt_len].</span>
<span class="sd">      atten_probs: a list of attention probs, each element is of shape [tgt_len,</span>
<span class="sd">        tgt_batch, src_len].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">default_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span>
    <span class="c1"># looks like fprop/wmt14_en_de_transformer/tower_0_0/dec</span>
    <span class="n">name_scope</span> <span class="o">=</span> <span class="n">default_graph</span><span class="o">.</span><span class="n">get_name_scope</span><span class="p">()</span>
    <span class="c1"># NOTE: shapes</span>
    <span class="c1"># source_paddings: [src_len, src_batch]</span>
    <span class="c1"># targets.paddings: [tgt_batch, tgt_len].</span>
    <span class="n">source_time</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">source_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">target_time</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">target_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">num_heads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trans</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">self_atten</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">num_attention_heads</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">)]):</span>
      <span class="n">target_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">target_batch</span><span class="p">)</span>

    <span class="n">source_padding_ratio</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">source_padding_ratio</span> <span class="o">/=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;source_padding_ratio&#39;</span><span class="p">,</span>
                         <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">source_padding_ratio</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">)):</span>
      <span class="n">suffix</span> <span class="o">=</span> <span class="s1">&#39;_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
      <span class="c1"># Tensor exported from MultiHeadedAttention.ComputeContextVectorWithSource</span>
      <span class="c1"># shape [target_time * batch_size, num_heads, source_time]</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">mha_probs</span> <span class="o">=</span> <span class="n">default_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span>
            <span class="n">name_scope</span> <span class="o">+</span> <span class="p">(</span><span class="s1">&#39;/aux_atten</span><span class="si">{}</span><span class="s1">/MultiHeadedAttention/&#39;</span>
                          <span class="s1">&#39;ComputeContextVectorWithSource/&#39;</span>
                          <span class="s1">&#39;multi_headed_atten_prob:0&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">suffix</span><span class="p">))</span>
      <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="c1"># no such tensor found, stop here</span>
        <span class="k">return</span>

      <span class="n">mha_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
          <span class="n">mha_probs</span><span class="p">,</span> <span class="p">(</span><span class="n">target_time</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">source_time</span><span class="p">))</span>

      <span class="c1"># remove time padding from target_time</span>
      <span class="c1"># (tgt_t, batch, n_heads, src_t) =&gt; (n_valid, n_heads, src_t)</span>
      <span class="c1"># explicit reshape is used here to give masks static ndims, otherwise</span>
      <span class="c1"># tf.boolean_mask will fail</span>
      <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">target_time</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">))</span>
      <span class="n">mha_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">mha_probs</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>

      <span class="c1"># note we did not remove invalid entries according to source_paddings,</span>
      <span class="c1"># because the result will no longer be a rectangular tensor, just</span>
      <span class="c1"># remember when interpreting some statistics like mean, there are some</span>
      <span class="c1"># padded zero entries due to non-uniform sequence lengths</span>

      <span class="c1"># (n_valid, n_heads, src_t) =&gt; (n_valid*n_heads, src_t)</span>
      <span class="n">mha_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mha_probs</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">mha_probs</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

      <span class="n">probs_top3</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">top_k</span><span class="p">(</span><span class="n">mha_probs</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
      <span class="n">probs_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">mha_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">probs_sum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">mha_probs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># sanity check</span>

      <span class="n">margins_12</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">probs_top3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">probs_top3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="n">margins_13</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">probs_top3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">probs_top3</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
      <span class="n">margins_1m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">probs_top3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">probs_mean</span><span class="p">)</span>
      <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;1_v_2/atten</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">margins_12</span><span class="p">)</span>
      <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;1_v_3/atten</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">margins_13</span><span class="p">)</span>
      <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;1_v_mean/atten</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">margins_1m</span><span class="p">)</span>
      <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;mean/atten</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">probs_mean</span><span class="p">))</span>
      <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;sum/atten</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">probs_sum</span><span class="p">))</span></div>

<div class="viewcode-block" id="TransformerDecoder._AddAttenProbsSummary"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._AddAttenProbsSummary">[docs]</a>  <span class="k">def</span> <span class="nf">_AddAttenProbsSummary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Add summary of attention probs.</span>

<span class="sd">    Args:</span>
<span class="sd">      source_paddings: source padding, of shape [src_len, src_batch].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">        predict. Each tensor in targets is of shape [tgt_batch, tgt_len].</span>
<span class="sd">      atten_probs: a list of attention probs, each element is of shape [tgt_len,</span>
<span class="sd">        tgt_batch, src_len].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_AddAttenProbsSummary</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster</span><span class="o">.</span><span class="n">add_summary</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">add_multiheaded_attention_scalar_summary</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_AddAttenProbsScalarSummary</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="InsertionDecoder"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.InsertionDecoder">[docs]</a><span class="k">class</span> <span class="nc">InsertionDecoder</span><span class="p">(</span><span class="n">base_decoder</span><span class="o">.</span><span class="n">BaseBeamSearchDecoder</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Basic Insertion decoder for MT (or any symbol based sequence).</span>

<span class="sd">  References:</span>
<span class="sd">    KERMIT: https://arxiv.org/pdf/1906.01604.pdf</span>
<span class="sd">    Insertion Transformer: https://arxiv.org/pdf/1902.03249.pdf</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="InsertionDecoder.Params"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.InsertionDecoder.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;token_emb&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Token embedding layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;position_emb&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">PositionalEmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Position embedding layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;model_dim&#39;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;Model dimension that applies to embedding &#39;</span>
        <span class="s1">&#39;layers and all Transformer layers.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_trans_layers&#39;</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;Number of Transformer layers.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;trans_tpl&#39;</span><span class="p">,</span> <span class="n">layers_with_attention</span><span class="o">.</span><span class="n">TransformerLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Transformer layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span> <span class="s1">&#39;Softmax params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;input_dropout_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;Prob at which we do input dropout.&#39;</span><span class="p">)</span>

    <span class="c1"># Default config for the token embeddings.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">32000</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">max_num_shards</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span>
        <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">))</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">scale_sqrt_depth</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Default config for the position embeddings.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>

    <span class="c1"># Default config for the transformer layers.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_atten_tpl</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_atten_tpl</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_fflayer_tpl</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_fflayer_tpl</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">4096</span>

    <span class="c1"># Default config for the softmax.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">32000</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_shards</span> <span class="o">=</span> <span class="mi">8</span>

    <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span> <span class="o">=</span> <span class="mi">300</span>

    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="InsertionDecoder.UpdateTargetVocabSize"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.InsertionDecoder.UpdateTargetVocabSize">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">UpdateTargetVocabSize</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">wpm_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the vocab size in the params.</span>

<span class="sd">    Args:</span>
<span class="sd">      p: model params.</span>
<span class="sd">      vocab_size: size of the vocabulary.</span>
<span class="sd">      wpm_model: file name prefix pointing to a wordpiece model.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Model params updated with the vocab size and wpm model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">vocab_size</span>
    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">%</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">embedding_dim</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;token_emb&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;position_emb&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">position_emb</span><span class="p">)</span>

    <span class="n">dropout_tpl</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">DropoutLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">dropout_tpl</span><span class="o">.</span><span class="n">keep_prob</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">input_dropout_prob</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;input_dropout&#39;</span><span class="p">,</span> <span class="n">dropout_tpl</span><span class="p">)</span>

    <span class="n">params_trans_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">):</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;trans_layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span>
      <span class="n">params</span><span class="o">.</span><span class="n">packed_input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
      <span class="n">params</span><span class="o">.</span><span class="n">has_aux_atten</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">mask_self_atten</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params_trans_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChildren</span><span class="p">(</span><span class="s1">&#39;trans&#39;</span><span class="p">,</span> <span class="n">params_trans_layers</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

<div class="viewcode-block" id="InsertionDecoder.ComputePredictions"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.InsertionDecoder.ComputePredictions">[docs]</a>  <span class="k">def</span> <span class="nf">ComputePredictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute 1-step of the insertion iteration.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: This should be None.</span>
<span class="sd">      targets: A `.NestedMap`.</span>
<span class="sd">        - ids: The target ids of shape [batch_size, time_dim].</span>
<span class="sd">        - paddings: The target paddings of shape [batch_size, time_dim].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `.NestedMap`.</span>
<span class="sd">        - outputs: The contextualized output vectors of shape</span>
<span class="sd">          [batch_size, time_dim, model_dim].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="c1"># TODO(williamchan): Enable cross-attention.</span>
    <span class="k">assert</span> <span class="n">encoder_outputs</span> <span class="ow">is</span> <span class="kc">None</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="c1"># [batch, time]</span>
      <span class="n">target_ids</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">ids</span>
      <span class="c1"># [time, batch]</span>
      <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">)</span>

      <span class="c1"># Embedding layer</span>
      <span class="c1"># [batch, time, model_dim]</span>
      <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">token_emb</span><span class="p">,</span> <span class="n">target_ids</span><span class="p">)</span>
      <span class="n">target_time</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_ids</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

      <span class="c1"># [1, time, model_dim]</span>
      <span class="n">posit_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">position_emb</span><span class="p">,</span> <span class="n">target_time</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>

      <span class="c1"># [time, batch, model_dim]</span>
      <span class="n">input_embs</span> <span class="o">=</span> <span class="n">token_embs</span> <span class="o">+</span> <span class="n">posit_embs</span>

      <span class="n">input_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">input_embs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
      <span class="n">input_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dropout</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">input_dropout</span><span class="p">,</span> <span class="n">input_embs</span><span class="p">)</span>

      <span class="n">layer_in</span> <span class="o">=</span> <span class="n">input_embs</span>
      <span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">layer_theta</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trans</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">trans</span><span class="p">):</span>
        <span class="c1"># [time, batch, model_dim]</span>
        <span class="n">layer_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">layer_theta</span><span class="p">,</span> <span class="n">layer_in</span><span class="p">,</span> <span class="n">target_paddings</span><span class="p">)</span>
        <span class="n">layer_in</span> <span class="o">=</span> <span class="n">layer_out</span>

      <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="n">layer_out</span><span class="p">)</span></div>

<div class="viewcode-block" id="InsertionDecoder.ComputeLoss"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.InsertionDecoder.ComputeLoss">[docs]</a>  <span class="k">def</span> <span class="nf">ComputeLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="c1"># pyformat: disable</span>
    <span class="sd">&quot;&quot;&quot;Returns the insertion loss.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object capturing decoder model parameters.</span>
<span class="sd">      predictions: A `.NestedMap` describing the decoding process, requiring</span>
<span class="sd">        .outputs: Tensor of shape [time, batch, params.softmax.input_dim].</span>
<span class="sd">      targets: A `.NestedMap`.</span>

<span class="sd">        - target_indices: A Tensor capturing the relevant insertion tokens to</span>
<span class="sd">          tf.gather_nd the log-probs.</span>

<span class="sd">        - target_weights: A Tensor capturing the relevant insertion tokens&#39;</span>
<span class="sd">          weights.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Two dicts.</span>
<span class="sd">        - A map from metric name (a python string) to a tuple (value, weight).</span>
<span class="sd">          Both value and weight are scalar Tensors.</span>
<span class="sd">        - A map from name to arbitrary tensors, where the first dimension must</span>
<span class="sd">          be the batch index.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># pyformat: enable</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">outputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span><span class="p">])</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">Logits</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">logits</span><span class="p">,</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">outputs</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span><span class="p">]</span>
        <span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>

    <span class="c1"># `target_indices` are in the form [batch, time, vocab], where as `logits`</span>
    <span class="c1"># are in the form [time, batch, vocab]. We need to swap the columns.</span>
    <span class="n">target_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
        <span class="n">predictions</span><span class="o">.</span><span class="n">tgt</span><span class="o">.</span><span class="n">target_indices</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span>
        <span class="n">predictions</span><span class="o">.</span><span class="n">tgt</span><span class="o">.</span><span class="n">target_indices</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">predictions</span><span class="o">.</span><span class="n">tgt</span><span class="o">.</span><span class="n">target_indices</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span>
    <span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">target_indices</span><span class="p">)</span> <span class="o">*</span>
        <span class="n">predictions</span><span class="o">.</span><span class="n">tgt</span><span class="o">.</span><span class="n">target_weights</span><span class="p">)</span>
    <span class="n">loss_weight</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">({</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">loss_weight</span><span class="p">)</span>
    <span class="p">},</span> <span class="p">{</span>
        <span class="s1">&#39;log_probs&#39;</span><span class="p">:</span> <span class="n">log_probs</span><span class="p">,</span>
        <span class="s1">&#39;logits&#39;</span><span class="p">:</span> <span class="n">logits</span>
    <span class="p">})</span></div></div>


<div class="viewcode-block" id="TransformerBatchMajorDecoder"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder">[docs]</a><span class="k">class</span> <span class="nc">TransformerBatchMajorDecoder</span><span class="p">(</span><span class="n">MTBaseDecoder</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Transformer decoder with batch major implementation.</span>

<span class="sd">  Implements the decoder of Transformer model:</span>
<span class="sd">  https://arxiv.org/abs/1706.03762.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="TransformerBatchMajorDecoder.Params"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;token_emb&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Token embedding layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;shared_emb&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Embedding shared with softmax.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;position_emb&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">PositionalEmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Position embedding layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;source_dim&#39;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;Dimension of encoder outputs.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;model_dim&#39;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;Model dimension that applies to embedding &#39;</span>
        <span class="s1">&#39;layers and all Transformer layers.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_trans_layers&#39;</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;Number of Transformer layers.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;trans_decoder_tpl&#39;</span><span class="p">,</span>
        <span class="n">batch_major_attention</span><span class="o">.</span><span class="n">TransformerDecoderLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
        <span class="s1">&#39;Transformer layer params. This can be a list of params &#39;</span>
        <span class="s1">&#39;of length equal to num_trans_layers or a factor of it, &#39;</span>
        <span class="s1">&#39;in which case the params are tiled as [a, a, ..., b, b, ...]&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;input_dropout_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;Prob at which we do input dropout.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;input_dropout_tpl&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">DropoutLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Input dropout layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;final_layer_norm&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;Whether or not to apply layer norm after transformer stack.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;use_fused_layernorm&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Whether to use fused layernorm.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;use_fast_softmax&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;Whether or not to use a faster softmax with label smoothing.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;input_data_format&#39;</span><span class="p">,</span> <span class="s1">&#39;TBC&#39;</span><span class="p">,</span> <span class="s1">&#39;The data format of input features: &#39;</span>
        <span class="s1">&#39;TBC for [time, batch, feature_dim], &#39;</span>
        <span class="s1">&#39;BTC for [batch, time, feature_dim].&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;prediction_data_format&#39;</span><span class="p">,</span> <span class="s1">&#39;TBC&#39;</span><span class="p">,</span>
        <span class="s1">&#39;The data format of predictions and per-example losses: &#39;</span>
        <span class="s1">&#39;TBC for [time, batch, ...], &#39;</span>
        <span class="s1">&#39;BTC for [batch, time, ...].&#39;</span><span class="p">)</span>

    <span class="c1"># Default config for the token embedding.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">32000</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">max_num_shards</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span>
        <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">))</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">scale_sqrt_depth</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Default config for the position embedding.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>

    <span class="c1"># Default config for the transformer decoder layers.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_decoder_tpl</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_decoder_tpl</span><span class="o">.</span><span class="n">tr_atten_tpl</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_decoder_tpl</span><span class="o">.</span><span class="n">tr_atten_tpl</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_decoder_tpl</span><span class="o">.</span><span class="n">tr_fflayer_tpl</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_decoder_tpl</span><span class="o">.</span><span class="n">tr_fflayer_tpl</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">2048</span>

    <span class="c1"># Default config for beam search.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">length_normalization</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">coverage_penalty</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">batch_major_state</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">batch_major_compute</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">short_seq_limit</span> <span class="o">=</span> <span class="mi">40</span>

    <span class="k">return</span> <span class="n">p</span></div>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">shared_emb</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">shared_emb</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">shared_emb</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;token_emb&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;position_emb&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">position_emb</span><span class="p">)</span>

    <span class="n">dropout_tpl</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">input_dropout_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
    <span class="n">dropout_tpl</span><span class="o">.</span><span class="n">keep_prob</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">input_dropout_prob</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;input_dropout&#39;</span><span class="p">,</span> <span class="n">dropout_tpl</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">trans_decoder_tpl</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">trans_decoder_tpl</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;num_trans_layers should be divisible by &#39;</span>
                         <span class="s1">&#39;len(p.trans_decoder_tpl)&#39;</span><span class="p">)</span>

    <span class="n">params_trans_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">trans_decoder_tpl</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">trans_decoder_tpl</span><span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">trans_decoder_tpl</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
        <span class="n">params</span><span class="o">.</span><span class="n">packed_input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">trans_decoder_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
        <span class="n">params</span><span class="o">.</span><span class="n">packed_input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;decoder_trans_layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span>
      <span class="n">params_trans_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">CreateChildren</span><span class="p">(</span><span class="s1">&#39;decoder_trans&#39;</span><span class="p">,</span> <span class="n">params_trans_layers</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">shared_emb</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">final_layer_norm</span><span class="p">:</span>
      <span class="n">layer_norm_p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNorm</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;final_ln&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">model_dim</span><span class="p">,</span>
          <span class="n">use_fused_layernorm</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">use_fused_layernorm</span><span class="p">,</span>
          <span class="n">fprop_dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">input_dropout_tpl</span><span class="o">.</span><span class="n">fprop_dtype</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;final_ln&#39;</span><span class="p">,</span> <span class="n">layer_norm_p</span><span class="p">)</span>

<div class="viewcode-block" id="TransformerBatchMajorDecoder._CreateChildrenVariables"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._CreateChildrenVariables">[docs]</a>  <span class="k">def</span> <span class="nf">_CreateChildrenVariables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">shared_emb</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;shared_emb&#39;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">AUTO_REUSE</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">InstantiateVariables</span><span class="p">()</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_CreateChildrenVariables</span><span class="p">()</span></div>

<div class="viewcode-block" id="TransformerBatchMajorDecoder._MaybeTransposeEncoderOutputs"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._MaybeTransposeEncoderOutputs">[docs]</a>  <span class="k">def</span> <span class="nf">_MaybeTransposeEncoderOutputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">target_data_format</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">input_data_format</span> <span class="o">==</span> <span class="n">target_data_format</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">encoder_outputs</span>
    <span class="n">transposed</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
        <span class="n">encoded</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">encoded</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">padding</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="s1">&#39;segment_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">transposed</span><span class="o">.</span><span class="n">segment_id</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">transposed</span><span class="o">.</span><span class="n">segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">segment_id</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">transposed</span></div>

<div class="viewcode-block" id="TransformerBatchMajorDecoder._MaybeTransposeTargets"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._MaybeTransposeTargets">[docs]</a>  <span class="k">def</span> <span class="nf">_MaybeTransposeTargets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">prediction_data_format</span> <span class="o">==</span> <span class="s1">&#39;BTC&#39;</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">targets</span>
    <span class="n">transposed</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">targets</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">k</span> <span class="o">!=</span> <span class="s1">&#39;transcripts&#39;</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;transpose_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">k</span><span class="p">):</span>
          <span class="n">v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
      <span class="n">transposed</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
    <span class="k">return</span> <span class="n">transposed</span></div>

<div class="viewcode-block" id="TransformerBatchMajorDecoder._FProp"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._FProp">[docs]</a>  <span class="k">def</span> <span class="nf">_FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decodes `targets` given encoded source.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: A &#39;.NestedMap&#39; object computed by encoder. * encoded -</span>
<span class="sd">        Source encoding of shape [source_time, source_batch, dim] or</span>
<span class="sd">        [source_batch, source_time, dim], depending on p.input_data_format. *</span>
<span class="sd">        paddings - Source encoding&#39;s padding of shape [source_time,</span>
<span class="sd">        source_batch] or [source_batch, source_time].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">        predict. Each tensor in targets is of shape [batch, target_time].</span>

<span class="sd">    Returns:</span>
<span class="sd">      softmax_input: Tensor of shape [target_time, batch, dim].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># [batch, source_time, dim]</span>
    <span class="n">encoder_out_bm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeTransposeEncoderOutputs</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="s1">&#39;BTC&#39;</span><span class="p">)</span>
    <span class="n">aux_vec</span> <span class="o">=</span> <span class="n">encoder_out_bm</span><span class="o">.</span><span class="n">encoded</span>
    <span class="n">aux_paddings</span> <span class="o">=</span> <span class="n">encoder_out_bm</span><span class="o">.</span><span class="n">padding</span>
    <span class="n">aux_segment_id</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">encoder_out_bm</span><span class="p">,</span> <span class="s1">&#39;segment_id&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="c1"># [batch, target_time]</span>
      <span class="n">target_ids</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">ids</span>
      <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span>
      <span class="n">target_time</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_ids</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
      <span class="n">target_segment_pos</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">target_segment_id</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
        <span class="n">target_segment_id</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">segment_ids</span>
        <span class="n">target_segment_pos</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">segment_pos</span>
        <span class="k">assert</span> <span class="n">aux_segment_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;Need to provide aux_segment_id &#39;</span>
                                            <span class="s1">&#39;for packed input.&#39;</span><span class="p">)</span>

      <span class="c1"># Embedding layer</span>
      <span class="c1"># [batch, target_time, dim]</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">shared_emb</span><span class="p">:</span>
        <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">token_emb</span><span class="p">,</span> <span class="n">target_ids</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">target_ids</span><span class="p">)</span>
      <span class="c1"># [1, target_time, dim]</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
        <span class="n">posit_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">FPropWithPosition</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">.</span><span class="n">position_emb</span><span class="p">,</span> <span class="n">target_segment_pos</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">posit_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">position_emb</span><span class="p">,</span> <span class="n">target_time</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
      <span class="c1"># [batch, target_time, dim]</span>
      <span class="n">input_embs</span> <span class="o">=</span> <span class="n">token_embs</span> <span class="o">+</span> <span class="n">posit_embs</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">input_dropout_tpl</span><span class="o">.</span><span class="n">fprop_dtype</span><span class="p">:</span>
        <span class="n">input_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">input_embs</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">input_dropout_tpl</span><span class="o">.</span><span class="n">fprop_dtype</span><span class="p">)</span>
        <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">,</span>
                                  <span class="n">p</span><span class="o">.</span><span class="n">input_dropout_tpl</span><span class="o">.</span><span class="n">fprop_dtype</span><span class="p">)</span>

      <span class="n">input_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dropout</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">input_dropout</span><span class="p">,</span> <span class="n">input_embs</span><span class="p">)</span>
      <span class="n">layer_in</span> <span class="o">=</span> <span class="n">input_embs</span>
      <span class="c1"># Explicitly set the input shape of Transformer layers, to avoid</span>
      <span class="c1"># unknown shape error occurred to tf.einsum on nonTPU devices.</span>
      <span class="n">batch</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">aux_vec</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
      <span class="n">layer_in</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">layer_in</span><span class="p">,</span> <span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">target_time</span><span class="p">,</span> <span class="n">dim</span><span class="p">])</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
        <span class="n">segment_padding</span> <span class="o">=</span> <span class="n">batch_major_attention</span><span class="o">.</span><span class="n">SegmentMask</span><span class="p">(</span>
            <span class="n">target_segment_id</span><span class="p">,</span>
            <span class="n">target_segment_id</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">layer_in</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">apply_dtype_min</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">causal_padding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
                    <span class="n">batch_major_attention</span><span class="o">.</span><span class="n">CausalPadding</span><span class="p">(</span>
                        <span class="n">target_time</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">layer_in</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span> <span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
            <span class="mi">1</span><span class="p">)</span>
        <span class="n">segment_padding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">causal_padding</span><span class="p">,</span> <span class="n">segment_padding</span><span class="p">)</span>
        <span class="n">segment_mask</span> <span class="o">=</span> <span class="n">segment_padding</span> <span class="o">*</span> <span class="n">batch_major_attention</span><span class="o">.</span><span class="n">GetDtypeMin</span><span class="p">(</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">layer_in</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">aux_segment_mask</span> <span class="o">=</span> <span class="n">batch_major_attention</span><span class="o">.</span><span class="n">SegmentMask</span><span class="p">(</span>
            <span class="n">target_segment_id</span><span class="p">,</span> <span class="n">aux_segment_id</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">layer_in</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">layer_theta</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder_trans</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">decoder_trans</span><span class="p">):</span>
        <span class="c1"># [batch, target_time, dim]</span>
        <span class="n">layer_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
            <span class="n">layer_theta</span><span class="p">,</span>
            <span class="n">layer_in</span><span class="p">,</span>
            <span class="n">target_paddings</span><span class="p">,</span>
            <span class="n">aux_vec</span><span class="p">,</span>
            <span class="n">aux_paddings</span><span class="p">,</span>
            <span class="n">segment_mask</span><span class="o">=</span><span class="n">segment_mask</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">aux_segment_mask</span><span class="o">=</span><span class="n">aux_segment_mask</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">layer_in</span> <span class="o">=</span> <span class="n">layer_out</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">final_layer_norm</span><span class="p">:</span>
        <span class="n">layer_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_ln</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">final_ln</span><span class="p">,</span> <span class="n">layer_out</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">prediction_data_format</span> <span class="o">==</span> <span class="s1">&#39;TBC&#39;</span><span class="p">:</span>
        <span class="c1"># Transpose the softmax_input to match the input requirement of</span>
        <span class="c1"># ComputePredictions.</span>
        <span class="n">layer_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">layer_out</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
      <span class="k">return</span> <span class="n">layer_out</span></div>

<div class="viewcode-block" id="TransformerBatchMajorDecoder.ExtendStep"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder.ExtendStep">[docs]</a>  <span class="k">def</span> <span class="nf">ExtendStep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">theta</span><span class="p">,</span>
                 <span class="n">encoder_outputs</span><span class="p">,</span>
                 <span class="n">new_ids</span><span class="p">,</span>
                 <span class="n">time_step</span><span class="p">,</span>
                 <span class="n">prefix_states</span><span class="p">,</span>
                 <span class="n">use_short_seq_opt</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Extend prefix as represented by `prefix_states` by one more step.</span>

<span class="sd">    This function is expected to be called during fast decoding of Transformer</span>
<span class="sd">    models.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: A &#39;.NestedMap&#39; object computed by encoder.</span>

<span class="sd">        - encoded: Source encoding of shape [source_time, source_batch, dim] or</span>
<span class="sd">          [source_batch, source_time, dim], depending on p.input_data_format.</span>
<span class="sd">        - paddings: Source encoding&#39;s padding of shape</span>
<span class="sd">          [source_time, source_batch] or [source_batch, source_time].</span>
<span class="sd">      new_ids: New input ids, of shape [target_batch, 1].</span>
<span class="sd">      time_step: A scalar, the current decode step, 0-based.</span>
<span class="sd">      prefix_states: A `.NestedMap` representing the previous decoded states.</span>

<span class="sd">        - key: [target_time, target_batch, num_heads, dim_per_head].</span>
<span class="sd">        - value: [target_time, target_batch, num_heads, dim_per_head].</span>
<span class="sd">      use_short_seq_opt: A bool, whether using short sequence optimization.</span>

<span class="sd">    Returns:</span>
<span class="sd">      last_decoder_out: The last decoder layer of shape [target_batch, dim].</span>
<span class="sd">      updated_prefix_states: A `.NestedMap` representing the updated states.</span>

<span class="sd">        - key: [target_time, target_batch, num_heads, dim_per_head].</span>
<span class="sd">        - value: [target_time, target_batch, num_heads, dim_per_head].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">encoder_out_bm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeTransposeEncoderOutputs</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="s1">&#39;BTC&#39;</span><span class="p">)</span>
    <span class="c1"># [source_batch, source_time, dim]</span>
    <span class="n">aux_vec</span> <span class="o">=</span> <span class="n">encoder_out_bm</span><span class="o">.</span><span class="n">encoded</span>
    <span class="c1"># [source_batch, source_time]</span>
    <span class="n">aux_paddings</span> <span class="o">=</span> <span class="n">encoder_out_bm</span><span class="o">.</span><span class="n">padding</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="c1"># Embedding layer</span>
      <span class="c1"># [target_batch, 1, dim]</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">shared_emb</span><span class="p">:</span>
        <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">token_emb</span><span class="p">,</span> <span class="n">new_ids</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">new_ids</span><span class="p">)</span>
      <span class="c1"># [1, 1, dim]</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">time_step</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">time_step_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">time_step</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">time_step</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">time_step_t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="n">time_step</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unexpected input type `</span><span class="si">%s</span><span class="s1">` for `time_step`.&#39;</span> <span class="o">%</span>
                         <span class="nb">type</span><span class="p">(</span><span class="n">time_step</span><span class="p">))</span>
      <span class="n">posit_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">FPropWithPosition</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">position_emb</span><span class="p">,</span>
                                                       <span class="n">time_step_t</span><span class="p">)</span>
      <span class="c1"># [target_batch, 1, dim]</span>
      <span class="n">input_embs</span> <span class="o">=</span> <span class="n">token_embs</span> <span class="o">+</span> <span class="n">posit_embs</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">input_dropout_tpl</span><span class="o">.</span><span class="n">fprop_dtype</span><span class="p">:</span>
        <span class="n">input_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">input_embs</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">input_dropout_tpl</span><span class="o">.</span><span class="n">fprop_dtype</span><span class="p">)</span>

      <span class="c1"># Make a copy of the input.</span>
      <span class="n">updated_prefix_states</span> <span class="o">=</span> <span class="n">prefix_states</span><span class="o">.</span><span class="n">DeepCopy</span><span class="p">()</span>

      <span class="n">input_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dropout</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">input_dropout</span><span class="p">,</span> <span class="n">input_embs</span><span class="p">)</span>
      <span class="n">layer_in</span> <span class="o">=</span> <span class="n">input_embs</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layer_theta</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
          <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder_trans</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">decoder_trans</span><span class="p">)):</span>
        <span class="c1"># [target_batch, 1, dim]</span>
        <span class="n">layer_out</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">updated_states</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">ExtendStep</span><span class="p">(</span>
            <span class="n">layer_theta</span><span class="p">,</span> <span class="n">layer_in</span><span class="p">,</span> <span class="n">aux_vec</span><span class="p">,</span> <span class="n">aux_paddings</span><span class="p">,</span>
            <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">],</span> <span class="n">time_step</span><span class="p">,</span> <span class="n">use_short_seq_opt</span><span class="p">)</span>
        <span class="n">updated_prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">updated_states</span>
        <span class="n">layer_in</span> <span class="o">=</span> <span class="n">layer_out</span>

      <span class="c1"># [target_batch, dim]</span>
      <span class="n">last_decoder_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">layer_out</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">final_layer_norm</span><span class="p">:</span>
        <span class="n">last_decoder_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_ln</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">final_ln</span><span class="p">,</span> <span class="n">last_decoder_out</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">last_decoder_out</span><span class="p">,</span> <span class="n">updated_prefix_states</span></div>

<div class="viewcode-block" id="TransformerBatchMajorDecoder.ComputePredictions"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder.ComputePredictions">[docs]</a>  <span class="k">def</span> <span class="nf">ComputePredictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decodes `targets` given encoded source.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: A &#39;.NestedMap&#39; object computed by encoder.</span>

<span class="sd">        - encoded: Source encoding of shape [source_time, source_batch, dim] or</span>
<span class="sd">          [source_batch, source_time, dim], depending on p.input_data_format.</span>
<span class="sd">        - paddings: Source encoding&#39;s padding of shape</span>
<span class="sd">          [source_time, source_batch] or [source_batch, source_time].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">        predict. Each tensor in targets is of shape [batch, target_time].</span>

<span class="sd">    Returns:</span>
<span class="sd">      Output of the last decoder layer, of shape [target_time, batch, dim].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_FProp</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span></div>

<div class="viewcode-block" id="TransformerBatchMajorDecoder._FPropFastSoftmax"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._FPropFastSoftmax">[docs]</a>  <span class="k">def</span> <span class="nf">_FPropFastSoftmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                        <span class="n">theta</span><span class="p">,</span>
                        <span class="n">softmax_input</span><span class="p">,</span>
                        <span class="n">target_labels</span><span class="p">,</span>
                        <span class="n">target_weights</span><span class="p">,</span>
                        <span class="n">time_axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes cross-entropy loss with label smoothing.</span>

<span class="sd">    As compared to the _FPropSoftmax, this version is faster by removing the</span>
<span class="sd">    data formatting overheads and bias of the linear projection. A normalizing</span>
<span class="sd">    factor is also added to the xentropy result be better model quality.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      softmax_input: A tensor of shape [time, batch, p.softmax.input_dim].</span>
<span class="sd">      target_labels: A matrix of tf.int32. [time, batch].</span>
<span class="sd">      target_weights: A matrix of params.dtype. [time, batch].</span>
<span class="sd">      time_axis: If 0, the inputs are time-major: [time, batch, ...]; if 1, the</span>
<span class="sd">        inputs are batch-major: [batch, time, ...].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (metrics, per_example_tensors).</span>
<span class="sd">        metrics:</span>
<span class="sd">          A dictionary containing metrics for the xent loss and prediction</span>
<span class="sd">          accuracy.</span>
<span class="sd">        per_example_tensors:</span>
<span class="sd">          A dictionary of per-example tensors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">per_word_avg_loss</span>

    <span class="n">softmax_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">softmax_input</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span><span class="p">])</span>

    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">SimpleLogits</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">softmax_input</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">high_confidence</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">uncertainty</span>
    <span class="n">low_confidence</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
        <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">normalizing</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span>
        <span class="n">high_confidence</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">high_confidence</span><span class="p">)</span> <span class="o">+</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="n">low_confidence</span> <span class="o">*</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">low_confidence</span> <span class="o">+</span> <span class="mf">1e-20</span><span class="p">))</span>

    <span class="n">target_labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_labels</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">soft_targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">target_labels</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
        <span class="n">depth</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span>
        <span class="n">on_value</span><span class="o">=</span><span class="n">high_confidence</span><span class="p">,</span>
        <span class="n">off_value</span><span class="o">=</span><span class="n">low_confidence</span><span class="p">)</span>

    <span class="n">xentropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">soft_targets</span><span class="p">)</span>
    <span class="n">xent</span> <span class="o">=</span> <span class="n">xentropy</span> <span class="o">-</span> <span class="n">normalizing</span>

    <span class="n">target_weights_shape</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">)</span>
    <span class="n">orig_target_weights</span> <span class="o">=</span> <span class="n">target_weights</span>
    <span class="n">target_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">xent</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">total_xent</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">xent</span> <span class="o">*</span> <span class="n">target_weights</span><span class="p">)</span>
    <span class="n">total_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">target_weights</span><span class="p">)</span>

    <span class="n">final_loss</span> <span class="o">=</span> <span class="n">total_xent</span> <span class="o">/</span> <span class="n">total_weights</span>
    <span class="n">loss_weight</span> <span class="o">=</span> <span class="n">total_weights</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">final_loss</span><span class="p">,</span> <span class="n">loss_weight</span><span class="p">),</span>
        <span class="s1">&#39;log_pplx&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">final_loss</span><span class="p">,</span> <span class="n">loss_weight</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="n">per_example_tensors</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_example_tensors</span><span class="p">:</span>
      <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;per_example_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
          <span class="n">xent</span><span class="p">,</span> <span class="n">target_weights_shape</span><span class="p">)</span>
      <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;per_sequence_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
          <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;per_example_loss&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">orig_target_weights</span><span class="p">,</span>
          <span class="n">axis</span><span class="o">=</span><span class="n">time_axis</span><span class="p">)</span>
      <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;per_sequence_loss&#39;</span><span class="p">]</span>
      <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
          <span class="n">logits</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">target_weights_shape</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">0</span><span class="p">))</span>
      <span class="n">per_example_tensors</span><span class="p">[</span><span class="s1">&#39;log_probs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">target_weights_shape</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">0</span><span class="p">))</span>

    <span class="c1"># NOTE: tf.argmax is not implemented for the JF backend, see b/36093673</span>
    <span class="c1"># Skip the fraction_of_correct_next_step_preds during training.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_eval</span><span class="p">:</span>
      <span class="n">correct_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_labels</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])),</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">correct_next_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
          <span class="n">correct_preds</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">target_weights</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
      <span class="n">num_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">target_weights</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
      <span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span>
          <span class="n">correct_next_preds</span> <span class="o">/</span> <span class="n">num_preds</span><span class="p">,</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fraction_of_correct_next_step_preds&#39;</span><span class="p">)</span>
      <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;fraction_of_correct_next_step_preds&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">num_preds</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">per_example_tensors</span></div>

<div class="viewcode-block" id="TransformerBatchMajorDecoder.ComputeLoss"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder.ComputeLoss">[docs]</a>  <span class="k">def</span> <span class="nf">ComputeLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Populates a metrics dictionary based on the output of ComputePredictions.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: Nested map describing decoder model parameters.</span>
<span class="sd">      predictions: NestedMap describing the decoding process, requiring:</span>
<span class="sd">        .softmax_input: Tensor of shape [time, batch, params.softmax.input_dim].</span>
<span class="sd">      targets: NestedMap describing the target sequences.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Two dicts.</span>

<span class="sd">        - A map from metric name (a python string) to a tuple (value, weight).</span>
<span class="sd">          Both value and weight are scalar Tensors.</span>
<span class="sd">        - A map from name to arbitrary tensors, where the first dimension must</span>
<span class="sd">          be the batch index.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeTransposeTargets</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">):</span>
      <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">softmax_input</span>
    <span class="n">time_axis</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;TBC&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;BTC&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">prediction_data_format</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_fast_softmax</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_FPropFastSoftmax</span><span class="p">(</span>
          <span class="n">theta</span><span class="p">,</span>
          <span class="n">predictions</span><span class="p">,</span>
          <span class="n">targets</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
          <span class="n">targets</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span>
          <span class="n">time_axis</span><span class="o">=</span><span class="n">time_axis</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_FPropSoftmax</span><span class="p">(</span>
          <span class="n">theta</span><span class="p">,</span>
          <span class="n">predictions</span><span class="p">,</span>
          <span class="n">targets</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
          <span class="n">targets</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span>
          <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">,</span>
          <span class="n">targets</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;segment_ids&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
          <span class="n">time_axis</span><span class="o">=</span><span class="n">time_axis</span><span class="p">)</span></div>

<div class="viewcode-block" id="TransformerBatchMajorDecoder._InitBeamSearchStateCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._InitBeamSearchStateCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_InitBeamSearchStateCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span>
                                   <span class="n">num_hyps_per_beam</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns initial beams search states.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: A &#39;.NestedMap&#39; object computed by encoder. * encoded -</span>
<span class="sd">        Source encoding of shape [source_time, source_batch, dim] or</span>
<span class="sd">        [source_batch, source_time, dim], depending on p.input_data_format. *</span>
<span class="sd">        paddings - Source encoding&#39;s padding of shape [source_time,</span>
<span class="sd">        source_batch] or [source_batch, source_time].</span>
<span class="sd">      num_hyps_per_beam: An int, number hyps to keep for source sentence.</span>

<span class="sd">    Returns:</span>
<span class="sd">      initial_results: A `.NestedMap` of initial beam search results.</span>
<span class="sd">        log_probs - Log prob for each of the tokens in the target vocab,</span>
<span class="sd">                    of shape [target_batch, vocab_size].</span>
<span class="sd">        atten_probs - The updated attention probs, of shape</span>
<span class="sd">                      [target_batch, source_time].</span>
<span class="sd">      states: A `.NestedMap` of initial model states.</span>
<span class="sd">        prefix_states - A `.NestedMap` representing the empty decoded states.</span>
<span class="sd">        key   - [target_time, target_batch, num_heads, dim_per_head].</span>
<span class="sd">        value - [target_time, target_batch, num_heads, dim_per_head].</span>
<span class="sd">        time_step - A scalar, the initial decode step (0).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>

    <span class="c1"># [source_batch, source_time, dim]</span>
    <span class="n">encoder_out_bm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeTransposeEncoderOutputs</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="s1">&#39;BTC&#39;</span><span class="p">)</span>
    <span class="n">aux_vec</span> <span class="o">=</span> <span class="n">encoder_out_bm</span><span class="o">.</span><span class="n">encoded</span>
    <span class="n">target_batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">aux_vec</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_hyps_per_beam</span>
    <span class="n">source_time</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">aux_vec</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">target_time</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span>

    <span class="n">log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span><span class="p">],</span>
                         <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="c1"># Dummy attention probs</span>
    <span class="n">atten_probs</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">source_time</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="o">/</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">source_time</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)))</span>
    <span class="n">initial_results</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
        <span class="n">log_probs</span><span class="o">=</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">atten_probs</span><span class="o">=</span><span class="n">atten_probs</span><span class="p">)</span>

    <span class="n">prefix_states</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">):</span>
      <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_trans</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="o">.</span><span class="n">InitStates</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">.</span><span class="n">decoder_trans</span><span class="p">[</span><span class="n">layer</span><span class="p">],</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">target_time</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">initial_results</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;prefix_states&#39;</span><span class="p">:</span> <span class="n">prefix_states</span><span class="p">,</span>
        <span class="s1">&#39;time_step&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="p">})</span></div>

<div class="viewcode-block" id="TransformerBatchMajorDecoder._PreBeamSearchStepCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._PreBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_PreBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                 <span class="n">theta</span><span class="p">,</span>
                                 <span class="n">encoder_outputs</span><span class="p">,</span>
                                 <span class="n">new_ids</span><span class="p">,</span>
                                 <span class="n">states</span><span class="p">,</span>
                                 <span class="n">num_hyps_per_beam</span><span class="p">,</span>
                                 <span class="n">use_short_seq_opt</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns logits for sampling ids and the next model states.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      encoder_outputs: A &#39;.NestedMap&#39; object computed by encoder.</span>

<span class="sd">        - encoded: Source encoding of shape [source_time, source_batch, dim] or</span>
<span class="sd">          [source_batch, source_time, dim], depending on p.input_data_format.</span>
<span class="sd">        - paddings: Source encoding&#39;s padding of shape</span>
<span class="sd">          [source_time, source_batch] or [source_batch, source_time].</span>
<span class="sd">      new_ids: A tensor of shape [target_batch, 1].</span>
<span class="sd">      states: A `.NestedMap` of tensors representing states that the clients</span>
<span class="sd">        would like to keep track of for each of the active hyps. prefix_states -</span>
<span class="sd">        A `.NestedMap` representing the previous decoded states.</span>

<span class="sd">          - key: [target_time, target_batch, num_heads, dim_per_head].</span>
<span class="sd">          - value: [target_time, target_batch, num_heads, dim_per_head].</span>
<span class="sd">          - time_step: A scalar, the current decode step, 0-based.</span>
<span class="sd">      num_hyps_per_beam: A scalar, beam size.</span>
<span class="sd">      use_short_seq_opt: A bool, whether using short sequence optimization.</span>

<span class="sd">    Returns:</span>
<span class="sd">      bs_results: A `.NestedMap` of beam search results.</span>
<span class="sd">        log_probs - Log prob for each of the tokens in the target vocab,</span>
<span class="sd">                    of shape [target_batch, vocab_size].</span>
<span class="sd">        atten_probs - The updated attention probs, of shape</span>
<span class="sd">                      [target_batch, source_time].</span>
<span class="sd">      new_states: A `.NestedMap` object. The updated states.</span>
<span class="sd">        prefix_states - A `.NestedMap` representing the updated decoded states.</span>
<span class="sd">        key   - [target_time, target_batch, num_heads, dim_per_head].</span>
<span class="sd">        value - [target_time, target_batch, num_heads, dim_per_head].</span>
<span class="sd">        time_step - A scalar, the current decode step, 0-based.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># [source_batch, source_time, dim]</span>
    <span class="n">encoder_out_bm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MaybeTransposeEncoderOutputs</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="s1">&#39;BTC&#39;</span><span class="p">)</span>

    <span class="n">target_batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">new_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">source_batch</span> <span class="o">=</span> <span class="n">target_batch</span> <span class="o">//</span> <span class="n">num_hyps_per_beam</span>

    <span class="n">new_states</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">time_step</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">time_step</span>
    <span class="n">prefix_states</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">prefix_states</span>

    <span class="c1"># The inputs are ordered as num_hyps_per_beam by num_beams,</span>
    <span class="c1"># which needs to be transposed for the layer computation.</span>
    <span class="c1"># [num_hyps_per_beam, source_batch, 1]</span>
    <span class="n">new_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_ids</span><span class="p">,</span> <span class="p">[</span><span class="n">num_hyps_per_beam</span><span class="p">,</span> <span class="n">source_batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="c1"># [source_batch, num_hyps_per_beam, 1]</span>
    <span class="n">new_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">new_ids</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="c1"># [source_batch * num_hyps_per_beam, 1]</span>
    <span class="n">new_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_ids</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="n">softmax_input</span><span class="p">,</span> <span class="n">updated_prefix_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ExtendStep</span><span class="p">(</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">new_ids</span><span class="p">,</span> <span class="n">time_step</span><span class="p">,</span> <span class="n">prefix_states</span><span class="p">,</span>
        <span class="n">use_short_seq_opt</span><span class="p">)</span>

    <span class="c1"># Transpose the outputs as num_beams by num_hyps_per_beam to match the</span>
    <span class="c1"># beam search requirement.</span>
    <span class="c1"># [source_batch, num_hyps_per_beam, dim]</span>
    <span class="n">softmax_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">softmax_input</span><span class="p">,</span>
                               <span class="p">[</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">num_hyps_per_beam</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="c1"># [num_hyps_per_beam, source_batch, dim]</span>
    <span class="n">softmax_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">softmax_input</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="c1"># [num_hyps_per_beam * source_batch, dim]</span>
    <span class="n">softmax_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">softmax_input</span><span class="p">,</span> <span class="p">[</span><span class="n">target_batch</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># [target_batch, vocab_size]</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">Logits</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="p">[</span><span class="n">softmax_input</span><span class="p">])</span>

    <span class="c1"># Only return logits for the last ids</span>
    <span class="n">log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>

    <span class="c1"># Dummy attention probs</span>
    <span class="n">source_time</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">encoder_out_bm</span><span class="o">.</span><span class="n">padding</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">atten_probs</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">source_time</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">))</span> <span class="o">/</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">source_time</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">FPropDtype</span><span class="p">(</span><span class="n">p</span><span class="p">)))</span>

    <span class="n">bs_results</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;log_probs&#39;</span><span class="p">:</span> <span class="n">log_probs</span><span class="p">,</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">atten_probs</span><span class="p">,</span>
    <span class="p">})</span>

    <span class="n">new_states</span><span class="o">.</span><span class="n">prefix_states</span> <span class="o">=</span> <span class="n">updated_prefix_states</span>
    <span class="n">new_states</span><span class="o">.</span><span class="n">time_step</span> <span class="o">=</span> <span class="n">time_step</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">bs_results</span><span class="p">,</span> <span class="n">new_states</span></div>

<div class="viewcode-block" id="TransformerBatchMajorDecoder._PostBeamSearchStepCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._PostBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_PostBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">new_step_ids</span><span class="p">,</span>
                                  <span class="n">states</span><span class="p">):</span>
    <span class="c1"># There is nothing to do here.</span>
    <span class="k">return</span> <span class="n">states</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2018.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>