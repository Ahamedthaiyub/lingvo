

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>lingvo.core.layers module &mdash; Lingvo  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="lingvo.core.layers_with_attention module" href="lingvo.core.layers_with_attention.html" />
    <link rel="prev" title="lingvo.core.inspect_utils module" href="lingvo.core.inspect_utils.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> Lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="lingvo.html">lingvo package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="lingvo.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="lingvo.core.html">lingvo.core package</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="lingvo.core.html#subpackages">Subpackages</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="lingvo.core.html#submodules">Submodules</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="lingvo.tasks.html">lingvo.tasks package</a></li>
<li class="toctree-l3"><a class="reference internal" href="lingvo.tools.html">lingvo.tools package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lingvo.html#submodules">Submodules</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="lingvo.html">lingvo package</a> &raquo;</li>
        
          <li><a href="lingvo.core.html">lingvo.core package</a> &raquo;</li>
        
      <li>lingvo.core.layers module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/lingvo.core.layers.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-lingvo.core.layers">
<span id="lingvo-core-layers-module"></span><h1>lingvo.core.layers module<a class="headerlink" href="#module-lingvo.core.layers" title="Permalink to this headline">¶</a></h1>
<p>Common layers.</p>
<dl class="py class">
<dt id="lingvo.core.layers.DeconvLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">DeconvLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DeconvLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DeconvLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Deconv (transposed conv2d) layer.</p>
<p>DeconvLayer is different from ConvTransposeLayer in that
DeconvLayer does not support padding and biasing. Hence,
it’s simpler and more basic than ConvTransposeLayer.</p>
<dl class="py method">
<dt id="lingvo.core.layers.DeconvLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DeconvLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DeconvLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.DeconvLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DeconvLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DeconvLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.DeconvLayer.OutShape">
<code class="sig-name descname">OutShape</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">in_shape</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DeconvLayer.OutShape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DeconvLayer.OutShape" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the output shape given the input shape.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.DeconvLayer._ApplyConv">
<code class="sig-name descname">_ApplyConv</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DeconvLayer._ApplyConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DeconvLayer._ApplyConv" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.DeconvLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DeconvLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DeconvLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply deconvolution to inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A NestedMap object containing weights’ values of this layer and its
children layers.</p></li>
<li><p><strong>inputs</strong> – The inputs tensor. It is expected to be of shape [batch, height,
width, channel].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>outputs. outputs is expected to have shape [batch, height * height_stride,
width * width_stride, out_channel].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.IdentityLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">IdentityLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#IdentityLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.IdentityLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Identity layer, adds name and propagates its input.</p>
<dl class="py method">
<dt id="lingvo.core.layers.IdentityLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#IdentityLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.IdentityLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Identity mapping.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – The input tensor or the input NestedMap.</p></li>
<li><p><strong>*args</strong> – Arguments to be ignored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor with the same shape and type of inputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.IdentityLayer.FPropMeta">
<em class="property">classmethod </em><code class="sig-name descname">FPropMeta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#IdentityLayer.FPropMeta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.IdentityLayer.FPropMeta" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns metadata about the <a class="reference internal" href="#lingvo.core.layers.IdentityLayer.FProp" title="lingvo.core.layers.IdentityLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> computation for this layer.</p>
<p><strong>Experimental feature.</strong>
Don’t use or depend on it without consulting Lingvo authors.</p>
<p>E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">SomeComplexLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
<span class="n">meta</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">FPropMeta</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">tshape</span><span class="o">.</span><span class="n">Shape</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;channels&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.flops</span></code> gives an estimate count of floating point operations done by
one <a class="reference internal" href="#lingvo.core.layers.IdentityLayer.FProp" title="lingvo.core.layers.IdentityLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> given an input tensor of shape [128, 20, 50, channels].
<code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.out_shapes</span></code> is a tuple of TShape, which tells you what shape
of tensors this layer will return.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – The param of a layer of this layer type.</p></li>
<li><p><strong>*args</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> with</p>
<ul class="simple">
<li><p>flops - The estimated number of floating point operations incurred by
this fprop.</p></li>
<li><p>out_shapes - A tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">TShape</span></code>. I.e., <code class="xref py py-obj docutils literal notranslate"><span class="pre">out_shapes[i]</span></code>
represents the shape of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">i</span></code>-th returned tensor of the fprop.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.BaseConv2DLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">BaseConv2DLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BaseConv2DLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.quant_utils.html#lingvo.core.quant_utils.QuantizableLayer" title="lingvo.core.quant_utils.QuantizableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.quant_utils.QuantizableLayer</span></code></a></p>
<p>Base class for 2D convolution layers.</p>
<p>Has support for optional batch-normalization, activation and sequence
padding.</p>
<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BaseConv2DLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BaseConv2DLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer._CreateChildrenVariables">
<code class="sig-name descname">_CreateChildrenVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BaseConv2DLayer._CreateChildrenVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer._CreateChildrenVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Create variables for child layers.</p>
<p>Should be rarely overridden, only in cases when control over the context of
children InstantiateVariables calls are needed. eg, if children variables
need to be created inside of a specific context manager.</p>
<p>There are a few cases of this in the codebase marked as for backwards
compability. This is only to ensure that variable scopes remain compatible
through the code migration. New layers should not copy that pattern, and
instead follow the standard pattern of self.CreateChild() in __init__() and
self.CreateVariable() in _CreateLayerVariables(). If you are okay with
breaking old checkpoints, you can go ahead and delete those functions.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer.output_channels">
<em class="property">property </em><code class="sig-name descname">output_channels</code><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer.output_channels" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of output channels for this conv layer.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer.filter_output_shape">
<em class="property">property </em><code class="sig-name descname">filter_output_shape</code><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer.filter_output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Final dims of the filter corresponding to the output channels.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A one (standard conv) or two (depthwise conv) element shape representing
the final dimensions of the filter weights that are output channel
specific for this layer. This shape is needed for any arithmetic that
needs to convert between a linear list of filter weights and the
arrangement in the actual filter.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer._is_bn_folded">
<em class="property">property </em><code class="sig-name descname">_is_bn_folded</code><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer._is_bn_folded" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether batchnorm folded weights are effectively enabled.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer._EvaluateConvKernel">
<code class="sig-name descname">_EvaluateConvKernel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">filter_w</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">dilation_rate</span></em>, <em class="sig-param"><span class="n">padding_algorithm</span></em>, <em class="sig-param"><span class="n">data_format</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BaseConv2DLayer._EvaluateConvKernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer._EvaluateConvKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the lower level convolution kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – As to tf.nn.convolution.</p></li>
<li><p><strong>filter_w</strong> – As to tf.nn.depthwise_conv2d.</p></li>
<li><p><strong>strides</strong> – As to tf.nn.convolution.</p></li>
<li><p><strong>dilation_rate</strong> – As to tf.nn.convolution.</p></li>
<li><p><strong>padding_algorithm</strong> – As to tf.nn.convolution (padding argument).</p></li>
<li><p><strong>data_format</strong> – As to tf.nn.convolution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Convolution kernel output.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer.OutputShape">
<em class="property">classmethod </em><code class="sig-name descname">OutputShape</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">params</span></em>, <em class="sig-param"><span class="n">in_shape</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BaseConv2DLayer.OutputShape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer.OutputShape" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer.OutShape">
<code class="sig-name descname">OutShape</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">in_shape</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BaseConv2DLayer.OutShape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer.OutShape" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the output shape given the input shape.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer._GetWeights">
<code class="sig-name descname">_GetWeights</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">convolution_lambda</span></em>, <em class="sig-param"><span class="n">folded_bn_padding</span></em>, <em class="sig-param"><span class="n">cast_dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BaseConv2DLayer._GetWeights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer._GetWeights" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets a dictionary of weights and biases for the convolution.</p>
<p>This is necessary for some operating modes where the weights are fused
with batch normalization differently for training vs eval.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing underlying weights values of this
layer and its children layers.</p></li>
<li><p><strong>convolution_lambda</strong> – Lambda which takes the convolution weights and runs
the convolution.</p></li>
<li><p><strong>folded_bn_padding</strong> – Padding to apply to folded batch normalization moment
computation (or None for no padding).</p></li>
<li><p><strong>cast_dtype</strong> – If not None, cast weights to the given dtype.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of (filter, biases).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer._ApplyConv">
<code class="sig-name descname">_ApplyConv</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">folded_bn_padding</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BaseConv2DLayer._ApplyConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer._ApplyConv" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BaseConv2DLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply convolution to inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – The inputs tensor. It is expected to be of shape [batch, time,
frequency, channel]. The time dimension corresponds to the height
dimension as in images and the frequency dimension corresponds to the
width dimension as in images.</p></li>
<li><p><strong>paddings</strong> – The paddings tensor. If None, the inputs have no paddings in the
sense of sequence training (e.g., in CNN models). Otherwise, it is
expected to be of shape [batch, time].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>outputs, out_paddings pair.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer._Compute">
<code class="sig-name descname">_Compute</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em>, <em class="sig-param"><span class="n">conv_padding</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BaseConv2DLayer._Compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer._Compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the forward prop (conv, bn, act).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BaseConv2DLayer._ComputeConvLast">
<code class="sig-name descname">_ComputeConvLast</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em>, <em class="sig-param"><span class="n">conv_padding</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BaseConv2DLayer._ComputeConvLast"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BaseConv2DLayer._ComputeConvLast" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the forward prop in conv_last mode (bn, act, conv).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.Conv2DLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">Conv2DLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#Conv2DLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.Conv2DLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.BaseConv2DLayer" title="lingvo.core.layers.BaseConv2DLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.BaseConv2DLayer</span></code></a></p>
<p>Convolution layer, with optional batch-normalization and activation.</p>
<dl class="py method">
<dt id="lingvo.core.layers.Conv2DLayer._EvaluateConvKernel">
<code class="sig-name descname">_EvaluateConvKernel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">filter_w</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">dilation_rate</span></em>, <em class="sig-param"><span class="n">padding_algorithm</span></em>, <em class="sig-param"><span class="n">data_format</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#Conv2DLayer._EvaluateConvKernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.Conv2DLayer._EvaluateConvKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the lower level convolution kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – As to tf.nn.convolution.</p></li>
<li><p><strong>filter_w</strong> – As to tf.nn.depthwise_conv2d.</p></li>
<li><p><strong>strides</strong> – As to tf.nn.convolution.</p></li>
<li><p><strong>dilation_rate</strong> – As to tf.nn.convolution.</p></li>
<li><p><strong>padding_algorithm</strong> – As to tf.nn.convolution (padding argument).</p></li>
<li><p><strong>data_format</strong> – As to tf.nn.convolution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Convolution kernel output.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.ConvNN2DLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">ConvNN2DLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ConvNN2DLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ConvNN2DLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.BaseConv2DLayer" title="lingvo.core.layers.BaseConv2DLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.BaseConv2DLayer</span></code></a></p>
<p>Convolution layer, based on tf.nn.conv2d instead of tf.nn.convolution.</p>
<p>tf.nn.convolution is using a different implementation on atrous convolutions,
by wrapping the actual convolution with space_to_batch and batch_to_space.
This implementation is not supported in tflite conversion, hence we need
a different layer for using atrous convolutions.</p>
<dl class="py method">
<dt id="lingvo.core.layers.ConvNN2DLayer._EvaluateConvKernel">
<code class="sig-name descname">_EvaluateConvKernel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">filter_w</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">dilation_rate</span></em>, <em class="sig-param"><span class="n">padding_algorithm</span></em>, <em class="sig-param"><span class="n">data_format</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ConvNN2DLayer._EvaluateConvKernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ConvNN2DLayer._EvaluateConvKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the lower level convolution kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – As to tf.nn.convolution.</p></li>
<li><p><strong>filter_w</strong> – As to tf.nn.depthwise_conv2d.</p></li>
<li><p><strong>strides</strong> – As to tf.nn.convolution.</p></li>
<li><p><strong>dilation_rate</strong> – As to tf.nn.convolution.</p></li>
<li><p><strong>padding_algorithm</strong> – As to tf.nn.convolution (padding argument).</p></li>
<li><p><strong>data_format</strong> – As to tf.nn.convolution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Convolution kernel output.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py attribute">
<dt id="lingvo.core.layers.ConvLayer">
<code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">ConvLayer</code><a class="headerlink" href="#lingvo.core.layers.ConvLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#lingvo.core.layers.Conv2DLayer" title="lingvo.core.layers.Conv2DLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.Conv2DLayer</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.DepthwiseConv2DLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">DepthwiseConv2DLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DepthwiseConv2DLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DepthwiseConv2DLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.BaseConv2DLayer" title="lingvo.core.layers.BaseConv2DLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.BaseConv2DLayer</span></code></a></p>
<p>Depthwise conv 2D layer.</p>
<p>paper: <a class="reference external" href="https://arxiv.org/abs/1610.02357">https://arxiv.org/abs/1610.02357</a></p>
<dl class="py method">
<dt id="lingvo.core.layers.DepthwiseConv2DLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DepthwiseConv2DLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DepthwiseConv2DLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.DepthwiseConv2DLayer.output_channels">
<em class="property">property </em><code class="sig-name descname">output_channels</code><a class="headerlink" href="#lingvo.core.layers.DepthwiseConv2DLayer.output_channels" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of output channels for this conv layer.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.DepthwiseConv2DLayer.filter_output_shape">
<em class="property">property </em><code class="sig-name descname">filter_output_shape</code><a class="headerlink" href="#lingvo.core.layers.DepthwiseConv2DLayer.filter_output_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Final dims of the filter corresponding to the output channels.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.DepthwiseConv2DLayer._EvaluateConvKernel">
<code class="sig-name descname">_EvaluateConvKernel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">filter_w</span></em>, <em class="sig-param"><span class="n">strides</span></em>, <em class="sig-param"><span class="n">dilation_rate</span></em>, <em class="sig-param"><span class="n">padding_algorithm</span></em>, <em class="sig-param"><span class="n">data_format</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DepthwiseConv2DLayer._EvaluateConvKernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DepthwiseConv2DLayer._EvaluateConvKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the lower level convolution kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – As to tf.nn.convolution.</p></li>
<li><p><strong>filter_w</strong> – As to tf.nn.depthwise_conv2d.</p></li>
<li><p><strong>strides</strong> – As to tf.nn.convolution.</p></li>
<li><p><strong>dilation_rate</strong> – As to tf.nn.convolution.</p></li>
<li><p><strong>padding_algorithm</strong> – As to tf.nn.convolution (padding argument).</p></li>
<li><p><strong>data_format</strong> – As to tf.nn.convolution.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Convolution kernel output.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.SeparableConv2DLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">SeparableConv2DLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SeparableConv2DLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SeparableConv2DLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.Conv2DLayer" title="lingvo.core.layers.Conv2DLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.Conv2DLayer</span></code></a></p>
<p>Separable 2D convolution.</p>
<p>This class aggregates a DepthwiseConv2DLayer that feeds in to the point
wise convolution defined by this layer. Since the point wise convolution
controls the output, this class is defined in terms of that and delegates
to a depthwise sub-layer.</p>
<dl class="simple">
<dt>The <code class="xref py py-obj docutils literal notranslate"><span class="pre">filter_shape</span></code> parameter is rewritten on initialization from the form:</dt><dd><p>(h, w, cin, cout)</p>
</dd>
<dt>To:</dt><dd><p>Depthwise filter: (h, w, cin, p.depth_multiplier)
Pointwise filter (on this instance): (1, 1, cin * p.depth_multiplier, cout)</p>
</dd>
</dl>
<p>This way, the layer is configured as if it were a normal 2D convolution
but is internally reconfigured to be separable.</p>
<p>paper: <a class="reference external" href="https://arxiv.org/abs/1610.02357">https://arxiv.org/abs/1610.02357</a></p>
<dl class="py method">
<dt id="lingvo.core.layers.SeparableConv2DLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SeparableConv2DLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SeparableConv2DLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SeparableConv2DLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SeparableConv2DLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SeparableConv2DLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply convolution to inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – The inputs tensor. It is expected to be of shape [batch, time,
frequency, channel]. The time dimension corresponds to the height
dimension as in images and the frequency dimension corresponds to the
width dimension as in images.</p></li>
<li><p><strong>paddings</strong> – The paddings tensor. If None, the inputs have no paddings in the
sense of sequence training (e.g., in CNN models). Otherwise, it is
expected to be of shape [batch, time].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>outputs, out_paddings pair.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SeparableConv2DLayer.OutShape">
<code class="sig-name descname">OutShape</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">in_shape</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SeparableConv2DLayer.OutShape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SeparableConv2DLayer.OutShape" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the output shape given the input shape.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.ProjectionLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">ProjectionLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ProjectionLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.quant_utils.html#lingvo.core.quant_utils.QuantizableLayer" title="lingvo.core.quant_utils.QuantizableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.quant_utils.QuantizableLayer</span></code></a></p>
<p>Projection layer, with batch normalization and relu activation.</p>
<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ProjectionLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer._GetBlockedMatMulInputOutputMultipliers">
<code class="sig-name descname">_GetBlockedMatMulInputOutputMultipliers</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ProjectionLayer._GetBlockedMatMulInputOutputMultipliers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer._GetBlockedMatMulInputOutputMultipliers" title="Permalink to this definition">¶</a></dt>
<dd><p>Get number of input and output blocks.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer._GetBlockedWeightMatrix">
<code class="sig-name descname">_GetBlockedWeightMatrix</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">w</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ProjectionLayer._GetBlockedWeightMatrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer._GetBlockedWeightMatrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a 3D weight matrix for blocked matmul.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ProjectionLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer._CreateChildrenVariables">
<code class="sig-name descname">_CreateChildrenVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ProjectionLayer._CreateChildrenVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer._CreateChildrenVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Create variables for child layers.</p>
<p>Should be rarely overridden, only in cases when control over the context of
children InstantiateVariables calls are needed. eg, if children variables
need to be created inside of a specific context manager.</p>
<p>There are a few cases of this in the codebase marked as for backwards
compability. This is only to ensure that variable scopes remain compatible
through the code migration. New layers should not copy that pattern, and
instead follow the standard pattern of self.CreateChild() in __init__() and
self.CreateVariable() in _CreateLayerVariables(). If you are okay with
breaking old checkpoints, you can go ahead and delete those functions.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer.NumOutputNodes">
<em class="property">classmethod </em><code class="sig-name descname">NumOutputNodes</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ProjectionLayer.NumOutputNodes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer.NumOutputNodes" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer.output_qt_name">
<em class="property">property </em><code class="sig-name descname">output_qt_name</code><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer.output_qt_name" title="Permalink to this definition">¶</a></dt>
<dd><p>Name of QTensor used for the output value.</p>
<p>Useful for grabbing the quantization of the output.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>String name of output qtensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ProjectionLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply projection to inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – The inputs tensor.  Shaped […, input_dim].</p></li>
<li><p><strong>paddings</strong> – The paddings tensor.  Shaped […, 1], where all but the last
dimension match.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output after applying projection, and optionally batch normalization and
relu non-linearity.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer._is_bn_folded">
<em class="property">property </em><code class="sig-name descname">_is_bn_folded</code><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer._is_bn_folded" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether batchnorm folded weights are effectively enabled.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer._GetWeights">
<code class="sig-name descname">_GetWeights</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ProjectionLayer._GetWeights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer._GetWeights" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the weights for the computation.</p>
<p>Weights will always have weight_norm applied and may have batch_norm
folded if enabled.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – Inputs (needed for batchnorm folding).</p></li>
<li><p><strong>paddings</strong> – Paddings (needed for batchnorm folding).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of (w, b) to use for the forward pass. b may be None if bias is
disabled.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer._ApplyProjectionKernel">
<code class="sig-name descname">_ApplyProjectionKernel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">w</span></em>, <em class="sig-param"><span class="n">b</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">with_activation</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">quant</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">bn</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ProjectionLayer._ApplyProjectionKernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer._ApplyProjectionKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies matmul/bias/activation in one step.</p>
<p>Note that it is important that these three ops be computed in this way as
downstream inference engines (esp. for quantized inference) can recognize
and fuse them. For floating point, this is an optimization, but for
quantization, it is required.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>w</strong> – Weight matrix.</p></li>
<li><p><strong>b</strong> – Bias vector (or None).</p></li>
<li><p><strong>inputs</strong> – FProp inputs.</p></li>
<li><p><strong>with_activation</strong> – Whether to also compute the activation function.</p></li>
<li><p><strong>quant</strong> – Whether to apply quantization.</p></li>
<li><p><strong>bn</strong> – Apply batchnorm.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor reshaped.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer._ApplyActivationFunction">
<code class="sig-name descname">_ApplyActivationFunction</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">out</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">with_activation</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">quant</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ProjectionLayer._ApplyActivationFunction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer._ApplyActivationFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the activation function in one step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out</strong> – The result of applying the weight matrix (and bias) to the inputs.</p></li>
<li><p><strong>inputs</strong> – FProp inputs.</p></li>
<li><p><strong>with_activation</strong> – Whether to also compute the activation function.</p></li>
<li><p><strong>quant</strong> – Whether to apply quantization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output tensor reshaped.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ProjectionLayer.FPropMeta">
<em class="property">classmethod </em><code class="sig-name descname">FPropMeta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ProjectionLayer.FPropMeta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ProjectionLayer.FPropMeta" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns metadata about the <a class="reference internal" href="#lingvo.core.layers.ProjectionLayer.FProp" title="lingvo.core.layers.ProjectionLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> computation for this layer.</p>
<p><strong>Experimental feature.</strong>
Don’t use or depend on it without consulting Lingvo authors.</p>
<p>E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">SomeComplexLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
<span class="n">meta</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">FPropMeta</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">tshape</span><span class="o">.</span><span class="n">Shape</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;channels&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.flops</span></code> gives an estimate count of floating point operations done by
one <a class="reference internal" href="#lingvo.core.layers.ProjectionLayer.FProp" title="lingvo.core.layers.ProjectionLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> given an input tensor of shape [128, 20, 50, channels].
<code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.out_shapes</span></code> is a tuple of TShape, which tells you what shape
of tensors this layer will return.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – The param of a layer of this layer type.</p></li>
<li><p><strong>*args</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> with</p>
<ul class="simple">
<li><p>flops - The estimated number of floating point operations incurred by
this fprop.</p></li>
<li><p>out_shapes - A tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">TShape</span></code>. I.e., <code class="xref py py-obj docutils literal notranslate"><span class="pre">out_shapes[i]</span></code>
represents the shape of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">i</span></code>-th returned tensor of the fprop.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.FCLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">FCLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#FCLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.FCLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.ProjectionLayer" title="lingvo.core.layers.ProjectionLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.ProjectionLayer</span></code></a></p>
<p>Fully-connected layer (matmul + bias + optional activation).</p>
<dl class="py method">
<dt id="lingvo.core.layers.FCLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#FCLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.FCLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.FeedForwardNet">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">FeedForwardNet</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#FeedForwardNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.FeedForwardNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.quant_utils.html#lingvo.core.quant_utils.QuantizableLayer" title="lingvo.core.quant_utils.QuantizableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.quant_utils.QuantizableLayer</span></code></a></p>
<p>A simple multiple layer feedforward network.</p>
<p>This class represents a stack of fully connected feedforward network. Each
layer in the network can be configured for whether or not to have batch-norm
applied to its output, its activation function, whether or not to apply
dropout to post-activation output.</p>
<dl class="py method">
<dt id="lingvo.core.layers.FeedForwardNet.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#FeedForwardNet.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.FeedForwardNet.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.FeedForwardNet.output_dim">
<em class="property">property </em><code class="sig-name descname">output_dim</code><a class="headerlink" href="#lingvo.core.layers.FeedForwardNet.output_dim" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns output dimension of the FeedForwardNet.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.FeedForwardNet.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#FeedForwardNet.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.FeedForwardNet.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagation.</p>
<p>The central interface that subclasses should implement. The caller
calls <a class="reference internal" href="#lingvo.core.layers.FeedForwardNet.FProp" title="lingvo.core.layers.FeedForwardNet.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> with a <code class="xref py py-obj docutils literal notranslate"><span class="pre">theta</span></code> dictionary. E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">foo</span> <span class="o">=</span> <span class="n">InstanceOfASubClassOfFoo</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">foo</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">foo</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>The implementation of <a class="reference internal" href="#lingvo.core.layers.FeedForwardNet.FProp" title="lingvo.core.layers.FeedForwardNet.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp()</span></code></a> computes a function given
the theta and the inputs. E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">subs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">a0</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="n">a1</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">a0</span><span class="p">)</span>
<span class="c1"># The same layer applied twice.</span>
<span class="n">a2</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span>
<span class="k">return</span> <span class="n">a2</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>*args</strong> – List args.</p></li>
<li><p><strong>**kwargs</strong> – Keyward args.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.FeedForwardNet.FPropMeta">
<em class="property">classmethod </em><code class="sig-name descname">FPropMeta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#FeedForwardNet.FPropMeta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.FeedForwardNet.FPropMeta" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns metadata about the <a class="reference internal" href="#lingvo.core.layers.FeedForwardNet.FProp" title="lingvo.core.layers.FeedForwardNet.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> computation for this layer.</p>
<p><strong>Experimental feature.</strong>
Don’t use or depend on it without consulting Lingvo authors.</p>
<p>E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">SomeComplexLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
<span class="n">meta</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">FPropMeta</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">tshape</span><span class="o">.</span><span class="n">Shape</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;channels&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.flops</span></code> gives an estimate count of floating point operations done by
one <a class="reference internal" href="#lingvo.core.layers.FeedForwardNet.FProp" title="lingvo.core.layers.FeedForwardNet.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> given an input tensor of shape [128, 20, 50, channels].
<code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.out_shapes</span></code> is a tuple of TShape, which tells you what shape
of tensors this layer will return.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – The param of a layer of this layer type.</p></li>
<li><p><strong>*args</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> with</p>
<ul class="simple">
<li><p>flops - The estimated number of floating point operations incurred by
this fprop.</p></li>
<li><p>out_shapes - A tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">TShape</span></code>. I.e., <code class="xref py py-obj docutils literal notranslate"><span class="pre">out_shapes[i]</span></code>
represents the shape of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">i</span></code>-th returned tensor of the fprop.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.StackingOverTime">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">StackingOverTime</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#StackingOverTime"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.StackingOverTime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Stacking applied along the time axis.</p>
<p>At each time step of an input sequence, elements are stacked over the
window of (‘left_context’ + 1 + ‘right_context’) steps around the current
time step. Zeros will be padded to the left or right of the sequence for
elements around the boundaries. Finally the stacked outputs are emitted
once every ‘stride’ steps.</p>
<p>E.g. if an input sequence is: [4], [1], [9], [3], [5], [2], [8]
left_context = 1, right_context = 1, stride = 3,
then the output sequence would be: [0, 4, 1], [9, 3, 5], [2, 8, 0]</p>
<p>Note that this layer only performs tensor transformation, so there are no
learnable parameters.</p>
<dl class="py method">
<dt id="lingvo.core.layers.StackingOverTime.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#StackingOverTime.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.StackingOverTime.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.StackingOverTime.window_size">
<em class="property">property </em><code class="sig-name descname">window_size</code><a class="headerlink" href="#lingvo.core.layers.StackingOverTime.window_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the stacking window size.</p>
<p>The output dimension will be window_size * the input dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Window size.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.StackingOverTime._ApplyStack">
<code class="sig-name descname">_ApplyStack</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">pad_value</span><span class="o">=</span><span class="default_value">0.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#StackingOverTime._ApplyStack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.StackingOverTime._ApplyStack" title="Permalink to this definition">¶</a></dt>
<dd><p>The core function to apply the stacking to inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – [batch, time, depth].</p></li>
<li><p><strong>pad_value</strong> – the padding value for left/right context.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[batch, ceil(time / stride), depth * stacking_window_length] tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.StackingOverTime.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#StackingOverTime.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.StackingOverTime.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the stacking to inputs along the time axis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – The inputs tensor. It is expected to be of shape [batch, time,
feature].</p></li>
<li><p><strong>paddings</strong> – The paddings tensor. It is expected to be of shape [batch, time,
1], where all but the last dimension match inputs. Each value is 0 or 1
indicating whether a time step of a sequence is padded in the inputs to
reach the max length in the batch.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>(outputs, out_paddings) pair.</dt><dd><p>outputs is of shape [batch, ceil(time / stride), feature * stacking].
out_paddings is of shape [batch, ceil(time / stride), 1]. out_paddings
will be 0 if any of the corresponding input padding is 0.</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.StackingOverTime.Unstack">
<code class="sig-name descname">Unstack</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">stacked</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#StackingOverTime.Unstack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.StackingOverTime.Unstack" title="Permalink to this definition">¶</a></dt>
<dd><p>Inverts stacking over time.</p>
<p>Given ‘stacked’ outputs from this StackingOverTime layer,</p>
<blockquote>
<div><p>stacked, _ = this_layer.FProp(inputs),</p>
</div></blockquote>
<p>this method attempts to reconstruct the original ‘inputs’.</p>
<p>If stride &gt; window_size, the original input cannot be recovered, and a
ValueError is raised.</p>
<p>Otherwise, if right_context + 1 &gt;= stride, this method returns a Tensor that
is identical to ‘inputs’ but potentially longer due to paddings.</p>
<p>If right_context + 1 &lt; stride, this method returns a Tensor that may be up
to <code class="docutils literal notranslate"><span class="pre">`stride</span> <span class="pre">-</span> <span class="pre">right_context</span> <span class="pre">-</span> <span class="pre">1`</span></code> frames shorter than the original input,
but identical in the frames that are returned. e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">left_context</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">right_context</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">4</span>
<span class="nb">input</span> <span class="n">sequence</span><span class="p">:</span>     <span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span> <span class="mi">8</span>
<span class="n">after</span> <span class="n">padding</span><span class="p">:</span>  <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span> <span class="mi">8</span> <span class="mi">0</span>
<span class="n">windows</span><span class="p">:</span>
  <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="mi">2</span><span class="p">]</span> <span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span> <span class="mi">8</span> <span class="mi">0</span>
   <span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span> <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span> <span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="mi">6</span><span class="p">]</span> <span class="mi">7</span> <span class="mi">8</span> <span class="mi">0</span>
<span class="n">stacked</span><span class="p">:</span>
  <span class="p">[[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span><span class="p">]]</span>
<span class="n">unstacked</span><span class="p">:</span>
  <span class="p">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span><span class="p">],</span> <span class="n">which</span> <span class="ow">is</span> <span class="mi">4</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">=</span> <span class="mi">2</span> <span class="p">(</span><span class="n">stride</span> <span class="o">-</span> <span class="n">right_context</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">frames</span> <span class="n">shorter</span> <span class="n">than</span> <span class="n">the</span> <span class="n">original</span> <span class="nb">input</span><span class="o">.</span>
</pre></div>
</div>
<p><a class="reference internal" href="#lingvo.core.layers.StackingOverTime.Unstack" title="lingvo.core.layers.StackingOverTime.Unstack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Unstack()</span></code></a> can be used to project the outputs of downstream layers back to
the shape of the original unstacked inputs. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># [batch, length, input_dim]</span>
<span class="c1"># [batch, ceil(length / stride), rnn_dim]</span>
<span class="n">rnn_out</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">stacking</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
<span class="c1"># [batch, length, rnn_dim]</span>
<span class="n">back_projected_rnn_out</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">PadOrTrimTo</span><span class="p">(</span>
    <span class="n">stacking</span><span class="o">.</span><span class="n">Unstack</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">rnn_out</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stacking</span><span class="o">.</span><span class="n">window_size</span><span class="p">])),</span>
    <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
</pre></div>
</div>
<p>Note this method does not take or return a separate padding tensor. The
caller is responsible for knowing which of outputs are padding (e.g. based
on the padding of the original FProp inputs).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>stacked</strong> – Tensor of shape [batch, time, window_size * feature_dim], assumed
to be the output of <a class="reference internal" href="#lingvo.core.layers.StackingOverTime.FProp" title="lingvo.core.layers.StackingOverTime.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The reconstructed input Tensor, with shape
[batch, (frames - 1) * stride + right_context + 1, feature_dim].</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.7/library/exceptions.html#ValueError" title="(in Python v3.7)"><strong>ValueError</strong></a> – if stride &gt; window_size.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.PoolingLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">PoolingLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#PoolingLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.PoolingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.quant_utils.html#lingvo.core.quant_utils.QuantizableLayer" title="lingvo.core.quant_utils.QuantizableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.quant_utils.QuantizableLayer</span></code></a></p>
<p>Pooling layer, by default performs max-pooling.</p>
<p>Quantization notes: Unlike the common pattern, the pooling layer inputs
and output must be quantized to the same range, so it tracks both (vs
just the output). The preceding layer must have its output quantization
disabled.</p>
<dl class="py method">
<dt id="lingvo.core.layers.PoolingLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#PoolingLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.PoolingLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.PoolingLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#PoolingLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.PoolingLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.PoolingLayer.OutputShape">
<em class="property">classmethod </em><code class="sig-name descname">OutputShape</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">params</span></em>, <em class="sig-param"><span class="n">in_shape</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#PoolingLayer.OutputShape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.PoolingLayer.OutputShape" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.PoolingLayer.OutShape">
<code class="sig-name descname">OutShape</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">in_shape</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#PoolingLayer.OutShape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.PoolingLayer.OutShape" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the output shape given the input shape.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.PoolingLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#PoolingLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.PoolingLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply pooling to inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – The inputs tensor. It is expected to be of shape [batch, time,
frequency, channel]. The time dimension corresponds to the height
dimension as in images and the frequency dimension corresponds to the
width dimension as in images.</p></li>
<li><p><strong>paddings</strong> – The paddings tensor. It is expected to be of shape [batch,
time]. Defaults to None, which means there no paddings.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>outputs, out_paddings pair.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.BlurPoolLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">BlurPoolLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BlurPoolLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BlurPoolLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>BlurPool from <a class="reference external" href="https://arxiv.org/pdf/1904.11486.pdf">https://arxiv.org/pdf/1904.11486.pdf</a>.</p>
<p>This layer blurs the input with a fixed filter and performs subsampling
afterwards. Only supports 2x1 or 2x2 spatial reduction.</p>
<dl class="py method">
<dt id="lingvo.core.layers.BlurPoolLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BlurPoolLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BlurPoolLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.BlurPoolLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#BlurPoolLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.BlurPoolLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply blur pooling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – The inputs tensor. It is expected to be of shape [batch, time,
frequency, channel]. The time dimension corresponds to the height
dimension as in images and the frequency dimension corresponds to the
width dimension as in images.</p></li>
<li><p><strong>paddings</strong> – The paddings tensor. It is expected to be of shape [batch,
time]. Defaults to None, which means there no paddings.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>outputs, out_paddings pair.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.SingleShardEmbeddingLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">SingleShardEmbeddingLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardEmbeddingLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardEmbeddingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Embedding layer that is not sharded.</p>
<p>This embedding layer is expected to be replicated over all compute devices
(e.g. tpu cores). It is intended to support small to medium embedding tables
(&lt; 50k) only.</p>
<p>This is intended to be a unification of EmbeddingLayer and
SimpleEmbeddingLayer (and cleanup of both). It is targeting the most common
use-case we have in speech/nmt/tts/deeprank. Currently we often first
configure a model using EmbeddingLayer, and then call ChangeToSimpleEmbedding
to switch to SimpleEmbedding where  we lose some configuration (e.g.
scale_by_sqrt_dim).</p>
<p>TODO(lingvo): Implement the matmul option which should be more efficient for
small vocabs (e.g. &lt; 1k vocab).</p>
<dl class="py method">
<dt id="lingvo.core.layers.SingleShardEmbeddingLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardEmbeddingLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardEmbeddingLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SingleShardEmbeddingLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardEmbeddingLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardEmbeddingLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SingleShardEmbeddingLayer.EmbLookupDefaultTheta">
<code class="sig-name descname">EmbLookupDefaultTheta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardEmbeddingLayer.EmbLookupDefaultTheta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardEmbeddingLayer.EmbLookupDefaultTheta" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SingleShardEmbeddingLayer.EmbLookup">
<code class="sig-name descname">EmbLookup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardEmbeddingLayer.EmbLookup"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardEmbeddingLayer.EmbLookup" title="Permalink to this definition">¶</a></dt>
<dd><p>Looks up embedding vectors for ids.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – Named tuple with the weight matrix for the embedding.</p></li>
<li><p><strong>ids</strong> – A rank-N int32 tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A rank-(N+1) params.dtype tensor.
embs[indices, :] is the embedding vector for ids[indices].</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SingleShardEmbeddingLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardEmbeddingLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardEmbeddingLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagation.</p>
<p>The central interface that subclasses should implement. The caller
calls <a class="reference internal" href="#lingvo.core.layers.SingleShardEmbeddingLayer.FProp" title="lingvo.core.layers.SingleShardEmbeddingLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> with a <code class="xref py py-obj docutils literal notranslate"><span class="pre">theta</span></code> dictionary. E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">foo</span> <span class="o">=</span> <span class="n">InstanceOfASubClassOfFoo</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">foo</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">foo</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>The implementation of <a class="reference internal" href="#lingvo.core.layers.SingleShardEmbeddingLayer.FProp" title="lingvo.core.layers.SingleShardEmbeddingLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp()</span></code></a> computes a function given
the theta and the inputs. E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">subs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">a0</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="n">a1</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">a0</span><span class="p">)</span>
<span class="c1"># The same layer applied twice.</span>
<span class="n">a2</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span>
<span class="k">return</span> <span class="n">a2</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>*args</strong> – List args.</p></li>
<li><p><strong>**kwargs</strong> – Keyward args.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.EmbeddingLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">EmbeddingLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#EmbeddingLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.EmbeddingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Embedding layer.</p>
<dl class="py method">
<dt id="lingvo.core.layers.EmbeddingLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#EmbeddingLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.EmbeddingLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py attribute">
<dt id="lingvo.core.layers.EmbeddingLayer.MIN_PARAMS_PER_SHARD">
<code class="sig-name descname">MIN_PARAMS_PER_SHARD</code><em class="property"> = 262144</em><a class="headerlink" href="#lingvo.core.layers.EmbeddingLayer.MIN_PARAMS_PER_SHARD" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.EmbeddingLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#EmbeddingLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.EmbeddingLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.EmbeddingLayer.EmbLookupDefaultTheta">
<code class="sig-name descname">EmbLookupDefaultTheta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#EmbeddingLayer.EmbLookupDefaultTheta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.EmbeddingLayer.EmbLookupDefaultTheta" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.EmbeddingLayer.EmbLookup">
<code class="sig-name descname">EmbLookup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#EmbeddingLayer.EmbLookup"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.EmbeddingLayer.EmbLookup" title="Permalink to this definition">¶</a></dt>
<dd><p>Looks up embedding vectors for ids.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – Named tuple with the weight matrix for the embedding.</p></li>
<li><p><strong>ids</strong> – A rank-N int32 tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A rank-(N+1) params.dtype tensor.
embs[indices, :] is the embedding vector for ids[indices].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.SimpleEmbeddingLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">SimpleEmbeddingLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleEmbeddingLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleEmbeddingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.quant_utils.html#lingvo.core.quant_utils.QuantizableLayer" title="lingvo.core.quant_utils.QuantizableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.quant_utils.QuantizableLayer</span></code></a></p>
<p>An embedding layer that is simple to compile (by XLA and Toco).</p>
<p>The params use_matmul and use_gather control how the lookup is performed.
If neither is True, then a loop is used to compute the embedding.</p>
<p>This layer is “simple” in comparison to ‘EmbeddingLayer’ in that it does
not shard the embeddings.</p>
<dl class="py method">
<dt id="lingvo.core.layers.SimpleEmbeddingLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleEmbeddingLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleEmbeddingLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleEmbeddingLayer._FpropImpl">
<code class="sig-name descname">_FpropImpl</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">embs</span></em>, <em class="sig-param"><span class="n">ids_vec</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleEmbeddingLayer._FpropImpl"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleEmbeddingLayer._FpropImpl" title="Permalink to this definition">¶</a></dt>
<dd><p>The embedding lookup implementation.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleEmbeddingLayer._GetWeightShape">
<code class="sig-name descname">_GetWeightShape</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleEmbeddingLayer._GetWeightShape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleEmbeddingLayer._GetWeightShape" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleEmbeddingLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleEmbeddingLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleEmbeddingLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleEmbeddingLayer.EmbLookupDefaultTheta">
<code class="sig-name descname">EmbLookupDefaultTheta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleEmbeddingLayer.EmbLookupDefaultTheta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleEmbeddingLayer.EmbLookupDefaultTheta" title="Permalink to this definition">¶</a></dt>
<dd><p>Lookups embedding vectors for ids.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleEmbeddingLayer.EmbLookup">
<code class="sig-name descname">EmbLookup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleEmbeddingLayer.EmbLookup"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleEmbeddingLayer.EmbLookup" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleEmbeddingLayer.EmbLookupDefaultThetaOnCpu">
<code class="sig-name descname">EmbLookupDefaultThetaOnCpu</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleEmbeddingLayer.EmbLookupDefaultThetaOnCpu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleEmbeddingLayer.EmbLookupDefaultThetaOnCpu" title="Permalink to this definition">¶</a></dt>
<dd><p>A faster path for CPU inference than the default gather.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleEmbeddingLayer._FlatFProp">
<code class="sig-name descname">_FlatFProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleEmbeddingLayer._FlatFProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleEmbeddingLayer._FlatFProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Lookups embedding vectors for ids.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – Named tuple collection of weights for the layer.</p></li>
<li><p><strong>ids</strong> – A rank-N int32 tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple of the flattened inputs to the embedding lookup, and a tensor that
is ready to be reshaped into the final shape in FProp.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleEmbeddingLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleEmbeddingLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleEmbeddingLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Lookups embedding vectors for ids.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – Named tuple collection of weights for the layer.</p></li>
<li><p><strong>ids</strong> – A rank-N int32 tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A rank-(N+1) params.dtype tensor.
embs[indices, :] is the embedding vector for ids[indices].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.OneHotEmbeddingLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">OneHotEmbeddingLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#OneHotEmbeddingLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.OneHotEmbeddingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Generates one-hot embeddings with uncertainties.</p>
<dl class="py method">
<dt id="lingvo.core.layers.OneHotEmbeddingLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#OneHotEmbeddingLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.OneHotEmbeddingLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.OneHotEmbeddingLayer.EmbLookupDefaultTheta">
<code class="sig-name descname">EmbLookupDefaultTheta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#OneHotEmbeddingLayer.EmbLookupDefaultTheta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.OneHotEmbeddingLayer.EmbLookupDefaultTheta" title="Permalink to this definition">¶</a></dt>
<dd><p>Lookups embedding vectors for ids.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.OneHotEmbeddingLayer.EmbLookup">
<code class="sig-name descname">EmbLookup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#OneHotEmbeddingLayer.EmbLookup"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.OneHotEmbeddingLayer.EmbLookup" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.OneHotEmbeddingLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#OneHotEmbeddingLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.OneHotEmbeddingLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Lookups embedding vectors for ids.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – Named tuple collection of weights for the layer.</p></li>
<li><p><strong>ids</strong> – A rank-N int32 tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A rank-(N+1) params.dtype tensor.
embs[indices, :] is the embedding vector for ids[indices].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.PositionalEmbeddingLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">PositionalEmbeddingLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#PositionalEmbeddingLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.PositionalEmbeddingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Generates sinusoidals with respect to the position in time and dimension.</p>
<p>Implements the positional embedding layer from ‘Attention is All You Need’,
the Transformer Network.</p>
<p>Code and comments are adapted from tensor2tensor/layers/common_attention.py</p>
<dl class="py method">
<dt id="lingvo.core.layers.PositionalEmbeddingLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#PositionalEmbeddingLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.PositionalEmbeddingLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.PositionalEmbeddingLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#PositionalEmbeddingLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.PositionalEmbeddingLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.PositionalEmbeddingLayer._PosEmbeddingsFromPositions">
<code class="sig-name descname">_PosEmbeddingsFromPositions</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">position</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#PositionalEmbeddingLayer._PosEmbeddingsFromPositions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.PositionalEmbeddingLayer._PosEmbeddingsFromPositions" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates the positional embeddings given the position tensor.</p>
<p>Factors out the common code from FProp and FPropWithPosition. Returns
positional embeddings corresponding to the input position tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>position</strong> – Position tensor of dtype float and shape [bs, seq_length] to
generate positional embeddings.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Tensor of shape [bs, seq_length, embedding_dim].</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.PositionalEmbeddingLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">seq_length</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#PositionalEmbeddingLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.PositionalEmbeddingLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a Tensor of sinusoids with different frequencies.</p>
<p>Each channel (dimension) of the generated positionanl embedding Tensor
corresponds to a sinusoid of different frequency and phase.</p>
<p>This allows attention to learn to use absolute and relative positions.
Timing signals should be added to some precursors of both the query and the
memory inputs to attention.</p>
<p>The use of relative position is possible because sin(x+y) and cos(x+y) can
be experessed in terms of y, sin(x) and cos(x).</p>
<p>In particular, we use a geometric sequence of timescales starting with
min_timescale and ending with max_timescale.  The number of different
timescales is equal to channels (dimension) / 2. For each timescale, we
generate the two sinusoidal signals sin(timestep/timescale) and
cos(timestep/timescale).  All of these sinusoids are concatenated in
the channels dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>seq_length</strong> – Sequence length of the embeddings to be generated</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Tensor of shape [seq_length, embedding_dim].</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.PositionalEmbeddingLayer.FPropWithPosition">
<code class="sig-name descname">FPropWithPosition</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">position_tensor</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#PositionalEmbeddingLayer.FPropWithPosition"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.PositionalEmbeddingLayer.FPropWithPosition" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a Tensor of sinusoids with different frequencies.</p>
<p>Uses the provided position tensor to generate positional embeddings. Refer
to FProp description for details of sinusoidal positional embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>position_tensor</strong> – Position tensor of shape [bs, seq_length] to generate
positional embeddings.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Tensor of shape [bs, seq_length, embedding_dim].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.RelativePositionalEmbeddingLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">RelativePositionalEmbeddingLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#RelativePositionalEmbeddingLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.RelativePositionalEmbeddingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Relative positional embedding.</p>
<p>Section 3.2 of <a class="reference external" href="https://arxiv.org/pdf/1803.02155.pdf">https://arxiv.org/pdf/1803.02155.pdf</a></p>
<dl class="py method">
<dt id="lingvo.core.layers.RelativePositionalEmbeddingLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#RelativePositionalEmbeddingLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.RelativePositionalEmbeddingLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.RelativePositionalEmbeddingLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#RelativePositionalEmbeddingLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.RelativePositionalEmbeddingLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.RelativePositionalEmbeddingLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">relative_distance</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#RelativePositionalEmbeddingLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.RelativePositionalEmbeddingLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes relative positional embedding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A NestedMap of Tensors of layer weights.</p></li>
<li><p><strong>relative_distance</strong> – A Tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A Tensor of shape relative_distance.shape + [params.dim]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.SinusoidalPositionalEmbeddingLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">SinusoidalPositionalEmbeddingLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SinusoidalPositionalEmbeddingLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SinusoidalPositionalEmbeddingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Generates sinusoidals with respect to the position in time and dimension.</p>
<p>Implements the a variant of the positional embedding layer from ‘Attention is
All You Need’, the Transformer Network that doesn’t require tuning of the
max_timescale/min_timescale. See this blog post and Ron’s colab.
<a class="reference external" href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding">https://kazemnejad.com/blog/transformer_architecture_positional_encoding</a></p>
<dl class="py method">
<dt id="lingvo.core.layers.SinusoidalPositionalEmbeddingLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SinusoidalPositionalEmbeddingLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SinusoidalPositionalEmbeddingLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SinusoidalPositionalEmbeddingLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">seq_length</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SinusoidalPositionalEmbeddingLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SinusoidalPositionalEmbeddingLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a Tensor of sinusoids with different frequencies.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>seq_length</strong> – Sequence length of the embeddings to be generated</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Tensor of shape [seq_length, embedding_dim].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.SoftmaxLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">SoftmaxLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SoftmaxLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SoftmaxLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.quant_utils.html#lingvo.core.quant_utils.QuantizableLayer" title="lingvo.core.quant_utils.QuantizableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.quant_utils.QuantizableLayer</span></code></a></p>
<p>Base class for softmax layers.</p>
<dl class="py method">
<dt id="lingvo.core.layers.SoftmaxLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SoftmaxLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SoftmaxLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Params for SoftmaxLayer.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SoftmaxLayer.Logits">
<code class="sig-name descname">Logits</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">unused</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SoftmaxLayer.Logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SoftmaxLayer.Logits" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the logits computed before the softmax.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SoftmaxLayer.XentLossFromLogits">
<code class="sig-name descname">XentLossFromLogits</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">unused</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SoftmaxLayer.XentLossFromLogits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SoftmaxLayer.XentLossFromLogits" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the Xent loss from pre-computed logits.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SoftmaxLayer.XentLoss">
<code class="sig-name descname">XentLoss</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SoftmaxLayer.XentLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SoftmaxLayer.XentLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes cross entropy.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SoftmaxLayer._FProp2D">
<code class="sig-name descname">_FProp2D</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">class_weights</span></em>, <em class="sig-param"><span class="n">class_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">class_probabilities</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SoftmaxLayer._FProp2D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SoftmaxLayer._FProp2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Specialized FProp for matrix inputs.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SoftmaxLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">class_weights</span></em>, <em class="sig-param"><span class="n">class_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">class_probabilities</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SoftmaxLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SoftmaxLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes logit, cross entropy etc.</p>
<p>This function can both work with class_ids, or probability distributions
over classes. Exactly one of class_ids or class_probabilities must be
provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – a list of a single tensor, or a single tensor with the shape […,
input_dim].</p></li>
<li><p><strong>class_weights</strong> – a tensor with shape […] containing the weights for each
target word.</p></li>
<li><p><strong>class_ids</strong> – a tensor with shape […, 1] of int32 dtype containing the
target class labels.</p></li>
<li><p><strong>class_probabilities</strong> – a tensor with shape […, num_classes] of float
values indicating class-membership probabilities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> containing the following fields</p>
<ul class="simple">
<li><p>logits: with shape […, num_classes]. Unnormalized softmax’s logits.</p></li>
<li><p>per_example_argmax: with shape […]. argmax of i-th example.</p></li>
<li><p>per_example_xent: with shape […]. Cross entropy between i-th example’s
prediction and its label.</p></li>
<li><p>per_example_weight: with shape […]. class_weights casted to
this layer’s dtype.</p></li>
<li><p>total_xent: A scalar. The sum of per_example_weight * per_example_xent.</p></li>
<li><p>total_weight: A scalar. The sum of per_example_weight.</p></li>
<li><p>avg_xent: A scalar. total_loss / total_weight.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.SimpleFullSoftmax">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">SimpleFullSoftmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleFullSoftmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleFullSoftmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.SoftmaxLayer" title="lingvo.core.layers.SoftmaxLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.SoftmaxLayer</span></code></a></p>
<p>A somewhat simple softmax layer.</p>
<dl class="py method">
<dt id="lingvo.core.layers.SimpleFullSoftmax.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleFullSoftmax.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleFullSoftmax.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Params for SimpleFullSoftmax.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleFullSoftmax._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleFullSoftmax._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleFullSoftmax._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleFullSoftmax._GetInputs">
<code class="sig-name descname">_GetInputs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleFullSoftmax._GetInputs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleFullSoftmax._GetInputs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleFullSoftmax._ConcatWeights">
<code class="sig-name descname">_ConcatWeights</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleFullSoftmax._ConcatWeights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleFullSoftmax._ConcatWeights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleFullSoftmax._LogitsUsingConcatenatedWeightsHelper">
<code class="sig-name descname">_LogitsUsingConcatenatedWeightsHelper</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleFullSoftmax._LogitsUsingConcatenatedWeightsHelper"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleFullSoftmax._LogitsUsingConcatenatedWeightsHelper" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleFullSoftmax._LogitsUsingConcatenatedWeights">
<code class="sig-name descname">_LogitsUsingConcatenatedWeights</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleFullSoftmax._LogitsUsingConcatenatedWeights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleFullSoftmax._LogitsUsingConcatenatedWeights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleFullSoftmax.SimpleLogits">
<code class="sig-name descname">SimpleLogits</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleFullSoftmax.SimpleLogits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleFullSoftmax.SimpleLogits" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the simple logits computed before the softmax.</p>
<p>Compared to the Logits function, this one has only weights, no bias for the
linear projection.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – A tensor with the shape [N, input_dim].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[N, num_classes]</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>logits</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleFullSoftmax.Logits">
<code class="sig-name descname">Logits</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleFullSoftmax.Logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleFullSoftmax.Logits" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the logits computed before the softmax.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – a list of a single tensor, or a single tensor with the shape [N,
input_dim].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>logits [batch, num_classes]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleFullSoftmax._XentLossByChunk">
<code class="sig-name descname">_XentLossByChunk</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">activation</span></em>, <em class="sig-param"><span class="n">class_ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleFullSoftmax._XentLossByChunk"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleFullSoftmax._XentLossByChunk" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes per-example xent loss between activation and class_ids.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleFullSoftmax._FProp2D">
<code class="sig-name descname">_FProp2D</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">class_weights</span></em>, <em class="sig-param"><span class="n">class_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">class_probabilities</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleFullSoftmax._FProp2D"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleFullSoftmax._FProp2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes xent loss and log-prob logit.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SimpleFullSoftmax.XentLossFromLogits">
<code class="sig-name descname">XentLossFromLogits</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">logits</span></em>, <em class="sig-param"><span class="n">class_weights</span></em>, <em class="sig-param"><span class="n">class_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">class_probabilities</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SimpleFullSoftmax.XentLossFromLogits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SimpleFullSoftmax.XentLossFromLogits" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes cross-entropy, argmax etc. from logits.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.SharedSoftmaxLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">SharedSoftmaxLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SharedSoftmaxLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SharedSoftmaxLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.SimpleFullSoftmax" title="lingvo.core.layers.SimpleFullSoftmax"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.SimpleFullSoftmax</span></code></a></p>
<p>Shared softmax layer for decoder embedding/softmax matrix.</p>
<dl class="py method">
<dt id="lingvo.core.layers.SharedSoftmaxLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SharedSoftmaxLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SharedSoftmaxLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Params for SharedSoftmaxLayer.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SharedSoftmaxLayer.EmbLookup">
<code class="sig-name descname">EmbLookup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SharedSoftmaxLayer.EmbLookup"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SharedSoftmaxLayer.EmbLookup" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.SingleShardFullSoftmax">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">SingleShardFullSoftmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardFullSoftmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardFullSoftmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.SoftmaxLayer" title="lingvo.core.layers.SoftmaxLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.SoftmaxLayer</span></code></a></p>
<p>Full softmax layer.</p>
<dl class="py method">
<dt id="lingvo.core.layers.SingleShardFullSoftmax.Logits">
<code class="sig-name descname">Logits</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardFullSoftmax.Logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardFullSoftmax.Logits" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the logits computed before the softmax.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – A single tensor with shape […, input_dim].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>logits […, num_classes]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SingleShardFullSoftmax.XentLossFromLogits">
<code class="sig-name descname">XentLossFromLogits</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">logits</span></em>, <em class="sig-param"><span class="n">class_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">class_probabilities</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardFullSoftmax.XentLossFromLogits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardFullSoftmax.XentLossFromLogits" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes cross-entropy, argmax etc. from logits.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SingleShardFullSoftmax.XentLossByChunk">
<code class="sig-name descname">XentLossByChunk</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">activation</span></em>, <em class="sig-param"><span class="n">class_ids</span></em>, <em class="sig-param"><span class="n">class_probabilities</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardFullSoftmax.XentLossByChunk"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardFullSoftmax.XentLossByChunk" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes per-example xent loss.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SingleShardFullSoftmax.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">class_weights</span></em>, <em class="sig-param"><span class="n">class_ids</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">class_probabilities</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardFullSoftmax.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardFullSoftmax.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes logits, cross entropy etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – a single tensor with shape […, input_dim].</p></li>
<li><p><strong>class_weights</strong> – a tensor with shape […, 1] containing the weights for
each target word.</p></li>
<li><p><strong>class_ids</strong> – a tensor with shape […, 1] of int32 dtype containing the
target class labels.</p></li>
<li><p><strong>class_probabilities</strong> – a tensor with shape […, num_classes] of float
values indicating class-membership probabilities.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> containing the following fields</p>
<ul class="simple">
<li><p>logits: with shape […, num_classes]. Unnormalized softmax’s logits.</p></li>
<li><p>per_example_argmax: with shape […]. argmax of i-th example.</p></li>
<li><p>per_example_xent: with shape […]. Cross entropy between i-th example’s
prediction and its label.</p></li>
<li><p>per_example_weight: with shape […]. class_weights casted to
this layer’s dtype.</p></li>
<li><p>total_xent: A scalar. The sum of per_example_weight * per_example_xent.</p></li>
<li><p>total_weight: A scalar. The sum of per_example_weight.</p></li>
<li><p>avg_xent: A scalar. total_loss / total_weight.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.SingleShardSharedEmbeddingSoftmax">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">SingleShardSharedEmbeddingSoftmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardSharedEmbeddingSoftmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardSharedEmbeddingSoftmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.SingleShardFullSoftmax" title="lingvo.core.layers.SingleShardFullSoftmax"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.SingleShardFullSoftmax</span></code></a></p>
<p>A shared softmax/embedding layer.</p>
<dl class="py method">
<dt id="lingvo.core.layers.SingleShardSharedEmbeddingSoftmax.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardSharedEmbeddingSoftmax.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardSharedEmbeddingSoftmax.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Params for SoftmaxLayer.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SingleShardSharedEmbeddingSoftmax.EmbLookupDefaultTheta">
<code class="sig-name descname">EmbLookupDefaultTheta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardSharedEmbeddingSoftmax.EmbLookupDefaultTheta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardSharedEmbeddingSoftmax.EmbLookupDefaultTheta" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.SingleShardSharedEmbeddingSoftmax.EmbLookup">
<code class="sig-name descname">EmbLookup</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#SingleShardSharedEmbeddingSoftmax.EmbLookup"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.SingleShardSharedEmbeddingSoftmax.EmbLookup" title="Permalink to this definition">¶</a></dt>
<dd><p>Looks up embedding vectors for ids.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – Named tuple with the weight matrix for the embedding.</p></li>
<li><p><strong>ids</strong> – A rank-N int32 tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A rank-(N+1) params.dtype tensor.
embs[indices, :] is the embedding vector for ids[indices].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.ConvSoftmax">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">ConvSoftmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ConvSoftmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ConvSoftmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.quant_utils.html#lingvo.core.quant_utils.QuantizableLayer" title="lingvo.core.quant_utils.QuantizableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.quant_utils.QuantizableLayer</span></code></a></p>
<p>A softmax implementation based on 1x1 convolution.</p>
<p>On TPU this is much more memory efficient than MatMul after reshaping logits
to a matrix.</p>
<dl class="py method">
<dt id="lingvo.core.layers.ConvSoftmax.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ConvSoftmax.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ConvSoftmax.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Params for SoftmaxLayer.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ConvSoftmax._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ConvSoftmax._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ConvSoftmax._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs a SimpleFullSoftmax layer.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ConvSoftmax.Logits">
<code class="sig-name descname">Logits</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ConvSoftmax.Logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ConvSoftmax.Logits" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.DropoutLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">DropoutLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DropoutLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DropoutLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Apply dropout during trainig.</p>
<dl class="py method">
<dt id="lingvo.core.layers.DropoutLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DropoutLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DropoutLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.DropoutLayer._Dropout">
<code class="sig-name descname">_Dropout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">noise_shape</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DropoutLayer._Dropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DropoutLayer._Dropout" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.DropoutLayer.NumOutputNodes">
<em class="property">classmethod </em><code class="sig-name descname">NumOutputNodes</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DropoutLayer.NumOutputNodes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DropoutLayer.NumOutputNodes" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.DropoutLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DropoutLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DropoutLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply dropout to inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – The inputs tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>inputs with dropout applied at training time.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.DropoutLayer.FPropMeta">
<em class="property">classmethod </em><code class="sig-name descname">FPropMeta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DropoutLayer.FPropMeta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DropoutLayer.FPropMeta" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns metadata about the <a class="reference internal" href="#lingvo.core.layers.DropoutLayer.FProp" title="lingvo.core.layers.DropoutLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> computation for this layer.</p>
<p><strong>Experimental feature.</strong>
Don’t use or depend on it without consulting Lingvo authors.</p>
<p>E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">SomeComplexLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
<span class="n">meta</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">FPropMeta</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">tshape</span><span class="o">.</span><span class="n">Shape</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;channels&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.flops</span></code> gives an estimate count of floating point operations done by
one <a class="reference internal" href="#lingvo.core.layers.DropoutLayer.FProp" title="lingvo.core.layers.DropoutLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> given an input tensor of shape [128, 20, 50, channels].
<code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.out_shapes</span></code> is a tuple of TShape, which tells you what shape
of tensors this layer will return.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – The param of a layer of this layer type.</p></li>
<li><p><strong>*args</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> with</p>
<ul class="simple">
<li><p>flops - The estimated number of floating point operations incurred by
this fprop.</p></li>
<li><p>out_shapes - A tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">TShape</span></code>. I.e., <code class="xref py py-obj docutils literal notranslate"><span class="pre">out_shapes[i]</span></code>
represents the shape of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">i</span></code>-th returned tensor of the fprop.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.DeterministicDropoutLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">DeterministicDropoutLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DeterministicDropoutLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DeterministicDropoutLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.DropoutLayer" title="lingvo.core.layers.DropoutLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.DropoutLayer</span></code></a></p>
<p>Apply dropout during trainig.</p>
<dl class="py method">
<dt id="lingvo.core.layers.DeterministicDropoutLayer._Dropout">
<code class="sig-name descname">_Dropout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">noise_shape</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#DeterministicDropoutLayer._Dropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.DeterministicDropoutLayer._Dropout" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.LayerNorm">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">LayerNorm</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LayerNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LayerNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Layer normalization.</p>
<p>Implements layer normalization:
<a class="reference external" href="https://arxiv.org/abs/1607.06450">https://arxiv.org/abs/1607.06450</a></p>
<dl class="py method">
<dt id="lingvo.core.layers.LayerNorm.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LayerNorm.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LayerNorm.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.LayerNorm._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LayerNorm._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LayerNorm._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.LayerNorm._GetScaleAndBias">
<code class="sig-name descname">_GetScaleAndBias</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LayerNorm._GetScaleAndBias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LayerNorm._GetScaleAndBias" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.LayerNorm.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LayerNorm.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LayerNorm.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies normalization over the last dimension (layer).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – A tensor of shape […, hidden_dim].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor of the same shape with inputs</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.LayerNorm.NumOutputNodes">
<em class="property">classmethod </em><code class="sig-name descname">NumOutputNodes</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LayerNorm.NumOutputNodes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LayerNorm.NumOutputNodes" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.LayerNorm.FPropMeta">
<em class="property">classmethod </em><code class="sig-name descname">FPropMeta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LayerNorm.FPropMeta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LayerNorm.FPropMeta" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns metadata about the <a class="reference internal" href="#lingvo.core.layers.LayerNorm.FProp" title="lingvo.core.layers.LayerNorm.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> computation for this layer.</p>
<p><strong>Experimental feature.</strong>
Don’t use or depend on it without consulting Lingvo authors.</p>
<p>E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">SomeComplexLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
<span class="n">meta</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">FPropMeta</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">tshape</span><span class="o">.</span><span class="n">Shape</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;channels&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.flops</span></code> gives an estimate count of floating point operations done by
one <a class="reference internal" href="#lingvo.core.layers.LayerNorm.FProp" title="lingvo.core.layers.LayerNorm.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> given an input tensor of shape [128, 20, 50, channels].
<code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.out_shapes</span></code> is a tuple of TShape, which tells you what shape
of tensors this layer will return.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – The param of a layer of this layer type.</p></li>
<li><p><strong>*args</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> with</p>
<ul class="simple">
<li><p>flops - The estimated number of floating point operations incurred by
this fprop.</p></li>
<li><p>out_shapes - A tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">TShape</span></code>. I.e., <code class="xref py py-obj docutils literal notranslate"><span class="pre">out_shapes[i]</span></code>
represents the shape of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">i</span></code>-th returned tensor of the fprop.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.CategoricalLayerNorm">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">CategoricalLayerNorm</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CategoricalLayerNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CategoricalLayerNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.LayerNorm" title="lingvo.core.layers.LayerNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.LayerNorm</span></code></a></p>
<p>Categorical layer normalization.</p>
<p>Allow dynamic switch of normalization params based on given class_index.</p>
<dl class="py method">
<dt id="lingvo.core.layers.CategoricalLayerNorm.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CategoricalLayerNorm.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CategoricalLayerNorm.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.CategoricalLayerNorm._BiasVarName">
<code class="sig-name descname">_BiasVarName</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">i</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CategoricalLayerNorm._BiasVarName"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CategoricalLayerNorm._BiasVarName" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.CategoricalLayerNorm._ScaleVarName">
<code class="sig-name descname">_ScaleVarName</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">i</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CategoricalLayerNorm._ScaleVarName"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CategoricalLayerNorm._ScaleVarName" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.CategoricalLayerNorm._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CategoricalLayerNorm._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CategoricalLayerNorm._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.CategoricalLayerNorm._GetScaleAndBias">
<code class="sig-name descname">_GetScaleAndBias</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CategoricalLayerNorm._GetScaleAndBias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CategoricalLayerNorm._GetScaleAndBias" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.ConvSetLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">ConvSetLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ConvSetLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ConvSetLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.quant_utils.html#lingvo.core.quant_utils.QuantizableLayer" title="lingvo.core.quant_utils.QuantizableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.quant_utils.QuantizableLayer</span></code></a></p>
<p>Set of Convolutions with different filter sizes in a single layer.</p>
<p>Applies a set of convolutions with different filter shapes to the inputs and
returns the concatenated outputs.</p>
<dl class="py method">
<dt id="lingvo.core.layers.ConvSetLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ConvSetLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ConvSetLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ConvSetLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ConvSetLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ConvSetLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ConvSetLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ConvSetLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ConvSetLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply all convolution sets to inputs and concatenate outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – The inputs tensor. It is expected to be of shape [batch, time,
frequency, channel]. The time dimension corresponds to the height
dimension as in images and the frequency dimension corresponds to the
width dimension as in images.</p></li>
<li><p><strong>paddings</strong> – The paddings tensor. It is expected to be of shape [batch,
time].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A tuple (out, output_paddings).</p>
<ul class="simple">
<li><p>out: output tensor. Expected to be of shape [batch, time_mod,
frequency_mod, out_channel_1 + out_channel_2 …] where time_mod and
frequency_mod depend on the conv layer strides and out_channel_i is
the output channel size of the i-th conv layer in the set.</p></li>
<li><p>output_paddings: Modified paddings generated within <code class="xref py py-obj docutils literal notranslate"><span class="pre">ConvLayer.FProp</span></code>.
Expected to be of the shape [batch, time_mod].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.LocalizedLabelSmoother">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">LocalizedLabelSmoother</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LocalizedLabelSmoother"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LocalizedLabelSmoother" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Smooths labels given as class ids.</p>
<p>Implements the smoothing from <a class="reference external" href="https://arxiv.org/abs/1612.02695">https://arxiv.org/abs/1612.02695</a>. Instead of
1-hot class ids the model is trained to predict a distribution over classes
that includes the correct class label and with a small probability the labels
of tokens that appear nearby in time in the ground truth. This typically acts
as a strong regularizer.</p>
<dl class="py method">
<dt id="lingvo.core.layers.LocalizedLabelSmoother.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LocalizedLabelSmoother.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LocalizedLabelSmoother.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.LocalizedLabelSmoother.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">target_paddings</span></em>, <em class="sig-param"><span class="n">target_labels</span></em>, <em class="sig-param"><span class="n">target_ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LocalizedLabelSmoother.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LocalizedLabelSmoother.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert class_ids to 1hot and smooth by neighborhood.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>target_paddings</strong> – float32 matrix [bs, seq_len]</p></li>
<li><p><strong>target_labels</strong> – int32 matrix [bs, seq_len]. This stores the target label
output at each decoder step as generated by the speech input generator
input_batch.tgt.labels</p></li>
<li><p><strong>target_ids</strong> – int32 matrix [bs, seq_len]. This stores the target_id that is
fed to the decoder, as generated by the speech input generator
input_batch.tgt.ids</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor [bs, seq_len, num_classes] denoting a smoothed distribution over
num_classes.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.UniformLabelSmoother">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">UniformLabelSmoother</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#UniformLabelSmoother"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.UniformLabelSmoother" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Smooths labels given as class ids and confidence.</p>
<p>Implements the smoothing from <a class="reference external" href="https://arxiv.org/abs/1512.00567">https://arxiv.org/abs/1512.00567</a>. Correct class
label confidence is dropped by eps and all the other classes are increased
by eps/num_classes.</p>
<dl class="py method">
<dt id="lingvo.core.layers.UniformLabelSmoother.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#UniformLabelSmoother.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.UniformLabelSmoother.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.UniformLabelSmoother.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">target_paddings</span></em>, <em class="sig-param"><span class="n">target_labels</span></em>, <em class="sig-param"><span class="n">target_ids</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#UniformLabelSmoother.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.UniformLabelSmoother.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert target_labels to 1hot and smooth uniformly.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>target_paddings</strong> – float32 matrix [bs, seq_len]</p></li>
<li><p><strong>target_labels</strong> – int32 matrix [bs, seq_len]. This stores the target label
output at each decoder step as generated by the speech input generator
input_batch.tgt.labels</p></li>
<li><p><strong>target_ids</strong> – int32 matrix [bs, seq_len]. This stores the target_id that is
fed to the decoder, as generated by the speech input generator
input_batch.tgt.ids</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor of float32 [bs, seq_len, num_classes] denoting a smoothed
distribution over num_classes.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.HighwaySkipLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">HighwaySkipLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#HighwaySkipLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.HighwaySkipLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>A highway skip layer.</p>
<p>This class represents a highway skip layer, which takes multiple
inputs (from different layers of the network) and gates them.
This returns C(x)x + T(x)h, initially biasing C to be open.
For some discussion about initialization please see:
Section 2.2 in [Srivastava, 2015]: <a class="reference external" href="https://arxiv.org/pdf/1505.00387v2.pdf">https://arxiv.org/pdf/1505.00387v2.pdf</a></p>
<dl class="py method">
<dt id="lingvo.core.layers.HighwaySkipLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#HighwaySkipLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.HighwaySkipLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.HighwaySkipLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">transformed_x</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#HighwaySkipLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.HighwaySkipLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Fprop for Highway Skip layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>x</strong> – feature at the lower layer.</p></li>
<li><p><strong>transformed_x</strong> – transformation of x at a higher layer.</p></li>
<li><p><strong>paddings</strong> – padding applied to the features.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>layer_out - activations after forward propagation.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.GatingLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">GatingLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GatingLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GatingLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>A gating layer.</p>
<p>This class represents a gating layer, which takes 2 inputs of the same shape
and gates them.</p>
<p>The output is: carry * x + (1 - carry) * y where, carry is given by
sigmoid(x &#64; w_1 + y &#64; w_2 + bias).</p>
<p>This is different from the HighwaySkipLayer above in that carry is also a
function of y (named transformed_x in HighwaySkipLayer).</p>
<dl class="py method">
<dt id="lingvo.core.layers.GatingLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GatingLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GatingLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.GatingLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GatingLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GatingLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Fprop for the gating layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>x</strong> – An input feature, the last dimension must match p.input_dim.</p></li>
<li><p><strong>y</strong> – Another input feature. Must have the same shape as ‘x’.</p></li>
<li><p><strong>paddings</strong> – padding applied to the features. When x and y have shape […,
input_dim], ‘paddings’, when specified, must have shaped […, 1], where
all but the last dimension match.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>layer_out - activations after forward propagation. Same shape as x and y.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.GradNormTracker">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">GradNormTracker</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GradNormTracker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GradNormTracker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>A helper class to keep track of gradient norm stats.</p>
<dl class="py method">
<dt id="lingvo.core.layers.GradNormTracker.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GradNormTracker.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GradNormTracker.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.GradNormTracker._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GradNormTracker._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GradNormTracker._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.GradNormTracker.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">grad_norm</span></em>, <em class="sig-param"><span class="n">has_nan</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GradNormTracker.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GradNormTracker.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Update gradient norm moving avgs, and returns whether or not …</p>
<p>to clip gradients to 0.0. If the current batch has NaN grads, does not
update the moving avgs and forces to clip the gradients to 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>grad_norm</strong> – A float scalar tensor.</p></li>
<li><p><strong>has_nan</strong> – A boolean scalar tensor to indicate if the current batch has nan.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A scalar float tensor with value of either 1.0 or 0.0. The value of 0.0
means the gradient norm is excessively large or contains NaN, and the step
should be aborted completely.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.WeightedSumLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">WeightedSumLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#WeightedSumLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.WeightedSumLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Returns the weighted sum of a list of input tensors.</p>
<dl class="py method">
<dt id="lingvo.core.layers.WeightedSumLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#WeightedSumLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.WeightedSumLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Params for this MergerLayer class.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.WeightedSumLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#WeightedSumLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.WeightedSumLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.WeightedSumLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#WeightedSumLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.WeightedSumLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Combines the list of input tensors into a single tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – A list of tensors of shape [time, batch, hidden_dim]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor of the same shape with input tensors.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.GatedAverageLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">GatedAverageLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GatedAverageLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GatedAverageLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Gated combination of n input vectors.</p>
<p>Given n inputs, x_1 … x_n. First learns a gate g in a single layer.
Returns g_1 * x_1 + … g_n * x_n.</p>
<dl class="py method">
<dt id="lingvo.core.layers.GatedAverageLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GatedAverageLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GatedAverageLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.GatedAverageLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GatedAverageLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GatedAverageLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.GatedAverageLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GatedAverageLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GatedAverageLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Gates, then merges a list of n input vectors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – gm (gate matrix)</p></li>
<li><p><strong>inputs</strong> – List of inputs, each of shape […, num_nodes]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a gated output vector […, num_nodes]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.LHUCLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">LHUCLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LHUCLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LHUCLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">Learning</span> <span class="pre">Hidden</span> <span class="pre">Unit</span> <span class="pre">Contribution</span> <span class="pre">(LHUC)</span></code> layer.</p>
<dl class="simple">
<dt>This paper proposes to use LHUC layer for NMT adaptation:</dt><dd><p><a class="reference external" href="http://aclweb.org/anthology/N18-2080">http://aclweb.org/anthology/N18-2080</a></p>
</dd>
</dl>
<p>During base model training, LHUC layer is fixed to 1.0 (no-op in
multiplication). During adaptation, only LHUC layer is trained, and all other
parameters in the model are frozen.</p>
<dl class="py method">
<dt id="lingvo.core.layers.LHUCLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LHUCLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LHUCLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.LHUCLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LHUCLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LHUCLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.LHUCLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inp</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#LHUCLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.LHUCLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Add learnt gate for adaptation.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.ResidualAdapterLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">ResidualAdapterLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ResidualAdapterLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ResidualAdapterLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Residual Adapter layer for NLP tasks.</p>
<p>This paper proposes using residual adapters for fine-tuning new tasks on BERT.
<a class="reference external" href="https://arxiv.org/pdf/1902.00751.pdf">https://arxiv.org/pdf/1902.00751.pdf</a></p>
<p>During adaptation, residual adapter layers can be added to a pre-trained
model and trained, while all other parameters are frozen.
In terms of operations, the layer is identical to a vanilla Transformer
feedforward layer. Separate implementation is meant to distinguish function.</p>
<dl class="py method">
<dt id="lingvo.core.layers.ResidualAdapterLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ResidualAdapterLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ResidualAdapterLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.ResidualAdapterLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#ResidualAdapterLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.ResidualAdapterLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Fprop for Residual Adapter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>x</strong> – […, input_dim].</p></li>
<li><p><strong>paddings</strong> – padding applied to the features.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>layer_out - […, input_dim].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="lingvo.core.layers.Conv2DFlops">
<code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">Conv2DFlops</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">filter_shape</span></em>, <em class="sig-param"><span class="n">stride</span></em>, <em class="sig-param"><span class="n">padding</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#Conv2DFlops"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.Conv2DFlops" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns number of float operations (mult/adds) for a Conv2D op.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – the input shape. Must have four elements.</p></li>
<li><p><strong>filter_shape</strong> – the convolution filter shape. Must have four elements.</p></li>
<li><p><strong>stride</strong> – the strides along height and width, respectively.</p></li>
<li><p><strong>padding</strong> – ‘SAME’ or ‘VALID’.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Number of multiplications and additions.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.Conv2DLayerNoPadding">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">Conv2DLayerNoPadding</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#Conv2DLayerNoPadding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.Conv2DLayerNoPadding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>2-D Convolution layer w/o padding.</p>
<p>TODO(laurenzo): Dedup in favor of SeparableConv2DLayer where possible.</p>
<dl class="py method">
<dt id="lingvo.core.layers.Conv2DLayerNoPadding.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#Conv2DLayerNoPadding.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.Conv2DLayerNoPadding.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.Conv2DLayerNoPadding._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#Conv2DLayerNoPadding._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.Conv2DLayerNoPadding._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.Conv2DLayerNoPadding.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#Conv2DLayerNoPadding.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.Conv2DLayerNoPadding.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply convolution to inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A NestedMap object containing weights’ values of this layer and its
children layers.</p></li>
<li><p><strong>x</strong> – The inputs tensor. It is expected to be of shape [batch, height, width,
channel].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Convolution output.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.Conv2DLayerNoPadding.FPropMeta">
<em class="property">classmethod </em><code class="sig-name descname">FPropMeta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#Conv2DLayerNoPadding.FPropMeta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.Conv2DLayerNoPadding.FPropMeta" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns metadata about the <a class="reference internal" href="#lingvo.core.layers.Conv2DLayerNoPadding.FProp" title="lingvo.core.layers.Conv2DLayerNoPadding.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> computation for this layer.</p>
<p><strong>Experimental feature.</strong>
Don’t use or depend on it without consulting Lingvo authors.</p>
<p>E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">SomeComplexLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
<span class="n">meta</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">FPropMeta</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">tshape</span><span class="o">.</span><span class="n">Shape</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;channels&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.flops</span></code> gives an estimate count of floating point operations done by
one <a class="reference internal" href="#lingvo.core.layers.Conv2DLayerNoPadding.FProp" title="lingvo.core.layers.Conv2DLayerNoPadding.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> given an input tensor of shape [128, 20, 50, channels].
<code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.out_shapes</span></code> is a tuple of TShape, which tells you what shape
of tensors this layer will return.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – The param of a layer of this layer type.</p></li>
<li><p><strong>*args</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> with</p>
<ul class="simple">
<li><p>flops - The estimated number of floating point operations incurred by
this fprop.</p></li>
<li><p>out_shapes - A tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">TShape</span></code>. I.e., <code class="xref py py-obj docutils literal notranslate"><span class="pre">out_shapes[i]</span></code>
represents the shape of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">i</span></code>-th returned tensor of the fprop.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.FetchLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">FetchLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#FetchLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.FetchLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>A layer facilitating fetching activations and their gradients.</p>
<dl class="py method">
<dt id="lingvo.core.layers.FetchLayer.FPropMeta">
<em class="property">classmethod </em><code class="sig-name descname">FPropMeta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">params</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#FetchLayer.FPropMeta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.FetchLayer.FPropMeta" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns metadata about the <a class="reference internal" href="#lingvo.core.layers.FetchLayer.FProp" title="lingvo.core.layers.FetchLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> computation for this layer.</p>
<p><strong>Experimental feature.</strong>
Don’t use or depend on it without consulting Lingvo authors.</p>
<p>E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">SomeComplexLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
<span class="n">meta</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">FPropMeta</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">tshape</span><span class="o">.</span><span class="n">Shape</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;channels&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.flops</span></code> gives an estimate count of floating point operations done by
one <a class="reference internal" href="#lingvo.core.layers.FetchLayer.FProp" title="lingvo.core.layers.FetchLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> given an input tensor of shape [128, 20, 50, channels].
<code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.out_shapes</span></code> is a tuple of TShape, which tells you what shape
of tensors this layer will return.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – The param of a layer of this layer type.</p></li>
<li><p><strong>*args</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> with</p>
<ul class="simple">
<li><p>flops - The estimated number of floating point operations incurred by
this fprop.</p></li>
<li><p>out_shapes - A tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">TShape</span></code>. I.e., <code class="xref py py-obj docutils literal notranslate"><span class="pre">out_shapes[i]</span></code>
represents the shape of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">i</span></code>-th returned tensor of the fprop.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.FetchLayer._ReturnSingleValueOrList">
<code class="sig-name descname">_ReturnSingleValueOrList</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">lst</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#FetchLayer._ReturnSingleValueOrList"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.FetchLayer._ReturnSingleValueOrList" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.FetchLayer.activation">
<em class="property">property </em><code class="sig-name descname">activation</code><a class="headerlink" href="#lingvo.core.layers.FetchLayer.activation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.FetchLayer.gradient">
<em class="property">property </em><code class="sig-name descname">gradient</code><a class="headerlink" href="#lingvo.core.layers.FetchLayer.gradient" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.FetchLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#FetchLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.FetchLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagation.</p>
<p>The central interface that subclasses should implement. The caller
calls <a class="reference internal" href="#lingvo.core.layers.FetchLayer.FProp" title="lingvo.core.layers.FetchLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> with a <code class="xref py py-obj docutils literal notranslate"><span class="pre">theta</span></code> dictionary. E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">foo</span> <span class="o">=</span> <span class="n">InstanceOfASubClassOfFoo</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">foo</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">foo</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>The implementation of <a class="reference internal" href="#lingvo.core.layers.FetchLayer.FProp" title="lingvo.core.layers.FetchLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp()</span></code></a> computes a function given
the theta and the inputs. E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">subs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">a0</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="n">a1</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">a0</span><span class="p">)</span>
<span class="c1"># The same layer applied twice.</span>
<span class="n">a2</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span>
<span class="k">return</span> <span class="n">a2</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>*args</strong> – List args.</p></li>
<li><p><strong>**kwargs</strong> – Keyward args.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.GluLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">GluLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GluLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GluLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Gated Linear Unit.</p>
<p>See <a class="reference external" href="https://arxiv.org/abs/1612.08083">https://arxiv.org/abs/1612.08083</a> for more details.</p>
<dl class="py method">
<dt id="lingvo.core.layers.GluLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GluLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GluLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.GluLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#GluLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.GluLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagation.</p>
<p>The central interface that subclasses should implement. The caller
calls <a class="reference internal" href="#lingvo.core.layers.GluLayer.FProp" title="lingvo.core.layers.GluLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> with a <code class="xref py py-obj docutils literal notranslate"><span class="pre">theta</span></code> dictionary. E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">foo</span> <span class="o">=</span> <span class="n">InstanceOfASubClassOfFoo</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">foo</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">foo</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>The implementation of <a class="reference internal" href="#lingvo.core.layers.GluLayer.FProp" title="lingvo.core.layers.GluLayer.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp()</span></code></a> computes a function given
the theta and the inputs. E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">subs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">a0</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="n">a1</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">a0</span><span class="p">)</span>
<span class="c1"># The same layer applied twice.</span>
<span class="n">a2</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span>
<span class="k">return</span> <span class="n">a2</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>*args</strong> – List args.</p></li>
<li><p><strong>**kwargs</strong> – Keyward args.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.MultitaskAdapterBaseLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">MultitaskAdapterBaseLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#MultitaskAdapterBaseLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.MultitaskAdapterBaseLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Residual adapter layer for multilingual models.</p>
<p>Residual adapters can be used to fine-tune a single model to multiple
domains, tasks, or languages: <a class="reference external" href="https://arxiv.org/pdf/1902.00751.pdf">https://arxiv.org/pdf/1902.00751.pdf</a></p>
<p>Each adapter consists of a “down” projection to a smaller dimension followed
by an “up” projection, the result of which is added back to the input
activation.  The projection weights and biases are task-specific.</p>
<p>Whereas ResidualAdapterLayer learns and applies the parameters for a single
task, this layer learns and applies the parameters for multiple tasks so that
we have a single model serving the different tasks. The parameters can be
trained for all tasks at the same time, or in one-off per-task training jobs.</p>
<dl class="py method">
<dt id="lingvo.core.layers.MultitaskAdapterBaseLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#MultitaskAdapterBaseLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.MultitaskAdapterBaseLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.MultitaskAdapterLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">MultitaskAdapterLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#MultitaskAdapterLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.MultitaskAdapterLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.MultitaskAdapterBaseLayer" title="lingvo.core.layers.MultitaskAdapterBaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.MultitaskAdapterBaseLayer</span></code></a></p>
<p>MultitaskAdapterBaseLayer implemented with EmbeddingLayers.</p>
<dl class="py method">
<dt id="lingvo.core.layers.MultitaskAdapterLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#MultitaskAdapterLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.MultitaskAdapterLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.MultitaskAdapterLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">tasks</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#MultitaskAdapterLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.MultitaskAdapterLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Fprop for multitask adapter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A NestedMap object containing weights’ values of this layer and its
children layers.</p></li>
<li><p><strong>inputs</strong> – A tensor containing the activations from the previous layer. For
‘TBC’, the shape is [time, batch, input_dim] and for ‘BTC’, it’s [batch,
time, input_dim].</p></li>
<li><p><strong>tasks</strong> – An int32 tensor containing the task ID for each input.  If ‘tasks’
is of rank 2, we assume it to be of shape [time, batch] if ‘BTC’ and
[batch, time] if ‘TBC’, indicating a different task for each timestep.
In this case we look up adapter params for each timestep.  If ‘tasks’ is
of rank 1, we assume it to be of shape [batch], indicating a single task
for all timesteps of a sequence. This latter setup uses substantially
less memory and is generally preferred.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor containing the adapted activations with shape
[time, batch, input_dim] for ‘TBC’ and [batch, time, input_dim] for ‘BTC’.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.MultitaskAdapterEinsumLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">MultitaskAdapterEinsumLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#MultitaskAdapterEinsumLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.MultitaskAdapterEinsumLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.layers.MultitaskAdapterBaseLayer" title="lingvo.core.layers.MultitaskAdapterBaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.layers.MultitaskAdapterBaseLayer</span></code></a></p>
<p>MultitaskAdapterBaseLayer implemented with Einsum.</p>
<p>The embedding-based solution sometimes triggers b/175464137.</p>
<dl class="py method">
<dt id="lingvo.core.layers.MultitaskAdapterEinsumLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#MultitaskAdapterEinsumLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.MultitaskAdapterEinsumLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.MultitaskAdapterEinsumLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#MultitaskAdapterEinsumLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.MultitaskAdapterEinsumLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.MultitaskAdapterEinsumLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">tasks</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#MultitaskAdapterEinsumLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.MultitaskAdapterEinsumLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Fprop for multitask adapter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A NestedMap object containing weights’ values of this layer and its
children layers.</p></li>
<li><p><strong>inputs</strong> – A tensor containing the activations from the previous layer.
[batch, time, input_dim].</p></li>
<li><p><strong>tasks</strong> – An int32 tensor containing the task ID for each input. [batch].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor containing the adapted activations with the same shape as inputs.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.CCTGatingNetwork">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">CCTGatingNetwork</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CCTGatingNetwork"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CCTGatingNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.quant_utils.html#lingvo.core.quant_utils.QuantizableLayer" title="lingvo.core.quant_utils.QuantizableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.quant_utils.QuantizableLayer</span></code></a></p>
<p>A gating network that is continous for training and discrete for eval.</p>
<p>Based on the gating network from <a class="reference external" href="https://arxiv.org/abs/2002.07106">https://arxiv.org/abs/2002.07106</a>.</p>
<dl class="py method">
<dt id="lingvo.core.layers.CCTGatingNetwork.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CCTGatingNetwork.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CCTGatingNetwork.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.CCTGatingNetwork.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CCTGatingNetwork.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CCTGatingNetwork.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagation.</p>
<p>The central interface that subclasses should implement. The caller
calls <a class="reference internal" href="#lingvo.core.layers.CCTGatingNetwork.FProp" title="lingvo.core.layers.CCTGatingNetwork.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> with a <code class="xref py py-obj docutils literal notranslate"><span class="pre">theta</span></code> dictionary. E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">foo</span> <span class="o">=</span> <span class="n">InstanceOfASubClassOfFoo</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">foo</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">foo</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>The implementation of <a class="reference internal" href="#lingvo.core.layers.CCTGatingNetwork.FProp" title="lingvo.core.layers.CCTGatingNetwork.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp()</span></code></a> computes a function given
the theta and the inputs. E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">subs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">a0</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="n">a1</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="n">a0</span><span class="p">)</span>
<span class="c1"># The same layer applied twice.</span>
<span class="n">a2</span> <span class="o">=</span> <span class="n">subs</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">linear</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span>
<span class="k">return</span> <span class="n">a2</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>*args</strong> – List args.</p></li>
<li><p><strong>**kwargs</strong> – Keyward args.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.CCTGatingNetwork.FPropMeta">
<em class="property">classmethod </em><code class="sig-name descname">FPropMeta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CCTGatingNetwork.FPropMeta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CCTGatingNetwork.FPropMeta" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns metadata about the <a class="reference internal" href="#lingvo.core.layers.CCTGatingNetwork.FProp" title="lingvo.core.layers.CCTGatingNetwork.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> computation for this layer.</p>
<p><strong>Experimental feature.</strong>
Don’t use or depend on it without consulting Lingvo authors.</p>
<p>E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">SomeComplexLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
<span class="n">meta</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="o">.</span><span class="n">FPropMeta</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">tshape</span><span class="o">.</span><span class="n">Shape</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;channels&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.flops</span></code> gives an estimate count of floating point operations done by
one <a class="reference internal" href="#lingvo.core.layers.CCTGatingNetwork.FProp" title="lingvo.core.layers.CCTGatingNetwork.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code></a> given an input tensor of shape [128, 20, 50, channels].
<code class="xref py py-obj docutils literal notranslate"><span class="pre">meta.out_shapes</span></code> is a tuple of TShape, which tells you what shape
of tensors this layer will return.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – The param of a layer of this layer type.</p></li>
<li><p><strong>*args</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
<li><p><strong>**kwargs</strong> – Corresponds to FProp with Tensors replaced by <code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorShape</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> with</p>
<ul class="simple">
<li><p>flops - The estimated number of floating point operations incurred by
this fprop.</p></li>
<li><p>out_shapes - A tuple of <code class="xref py py-obj docutils literal notranslate"><span class="pre">TShape</span></code>. I.e., <code class="xref py py-obj docutils literal notranslate"><span class="pre">out_shapes[i]</span></code>
represents the shape of the <code class="xref py py-obj docutils literal notranslate"><span class="pre">i</span></code>-th returned tensor of the fprop.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.layers.CondScaleShiftFFNLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.layers.</code><code class="sig-name descname">CondScaleShiftFFNLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CondScaleShiftFFNLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CondScaleShiftFFNLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Feature Modulation layer.</p>
<p><a class="reference external" href="https://distill.pub/2018/feature-wise-transformations/">https://distill.pub/2018/feature-wise-transformations/</a></p>
<dl class="py method">
<dt id="lingvo.core.layers.CondScaleShiftFFNLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CondScaleShiftFFNLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CondScaleShiftFFNLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.layers.CondScaleShiftFFNLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/layers.html#CondScaleShiftFFNLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.layers.CondScaleShiftFFNLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate scale shift and modify input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – params.</p></li>
<li><p><strong>inputs</strong> – The input tensor. Shaped […, input_dim].</p></li>
<li><p><strong>paddings</strong> – The input padding tensors.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output after calculating shift and scale (2 tensors).
Shaped […, output_dim].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="lingvo.core.layers_with_attention.html" class="btn btn-neutral float-right" title="lingvo.core.layers_with_attention module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="lingvo.core.inspect_utils.html" class="btn btn-neutral float-left" title="lingvo.core.inspect_utils module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2018

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>