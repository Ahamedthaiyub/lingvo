

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>lingvo.core.rnn_layers module &mdash; Lingvo  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="lingvo.core.saver module" href="lingvo.core.saver.html" />
    <link rel="prev" title="lingvo.core.rnn_cell module" href="lingvo.core.rnn_cell.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="lingvo.html">lingvo package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="lingvo.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="lingvo.core.html">lingvo.core package</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="lingvo.core.html#subpackages">Subpackages</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="lingvo.core.html#submodules">Submodules</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="lingvo.tasks.html">lingvo.tasks package</a></li>
<li class="toctree-l3"><a class="reference internal" href="lingvo.tools.html">lingvo.tools package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lingvo.html#submodules">Submodules</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="lingvo.html">lingvo package</a> &raquo;</li>
        
          <li><a href="lingvo.core.html">lingvo.core package</a> &raquo;</li>
        
      <li>lingvo.core.rnn_layers module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/lingvo.core.rnn_layers.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-lingvo.core.rnn_layers">
<span id="lingvo-core-rnn-layers-module"></span><h1>lingvo.core.rnn_layers module<a class="headerlink" href="#module-lingvo.core.rnn_layers" title="Permalink to this headline">¶</a></h1>
<p>Lingvo RNN layers.</p>
<dl class="py function">
<dt id="lingvo.core.rnn_layers.GeneratePackedInputResetMask">
<code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">GeneratePackedInputResetMask</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">segment_id</span></em>, <em class="sig-param"><span class="n">is_reverse</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#GeneratePackedInputResetMask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.GeneratePackedInputResetMask" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates mask inputs for RNN cells from segment_id.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>segment_id</strong> – A tensor of shape [time, batch_size, 1].</p></li>
<li><p><strong>is_reverse</strong> – True if inputs are fed to the RNN in reverse order.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>reset_mask - a tensor of shape [time, batch_size, 1]. Set to 0 for samples</dt><dd><p>where state needs to be reset (at example boundaries), and 1 otherwise.</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="lingvo.core.rnn_layers.IdentitySeqLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">IdentitySeqLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#IdentitySeqLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.IdentitySeqLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>A no-op sequence layer.</p>
<dl class="py method">
<dt id="lingvo.core.rnn_layers.IdentitySeqLayer.zero_state">
<code class="sig-name descname">zero_state</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">batch_size</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#IdentitySeqLayer.zero_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.IdentitySeqLayer.zero_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.IdentitySeqLayer.FPropFullSequence">
<code class="sig-name descname">FPropFullSequence</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#IdentitySeqLayer.FPropFullSequence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.IdentitySeqLayer.FPropFullSequence" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.rnn_layers.RNN">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">RNN</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#RNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.RNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Statically unrolled RNN.</p>
<dl class="py method">
<dt id="lingvo.core.rnn_layers.RNN.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#RNN.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.RNN.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.RNN._CreateChildrenVariables">
<code class="sig-name descname">_CreateChildrenVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#RNN._CreateChildrenVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.RNN._CreateChildrenVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Create variables for child layers.</p>
<p>Should be rarely overridden, only in cases when control over the context of
children InstantiateVariables calls are needed. eg, if children variables
need to be created inside of a specific context manager.</p>
<p>There are a few cases of this in the codebase marked as for backwards
compability. This is only to ensure that variable scopes remain compatible
through the code migration. New layers should not copy that pattern, and
instead follow the standard pattern of self.CreateChild() in __init__() and
self.CreateVariable() in _CreateLayerVariables(). If you are okay with
breaking old checkpoints, you can go ahead and delete those functions.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.RNN.zero_state">
<code class="sig-name descname">zero_state</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">batch_size</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#RNN.zero_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.RNN.zero_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.RNN.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em>, <em class="sig-param"><span class="n">state0</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#RNN.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.RNN.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute RNN forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>inputs</strong> – A single tensor or a tuple of tensors with cardinality equal to
rnn_cell.inputs_arity. For every input tensor, the first dimension is
assumed to be time, second dimension batch, and third dimension depth.</p></li>
<li><p><strong>paddings</strong> – A tensor. First dim is time, second dim is batch, and third dim
is expected to be 1.</p></li>
<li><p><strong>state0</strong> – If not None, the initial rnn state in a <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>. Defaults
to the cell’s zero-state.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor of [time, batch, dims].
The final recurrent state.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.rnn_layers.StackedRNNBase">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">StackedRNNBase</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedRNNBase"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedRNNBase" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Stacked RNN base class.</p>
<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedRNNBase.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedRNNBase.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedRNNBase.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedRNNBase._GetCellTpls">
<code class="sig-name descname">_GetCellTpls</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedRNNBase._GetCellTpls"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedRNNBase._GetCellTpls" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.rnn_layers.StackedFRNNLayerByLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">StackedFRNNLayerByLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedFRNNLayerByLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedFRNNLayerByLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.rnn_layers.StackedRNNBase" title="lingvo.core.rnn_layers.StackedRNNBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.rnn_layers.StackedRNNBase</span></code></a>, <a class="reference internal" href="lingvo.core.quant_utils.html#lingvo.core.quant_utils.QuantizableLayer" title="lingvo.core.quant_utils.QuantizableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.quant_utils.QuantizableLayer</span></code></a></p>
<p>An implemention of StackedRNNBase which computes layer-by-layer.</p>
<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedFRNNLayerByLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedFRNNLayerByLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedFRNNLayerByLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedFRNNLayerByLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedFRNNLayerByLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedFRNNLayerByLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedFRNNLayerByLayer._CreateChildrenVariables">
<code class="sig-name descname">_CreateChildrenVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedFRNNLayerByLayer._CreateChildrenVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedFRNNLayerByLayer._CreateChildrenVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Create variables for child layers.</p>
<p>Should be rarely overridden, only in cases when control over the context of
children InstantiateVariables calls are needed. eg, if children variables
need to be created inside of a specific context manager.</p>
<p>There are a few cases of this in the codebase marked as for backwards
compability. This is only to ensure that variable scopes remain compatible
through the code migration. New layers should not copy that pattern, and
instead follow the standard pattern of self.CreateChild() in __init__() and
self.CreateVariable() in _CreateLayerVariables(). If you are okay with
breaking old checkpoints, you can go ahead and delete those functions.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedFRNNLayerByLayer.zero_state">
<code class="sig-name descname">zero_state</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">batch_size</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedFRNNLayerByLayer.zero_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedFRNNLayerByLayer.zero_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedFRNNLayerByLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em>, <em class="sig-param"><span class="n">state0</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedFRNNLayerByLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedFRNNLayerByLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute RNN forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>inputs</strong> – A single tensor of shape [time, batch, dims].</p></li>
<li><p><strong>paddings</strong> – A single tensor of shape [time, batch, 1].</p></li>
<li><p><strong>state0</strong> – If not None, the initial rnn state in a <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>. Defaults
to the init state.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(outputs, state1)
outputs: A tensor of [time, batch, dims].
state1: The final state.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedFRNNLayerByLayer.FPropFullSequence">
<code class="sig-name descname">FPropFullSequence</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedFRNNLayerByLayer.FPropFullSequence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedFRNNLayerByLayer.FPropFullSequence" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.rnn_layers.StackedBiFRNNLayerByLayer">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">StackedBiFRNNLayerByLayer</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedBiFRNNLayerByLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedBiFRNNLayerByLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.core.rnn_layers.StackedRNNBase" title="lingvo.core.rnn_layers.StackedRNNBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.rnn_layers.StackedRNNBase</span></code></a>, <a class="reference internal" href="lingvo.core.quant_utils.html#lingvo.core.quant_utils.QuantizableLayer" title="lingvo.core.quant_utils.QuantizableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.quant_utils.QuantizableLayer</span></code></a></p>
<p>An implemention of StackedRNNBase with bidirection RNN layers.</p>
<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedBiFRNNLayerByLayer.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedBiFRNNLayerByLayer.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedBiFRNNLayerByLayer.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedBiFRNNLayerByLayer._CreateLayerVariables">
<code class="sig-name descname">_CreateLayerVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedBiFRNNLayerByLayer._CreateLayerVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedBiFRNNLayerByLayer._CreateLayerVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Actually create variables for this layer.</p>
<p>Subclasses should override this function.</p>
<p>Variables are created inside of tf.variable_scope(self.params.name).</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedBiFRNNLayerByLayer._CreateChildrenVariables">
<code class="sig-name descname">_CreateChildrenVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedBiFRNNLayerByLayer._CreateChildrenVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedBiFRNNLayerByLayer._CreateChildrenVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Create variables for child layers.</p>
<p>Should be rarely overridden, only in cases when control over the context of
children InstantiateVariables calls are needed. eg, if children variables
need to be created inside of a specific context manager.</p>
<p>There are a few cases of this in the codebase marked as for backwards
compability. This is only to ensure that variable scopes remain compatible
through the code migration. New layers should not copy that pattern, and
instead follow the standard pattern of self.CreateChild() in __init__() and
self.CreateVariable() in _CreateLayerVariables(). If you are okay with
breaking old checkpoints, you can go ahead and delete those functions.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedBiFRNNLayerByLayer.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedBiFRNNLayerByLayer.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedBiFRNNLayerByLayer.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>inputs</strong> – A single tensor of shape [time, batch, dims].</p></li>
<li><p><strong>paddings</strong> – A single tensor of shape [time, batch, 1].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor of [time, batch, dims].</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.StackedBiFRNNLayerByLayer.FPropFullSequence">
<code class="sig-name descname">FPropFullSequence</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#StackedBiFRNNLayerByLayer.FPropFullSequence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.StackedBiFRNNLayerByLayer.FPropFullSequence" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.rnn_layers.FRNN">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">FRNN</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Functional while based RNN.</p>
<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNN.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNN.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNN.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNN._CreateChildrenVariables">
<code class="sig-name descname">_CreateChildrenVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNN._CreateChildrenVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNN._CreateChildrenVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Create variables for child layers.</p>
<p>Should be rarely overridden, only in cases when control over the context of
children InstantiateVariables calls are needed. eg, if children variables
need to be created inside of a specific context manager.</p>
<p>There are a few cases of this in the codebase marked as for backwards
compability. This is only to ensure that variable scopes remain compatible
through the code migration. New layers should not copy that pattern, and
instead follow the standard pattern of self.CreateChild() in __init__() and
self.CreateVariable() in _CreateLayerVariables(). If you are okay with
breaking old checkpoints, you can go ahead and delete those functions.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNN.rnn_cell">
<em class="property">property </em><code class="sig-name descname">rnn_cell</code><a class="headerlink" href="#lingvo.core.rnn_layers.FRNN.rnn_cell" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNN.zero_state">
<code class="sig-name descname">zero_state</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">batch_size</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNN.zero_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNN.zero_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNN.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em>, <em class="sig-param"><span class="n">state0</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">segment_id</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNN.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNN.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute RNN forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>inputs</strong> – A single tensor or a tuple of tensors with cardinality equal to
rnn_cell.inputs_arity. For every input tensor, the first dimension is
assumed to be time, second dimension batch, and third dimension depth.</p></li>
<li><p><strong>paddings</strong> – A tensor. First dim is time, second dim is batch, and third dim
is expected to be 1.</p></li>
<li><p><strong>state0</strong> – If not None, the initial rnn state in a <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>. Defaults
to the cell’s zero-state.</p></li>
<li><p><strong>segment_id</strong> – A tensor to support packed inputs. First dim is time, second
dim is batch, and third dim is expected to be 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor of [time, batch, dims].
The final recurrent state.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.rnn_layers.BidirectionalFRNN">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">BidirectionalFRNN</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalFRNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalFRNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Bidirectional functional RNN.</p>
<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalFRNN.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalFRNN.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalFRNN.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalFRNN._CreateChildrenVariables">
<code class="sig-name descname">_CreateChildrenVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalFRNN._CreateChildrenVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalFRNN._CreateChildrenVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Create variables for child layers.</p>
<p>Should be rarely overridden, only in cases when control over the context of
children InstantiateVariables calls are needed. eg, if children variables
need to be created inside of a specific context manager.</p>
<p>There are a few cases of this in the codebase marked as for backwards
compability. This is only to ensure that variable scopes remain compatible
through the code migration. New layers should not copy that pattern, and
instead follow the standard pattern of self.CreateChild() in __init__() and
self.CreateVariable() in _CreateLayerVariables(). If you are okay with
breaking old checkpoints, you can go ahead and delete those functions.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalFRNN.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em>, <em class="sig-param"><span class="n">segment_id</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalFRNN.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalFRNN.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute bidi-RNN forward pass.</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">rcell_forward</span></code> unroll the sequence in the forward direction and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">rcell_backward</span></code> unroll the sequence in the backward direction. The
outputs are concatenated in the last output dim.</p>
<p>See <a class="reference internal" href="#lingvo.core.rnn_layers.FRNN.FProp" title="lingvo.core.rnn_layers.FRNN.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FRNN.FProp</span></code></a> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>inputs</strong> – A single tensor or a tuple of tensors with cardinality equal to
rnn_cell.inputs_arity. For every input tensor, the first dimension is
assumed to be time, second dimension batch, and third dimension depth.</p></li>
<li><p><strong>paddings</strong> – A tensor. First dim is time, second dim is batch, and third dim
is expected to be 1.</p></li>
<li><p><strong>segment_id</strong> – A tensor to support packed inputs. First dim is time, second
dim is batch, and third dim is expected to be 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor of [time, batch, dims].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.rnn_layers.BidirectionalRNN">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">BidirectionalRNN</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalRNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalRNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Statically unrolled bidirectional RNN.</p>
<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalRNN.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalRNN.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalRNN.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalRNN._CreateChildrenVariables">
<code class="sig-name descname">_CreateChildrenVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalRNN._CreateChildrenVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalRNN._CreateChildrenVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Create variables for child layers.</p>
<p>Should be rarely overridden, only in cases when control over the context of
children InstantiateVariables calls are needed. eg, if children variables
need to be created inside of a specific context manager.</p>
<p>There are a few cases of this in the codebase marked as for backwards
compability. This is only to ensure that variable scopes remain compatible
through the code migration. New layers should not copy that pattern, and
instead follow the standard pattern of self.CreateChild() in __init__() and
self.CreateVariable() in _CreateLayerVariables(). If you are okay with
breaking old checkpoints, you can go ahead and delete those functions.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalRNN.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalRNN.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalRNN.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute bidi-RNN forward pass.</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">rcell_forward</span></code> is responsible for unrolling the sequence in the forward
direction and <code class="xref py py-obj docutils literal notranslate"><span class="pre">rcell_backward</span></code> in the backward direction. Output from
forward and backward rnns are concatenated on the last output dim.</p>
<p>See <a class="reference internal" href="#lingvo.core.rnn_layers.RNN.FProp" title="lingvo.core.rnn_layers.RNN.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RNN.FProp()</span></code></a> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>inputs</strong> – A single tensor or a tuple of tensors with cardinality equal to
rnn_cell.inputs_arity. For every input tensor, the first dimension is
assumed to be time, second dimension batch, and third dimension depth.</p></li>
<li><p><strong>paddings</strong> – A tensor. First dim is time, second dim is batch, and third dim
is expected to be 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor of [time, batch, dims].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.rnn_layers.BidirectionalRNNV2">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">BidirectionalRNNV2</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalRNNV2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalRNNV2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Statically unrolled bidirectional RNN.</p>
<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalRNNV2.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalRNNV2.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalRNNV2.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalRNNV2._CreateChildrenVariables">
<code class="sig-name descname">_CreateChildrenVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalRNNV2._CreateChildrenVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalRNNV2._CreateChildrenVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Create variables for child layers.</p>
<p>Should be rarely overridden, only in cases when control over the context of
children InstantiateVariables calls are needed. eg, if children variables
need to be created inside of a specific context manager.</p>
<p>There are a few cases of this in the codebase marked as for backwards
compability. This is only to ensure that variable scopes remain compatible
through the code migration. New layers should not copy that pattern, and
instead follow the standard pattern of self.CreateChild() in __init__() and
self.CreateVariable() in _CreateLayerVariables(). If you are okay with
breaking old checkpoints, you can go ahead and delete those functions.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalRNNV2._PadSequenceToLength">
<code class="sig-name descname">_PadSequenceToLength</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t_input</span></em>, <em class="sig-param"><span class="n">length</span></em>, <em class="sig-param"><span class="n">pad_value</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalRNNV2._PadSequenceToLength"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalRNNV2._PadSequenceToLength" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalRNNV2.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalRNNV2.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalRNNV2.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute bidi-RNN forward pass.</p>
<p>rcell_forward is responsible for unrolling the sequence in the forward
direction and rcell_backward in the backward direction. Output from forward
and backward rnns are concatenated on the last output dim.</p>
<p>See RNN.FProp() for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>inputs</strong> – A single tensor or a tuple of tensors with cardinality equal to
rnn_cell.inputs_arity. For every input tensor, the first dimension is
assumed to be time, second dimension batch, and third dimension depth.</p></li>
<li><p><strong>paddings</strong> – A tensor. First dim is time, second dim is batch, and third dim
is expected to be 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor of [time, batch, dims].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="lingvo.core.rnn_layers._ConcatLastDim">
<code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">_ConcatLastDim</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#_ConcatLastDim"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers._ConcatLastDim" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenates all args along the last dimension.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.rnn_layers._ShiftRight">
<code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">_ShiftRight</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x0</span></em>, <em class="sig-param"><span class="n">xs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#_ShiftRight"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers._ShiftRight" title="Permalink to this definition">¶</a></dt>
<dd><p>Shifts xs[:-1] one step to the right and attaches x0 on the left.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.rnn_layers._ShiftRightWithMasking">
<code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">_ShiftRightWithMasking</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x0</span></em>, <em class="sig-param"><span class="n">xs</span></em>, <em class="sig-param"><span class="n">mask</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#_ShiftRightWithMasking"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers._ShiftRightWithMasking" title="Permalink to this definition">¶</a></dt>
<dd><p>Shifts xs[:-1] one step to the right and attaches x0 on the left.</p>
</dd></dl>

<dl class="py class">
<dt id="lingvo.core.rnn_layers.FRNNWithAttention">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">FRNNWithAttention</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNNWithAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNNWithAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>An RNN layer intertwined with an attention layer.</p>
<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNNWithAttention.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNNWithAttention.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNNWithAttention.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNNWithAttention._CreateChildrenVariables">
<code class="sig-name descname">_CreateChildrenVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNNWithAttention._CreateChildrenVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNNWithAttention._CreateChildrenVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Create variables for child layers.</p>
<p>Should be rarely overridden, only in cases when control over the context of
children InstantiateVariables calls are needed. eg, if children variables
need to be created inside of a specific context manager.</p>
<p>There are a few cases of this in the codebase marked as for backwards
compability. This is only to ensure that variable scopes remain compatible
through the code migration. New layers should not copy that pattern, and
instead follow the standard pattern of self.CreateChild() in __init__() and
self.CreateVariable() in _CreateLayerVariables(). If you are okay with
breaking old checkpoints, you can go ahead and delete those functions.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNNWithAttention.rnn_cell">
<em class="property">property </em><code class="sig-name descname">rnn_cell</code><a class="headerlink" href="#lingvo.core.rnn_layers.FRNNWithAttention.rnn_cell" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNNWithAttention.attention">
<em class="property">property </em><code class="sig-name descname">attention</code><a class="headerlink" href="#lingvo.core.rnn_layers.FRNNWithAttention.attention" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNNWithAttention.InitForSourcePacked">
<code class="sig-name descname">InitForSourcePacked</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">src_encs</span></em>, <em class="sig-param"><span class="n">src_paddings</span></em>, <em class="sig-param"><span class="n">src_contexts</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">src_segment_id</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNNWithAttention.InitForSourcePacked"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNNWithAttention.InitForSourcePacked" title="Permalink to this definition">¶</a></dt>
<dd><p>A wrapper of InitForSourcePacked of child attention layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>src_encs</strong> – A tensor of shape [source_seq_length, batch_size, source_dim].</p></li>
<li><p><strong>src_paddings</strong> – A tensor of shape [source_seq_length, batch_size].</p></li>
<li><p><strong>src_contexts</strong> – [Optional] If specified, must be a tensor of shape
[source_seq_length, batch_size, some_dim]. When specified, this tensor
will be used as the source context vectors when computing attention
context, and src_ends will be only used to compute the attention score
for each context. If set to None, the ‘src_encs’ will be used as
source context.</p></li>
<li><p><strong>src_segment_id</strong> – A tensor of shape [source_seq_length, batch_size], to
support packed inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>packed_src - A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> containing packed source.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNNWithAttention.zero_state">
<code class="sig-name descname">zero_state</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">src_encs</span></em>, <em class="sig-param"><span class="n">packed_src</span></em>, <em class="sig-param"><span class="n">batch_size</span></em>, <em class="sig-param"><span class="n">atten_state_dim</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNNWithAttention.zero_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNNWithAttention.zero_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initial state of this layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>src_encs</strong> – A tensor of shape [source_seq_length, batch_size, source_dim].</p></li>
<li><p><strong>packed_src</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> containing packed source.</p></li>
<li><p><strong>batch_size</strong> – Batch size.</p></li>
<li><p><strong>atten_state_dim</strong> – Attention state dim when using zero_atten_state</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>state0 - A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> containing initial states of RNN and attention.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNNWithAttention.reset_atten_state">
<code class="sig-name descname">reset_atten_state</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">state</span></em>, <em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNNWithAttention.reset_atten_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNNWithAttention.reset_atten_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNNWithAttention.AccumulateStates">
<code class="sig-name descname">AccumulateStates</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">src_encs</span></em>, <em class="sig-param"><span class="n">src_paddings</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em>, <em class="sig-param"><span class="n">src_contexts</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">state0</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">src_segment_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">segment_id</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNNWithAttention.AccumulateStates"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNNWithAttention.AccumulateStates" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets up and runs the recurrence, returning the raw accumulated states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>src_encs</strong> – A tensor of shape [source_seq_length, batch_size, source_dim].</p></li>
<li><p><strong>src_paddings</strong> – A tensor of shape [source_seq_length, batch_size].</p></li>
<li><p><strong>inputs</strong> – A tensor of [time, batch, dims].</p></li>
<li><p><strong>paddings</strong> – A tensor of [time, batch, 1].</p></li>
<li><p><strong>src_contexts</strong> – [Optional] If specified, must be a tensor of shape
[source_seq_length, batch_size, some_dim]. When specified, this tensor
will be used as the source context vectors when computing attention
context, and src_ends will be only used to compute the attention score
for each context. If set to None, the ‘src_encs’ will be used as source
context.</p></li>
<li><p><strong>state0</strong> – [Optional] If not None, the initial rnn state and attention
context in a <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>. Defaults to the cell’s zero-state.</p></li>
<li><p><strong>src_segment_id</strong> – A tensor of shape [source_seq_length, batch_size] to
support masking with packed inputs.</p></li>
<li><p><strong>segment_id</strong> – A tensor of [time, batch, 1].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>accumulated_state: a NestedMap of accumulated states from recurrence.</p></li>
<li><p>final_state: final_state: The final recurrent state.</p></li>
<li><p>side_info: NestedMap of intermediate results needed for post-processing.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple of 3 NestedMaps</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNNWithAttention.PostProcessStates">
<code class="sig-name descname">PostProcessStates</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">acc_state</span></em>, <em class="sig-param"><span class="n">side_info</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNNWithAttention.PostProcessStates"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNNWithAttention.PostProcessStates" title="Permalink to this definition">¶</a></dt>
<dd><p>Post-process accumulated states to fulfill FProp’s interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acc_state</strong> – a NestedMap of the raw accumulated states from the recurrence.</p></li>
<li><p><strong>side_info</strong> – side-information collected by AccumulateStates.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A tuple (atten_context, rnn_output, atten_probs).</p>
<ul class="simple">
<li><p>atten_context: a tensor of [time, batch, attention.context_dim].</p></li>
<li><p>rnn_output: a tensor of [time, batch, rcell.num_output_nodes].</p></li>
<li><p>atten_probs: a tensor of [time, batch, source_seq_length].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.FRNNWithAttention.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">src_encs</span></em>, <em class="sig-param"><span class="n">src_paddings</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em>, <em class="sig-param"><span class="n">src_contexts</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">state0</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">src_segment_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">segment_id</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#FRNNWithAttention.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.FRNNWithAttention.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagate through a rnn layer with attention.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>src_encs</strong> – A tensor of shape [source_seq_length, batch_size, source_dim].</p></li>
<li><p><strong>src_paddings</strong> – A tensor of shape [source_seq_length, batch_size].</p></li>
<li><p><strong>inputs</strong> – A tensor of [time, batch, dims].</p></li>
<li><p><strong>paddings</strong> – A tensor of [time, batch, 1].</p></li>
<li><p><strong>src_contexts</strong> – [Optional] If specified, must be a tensor of shape
[source_seq_length, batch_size, some_dim]. When specified, this tensor
will be used as the source context vectors when computing attention
context, and src_ends will be only used to compute the attention score
for each context. If set to None, the ‘src_encs’ will be used as source
context.</p></li>
<li><p><strong>state0</strong> – [Optional] If not None, the initial rnn state and attention
context in a <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>. Defaults to the cell’s zero-state.</p></li>
<li><p><strong>src_segment_id</strong> – A tensor of shape [source_seq_length, batch_size] to
support masking with packed inputs.</p></li>
<li><p><strong>segment_id</strong> – A tensor of [time, batch, 1].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A tuple (atten_context, rnn_output, atten_probs, final_state).</p>
<ul class="simple">
<li><p>atten_context: a tensor of [time, batch, attention.context_dim].</p></li>
<li><p>rnn_output: a tensor of [time, batch, rcell.num_output_nodes].</p></li>
<li><p>atten_probs: a tensor of [time, batch, source_seq_length].</p></li>
<li><p>final_state: The final recurrent state.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.rnn_layers.MultiSourceFRNNWithAttention">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">MultiSourceFRNNWithAttention</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#MultiSourceFRNNWithAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.MultiSourceFRNNWithAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>RNN layer intertwined with an attention layer for multiple sources.</p>
<p>Allows different attention params per source, if attention is not shared.</p>
<dl class="py method">
<dt id="lingvo.core.rnn_layers.MultiSourceFRNNWithAttention.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#MultiSourceFRNNWithAttention.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.MultiSourceFRNNWithAttention.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Params for this MultiSourceFRNNWithAttention class.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.MultiSourceFRNNWithAttention.rnn_cell">
<em class="property">property </em><code class="sig-name descname">rnn_cell</code><a class="headerlink" href="#lingvo.core.rnn_layers.MultiSourceFRNNWithAttention.rnn_cell" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the RNN cell of this layer.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.MultiSourceFRNNWithAttention.attention">
<em class="property">property </em><code class="sig-name descname">attention</code><a class="headerlink" href="#lingvo.core.rnn_layers.MultiSourceFRNNWithAttention.attention" title="Permalink to this definition">¶</a></dt>
<dd><p>Reference to the attention layer(s) of this layer.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.MultiSourceFRNNWithAttention._CreateChildrenVariables">
<code class="sig-name descname">_CreateChildrenVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#MultiSourceFRNNWithAttention._CreateChildrenVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.MultiSourceFRNNWithAttention._CreateChildrenVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Create variables for child layers.</p>
<p>Should be rarely overridden, only in cases when control over the context of
children InstantiateVariables calls are needed. eg, if children variables
need to be created inside of a specific context manager.</p>
<p>There are a few cases of this in the codebase marked as for backwards
compability. This is only to ensure that variable scopes remain compatible
through the code migration. New layers should not copy that pattern, and
instead follow the standard pattern of self.CreateChild() in __init__() and
self.CreateVariable() in _CreateLayerVariables(). If you are okay with
breaking old checkpoints, you can go ahead and delete those functions.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.MultiSourceFRNNWithAttention.InitAttention">
<code class="sig-name descname">InitAttention</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">src_encs</span></em>, <em class="sig-param"><span class="n">src_paddings</span></em>, <em class="sig-param"><span class="n">batch_size</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#MultiSourceFRNNWithAttention.InitAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.MultiSourceFRNNWithAttention.InitAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes initial states for attention layer(s).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>src_encs</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing source encoding tensors,
each of shape [source_seq_length, batch_size, source_dim]. Children
names of the <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> is defined by source_names.</p></li>
<li><p><strong>src_paddings</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object contraining source padding tensors,
each of shape [source_seq_length, batch_size]. Children names of the
<a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> is defined by source_names.</p></li>
<li><p><strong>batch_size</strong> – Scalar Tensor of type int, for initial state shape.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>state0 - Initial attention-rnn state in a <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>. Zeros for the rnn
initial state, and merger output for attention initial state.</p>
<p>Transformed source vectors and transposed source vectors.</p>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.MultiSourceFRNNWithAttention.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">src_encs</span></em>, <em class="sig-param"><span class="n">src_paddings</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#MultiSourceFRNNWithAttention.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.MultiSourceFRNNWithAttention.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward propagate through a RNN layer with attention(s).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>src_encs</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing source encoding tensors, each
of shape [source_seq_length, batch_size, source_dim]. Children names of
the <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> is defined by source_names.</p></li>
<li><p><strong>src_paddings</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object contraining source padding tensors,
each of shape [source_seq_length, batch_size]. Children names of the
<a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> is defined by source_names.</p></li>
<li><p><strong>inputs</strong> – A tensor of [time, batch, dims].</p></li>
<li><p><strong>paddings</strong> – A tensor of [time, batch, 1].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A tuple (atten_context, rnn_output)</p>
<ul class="simple">
<li><p>atten_context: a tensor of [time, batch, attention.hidden_dim].</p></li>
<li><p>rnn_output: a tensor of [time, batch, p.cell.num_output_nodes].</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.7/library/exceptions.html#ValueError" title="(in Python v3.7)"><strong>ValueError</strong></a> – dtype mismatch of attention layers.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.rnn_layers.BidirectionalFRNNQuasi">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.rnn_layers.</code><code class="sig-name descname">BidirectionalFRNNQuasi</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalFRNNQuasi"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalFRNNQuasi" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_layer.html#lingvo.core.base_layer.BaseLayer" title="lingvo.core.base_layer.BaseLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_layer.BaseLayer</span></code></a></p>
<p>Bidirectional functional Quasi-RNN.</p>
<p>This is very similar to BidirectionalFRNN except the input is a list of the
forward and backward inputs. It is split because quasi-rnns do the
matrix/convolution unrolled over time outside of the recurrent part. Also,
this uses quasi-rnn instead of LSTM.</p>
<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalFRNNQuasi.Params">
<em class="property">classmethod </em><code class="sig-name descname">Params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalFRNNQuasi.Params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalFRNNQuasi.Params" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalFRNNQuasi._CreateChildrenVariables">
<code class="sig-name descname">_CreateChildrenVariables</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalFRNNQuasi._CreateChildrenVariables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalFRNNQuasi._CreateChildrenVariables" title="Permalink to this definition">¶</a></dt>
<dd><p>Create variables for child layers.</p>
<p>Should be rarely overridden, only in cases when control over the context of
children InstantiateVariables calls are needed. eg, if children variables
need to be created inside of a specific context manager.</p>
<p>There are a few cases of this in the codebase marked as for backwards
compability. This is only to ensure that variable scopes remain compatible
through the code migration. New layers should not copy that pattern, and
instead follow the standard pattern of self.CreateChild() in __init__() and
self.CreateVariable() in _CreateLayerVariables(). If you are okay with
breaking old checkpoints, you can go ahead and delete those functions.</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.rnn_layers.BidirectionalFRNNQuasi.FProp">
<code class="sig-name descname">FProp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">paddings</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/rnn_layers.html#BidirectionalFRNNQuasi.FProp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.rnn_layers.BidirectionalFRNNQuasi.FProp" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute bidi-quasi-RNN forward pass.</p>
<p>fwd_rnn unroll the sequence in the forward direction and
bak_rnn unroll the sequence in the backward direction. The
outputs are concatenated in the last output dim.</p>
<p>See <a class="reference internal" href="#lingvo.core.rnn_layers.FRNN.FProp" title="lingvo.core.rnn_layers.FRNN.FProp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FRNN.FProp</span></code></a> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>inputs</strong> – A list of the fwd and bak tensors. Each item in the list should be
A single tensor or a tuple of tensors with cardinality equal to
rnn_cell.inputs_arity. For every input tensor, the first dimension is
assumed to be time, second dimension batch, and third dimension depth.</p></li>
<li><p><strong>paddings</strong> – A tensor. First dim is time, second dim is batch, and third dim
is expected to be 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tensor of [time, batch, dims].</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="lingvo.core.saver.html" class="btn btn-neutral float-right" title="lingvo.core.saver module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="lingvo.core.rnn_cell.html" class="btn btn-neutral float-left" title="lingvo.core.rnn_cell module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2018.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>