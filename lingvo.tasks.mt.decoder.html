<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>lingvo.tasks.mt.decoder module &mdash; Lingvo  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="lingvo.tasks.mt.encoder module" href="lingvo.tasks.mt.encoder.html" />
    <link rel="prev" title="lingvo.tasks.mt.data_augmenter module" href="lingvo.tasks.mt.data_augmenter.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Lingvo
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="lingvo.html">lingvo package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="lingvo.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="lingvo.core.html">lingvo.core package</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="lingvo.tasks.html">lingvo.tasks package</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="lingvo.tasks.html#subpackages">Subpackages</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="lingvo.tools.html">lingvo.tools package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lingvo.html#submodules">Submodules</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Lingvo</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="lingvo.html">lingvo package</a> &raquo;</li>
          <li><a href="lingvo.tasks.html">lingvo.tasks package</a> &raquo;</li>
          <li><a href="lingvo.tasks.mt.html">lingvo.tasks.mt package</a> &raquo;</li>
      <li>lingvo.tasks.mt.decoder module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/lingvo.tasks.mt.decoder.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-lingvo.tasks.mt.decoder">
<span id="lingvo-tasks-mt-decoder-module"></span><h1>lingvo.tasks.mt.decoder module<a class="headerlink" href="#module-lingvo.tasks.mt.decoder" title="Permalink to this headline"></a></h1>
<p>Machine translation decoder.</p>
<dl class="py class">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTBaseDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lingvo.tasks.mt.decoder.</span></span><span class="sig-name descname"><span class="pre">MTBaseDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTBaseDecoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTBaseDecoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder" title="lingvo.core.base_decoder.BaseBeamSearchDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_decoder.BaseBeamSearchDecoder</span></code></a></p>
<p>Base class for Lingvo MT decoders.</p>
<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTBaseDecoder.Params">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTBaseDecoder.Params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTBaseDecoder.Params" title="Permalink to this definition"></a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTBaseDecoder.UpdateTargetVocabSize">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">UpdateTargetVocabSize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wpm_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTBaseDecoder.UpdateTargetVocabSize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTBaseDecoder.UpdateTargetVocabSize" title="Permalink to this definition"></a></dt>
<dd><p>Sets the params with the given vocab size and wpm model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> – model params.</p></li>
<li><p><strong>vocab_size</strong> – size of the vocabulary.</p></li>
<li><p><strong>wpm_model</strong> – file name prefix pointing to a wordpiece model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Model params updated with the vocab size and wpm model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTBaseDecoder._ComputeXentLoss">
<span class="sig-name descname"><span class="pre">_ComputeXentLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">softmax_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_segment_ids</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTBaseDecoder._ComputeXentLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTBaseDecoder._ComputeXentLoss" title="Permalink to this definition"></a></dt>
<dd><p>Computes cross-entropy loss given the softmax input, labels and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this
layer and its children layers.</p></li>
<li><p><strong>softmax_input</strong> – A tensor of shape [time, batch, p.softmax.input_dim].</p></li>
<li><p><strong>target_labels</strong> – A matrix of tf.int32. [time, batch].</p></li>
<li><p><strong>target_weights</strong> – A matrix of params.dtype. [time, batch].</p></li>
<li><p><strong>target_paddings</strong> – A matrix of params.dtype. [time, batch].</p></li>
<li><p><strong>target_segment_ids</strong> – A matrix of params.dtype. [time, batch].</p></li>
<li><p><strong>time_axis</strong> – If 0, the inputs are time-major: [time, batch, …]; if 1, the
inputs are batch-major: [batch, time, …].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The cross entropy loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTBaseDecoder._ComputeSoftmaxMetrics">
<span class="sig-name descname"><span class="pre">_ComputeSoftmaxMetrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">xent_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_segment_ids</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTBaseDecoder._ComputeSoftmaxMetrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTBaseDecoder._ComputeSoftmaxMetrics" title="Permalink to this definition"></a></dt>
<dd><p>Computes cross-entropy metrics given the cross-entropy loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xent_loss</strong> – The output of <a class="reference internal" href="#lingvo.tasks.mt.decoder.MTBaseDecoder._ComputeXentLoss" title="lingvo.tasks.mt.decoder.MTBaseDecoder._ComputeXentLoss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">_ComputeXentLoss</span></code></a>.</p></li>
<li><p><strong>target_labels</strong> – A matrix of tf.int32. [time, batch].</p></li>
<li><p><strong>target_weights</strong> – A matrix of params.dtype. [time, batch].</p></li>
<li><p><strong>target_segment_ids</strong> – A matrix of params.dtype. [time, batch].</p></li>
<li><p><strong>time_axis</strong> – If 0, the inputs are time-major: [time, batch, …]; if 1, the
inputs are batch-major: [batch, time, …].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple (metrics, per_example_tensors).</dt><dd><dl class="simple">
<dt>metrics:</dt><dd><p>A dictionary containing metrics for the xent loss and prediction
accuracy.</p>
</dd>
<dt>per_example_tensors:</dt><dd><p>A dictionary of per-example tensors.</p>
</dd>
</dl>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTBaseDecoder._FPropSoftmax">
<span class="sig-name descname"><span class="pre">_FPropSoftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">softmax_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_segment_ids</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTBaseDecoder._FPropSoftmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTBaseDecoder._FPropSoftmax" title="Permalink to this definition"></a></dt>
<dd><p>Computes cross-entropy loss given the softmax input, labels and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>softmax_input</strong> – A tensor of shape [time, batch, p.softmax.input_dim].</p></li>
<li><p><strong>target_labels</strong> – A matrix of tf.int32. [time, batch].</p></li>
<li><p><strong>target_weights</strong> – A matrix of params.dtype. [time, batch].</p></li>
<li><p><strong>target_paddings</strong> – A matrix of params.dtype. [time, batch].</p></li>
<li><p><strong>target_segment_ids</strong> – A matrix of params.dtype. [time, batch].</p></li>
<li><p><strong>time_axis</strong> – If 0, the inputs are time-major: [time, batch, …]; if 1, the
inputs are batch-major: [batch, time, …].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple (metrics, per_example_tensors).</dt><dd><dl class="simple">
<dt>metrics:</dt><dd><p>A dictionary containing metrics for the xent loss and prediction
accuracy.</p>
</dd>
<dt>per_example_tensors:</dt><dd><p>A dictionary of per-example tensors.</p>
</dd>
</dl>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTBaseDecoder.ComputeLoss">
<span class="sig-name descname"><span class="pre">ComputeLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTBaseDecoder.ComputeLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTBaseDecoder.ComputeLoss" title="Permalink to this definition"></a></dt>
<dd><p>Populates a metrics dictionary based on the output of ComputePredictions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – Nested map describing decoder model parameters.</p></li>
<li><p><strong>predictions</strong> – NestedMap describing the decoding process, requiring:
.softmax_input: Tensor of shape [time, batch, params.softmax.input_dim].</p></li>
<li><p><strong>targets</strong> – NestedMap describing the target sequences.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>Two dicts.</p>
<blockquote>
<div><ul class="simple">
<li><p>A map from metric name (a python string) to a tuple (value, weight).
Both value and weight are scalar Tensors.</p></li>
<li><p>A map from name to arbitrary tensors, where the first dimension must
be the batch index.</p></li>
</ul>
</div></blockquote>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTBaseDecoder._TruncateTargetSequence">
<span class="sig-name descname"><span class="pre">_TruncateTargetSequence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTBaseDecoder._TruncateTargetSequence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTBaseDecoder._TruncateTargetSequence" title="Permalink to this definition"></a></dt>
<dd><p>Truncate padded time steps from all sequences.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTBaseDecoder._AddAttenProbsSummary">
<span class="sig-name descname"><span class="pre">_AddAttenProbsSummary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source_paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atten_probs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTBaseDecoder._AddAttenProbsSummary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTBaseDecoder._AddAttenProbsSummary" title="Permalink to this definition"></a></dt>
<dd><p>Add summary of attention probs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source_paddings</strong> – source padding, of shape [src_len, src_batch].</p></li>
<li><p><strong>targets</strong> – A dict of string to tensors representing the targets one try to
predict. Each tensor in targets is of shape [tgt_batch, tgt_len].</p></li>
<li><p><strong>atten_probs</strong> – a list of attention probs, each element is of shape [tgt_len,
tgt_batch, src_len].</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTBaseDecoder._AddAttenProbsHistogramSummary">
<span class="sig-name descname"><span class="pre">_AddAttenProbsHistogramSummary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">atten_probs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTBaseDecoder._AddAttenProbsHistogramSummary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTBaseDecoder._AddAttenProbsHistogramSummary" title="Permalink to this definition"></a></dt>
<dd><p>Add histogram summary of attention probs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>atten_probs</strong> – a list of attention probs, each element is of shape [tgt_len,
tgt_batch, src_len].</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTBaseDecoder._AddAttenProbsImageSummary">
<span class="sig-name descname"><span class="pre">_AddAttenProbsImageSummary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source_paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atten_probs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTBaseDecoder._AddAttenProbsImageSummary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTBaseDecoder._AddAttenProbsImageSummary" title="Permalink to this definition"></a></dt>
<dd><p>Add image summary of attention probs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source_paddings</strong> – source padding, of shape [src_len, src_batch].</p></li>
<li><p><strong>targets</strong> – A dict of string to tensors representing the targets one try to
predict. Each tensor in targets is of shape [tgt_batch, tgt_len].</p></li>
<li><p><strong>atten_probs</strong> – a list of attention probs, each element is of shape [tgt_len,
tgt_batch, src_len].</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTBaseDecoder._ExpandToNumHyps">
<span class="sig-name descname"><span class="pre">_ExpandToNumHyps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source_enc_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hyps_per_beam</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTBaseDecoder._ExpandToNumHyps"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTBaseDecoder._ExpandToNumHyps" title="Permalink to this definition"></a></dt>
<dd><p>Repeat each value according to num hyps.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source_enc_len</strong> – source encoder length; int [batch].</p></li>
<li><p><strong>num_hyps_per_beam</strong> – number of hypotheses</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>New version of source_enc_len; int [batch * num_hyps_per_beam].
Target_batch is (num_hyps_per_beam * batch).
Example: src_enc_len = [3, 2, 1] and num_hyps_per_beam = 2
–&gt; [3, 2, 1, 3, 2, 1]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lingvo.tasks.mt.decoder.</span></span><span class="sig-name descname"><span class="pre">MTDecoderV1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.tasks.mt.decoder.MTBaseDecoder" title="lingvo.tasks.mt.decoder.MTBaseDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.tasks.mt.decoder.MTBaseDecoder</span></code></a>, <a class="reference internal" href="lingvo.core.quant_utils.html#lingvo.core.quant_utils.QuantizableLayer" title="lingvo.core.quant_utils.QuantizableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.quant_utils.QuantizableLayer</span></code></a></p>
<p>MT decoder v1.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._FLOAT_DTYPE_MAX_SCALER">
<span class="sig-name descname"><span class="pre">_FLOAT_DTYPE_MAX_SCALER</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1e-05</span></em><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._FLOAT_DTYPE_MAX_SCALER" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1.Params">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1.Params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1.Params" title="Permalink to this definition"></a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1.UpdateTargetVocabSize">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">UpdateTargetVocabSize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wpm_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1.UpdateTargetVocabSize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1.UpdateTargetVocabSize" title="Permalink to this definition"></a></dt>
<dd><p>Updates the params with the input vocab_size and WPM model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> – model params.</p></li>
<li><p><strong>vocab_size</strong> – size of the vocabulary.</p></li>
<li><p><strong>wpm_model</strong> – file name prefix pointing to a wordpiece model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Model params updated with the vocab size and wpm model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._CreateProjection">
<span class="sig-name descname"><span class="pre">_CreateProjection</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">proj_tpl</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1._CreateProjection"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._CreateProjection" title="Permalink to this definition"></a></dt>
<dd><p>Creates a projection layer(projects from <code class="xref py py-obj docutils literal notranslate"><span class="pre">input_dim</span></code> to <code class="xref py py-obj docutils literal notranslate"><span class="pre">output_dim</span></code>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._child_variable_scope_override">
<span class="sig-name descname"><span class="pre">_child_variable_scope_override</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1._child_variable_scope_override"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._child_variable_scope_override" title="Permalink to this definition"></a></dt>
<dd><p>Override the variable scope for individual children.</p>
<p>Should only be overridden for backwards compatibility with old checkpoints.</p>
<p>By default, all children will be created in tf.variable_scope(p.name) of
this layer. This can be overridden by providing a list of variable scopes
keyed by a child name.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dict mapping child names to a list of variable scopes to apply.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1.ApplyDropout">
<span class="sig-name descname"><span class="pre">ApplyDropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_in</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1.ApplyDropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1.ApplyDropout" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1.ApplyClipping">
<span class="sig-name descname"><span class="pre">ApplyClipping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1.ApplyClipping"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1.ApplyClipping" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._ZeroOutFirstTimeStep">
<span class="sig-name descname"><span class="pre">_ZeroOutFirstTimeStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">token_embs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1._ZeroOutFirstTimeStep"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._ZeroOutFirstTimeStep" title="Permalink to this definition"></a></dt>
<dd><p>Zeroes out the first time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>token_embs</strong> – [time, batch, model_dim] embeding lookups.</p></li>
<li><p><strong>batch</strong> – Batch size scalar.</p></li>
<li><p><strong>time</strong> – Target sequence length scalar.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>modified token_embs with the first time step zeroed out.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1.ComputePredictions">
<span class="sig-name descname"><span class="pre">ComputePredictions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1.ComputePredictions" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1.AddExtraDecodingInfo">
<span class="sig-name descname"><span class="pre">AddExtraDecodingInfo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1.AddExtraDecodingInfo"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1.AddExtraDecodingInfo" title="Permalink to this definition"></a></dt>
<dd><p>Adds extra decoding information to encoded_outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_outputs</strong> – a NestedMap computed by encoder.</p></li>
<li><p><strong>targets</strong> – a NestedMap containing target input fields.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>encoder_ouputs with extra information used for decoding.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._InitDecoder">
<span class="sig-name descname"><span class="pre">_InitDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._InitDecoder" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._DecodeStep">
<span class="sig-name descname"><span class="pre">_DecodeStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._DecodeStep" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._GetAttentionInitState">
<span class="sig-name descname"><span class="pre">_GetAttentionInitState</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1._GetAttentionInitState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._GetAttentionInitState" title="Permalink to this definition"></a></dt>
<dd><p>Gets the attention initialization state.</p>
<p>It is valid to call this after <code class="xref py py-obj docutils literal notranslate"><span class="pre">_DecoderInit()</span></code>. Inference subclasses use
this to split computation across subgraph boundaries.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of attention source states.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._SetAttentionInitState">
<span class="sig-name descname"><span class="pre">_SetAttentionInitState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_init_state</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1._SetAttentionInitState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._SetAttentionInitState" title="Permalink to this definition"></a></dt>
<dd><p>Sets the attention initialization state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>new_init_state</strong> – <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> compatible with that returned from
<code class="xref py py-obj docutils literal notranslate"><span class="pre">_GetAttentionSourceState</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._InitBeamSearchStateCallback">
<span class="sig-name descname"><span class="pre">_InitBeamSearchStateCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hyps_per_beam</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1._InitBeamSearchStateCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._InitBeamSearchStateCallback" title="Permalink to this definition"></a></dt>
<dd><p>Returns initial beams search states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – a NestedMap of parameters.</p></li>
<li><p><strong>encoder_outputs</strong> – a NestedMap computed by encoder.</p></li>
<li><p><strong>num_hyps_per_beam</strong> – An int, number hyps to keep for source sentence.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple (initial_results, states).</dt><dd><dl class="simple">
<dt>initial_results: a <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of initial results.</dt><dd><dl class="simple">
<dt>atten_probs:</dt><dd><p>The initial attention probs, of shape [tgt_batch, src_len].</p>
</dd>
</dl>
</dd>
<dt>states: a <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of initial model states.</dt><dd><dl class="simple">
<dt>rnn_states:</dt><dd><p>Initial state of the RNN.</p>
</dd>
<dt>atten_context:</dt><dd><p>Initial attention context vector.</p>
</dd>
<dt>atten_states:</dt><dd><p>Initial attention state.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._PreBeamSearchStepCallback">
<span class="sig-name descname"><span class="pre">_PreBeamSearchStepCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._PreBeamSearchStepCallback" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._PostBeamSearchStepCallback">
<span class="sig-name descname"><span class="pre">_PostBeamSearchStepCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_step_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">states</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1._PostBeamSearchStepCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._PostBeamSearchStepCallback" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._ForceAlignment">
<span class="sig-name descname"><span class="pre">_ForceAlignment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_probs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source_num_sentences</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hyp_num_sentences</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1._ForceAlignment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._ForceAlignment" title="Permalink to this definition"></a></dt>
<dd><p>Update ‘log_probs’ to for alignment.</p>
<p>We adjust ‘log_probs’ to disallow p.sentence_boundary_token_id or EOS if
emitting it would result in a misaligned output with an unequal number
of sentences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_probs</strong> – encoder’s log_probs output.</p></li>
<li><p><strong>source_num_sentences</strong> – shape [beam_size * num_hyps_per_beam], int32. The
number of sentences in source.</p></li>
<li><p><strong>hyp_num_sentences</strong> – shape [beam_size * num_hyps_per_beam], int32. The
number of sentences in hyp.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The adjusted log_probs (score used for beam search) which ensures
aligned output in terms of number of sentences.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.MTDecoderV1._UpdateLogitsForSingleTokenFastDecode">
<span class="sig-name descname"><span class="pre">_UpdateLogitsForSingleTokenFastDecode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_probs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_single_token</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hyps_per_beam</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#MTDecoderV1._UpdateLogitsForSingleTokenFastDecode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.MTDecoderV1._UpdateLogitsForSingleTokenFastDecode" title="Permalink to this definition"></a></dt>
<dd><p>Update ‘log_probs’ to enable fast decode for single token inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_probs</strong> – encoder’s log_probs output, shape [tgt_batch, vocab_size].</p></li>
<li><p><strong>is_single_token</strong> – [src_batch], whether the input contains only a single
token.</p></li>
<li><p><strong>num_hyps_per_beam</strong> – int, num_hyps_per_beam * src_batch = tgt_batch.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The updated log_probs (score used for beam search) which ensures
fast decoding when input has a single token.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lingvo.tasks.mt.decoder.</span></span><span class="sig-name descname"><span class="pre">TransformerDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.tasks.mt.decoder.MTBaseDecoder" title="lingvo.tasks.mt.decoder.MTBaseDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.tasks.mt.decoder.MTBaseDecoder</span></code></a></p>
<p>Transformer decoder.</p>
<p>Implements the decoder of Transformer model:
<a class="reference external" href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder.Params">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder.Params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder.Params" title="Permalink to this definition"></a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder._child_variable_scope_override">
<span class="sig-name descname"><span class="pre">_child_variable_scope_override</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder._child_variable_scope_override"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder._child_variable_scope_override" title="Permalink to this definition"></a></dt>
<dd><p>Override the variable scope for individual children.</p>
<p>Should only be overridden for backwards compatibility with old checkpoints.</p>
<p>By default, all children will be created in tf.variable_scope(p.name) of
this layer. This can be overridden by providing a list of variable scopes
keyed by a child name.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dict mapping child names to a list of variable scopes to apply.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder._RemoveEOSProbs">
<span class="sig-name descname"><span class="pre">_RemoveEOSProbs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source_enc_len</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder._RemoveEOSProbs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder._RemoveEOSProbs" title="Permalink to this definition"></a></dt>
<dd><p>Remove the attention probs on EOS symbol and renormalize.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> – decoder params.</p></li>
<li><p><strong>probs</strong> – attention probs matrix; float [batch, target_len, source_len].</p></li>
<li><p><strong>source_enc_len</strong> – source encoder length; int [batch].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>probs with value on last actual token (EOS token) replaced by 0 and
renormalized so that final dim (src_len) sums to 1 again; float
[batch, target_len, source_len].</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder._ZeroOutFirstTimeStep">
<span class="sig-name descname"><span class="pre">_ZeroOutFirstTimeStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">token_embs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_time</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder._ZeroOutFirstTimeStep"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder._ZeroOutFirstTimeStep" title="Permalink to this definition"></a></dt>
<dd><p>Zeroes out the first time step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>token_embs</strong> – [batch, time, model_dim] embeding lookups</p></li>
<li><p><strong>batch</strong> – Batch size scalar</p></li>
<li><p><strong>target_time</strong> – Target sequence length scalar.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>modified token_embs with the first time step zeroed out.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder._FProp">
<span class="sig-name descname"><span class="pre">_FProp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder._FProp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder._FProp" title="Permalink to this definition"></a></dt>
<dd><p>Decodes <code class="xref py py-obj docutils literal notranslate"><span class="pre">targets</span></code> given encoded source.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – a NestedMap computed by encoder. Expected to contain:
encoded - source encoding. When <code class="xref py py-obj docutils literal notranslate"><span class="pre">p.is_transparent</span></code> is False, it is a
tensor of shape [time, batch, depth]. When <code class="xref py py-obj docutils literal notranslate"><span class="pre">p.is_transparent</span></code> is True,
it is a tensor of shape [time, batch, depth, num_trans_layers] if
<code class="xref py py-obj docutils literal notranslate"><span class="pre">self.do_eval</span></code> is True, and a list of <code class="xref py py-obj docutils literal notranslate"><span class="pre">num_trans_layers</span></code> tensors of
shape [time, batch, depth] if <code class="xref py py-obj docutils literal notranslate"><span class="pre">self.do_eval</span></code> is False.  padding - source
encoding’s padding, of shape [time, batch]. segment_id - source segment
id, of shape [time, batch].</p></li>
<li><p><strong>targets</strong> – A dict of string to tensors representing the targets one try to
predict. Each tensor in targets is of shape [batch, time].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> containing output of last decoder layer and attention probs</p>
<ul class="simple">
<li><p>softmax_input: Tensor of shape [time, batch, params.softmax.input_dim].</p></li>
<li><p>attention: <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of attention distributions of shape
[batch, target_length, source_length].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder.AddExtraDecodingInfo">
<span class="sig-name descname"><span class="pre">AddExtraDecodingInfo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder.AddExtraDecodingInfo"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder.AddExtraDecodingInfo" title="Permalink to this definition"></a></dt>
<dd><p>Adds extra decoding information to encoded_outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_outputs</strong> – a NestedMap computed by encoder.</p></li>
<li><p><strong>targets</strong> – a NestedMap containing target input fields.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>encoder_ouputs with extra information used for decoding.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder.ExtendStep">
<span class="sig-name descname"><span class="pre">ExtendStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_states</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder.ExtendStep"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder.ExtendStep" title="Permalink to this definition"></a></dt>
<dd><p>Extend prefix as represented by <code class="xref py py-obj docutils literal notranslate"><span class="pre">prefix_states</span></code> by one more step.</p>
<p>This function is expected to be called during fast decoding of Transformer
models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – <p>a NestedMap computed by encoder, containing:</p>
<ul>
<li><p>encoded: source encoding, of shape [time, batch, depth]. Can be [time,
bs, depth, num_trans_layers] if is_transparent is set.</p></li>
<li><p>padding: source encoding’s padding, of shape [time, batch].</p></li>
</ul>
</p></li>
<li><p><strong>new_ids</strong> – new input ids, of shape [batch].</p></li>
<li><p><strong>t</strong> – a scalar, the current time step, 0-based.</p></li>
<li><p><strong>prefix_states</strong> – a <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> representing the prefix that has already
been decoded.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple (last_decoder_out, prefix_states, atten_probs), where
last_decoder_out is the output of the last decoder layer of
shape [batch, model_dim], <code class="xref py py-obj docutils literal notranslate"><span class="pre">prefix_states</span></code> is the update prefix states,
and atten_probs contains attention in shape [batch, src_len] for the
given target position.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder.ComputePredictions">
<span class="sig-name descname"><span class="pre">ComputePredictions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder.ComputePredictions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder.ComputePredictions" title="Permalink to this definition"></a></dt>
<dd><p>Decodes <code class="xref py py-obj docutils literal notranslate"><span class="pre">targets</span></code> given encoded source.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – <p>a NestedMap computed by encoder. Expected to contain:</p>
<dl class="simple">
<dt>encoded - source encoding, of shape [time, batch, depth]. Can be [time,</dt><dd><p>batch, depth, num_layers] if is_transparent is set.</p>
</dd>
</dl>
<p>padding - source encoding’s padding, of shape [time, batch].
segment_id - source segment id, of shape [time, batch].</p>
</p></li>
<li><p><strong>targets</strong> – A dict of string to tensors representing the targets one try to
predict. Each tensor in targets is of shape [batch, time].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> containing output of last decoder layer and attention probs</p>
<ul class="simple">
<li><p>softmax_input: Tensor of shape [time, batch, params.softmax.input_dim].</p></li>
<li><p>attention: <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of attention distributions of shape
[batch, time, source_len].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder.SampleSequenceDecode">
<span class="sig-name descname"><span class="pre">SampleSequenceDecode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder.SampleSequenceDecode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder.SampleSequenceDecode" title="Permalink to this definition"></a></dt>
<dd><p>Decode via sampling from softmax at each step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>encoder_outputs</strong> – the outputs of the encoder.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>BeamSearchDecodeOutput, same as what BeamSearchDecode returns.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder._InitBeamSearchStateCallback">
<span class="sig-name descname"><span class="pre">_InitBeamSearchStateCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hyps_per_beam</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder._InitBeamSearchStateCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder._InitBeamSearchStateCallback" title="Permalink to this definition"></a></dt>
<dd><p>Returns initial beams search states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – a NestedMap computed by encoder.</p></li>
<li><p><strong>num_hyps_per_beam</strong> – An int, number hyps to keep for source sentence.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple (initial_results, states).</dt><dd><dl class="simple">
<dt>initial_results: a <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of initial results.</dt><dd><dl class="simple">
<dt>atten_probs:</dt><dd><p>The initial attention probs, of shape [tgt_batch, src_len].</p>
</dd>
</dl>
</dd>
<dt>states: a <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of initial model states.</dt><dd><dl class="simple">
<dt>source_encs:</dt><dd><p>A tensor of shape [src_batch, src_len, source_dim].</p>
</dd>
<dt>source_paddings:</dt><dd><p>A tensor of shape [src_batch, src_len].</p>
</dd>
<dt>target_ids:</dt><dd><p>Initial empty list of decoded ids. [num_hyps, 0].</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder._PreBeamSearchStepCallback">
<span class="sig-name descname"><span class="pre">_PreBeamSearchStepCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hyps_per_beam</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder._PreBeamSearchStepCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder._PreBeamSearchStepCallback" title="Permalink to this definition"></a></dt>
<dd><p>Returns logits for sampling ids and the next model states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – a NestedMap computed by encoder.</p></li>
<li><p><strong>step_ids</strong> – A tensor of shape [tgt_batch, 1].</p></li>
<li><p><strong>states</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors representing states that the clients
would like to keep track of for each of the active hyps.</p></li>
<li><p><strong>num_hyps_per_beam</strong> – Beam size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple (results, out_states).</dt><dd><dl class="simple">
<dt>results: A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of beam search results.</dt><dd><dl class="simple">
<dt>atten_probs:</dt><dd><p>The updated attention probs, of shape [tgt_batch, src_len].</p>
</dd>
<dt>log_probs:</dt><dd><p>Log prob for each of the tokens in the target vocab. This is of
shape [tgt_batch, vocab_size].</p>
</dd>
</dl>
</dd>
<dt>out_states: A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>. The updated states.</dt><dd><dl class="simple">
<dt>source_encs:</dt><dd><p>A tensor of shape [src_batch, src_len, source_dim].</p>
</dd>
<dt>source_paddings:</dt><dd><p>A tensor of shape [src_batch, src_len].</p>
</dd>
<dt>target_ids:</dt><dd><p>Updated list of decoded ids. [num_hyps, Num of decoded ids].</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder._PostBeamSearchStepCallback">
<span class="sig-name descname"><span class="pre">_PostBeamSearchStepCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_step_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">states</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder._PostBeamSearchStepCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder._PostBeamSearchStepCallback" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder._AddAttenProbsScalarSummary">
<span class="sig-name descname"><span class="pre">_AddAttenProbsScalarSummary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source_paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atten_probs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder._AddAttenProbsScalarSummary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder._AddAttenProbsScalarSummary" title="Permalink to this definition"></a></dt>
<dd><p>Add scalar summary of multi-headed transformer attention probs.</p>
<p>This summary is primarily used to show statistics of the multi-headed
attention that reveals potential sparsity related properties. The
multi-headed attention probability tensors are exposed by
<code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiHeadedAttention.ComputeContextVectorWithSource</span></code> with the name
<code class="xref py py-obj docutils literal notranslate"><span class="pre">multi_headed_atten_prob</span></code>. The following statistics are summarized:</p>
<ul class="simple">
<li><p>1_v_2: margin of the largest value vs. the 2nd largest</p></li>
<li><p>1_v_3: similar, but vs the 3rd largest</p></li>
<li><dl class="simple">
<dt>mean: mean of the attention probs. NOTE: the sequences in a mini-batch</dt><dd><p>are not always of the same length. The attention probability for the
padded time index in target sequences are removed. However, the padding
for the source sequences are left unchanged. As a result, the atten
probs vectors will have some extra zero entries, so the mean calculated
here will be smaller than the true mean.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>source_padding_ratio: as explained above, the source paddings are not</dt><dd><p>handled when computing the mean. This summary show the average ratio
of time-steps that are padded values in the source sequences, to give
a reference of roughly how much the mean summarized above should be
adjusted.</p>
</dd>
</dl>
</li>
<li><p>1_v_mean: margin of the largest value vs the mean value.</p></li>
<li><dl class="simple">
<dt>sum: the sum of the attention prob vectors. Should always be 1, for sanity</dt><dd><p>check only.</p>
</dd>
</dl>
</li>
</ul>
<p>The quantity above are computed for each sequence in the mini-batch, each
valid (target) sequence index, and each attention head, and then the
average value is reported to the tensorboard as a scalar summary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source_paddings</strong> – source padding, of shape [src_len, src_batch].</p></li>
<li><p><strong>targets</strong> – A dict of string to tensors representing the targets one try to
predict. Each tensor in targets is of shape [tgt_batch, tgt_len].</p></li>
<li><p><strong>atten_probs</strong> – a list of attention probs, each element is of shape [tgt_len,
tgt_batch, src_len].</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerDecoder._AddAttenProbsSummary">
<span class="sig-name descname"><span class="pre">_AddAttenProbsSummary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source_paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">atten_probs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerDecoder._AddAttenProbsSummary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerDecoder._AddAttenProbsSummary" title="Permalink to this definition"></a></dt>
<dd><p>Add summary of attention probs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source_paddings</strong> – source padding, of shape [src_len, src_batch].</p></li>
<li><p><strong>targets</strong> – A dict of string to tensors representing the targets one try to
predict. Each tensor in targets is of shape [tgt_batch, tgt_len].</p></li>
<li><p><strong>atten_probs</strong> – a list of attention probs, each element is of shape [tgt_len,
tgt_batch, src_len].</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.InsertionDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lingvo.tasks.mt.decoder.</span></span><span class="sig-name descname"><span class="pre">InsertionDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#InsertionDecoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.InsertionDecoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="lingvo.core.base_decoder.html#lingvo.core.base_decoder.BaseBeamSearchDecoder" title="lingvo.core.base_decoder.BaseBeamSearchDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.core.base_decoder.BaseBeamSearchDecoder</span></code></a></p>
<p>Basic Insertion decoder for MT (or any symbol based sequence).</p>
<p class="rubric">References</p>
<p>KERMIT: <a class="reference external" href="https://arxiv.org/pdf/1906.01604.pdf">https://arxiv.org/pdf/1906.01604.pdf</a>
Insertion Transformer: <a class="reference external" href="https://arxiv.org/pdf/1902.03249.pdf">https://arxiv.org/pdf/1902.03249.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.InsertionDecoder.Params">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#InsertionDecoder.Params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.InsertionDecoder.Params" title="Permalink to this definition"></a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.InsertionDecoder.UpdateTargetVocabSize">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">UpdateTargetVocabSize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wpm_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#InsertionDecoder.UpdateTargetVocabSize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.InsertionDecoder.UpdateTargetVocabSize" title="Permalink to this definition"></a></dt>
<dd><p>Sets the vocab size in the params.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> – model params.</p></li>
<li><p><strong>vocab_size</strong> – size of the vocabulary.</p></li>
<li><p><strong>wpm_model</strong> – file name prefix pointing to a wordpiece model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Model params updated with the vocab size and wpm model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.InsertionDecoder.ComputePredictions">
<span class="sig-name descname"><span class="pre">ComputePredictions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#InsertionDecoder.ComputePredictions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.InsertionDecoder.ComputePredictions" title="Permalink to this definition"></a></dt>
<dd><p>Compute 1-step of the insertion iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – This should be None.</p></li>
<li><p><strong>targets</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>.
- ids: The target ids of shape [batch_size, time_dim].
- paddings: The target paddings of shape [batch_size, time_dim].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>.</dt><dd><ul class="simple">
<li><p>outputs: The contextualized output vectors of shape
[batch_size, time_dim, model_dim].</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.InsertionDecoder.ComputeLoss">
<span class="sig-name descname"><span class="pre">ComputeLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#InsertionDecoder.ComputeLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.InsertionDecoder.ComputeLoss" title="Permalink to this definition"></a></dt>
<dd><p>Returns the insertion loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object capturing decoder model parameters.</p></li>
<li><p><strong>predictions</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> describing the decoding process, requiring
.outputs: Tensor of shape [time, batch, params.softmax.input_dim].</p></li>
<li><p><strong>targets</strong> – <p>A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>.</p>
<ul>
<li><p>target_indices: A Tensor capturing the relevant insertion tokens to
tf.gather_nd the log-probs.</p></li>
<li><p>target_weights: A Tensor capturing the relevant insertion tokens’
weights.</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Two dicts.</dt><dd><ul class="simple">
<li><p>A map from metric name (a python string) to a tuple (value, weight).
Both value and weight are scalar Tensors.</p></li>
<li><p>A map from name to arbitrary tensors, where the first dimension must
be the batch index.</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lingvo.tasks.mt.decoder.</span></span><span class="sig-name descname"><span class="pre">TransformerBatchMajorDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.tasks.mt.decoder.MTBaseDecoder" title="lingvo.tasks.mt.decoder.MTBaseDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.tasks.mt.decoder.MTBaseDecoder</span></code></a></p>
<p>Transformer decoder with batch major implementation.</p>
<p>Implements the decoder of Transformer model:
<a class="reference external" href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder.Params">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder.Params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder.Params" title="Permalink to this definition"></a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._child_variable_scope_override">
<span class="sig-name descname"><span class="pre">_child_variable_scope_override</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder._child_variable_scope_override"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._child_variable_scope_override" title="Permalink to this definition"></a></dt>
<dd><p>Override the variable scope for individual children.</p>
<p>Should only be overridden for backwards compatibility with old checkpoints.</p>
<p>By default, all children will be created in tf.variable_scope(p.name) of
this layer. This can be overridden by providing a list of variable scopes
keyed by a child name.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dict mapping child names to a list of variable scopes to apply.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._MaybeTransposeEncoderOutputs">
<span class="sig-name descname"><span class="pre">_MaybeTransposeEncoderOutputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_data_format</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder._MaybeTransposeEncoderOutputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._MaybeTransposeEncoderOutputs" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._MaybeTransposeTargets">
<span class="sig-name descname"><span class="pre">_MaybeTransposeTargets</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder._MaybeTransposeTargets"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._MaybeTransposeTargets" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._FProp">
<span class="sig-name descname"><span class="pre">_FProp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder._FProp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._FProp" title="Permalink to this definition"></a></dt>
<dd><p>Decodes <code class="xref py py-obj docutils literal notranslate"><span class="pre">targets</span></code> given encoded source.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – A ‘.NestedMap’ object computed by encoder. * encoded -
Source encoding of shape [source_time, source_batch, dim] or
[source_batch, source_time, dim], depending on p.input_data_format. *
paddings - Source encoding’s padding of shape [source_time,
source_batch] or [source_batch, source_time].</p></li>
<li><p><strong>targets</strong> – A dict of string to tensors representing the targets one try to
predict. Each tensor in targets is of shape [batch, target_time].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor of shape [target_time, batch, dim].</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>softmax_input</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder.ExtendStep">
<span class="sig-name descname"><span class="pre">ExtendStep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_step</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_short_seq_opt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder.ExtendStep"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder.ExtendStep" title="Permalink to this definition"></a></dt>
<dd><p>Extend prefix as represented by <code class="xref py py-obj docutils literal notranslate"><span class="pre">prefix_states</span></code> by one more step.</p>
<p>This function is expected to be called during fast decoding of Transformer
models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – <p>A ‘.NestedMap’ object computed by encoder.</p>
<ul>
<li><p>encoded: Source encoding of shape [source_time, source_batch, dim] or
[source_batch, source_time, dim], depending on p.input_data_format.</p></li>
<li><p>paddings: Source encoding’s padding of shape
[source_time, source_batch] or [source_batch, source_time].</p></li>
</ul>
</p></li>
<li><p><strong>new_ids</strong> – New input ids, of shape [target_batch, 1].</p></li>
<li><p><strong>time_step</strong> – A scalar, the current decode step, 0-based.</p></li>
<li><p><strong>prefix_states</strong> – <p>A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> representing the previous decoded states.</p>
<ul>
<li><p>key: [target_time, target_batch, num_heads, dim_per_head].</p></li>
<li><p>value: [target_time, target_batch, num_heads, dim_per_head].</p></li>
</ul>
</p></li>
<li><p><strong>use_short_seq_opt</strong> – A bool, whether using short sequence optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>The last decoder layer of shape [target_batch, dim].
updated_prefix_states: A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> representing the updated states.</p>
<blockquote>
<div><ul class="simple">
<li><p>key: [target_time, target_batch, num_heads, dim_per_head].</p></li>
<li><p>value: [target_time, target_batch, num_heads, dim_per_head].</p></li>
</ul>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>last_decoder_out</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder.ComputePredictions">
<span class="sig-name descname"><span class="pre">ComputePredictions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder.ComputePredictions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder.ComputePredictions" title="Permalink to this definition"></a></dt>
<dd><p>Decodes <code class="xref py py-obj docutils literal notranslate"><span class="pre">targets</span></code> given encoded source.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – <p>A ‘.NestedMap’ object computed by encoder.</p>
<ul>
<li><p>encoded: Source encoding of shape [source_time, source_batch, dim] or
[source_batch, source_time, dim], depending on p.input_data_format.</p></li>
<li><p>paddings: Source encoding’s padding of shape
[source_time, source_batch] or [source_batch, source_time].</p></li>
</ul>
</p></li>
<li><p><strong>targets</strong> – A dict of string to tensors representing the targets one try to
predict. Each tensor in targets is of shape [batch, target_time].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Output of the last decoder layer, of shape [target_time, batch, dim].</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._FPropFastSoftmax">
<span class="sig-name descname"><span class="pre">_FPropFastSoftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">softmax_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder._FPropFastSoftmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._FPropFastSoftmax" title="Permalink to this definition"></a></dt>
<dd><p>Computes cross-entropy loss with label smoothing.</p>
<p>As compared to the _FPropSoftmax, this version is faster by removing the
data formatting overheads and bias of the linear projection. A normalizing
factor is also added to the xentropy result be better model quality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>softmax_input</strong> – A tensor of shape [time, batch, p.softmax.input_dim].</p></li>
<li><p><strong>target_labels</strong> – A matrix of tf.int32. [time, batch].</p></li>
<li><p><strong>target_weights</strong> – A matrix of params.dtype. [time, batch].</p></li>
<li><p><strong>time_axis</strong> – If 0, the inputs are time-major: [time, batch, …]; if 1, the
inputs are batch-major: [batch, time, …].</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple (metrics, per_example_tensors).</dt><dd><dl class="simple">
<dt>metrics:</dt><dd><p>A dictionary containing metrics for the xent loss and prediction
accuracy.</p>
</dd>
<dt>per_example_tensors:</dt><dd><p>A dictionary of per-example tensors.</p>
</dd>
</dl>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder.ComputeLoss">
<span class="sig-name descname"><span class="pre">ComputeLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder.ComputeLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder.ComputeLoss" title="Permalink to this definition"></a></dt>
<dd><p>Populates a metrics dictionary based on the output of ComputePredictions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – Nested map describing decoder model parameters.</p></li>
<li><p><strong>predictions</strong> – NestedMap describing the decoding process, requiring:
.softmax_input: Tensor of shape [time, batch, params.softmax.input_dim].</p></li>
<li><p><strong>targets</strong> – NestedMap describing the target sequences.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>Two dicts.</p>
<blockquote>
<div><ul class="simple">
<li><p>A map from metric name (a python string) to a tuple (value, weight).
Both value and weight are scalar Tensors.</p></li>
<li><p>A map from name to arbitrary tensors, where the first dimension must
be the batch index.</p></li>
</ul>
</div></blockquote>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._InitBeamSearchStateCallback">
<span class="sig-name descname"><span class="pre">_InitBeamSearchStateCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hyps_per_beam</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder._InitBeamSearchStateCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._InitBeamSearchStateCallback" title="Permalink to this definition"></a></dt>
<dd><p>Returns initial beams search states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – A ‘.NestedMap’ object computed by encoder. * encoded -
Source encoding of shape [source_time, source_batch, dim] or
[source_batch, source_time, dim], depending on p.input_data_format. *
paddings - Source encoding’s padding of shape [source_time,
source_batch] or [source_batch, source_time].</p></li>
<li><p><strong>num_hyps_per_beam</strong> – An int, number hyps to keep for source sentence.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of initial beam search results.</dt><dd><dl class="simple">
<dt>log_probs - Log prob for each of the tokens in the target vocab,</dt><dd><p>of shape [target_batch, vocab_size].</p>
</dd>
<dt>atten_probs - The updated attention probs, of shape</dt><dd><p>[target_batch, source_time].</p>
</dd>
</dl>
</dd>
<dt>states: A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of initial model states.</dt><dd><p>prefix_states - A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> representing the empty decoded states.
key   - [target_time, target_batch, num_heads, dim_per_head].
value - [target_time, target_batch, num_heads, dim_per_head].
time_step - A scalar, the initial decode step (0).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>initial_results</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._PreBeamSearchStepCallback">
<span class="sig-name descname"><span class="pre">_PreBeamSearchStepCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hyps_per_beam</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_short_seq_opt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder._PreBeamSearchStepCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._PreBeamSearchStepCallback" title="Permalink to this definition"></a></dt>
<dd><p>Returns logits for sampling ids and the next model states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – <p>A ‘.NestedMap’ object computed by encoder.</p>
<ul>
<li><p>encoded: Source encoding of shape [source_time, source_batch, dim] or
[source_batch, source_time, dim], depending on p.input_data_format.</p></li>
<li><p>paddings: Source encoding’s padding of shape
[source_time, source_batch] or [source_batch, source_time].</p></li>
</ul>
</p></li>
<li><p><strong>new_ids</strong> – A tensor of shape [target_batch, 1].</p></li>
<li><p><strong>states</strong> – <p>A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors representing states that the clients
would like to keep track of for each of the active hyps. prefix_states -
A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> representing the previous decoded states.</p>
<blockquote>
<div><ul>
<li><p>key: [target_time, target_batch, num_heads, dim_per_head].</p></li>
<li><p>value: [target_time, target_batch, num_heads, dim_per_head].</p></li>
<li><p>time_step: A scalar, the current decode step, 0-based.</p></li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>num_hyps_per_beam</strong> – A scalar, beam size.</p></li>
<li><p><strong>use_short_seq_opt</strong> – A bool, whether using short sequence optimization.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of beam search results.</dt><dd><dl class="simple">
<dt>log_probs - Log prob for each of the tokens in the target vocab,</dt><dd><p>of shape [target_batch, vocab_size].</p>
</dd>
<dt>atten_probs - The updated attention probs, of shape</dt><dd><p>[target_batch, source_time].</p>
</dd>
</dl>
</dd>
<dt>new_states: A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object. The updated states.</dt><dd><p>prefix_states - A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> representing the updated decoded states.
key   - [target_time, target_batch, num_heads, dim_per_head].
value - [target_time, target_batch, num_heads, dim_per_head].
time_step - A scalar, the current decode step, 0-based.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bs_results</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._PostBeamSearchStepCallback">
<span class="sig-name descname"><span class="pre">_PostBeamSearchStepCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_step_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">states</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerBatchMajorDecoder._PostBeamSearchStepCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerBatchMajorDecoder._PostBeamSearchStepCallback" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerXDecoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">lingvo.tasks.mt.decoder.</span></span><span class="sig-name descname"><span class="pre">TransformerXDecoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerXDecoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerXDecoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#lingvo.tasks.mt.decoder.TransformerDecoder" title="lingvo.tasks.mt.decoder.TransformerDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">lingvo.tasks.mt.decoder.TransformerDecoder</span></code></a></p>
<p>Transformer Decoder.</p>
<p>Mainly add a feature to calculate the KL loss with respect to another
prediction and support combining two input embeddings with their
interpolation vectors.</p>
<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerXDecoder.Params">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">Params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerXDecoder.Params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerXDecoder.Params" title="Permalink to this definition"></a></dt>
<dd><p>Returns the layer params.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerXDecoder._FProp">
<span class="sig-name descname"><span class="pre">_FProp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpolation_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerXDecoder._FProp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerXDecoder._FProp" title="Permalink to this definition"></a></dt>
<dd><p>Decodes <code class="xref py py-obj docutils literal notranslate"><span class="pre">targets</span></code> given encoded source.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – a NestedMap computed by encoder. Expected to contain:
encoded - source encoding. When <code class="xref py py-obj docutils literal notranslate"><span class="pre">p.is_transparent</span></code> is False, it is a
tensor of shape [time, batch, depth]. When <code class="xref py py-obj docutils literal notranslate"><span class="pre">p.is_transparent</span></code> is True,
it is a tensor of shape [time, batch, depth, num_trans_layers] if
<code class="xref py py-obj docutils literal notranslate"><span class="pre">self.do_eval</span></code> is True, and a list of <code class="xref py py-obj docutils literal notranslate"><span class="pre">num_trans_layers</span></code> tensors of
shape [time, batch, depth] if <code class="xref py py-obj docutils literal notranslate"><span class="pre">self.do_eval</span></code> is False.  padding - source
encoding’s padding, of shape [time, batch]. segment_id - source segment
id, of shape [time, batch].</p></li>
<li><p><strong>targets</strong> – A dict of string to tensors representing the targets one try to
predict. Each tensor in targets is of shape [batch, time].</p></li>
<li><p><strong>interpolation_batch</strong> – Same as targets of shape [batch, time, emb_dim]</p></li>
<li><p><strong>lambdas</strong> – A pair of float tensors to combine embeddings of two inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> containing output of last decoder layer and attention probs</p>
<ul class="simple">
<li><p>softmax_input: Tensor of shape [time, batch, params.softmax.input_dim].</p></li>
<li><p>attention: <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of attention distributions of shape
[batch, target_length, source_length].</p></li>
<li><p>source_embs: Tensor of shape [batch, time, emb_dim].</p></li>
<li><p>target_embs: Tensor of shape [batch, time, emb_dim].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerXDecoder.ComputePredictions">
<span class="sig-name descname"><span class="pre">ComputePredictions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpolation_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerXDecoder.ComputePredictions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerXDecoder.ComputePredictions" title="Permalink to this definition"></a></dt>
<dd><p>Decodes <code class="xref py py-obj docutils literal notranslate"><span class="pre">targets</span></code> given encoded source.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>encoder_outputs</strong> – a NestedMap computed by encoder. Expected to contain:
encoded - source encoding, of shape [time, batch, depth]. Can be [time,
batch, depth, num_layers] if is_transparent is set.  padding - source
encoding’s padding, of shape [time, batch]. segment_id - source segment
id, of shape [time, batch].</p></li>
<li><p><strong>targets</strong> – A dict of string to tensors representing the targets one try to
predict. Each tensor in targets is of shape [batch, time].</p></li>
<li><p><strong>interpolation_batch</strong> – Same as targets of shape [batch, time, emb_dim]</p></li>
<li><p><strong>lambdas</strong> – A pair of float tensors to combine embeddings of two inputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> containing output of last decoder layer and attention probs</p>
<ul class="simple">
<li><p>softmax_input: Tensor of shape [time, batch, params.softmax.input_dim].</p></li>
<li><p>attention: <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of attention distributions of shape
[batch, time, source_len].</p></li>
<li><p>source_embs: Tensor of shape [batch, time, emb_dim].</p></li>
<li><p>target_embs: Tensor of shape [batch, time, emb_dim].</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerXDecoder._FPropSoftmax">
<span class="sig-name descname"><span class="pre">_FPropSoftmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">softmax_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_paddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_segment_ids</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerXDecoder._FPropSoftmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerXDecoder._FPropSoftmax" title="Permalink to this definition"></a></dt>
<dd><p>Computes cross-entropy loss given the softmax input, labels and weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – A <a class="reference internal" href="lingvo.core.nested_map.html#lingvo.core.nested_map.NestedMap" title="lingvo.core.nested_map.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> object containing weights’ values of this layer and
its children layers.</p></li>
<li><p><strong>softmax_input</strong> – A tensor of shape [time, batch, p.softmax.input_dim].</p></li>
<li><p><strong>target_labels</strong> – A matrix of tf.int32. [time, batch].</p></li>
<li><p><strong>target_weights</strong> – A matrix of params.dtype. [time, batch].</p></li>
<li><p><strong>target_paddings</strong> – A matrix of params.dtype. [time, batch].</p></li>
<li><p><strong>target_segment_ids</strong> – A matrix of params.dtype. [time, batch].</p></li>
<li><p><strong>ref_probs</strong> – A tesnor of shape [batch, time, vocab_size]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple (metrics, per_example_tensors).</dt><dd><dl class="simple">
<dt>metrics:</dt><dd><p>A dictionary containing metrics for the xent loss and prediction
accuracy.</p>
</dd>
<dt>per_example_tensors:</dt><dd><p>A dictionary of per-example tensors.</p>
</dd>
</dl>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="lingvo.tasks.mt.decoder.TransformerXDecoder.ComputeLoss">
<span class="sig-name descname"><span class="pre">ComputeLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">theta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ref_probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/tasks/mt/decoder.html#TransformerXDecoder.ComputeLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#lingvo.tasks.mt.decoder.TransformerXDecoder.ComputeLoss" title="Permalink to this definition"></a></dt>
<dd><p>Populates a metrics dictionary based on the output of ComputePredictions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – Nested map describing decoder model parameters.</p></li>
<li><p><strong>predictions</strong> – NestedMap describing the decoding process, requiring:
.softmax_input: Tensor of shape [time, batch, params.softmax.input_dim].</p></li>
<li><p><strong>targets</strong> – NestedMap describing the target sequences.</p></li>
<li><p><strong>ref_probs</strong> – A tesnor of shape [batch, time, vocab_size]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>Two dicts.</p>
<blockquote>
<div><ul class="simple">
<li><p>A map from metric name (a python string) to a tuple (value, weight).
Both value and weight are scalar Tensors.</p></li>
<li><p>A map from name to arbitrary tensors, where the first dimension must
be the batch index.</p></li>
</ul>
</div></blockquote>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="lingvo.tasks.mt.data_augmenter.html" class="btn btn-neutral float-left" title="lingvo.tasks.mt.data_augmenter module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="lingvo.tasks.mt.encoder.html" class="btn btn-neutral float-right" title="lingvo.tasks.mt.encoder module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>